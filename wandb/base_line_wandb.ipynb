{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18bbe02e",
   "metadata": {},
   "source": [
    "# ğŸ“„ Document type classification baseline code with WandB Integration\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92dc69ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: albumentations==1.3.1 in /opt/conda/lib/python3.10/site-packages (from -r ../requirements.txt (line 1)) (1.3.1)\n",
      "Requirement already satisfied: ipykernel==6.27.1 in /opt/conda/lib/python3.10/site-packages (from -r ../requirements.txt (line 2)) (6.27.1)\n",
      "Requirement already satisfied: ipython==8.15.0 in /opt/conda/lib/python3.10/site-packages (from -r ../requirements.txt (line 3)) (8.15.0)\n",
      "Requirement already satisfied: ipywidgets==8.1.1 in /opt/conda/lib/python3.10/site-packages (from -r ../requirements.txt (line 4)) (8.1.1)\n",
      "Requirement already satisfied: jupyter==1.0.0 in /opt/conda/lib/python3.10/site-packages (from -r ../requirements.txt (line 5)) (1.0.0)\n",
      "Requirement already satisfied: matplotlib-inline==0.1.6 in /opt/conda/lib/python3.10/site-packages (from -r ../requirements.txt (line 6)) (0.1.6)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from -r ../requirements.txt (line 7)) (1.26.0)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from -r ../requirements.txt (line 8)) (2.1.4)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from -r ../requirements.txt (line 9)) (9.4.0)\n",
      "Requirement already satisfied: seaborn in /opt/conda/lib/python3.10/site-packages (from -r ../requirements.txt (line 10)) (0.13.2)\n",
      "Requirement already satisfied: timm==0.9.12 in /opt/conda/lib/python3.10/site-packages (from -r ../requirements.txt (line 11)) (0.9.12)\n",
      "Requirement already satisfied: plotly in /opt/conda/lib/python3.10/site-packages (from -r ../requirements.txt (line 12)) (6.3.0)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from -r ../requirements.txt (line 13)) (3.10.6)\n",
      "Requirement already satisfied: optuna in /opt/conda/lib/python3.10/site-packages (from -r ../requirements.txt (line 14)) (4.5.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from albumentations==1.3.1->-r ../requirements.txt (line 1)) (1.11.4)\n",
      "Requirement already satisfied: scikit-image>=0.16.1 in /opt/conda/lib/python3.10/site-packages (from albumentations==1.3.1->-r ../requirements.txt (line 1)) (0.22.0)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from albumentations==1.3.1->-r ../requirements.txt (line 1)) (6.0.2)\n",
      "Requirement already satisfied: qudida>=0.0.4 in /opt/conda/lib/python3.10/site-packages (from albumentations==1.3.1->-r ../requirements.txt (line 1)) (0.0.4)\n",
      "Requirement already satisfied: opencv-python-headless>=4.1.1 in /opt/conda/lib/python3.10/site-packages (from albumentations==1.3.1->-r ../requirements.txt (line 1)) (4.8.1.78)\n",
      "Requirement already satisfied: comm>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from ipykernel==6.27.1->-r ../requirements.txt (line 2)) (0.2.0)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /opt/conda/lib/python3.10/site-packages (from ipykernel==6.27.1->-r ../requirements.txt (line 2)) (1.8.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /opt/conda/lib/python3.10/site-packages (from ipykernel==6.27.1->-r ../requirements.txt (line 2)) (8.6.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /opt/conda/lib/python3.10/site-packages (from ipykernel==6.27.1->-r ../requirements.txt (line 2)) (5.5.0)\n",
      "Requirement already satisfied: nest-asyncio in /opt/conda/lib/python3.10/site-packages (from ipykernel==6.27.1->-r ../requirements.txt (line 2)) (1.5.8)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from ipykernel==6.27.1->-r ../requirements.txt (line 2)) (23.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from ipykernel==6.27.1->-r ../requirements.txt (line 2)) (5.9.0)\n",
      "Requirement already satisfied: pyzmq>=20 in /opt/conda/lib/python3.10/site-packages (from ipykernel==6.27.1->-r ../requirements.txt (line 2)) (25.1.2)\n",
      "Requirement already satisfied: tornado>=6.1 in /opt/conda/lib/python3.10/site-packages (from ipykernel==6.27.1->-r ../requirements.txt (line 2)) (6.4)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in /opt/conda/lib/python3.10/site-packages (from ipykernel==6.27.1->-r ../requirements.txt (line 2)) (5.7.1)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.10/site-packages (from ipython==8.15.0->-r ../requirements.txt (line 3)) (0.2.0)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.10/site-packages (from ipython==8.15.0->-r ../requirements.txt (line 3)) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.10/site-packages (from ipython==8.15.0->-r ../requirements.txt (line 3)) (0.18.1)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.10/site-packages (from ipython==8.15.0->-r ../requirements.txt (line 3)) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /opt/conda/lib/python3.10/site-packages (from ipython==8.15.0->-r ../requirements.txt (line 3)) (3.0.36)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.10/site-packages (from ipython==8.15.0->-r ../requirements.txt (line 3)) (2.15.1)\n",
      "Requirement already satisfied: stack-data in /opt/conda/lib/python3.10/site-packages (from ipython==8.15.0->-r ../requirements.txt (line 3)) (0.2.0)\n",
      "Requirement already satisfied: exceptiongroup in /opt/conda/lib/python3.10/site-packages (from ipython==8.15.0->-r ../requirements.txt (line 3)) (1.0.4)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.10/site-packages (from ipython==8.15.0->-r ../requirements.txt (line 3)) (4.8.0)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.9 in /opt/conda/lib/python3.10/site-packages (from ipywidgets==8.1.1->-r ../requirements.txt (line 4)) (4.0.9)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.9 in /opt/conda/lib/python3.10/site-packages (from ipywidgets==8.1.1->-r ../requirements.txt (line 4)) (3.0.9)\n",
      "Requirement already satisfied: notebook in /opt/conda/lib/python3.10/site-packages (from jupyter==1.0.0->-r ../requirements.txt (line 5)) (7.0.6)\n",
      "Requirement already satisfied: qtconsole in /opt/conda/lib/python3.10/site-packages (from jupyter==1.0.0->-r ../requirements.txt (line 5)) (5.5.1)\n",
      "Requirement already satisfied: jupyter-console in /opt/conda/lib/python3.10/site-packages (from jupyter==1.0.0->-r ../requirements.txt (line 5)) (6.6.3)\n",
      "Requirement already satisfied: nbconvert in /opt/conda/lib/python3.10/site-packages (from jupyter==1.0.0->-r ../requirements.txt (line 5)) (7.12.0)\n",
      "Requirement already satisfied: torch>=1.7 in /opt/conda/lib/python3.10/site-packages (from timm==0.9.12->-r ../requirements.txt (line 11)) (2.1.0)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from timm==0.9.12->-r ../requirements.txt (line 11)) (0.16.0)\n",
      "Requirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from timm==0.9.12->-r ../requirements.txt (line 11)) (0.19.4)\n",
      "Requirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from timm==0.9.12->-r ../requirements.txt (line 11)) (0.4.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->-r ../requirements.txt (line 8)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->-r ../requirements.txt (line 8)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->-r ../requirements.txt (line 8)) (2023.3)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in /opt/conda/lib/python3.10/site-packages (from plotly->-r ../requirements.txt (line 12)) (2.3.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->-r ../requirements.txt (line 13)) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->-r ../requirements.txt (line 13)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->-r ../requirements.txt (line 13)) (4.59.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->-r ../requirements.txt (line 13)) (1.4.9)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->-r ../requirements.txt (line 13)) (3.2.3)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /opt/conda/lib/python3.10/site-packages (from optuna->-r ../requirements.txt (line 14)) (1.16.5)\n",
      "Requirement already satisfied: colorlog in /opt/conda/lib/python3.10/site-packages (from optuna->-r ../requirements.txt (line 14)) (6.9.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in /opt/conda/lib/python3.10/site-packages (from optuna->-r ../requirements.txt (line 14)) (2.0.43)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from optuna->-r ../requirements.txt (line 14)) (4.65.0)\n",
      "Requirement already satisfied: Mako in /opt/conda/lib/python3.10/site-packages (from alembic>=1.5.0->optuna->-r ../requirements.txt (line 14)) (1.3.10)\n",
      "Requirement already satisfied: typing-extensions>=4.12 in /opt/conda/lib/python3.10/site-packages (from alembic>=1.5.0->optuna->-r ../requirements.txt (line 14)) (4.15.0)\n",
      "Requirement already satisfied: tomli in /opt/conda/lib/python3.10/site-packages (from alembic>=1.5.0->optuna->-r ../requirements.txt (line 14)) (2.0.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from jedi>=0.16->ipython==8.15.0->-r ../requirements.txt (line 3)) (0.8.3)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /opt/conda/lib/python3.10/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel==6.27.1->-r ../requirements.txt (line 2)) (4.1.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.10/site-packages (from pexpect>4.3->ipython==8.15.0->-r ../requirements.txt (line 3)) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython==8.15.0->-r ../requirements.txt (line 3)) (0.2.5)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->-r ../requirements.txt (line 8)) (1.10.0)\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in /opt/conda/lib/python3.10/site-packages (from qudida>=0.0.4->albumentations==1.3.1->-r ../requirements.txt (line 1)) (1.3.2)\n",
      "Requirement already satisfied: networkx>=2.8 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.16.1->albumentations==1.3.1->-r ../requirements.txt (line 1)) (3.1)\n",
      "Requirement already satisfied: imageio>=2.27 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.16.1->albumentations==1.3.1->-r ../requirements.txt (line 1)) (2.33.1)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.16.1->albumentations==1.3.1->-r ../requirements.txt (line 1)) (2023.12.9)\n",
      "Requirement already satisfied: lazy_loader>=0.3 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.16.1->albumentations==1.3.1->-r ../requirements.txt (line 1)) (0.3)\n",
      "Requirement already satisfied: greenlet>=1 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy>=1.4.2->optuna->-r ../requirements.txt (line 14)) (3.2.4)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->timm==0.9.12->-r ../requirements.txt (line 11)) (3.9.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->timm==0.9.12->-r ../requirements.txt (line 11)) (1.11.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->timm==0.9.12->-r ../requirements.txt (line 11)) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->timm==0.9.12->-r ../requirements.txt (line 11)) (2023.9.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->timm==0.9.12->-r ../requirements.txt (line 11)) (2.31.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from nbconvert->jupyter==1.0.0->-r ../requirements.txt (line 5)) (4.12.2)\n",
      "Requirement already satisfied: bleach!=5.0.0 in /opt/conda/lib/python3.10/site-packages (from nbconvert->jupyter==1.0.0->-r ../requirements.txt (line 5)) (6.1.0)\n",
      "Requirement already satisfied: defusedxml in /opt/conda/lib/python3.10/site-packages (from nbconvert->jupyter==1.0.0->-r ../requirements.txt (line 5)) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in /opt/conda/lib/python3.10/site-packages (from nbconvert->jupyter==1.0.0->-r ../requirements.txt (line 5)) (0.3.0)\n",
      "Requirement already satisfied: markupsafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from nbconvert->jupyter==1.0.0->-r ../requirements.txt (line 5)) (3.0.2)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in /opt/conda/lib/python3.10/site-packages (from nbconvert->jupyter==1.0.0->-r ../requirements.txt (line 5)) (3.0.2)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /opt/conda/lib/python3.10/site-packages (from nbconvert->jupyter==1.0.0->-r ../requirements.txt (line 5)) (0.9.0)\n",
      "Requirement already satisfied: nbformat>=5.7 in /opt/conda/lib/python3.10/site-packages (from nbconvert->jupyter==1.0.0->-r ../requirements.txt (line 5)) (5.9.2)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/lib/python3.10/site-packages (from nbconvert->jupyter==1.0.0->-r ../requirements.txt (line 5)) (1.5.0)\n",
      "Requirement already satisfied: tinycss2 in /opt/conda/lib/python3.10/site-packages (from nbconvert->jupyter==1.0.0->-r ../requirements.txt (line 5)) (1.2.1)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in /opt/conda/lib/python3.10/site-packages (from notebook->jupyter==1.0.0->-r ../requirements.txt (line 5)) (2.12.1)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.22.1 in /opt/conda/lib/python3.10/site-packages (from notebook->jupyter==1.0.0->-r ../requirements.txt (line 5)) (2.25.2)\n",
      "Requirement already satisfied: jupyterlab<5,>=4.0.2 in /opt/conda/lib/python3.10/site-packages (from notebook->jupyter==1.0.0->-r ../requirements.txt (line 5)) (4.0.9)\n",
      "Requirement already satisfied: notebook-shim<0.3,>=0.2 in /opt/conda/lib/python3.10/site-packages (from notebook->jupyter==1.0.0->-r ../requirements.txt (line 5)) (0.2.3)\n",
      "Requirement already satisfied: qtpy>=2.4.0 in /opt/conda/lib/python3.10/site-packages (from qtconsole->jupyter==1.0.0->-r ../requirements.txt (line 5)) (2.4.1)\n",
      "Requirement already satisfied: executing in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython==8.15.0->-r ../requirements.txt (line 3)) (0.8.3)\n",
      "Requirement already satisfied: asttokens in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython==8.15.0->-r ../requirements.txt (line 3)) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython==8.15.0->-r ../requirements.txt (line 3)) (0.2.2)\n",
      "Requirement already satisfied: webencodings in /opt/conda/lib/python3.10/site-packages (from bleach!=5.0.0->nbconvert->jupyter==1.0.0->-r ../requirements.txt (line 5)) (0.5.1)\n",
      "Requirement already satisfied: anyio>=3.1.0 in /opt/conda/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->-r ../requirements.txt (line 5)) (4.1.0)\n",
      "Requirement already satisfied: argon2-cffi in /opt/conda/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->-r ../requirements.txt (line 5)) (23.1.0)\n",
      "Requirement already satisfied: jupyter-events>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->-r ../requirements.txt (line 5)) (0.9.0)\n",
      "Requirement already satisfied: jupyter-server-terminals in /opt/conda/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->-r ../requirements.txt (line 5)) (0.5.0)\n",
      "Requirement already satisfied: overrides in /opt/conda/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->-r ../requirements.txt (line 5)) (7.4.0)\n",
      "Requirement already satisfied: prometheus-client in /opt/conda/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->-r ../requirements.txt (line 5)) (0.19.0)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in /opt/conda/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->-r ../requirements.txt (line 5)) (1.8.2)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /opt/conda/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->-r ../requirements.txt (line 5)) (0.18.0)\n",
      "Requirement already satisfied: websocket-client in /opt/conda/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->-r ../requirements.txt (line 5)) (1.7.0)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from jupyterlab<5,>=4.0.2->notebook->jupyter==1.0.0->-r ../requirements.txt (line 5)) (2.0.4)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from jupyterlab<5,>=4.0.2->notebook->jupyter==1.0.0->-r ../requirements.txt (line 5)) (2.2.1)\n",
      "Requirement already satisfied: babel>=2.10 in /opt/conda/lib/python3.10/site-packages (from jupyterlab-server<3,>=2.22.1->notebook->jupyter==1.0.0->-r ../requirements.txt (line 5)) (2.17.0)\n",
      "Requirement already satisfied: json5>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from jupyterlab-server<3,>=2.22.1->notebook->jupyter==1.0.0->-r ../requirements.txt (line 5)) (0.9.14)\n",
      "Requirement already satisfied: jsonschema>=4.18.0 in /opt/conda/lib/python3.10/site-packages (from jupyterlab-server<3,>=2.22.1->notebook->jupyter==1.0.0->-r ../requirements.txt (line 5)) (4.20.0)\n",
      "Requirement already satisfied: fastjsonschema in /opt/conda/lib/python3.10/site-packages (from nbformat>=5.7->nbconvert->jupyter==1.0.0->-r ../requirements.txt (line 5)) (2.19.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->timm==0.9.12->-r ../requirements.txt (line 11)) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->timm==0.9.12->-r ../requirements.txt (line 11)) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->timm==0.9.12->-r ../requirements.txt (line 11)) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->timm==0.9.12->-r ../requirements.txt (line 11)) (2023.7.22)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations==1.3.1->-r ../requirements.txt (line 1)) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations==1.3.1->-r ../requirements.txt (line 1)) (3.2.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->nbconvert->jupyter==1.0.0->-r ../requirements.txt (line 5)) (2.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.7->timm==0.9.12->-r ../requirements.txt (line 11)) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->-r ../requirements.txt (line 5)) (1.3.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook->jupyter==1.0.0->-r ../requirements.txt (line 5)) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook->jupyter==1.0.0->-r ../requirements.txt (line 5)) (2023.11.2)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook->jupyter==1.0.0->-r ../requirements.txt (line 5)) (0.32.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook->jupyter==1.0.0->-r ../requirements.txt (line 5)) (0.13.2)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in /opt/conda/lib/python3.10/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->-r ../requirements.txt (line 5)) (2.0.7)\n",
      "Requirement already satisfied: rfc3339-validator in /opt/conda/lib/python3.10/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->-r ../requirements.txt (line 5)) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->-r ../requirements.txt (line 5)) (0.1.1)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /opt/conda/lib/python3.10/site-packages (from argon2-cffi->jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->-r ../requirements.txt (line 5)) (21.2.0)\n",
      "Requirement already satisfied: fqdn in /opt/conda/lib/python3.10/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook->jupyter==1.0.0->-r ../requirements.txt (line 5)) (1.5.1)\n",
      "Requirement already satisfied: isoduration in /opt/conda/lib/python3.10/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook->jupyter==1.0.0->-r ../requirements.txt (line 5)) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook->jupyter==1.0.0->-r ../requirements.txt (line 5)) (2.1)\n",
      "Requirement already satisfied: uri-template in /opt/conda/lib/python3.10/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook->jupyter==1.0.0->-r ../requirements.txt (line 5)) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=1.11 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook->jupyter==1.0.0->-r ../requirements.txt (line 5)) (1.13)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from argon2-cffi-bindings->argon2-cffi->jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->-r ../requirements.txt (line 5)) (1.15.1)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->-r ../requirements.txt (line 5)) (2.21)\n",
      "Requirement already satisfied: arrow>=0.15.0 in /opt/conda/lib/python3.10/site-packages (from isoduration->jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook->jupyter==1.0.0->-r ../requirements.txt (line 5)) (1.3.0)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in /opt/conda/lib/python3.10/site-packages (from arrow>=0.15.0->isoduration->jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook->jupyter==1.0.0->-r ../requirements.txt (line 5)) (2.8.19.14)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# 0. Prepare Environments & Install Libraries\n",
    "# =============================================================================\n",
    "\n",
    "# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤.\n",
    "!pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "773408ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 1. Import Libraries & Define Functions\n",
    "# =============================================================================\n",
    "\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import copy\n",
    "\n",
    "import optuna, math\n",
    "import timm\n",
    "import torch\n",
    "import albumentations as A\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.optim import Adam\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.cuda.amp import autocast, GradScaler  # Mixed Precisionìš©\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# WandB ê´€ë ¨ import ì¶”ê°€\n",
    "import wandb\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e142354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WandB ë¡œê·¸ì¸ ìƒíƒœ: kimsunmin0227\n",
      "í”„ë¡œì íŠ¸: document-classification-team\n",
      "ì‹¤í—˜ëª…: efficientnet-b3-baseline\n",
      "íŒ€ì›ë“¤ì€ EXPERIMENT_NAMEì„ ê°ì ë‹¤ë¥´ê²Œ ë³€ê²½í•´ì£¼ì„¸ìš”!\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 1-1. WandB Login and Configuration\n",
    "# =============================================================================\n",
    "\"\"\"\n",
    "ğŸš€ íŒ€ì› ì‚¬ìš© ê°€ì´ë“œ:\n",
    "\n",
    "1. WandB ê³„ì • ìƒì„±: https://wandb.ai/signup\n",
    "2. ì´ ì…€ ì‹¤í–‰ ì‹œ ë¡œê·¸ì¸ í”„ë¡¬í”„íŠ¸ê°€ ë‚˜íƒ€ë‚˜ë©´ ê°œì¸ API í‚¤ ì…ë ¥\n",
    "3. EXPERIMENT_NAMEì„ ë‹¤ìŒê³¼ ê°™ì´ ë³€ê²½:\n",
    "   - \"member1-baseline\"\n",
    "   - \"member2-augmentation-test\"  \n",
    "   - \"member3-hyperparameter-tuning\"\n",
    "   ë“±ë“± ê°ì ë‹¤ë¥¸ ì´ë¦„ ì‚¬ìš©\n",
    "\n",
    "4. íŒ€ ëŒ€ì‹œë³´ë“œ URL: [ì—¬ê¸°ì— ë‹¹ì‹ ì˜ í”„ë¡œì íŠ¸ URL ì¶”ê°€]\n",
    "\n",
    "âš ï¸ ì£¼ì˜ì‚¬í•­:\n",
    "- ì ˆëŒ€ API í‚¤ë¥¼ ì½”ë“œì— í•˜ë“œì½”ë”©í•˜ì§€ ë§ˆì„¸ìš”\n",
    "- EXPERIMENT_NAMEë§Œ ë³€ê²½í•˜ê³  PROJECT_NAMEì€ ê·¸ëŒ€ë¡œ ë‘ì„¸ìš”\n",
    "- ê°ì ê°œì¸ ê³„ì •ìœ¼ë¡œ ë¡œê·¸ì¸í•´ì„œ ì‹¤í—˜ì„ ì¶”ê°€í•˜ì„¸ìš”\n",
    "\"\"\"\n",
    "\n",
    "# WandB ë¡œê·¸ì¸ (ê°ì ì‹¤í–‰)\n",
    "try:\n",
    "    if wandb.api.api_key is None:\n",
    "        print(\"WandBì— ë¡œê·¸ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤.\")\n",
    "        wandb.login()\n",
    "    else:\n",
    "        print(f\"WandB ë¡œê·¸ì¸ ìƒíƒœ: {wandb.api.viewer()['username']}\")\n",
    "except:\n",
    "    print(\"WandB ë¡œê·¸ì¸ì„ ì§„í–‰í•©ë‹ˆë‹¤...\")\n",
    "    wandb.login()\n",
    "\n",
    "# í”„ë¡œì íŠ¸ ì„¤ì • (ê°ì ìˆ˜ì •í•  ë¶€ë¶„)\n",
    "PROJECT_NAME = \"document-classification-team\"  # ëª¨ë“  íŒ€ì› ë™ì¼\n",
    "ENTITY = None  # ê°ì ê°œì¸ ê³„ì • ì‚¬ìš©\n",
    "EXPERIMENT_NAME = \"efficientnet-b3-baseline\"  # íŒ€ì›ë³„ë¡œ ë³€ê²½ (ì˜ˆ: \"member1-hyperopt\", \"member2-augmentation\")\n",
    "\n",
    "print(f\"í”„ë¡œì íŠ¸: {PROJECT_NAME}\")\n",
    "print(f\"ì‹¤í—˜ëª…: {EXPERIMENT_NAME}\")\n",
    "print(\"íŒ€ì›ë“¤ì€ EXPERIMENT_NAMEì„ ê°ì ë‹¤ë¥´ê²Œ ë³€ê²½í•´ì£¼ì„¸ìš”!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "448a2f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 3. Seed & basic augmentations (Mixup)\n",
    "# =============================================================================\n",
    "\n",
    "# ì‹œë“œë¥¼ ê³ ì •í•©ë‹ˆë‹¤.\n",
    "SEED = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.benchmark = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f9d1a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# 4. Dataset Class\n",
    "# =============================================================================\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, data, path, transform=None):\n",
    "        # CSV íŒŒì¼ì´ë©´ ì½ê³ , DataFrameì´ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©\n",
    "        if isinstance(data, str):\n",
    "            self.df = pd.read_csv(data).values\n",
    "        else:\n",
    "            self.df = data.values  # DataFrameì„ numpy arrayë¡œ ë³€í™˜\n",
    "        self.path = path\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        name, target = self.df[idx]\n",
    "        img = np.array(Image.open(os.path.join(self.path, name)))\n",
    "        if self.transform:\n",
    "            img = self.transform(image=img)['image']\n",
    "        return img, target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0cacecd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import wandb\n",
    "\n",
    "# Cutout (Random Erasing) í•¨ìˆ˜ ì •ì˜\n",
    "def random_erasing(image, p=0.5, scale=(0.02, 0.33), ratio=(0.3, 3.3)):\n",
    "    if random.random() > p:\n",
    "        return image\n",
    "    img_c, img_h, img_w = image.shape[1], image.shape[2], image.shape[3]\n",
    "    area = img_h * img_w\n",
    "    \n",
    "    target_area = random.uniform(scale[0], scale[1]) * area\n",
    "    aspect_ratio = random.uniform(ratio[0], ratio[1])\n",
    "    h = int(round(math.sqrt(target_area * aspect_ratio)))\n",
    "    w = int(round(math.sqrt(target_area / aspect_ratio)))\n",
    "    \n",
    "    if h < img_h and w < img_w:\n",
    "        x = random.randint(0, img_w - w)\n",
    "        y = random.randint(0, img_h - h)\n",
    "        image[:, :, y:y+h, x:x+w] = 0.0  # ì œê±°ëœ ì˜ì—­ì„ 0ìœ¼ë¡œ ì„¤ì •\n",
    "    return image\n",
    "\n",
    "# RandomCrop í•¨ìˆ˜ ì •ì˜\n",
    "def random_crop(image, crop_size=0.8):\n",
    "    img_c, img_h, img_w = image.shape[1], image.shape[2], image.shape[3]\n",
    "    crop_h = int(img_h * crop_size)\n",
    "    crop_w = int(img_w * crop_size)\n",
    "    \n",
    "    if crop_h >= img_h or crop_w >= img_w:\n",
    "        return image\n",
    "    \n",
    "    x = random.randint(0, img_w - crop_w)\n",
    "    y = random.randint(0, img_h - crop_h)\n",
    "    cropped_image = image[:, :, y:y+crop_h, x:x+crop_w]\n",
    "    \n",
    "    # ì›ë˜ ì´ë¯¸ì§€ í¬ê¸°ë¡œ ë³µì› (íŒ¨ë”© ë˜ëŠ” ë¦¬ì‚¬ì´ì¦ˆ)\n",
    "    cropped_image = torch.nn.functional.interpolate(cropped_image, size=(img_h, img_w), mode='bilinear', align_corners=False)\n",
    "    return cropped_image\n",
    "\n",
    "# Mixup í•¨ìˆ˜ ì •ì˜\n",
    "def mixup_data(x, y, alpha=1.0):\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "    batch_size = x.size()[0]\n",
    "    index = torch.randperm(batch_size).cuda()\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "def train_one_epoch(loader, model, optimizer, loss_fn, device, epoch=None, fold=None):\n",
    "    scaler = GradScaler()\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    preds_list = []\n",
    "    targets_list = []\n",
    "\n",
    "    pbar = tqdm(loader, desc=f\"Training Epoch {epoch+1 if epoch else '?'}\")\n",
    "    batch_count = 0\n",
    "    \n",
    "    for image, targets in pbar:\n",
    "        image = image.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        # ì¦ê°• ê¸°ë²• ì„ íƒ (Mixup 25%, Cutout 25%, RandomCrop 25%, None 25%) -> (Mixup 25%, Cutout 25%, RandomCrop 50%)\n",
    "        aug_type = random.choices(['mixup', 'cutout', 'random_crop'], weights=[0.25, 0.25, 0.5])[0]\n",
    "        mixup_applied = False\n",
    "        cutout_applied = False\n",
    "        random_crop_applied = False\n",
    "        \n",
    "        if aug_type == 'mixup':\n",
    "            mixed_x, y_a, y_b, lam = mixup_data(image, targets, alpha=1.0)\n",
    "            with autocast(): \n",
    "                preds = model(mixed_x)\n",
    "            loss = lam * loss_fn(preds, y_a) + (1 - lam) * loss_fn(preds, y_b)\n",
    "            mixup_applied = True\n",
    "        elif aug_type == 'cutout':\n",
    "            image = random_erasing(image, p=0.5, scale=(0.02, 0.33), ratio=(0.3, 3.3))\n",
    "            with autocast(): \n",
    "                preds = model(image)\n",
    "            loss = loss_fn(preds, targets)\n",
    "            cutout_applied = True\n",
    "        elif aug_type == 'random_crop':\n",
    "            image = random_crop(image, crop_size=0.8)\n",
    "            with autocast(): \n",
    "                preds = model(image)\n",
    "            loss = loss_fn(preds, targets)\n",
    "            random_crop_applied = True\n",
    "        else:\n",
    "            with autocast(): \n",
    "                preds = model(image)\n",
    "            loss = loss_fn(preds, targets)\n",
    "\n",
    "        model.zero_grad(set_to_none=True)\n",
    "        scaler.scale(loss).backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
    "        targets_list.extend(targets.detach().cpu().numpy())\n",
    "\n",
    "        # ë°°ì¹˜ë³„ ìƒì„¸ ë¡œê¹… (100 ë°°ì¹˜ë§ˆë‹¤)\n",
    "        if batch_count % 100 == 0 and wandb.run is not None:\n",
    "            step = epoch * len(loader) + batch_count if epoch is not None else batch_count\n",
    "            wandb.log({\n",
    "                f\"fold_{fold}/train_batch_loss\": loss.item(),\n",
    "                f\"fold_{fold}/mixup_applied\": int(mixup_applied),\n",
    "                f\"fold_{fold}/cutout_applied\": int(cutout_applied),\n",
    "                f\"fold_{fold}/random_crop_applied\": int(random_crop_applied),\n",
    "                f\"fold_{fold}/batch_step\": step\n",
    "            })\n",
    "        \n",
    "        batch_count += 1\n",
    "        pbar.set_description(f\"Loss: {loss.item():.4f}, Mixup: {mixup_applied}, Cutout: {cutout_applied}, RandomCrop: {random_crop_applied}\")\n",
    "\n",
    "    train_loss /= len(loader)\n",
    "    train_acc = accuracy_score(targets_list, preds_list)\n",
    "    train_f1 = f1_score(targets_list, preds_list, average='macro')\n",
    "\n",
    "    ret = {\n",
    "        \"train_loss\": train_loss,\n",
    "        \"train_acc\": train_acc,\n",
    "        \"train_f1\": train_f1,\n",
    "    }\n",
    "\n",
    "    return ret\n",
    "\n",
    "def validate_one_epoch(loader, model, loss_fn, device, epoch=None, fold=None, log_confusion=False):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    preds_list = []\n",
    "    targets_list = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(loader, desc=f\"Validating Epoch {epoch+1 if epoch else '?'}\")\n",
    "        for image, targets in pbar:\n",
    "            image = image.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            preds = model(image)\n",
    "            loss = loss_fn(preds, targets)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
    "            targets_list.extend(targets.detach().cpu().numpy())\n",
    "            \n",
    "            pbar.set_description(f\"Val Loss: {loss.item():.4f}\")\n",
    "    \n",
    "    val_loss /= len(loader)\n",
    "    val_acc = accuracy_score(targets_list, preds_list)\n",
    "    val_f1 = f1_score(targets_list, preds_list, average='macro')\n",
    "    \n",
    "    # Confusion Matrix ë¡œê¹… (ë§ˆì§€ë§‰ epochì—ë§Œ)\n",
    "    if log_confusion and wandb.run is not None:\n",
    "        try:\n",
    "            wandb.log({\n",
    "                f\"fold_{fold}/confusion_matrix\": wandb.plot.confusion_matrix(\n",
    "                    probs=None,\n",
    "                    y_true=targets_list,\n",
    "                    preds=preds_list,\n",
    "                    class_names=[f\"Class_{i}\" for i in range(17)]\n",
    "                )\n",
    "            })\n",
    "            \n",
    "            # í´ë˜ìŠ¤ë³„ F1 ìŠ¤ì½”ì–´\n",
    "            class_f1_scores = f1_score(targets_list, preds_list, average=None)\n",
    "            for i, class_f1 in enumerate(class_f1_scores):\n",
    "                wandb.log({f\"fold_{fold}/class_{i}_f1\": class_f1})\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\" Confusion matrix ë¡œê¹… ì‹¤íŒ¨: {e}\")\n",
    "    \n",
    "    ret = {\n",
    "        \"val_loss\": val_loss,\n",
    "        \"val_acc\": val_acc,  \n",
    "        \"val_f1\": val_f1,\n",
    "    }\n",
    "    \n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "193dae06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Using device: cuda\n",
      " í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì • ì™„ë£Œ!\n",
      " ëª¨ë¸: efficientnet_b3\n",
      " ì´ë¯¸ì§€ í¬ê¸°: 384x384\n",
      " ë°°ì¹˜ í¬ê¸°: 32\n",
      " í•™ìŠµë¥ : 0.0005\n",
      " ì—í­: 50\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 6. Hyper-parameters with WandB Config\n",
    "# =============================================================================\n",
    "\n",
    "# device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\" Using device: {device}\")\n",
    "\n",
    "# data config\n",
    "data_path = '../data/'\n",
    "\n",
    "# model config\n",
    "model_name = 'efficientnet_b3' # 'resnet50' 'efficientnet-b0', ...\n",
    "\n",
    "# training config\n",
    "img_size = 384\n",
    "LR = 5e-4\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 32\n",
    "num_workers = 30\n",
    "\n",
    "# K-Fold config\n",
    "N_FOLDS = 5  # 5-foldë¡œ ì„¤ì •\n",
    "\n",
    "# WandB Config ì„¤ì •\n",
    "config = {\n",
    "    # Model config\n",
    "    \"model_name\": model_name,\n",
    "    \"img_size\": img_size,\n",
    "    \"num_classes\": 17,\n",
    "    \"architecture\": \"EfficientNet-B3\",\n",
    "    \n",
    "    # Training config  \n",
    "    \"lr\": LR,\n",
    "    \"epochs\": EPOCHS,\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"num_workers\": num_workers,\n",
    "    \"device\": str(device),\n",
    "    \n",
    "    # K-Fold config\n",
    "    \"n_folds\": N_FOLDS,\n",
    "    \"seed\": SEED,\n",
    "    \"cv_strategy\": \"StratifiedKFold\",\n",
    "    \n",
    "    # Augmentation & Training techniques\n",
    "    \"mixup_alpha\": 1.0,\n",
    "    \"mixup_prob\": 0.3,\n",
    "    \"label_smoothing\": 0.2,\n",
    "    \"gradient_clipping\": 1.0,\n",
    "    \"mixed_precision\": True,\n",
    "    \n",
    "    # Optimizer & Scheduler\n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"scheduler\": \"CosineAnnealingLR\",\n",
    "    \n",
    "    # Data\n",
    "    \"data_path\": data_path,\n",
    "    \"train_transforms\": \"Advanced\",\n",
    "    \"test_transforms\": \"Basic\",\n",
    "}\n",
    "\n",
    "print(\" í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì • ì™„ë£Œ!\")\n",
    "print(f\" ëª¨ë¸: {model_name}\")\n",
    "print(f\" ì´ë¯¸ì§€ í¬ê¸°: {img_size}x{img_size}\")\n",
    "print(f\" ë°°ì¹˜ í¬ê¸°: {BATCH_SIZE}\")\n",
    "print(f\" í•™ìŠµë¥ : {LR}\")\n",
    "print(f\" ì—í­: {EPOCHS}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a4e28f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â­ï¸ Optuna íŠœë‹ ê±´ë„ˆë›°ê¸° (USE_OPTUNA=False)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# 7. Optuna Hyperparameter Tuning (ì„ íƒì )\n",
    "# =============================================================================\n",
    "\n",
    "USE_OPTUNA = False  # Trueë¡œ ë°”ê¾¸ë©´ íŠœë‹ ì‹¤í–‰\n",
    "\n",
    "if USE_OPTUNA:\n",
    "    print(\"ğŸ” Optuna í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ì‹œì‘...\")\n",
    "    \n",
    "    def objective(trial):\n",
    "        lr = trial.suggest_loguniform('lr', 1e-5, 1e-2)\n",
    "        batch_size = trial.suggest_categorical('batch_size', [32, 64, 128])\n",
    "        \n",
    "        # WandBì— Optuna ì‹œí–‰ ë¡œê¹…\n",
    "        optuna_run = wandb.init(\n",
    "            project=PROJECT_NAME,\n",
    "            entity=ENTITY,\n",
    "            name=f\"optuna-trial-{trial.number}\",\n",
    "            config={**config, \"lr\": lr, \"batch_size\": batch_size},\n",
    "            tags=[\"optuna\", \"hyperparameter-tuning\"],\n",
    "            group=\"optuna-study\",\n",
    "            job_type=\"hyperparameter-optimization\",\n",
    "            reinit=True\n",
    "        )\n",
    "        \n",
    "        # ê°„ë‹¨í•œ 3-fold CVë¡œ ë¹ ë¥¸ í‰ê°€\n",
    "        skf_simple = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "        fold_scores = []\n",
    "        \n",
    "        # ê°„ë‹¨í•œ í‰ê°€ ë¡œì§ (ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ë” ë‹¨ìˆœí™”)\n",
    "        # ... (Optuna ë¡œì§ì€ ë³µì¡í•˜ë¯€ë¡œ ê¸°ë³¸ì ìœ¼ë¡œ ë¹„í™œì„±í™”)\n",
    "        \n",
    "        optuna_run.finish()\n",
    "        return np.random.random()  # placeholder\n",
    "    \n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=10)\n",
    "    \n",
    "    # ìµœì  íŒŒë¼ë¯¸í„° ì ìš©\n",
    "    best_params = study.best_params\n",
    "    LR = best_params.get('lr', LR)\n",
    "    BATCH_SIZE = best_params.get('batch_size', BATCH_SIZE)\n",
    "    config.update(best_params)\n",
    "    print(f\"ğŸ¯ Optuna ìµœì  íŒŒë¼ë¯¸í„°: {best_params}\")\n",
    "else:\n",
    "    print(\"â­ï¸ Optuna íŠœë‹ ê±´ë„ˆë›°ê¸° (USE_OPTUNA=False)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6514acaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ë°ì´í„° ë³€í™˜ ì„¤ì • ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 8. Data Transforms\n",
    "# =============================================================================\n",
    "\n",
    "# augmentationì„ ìœ„í•œ transform ì½”ë“œ\n",
    "trn_transform = A.Compose([\n",
    "    # ë¹„ìœ¨ ë³´ì¡´ ë¦¬ì‚¬ì´ì§• (í•µì‹¬ ê°œì„ )\n",
    "    A.LongestMaxSize(max_size=img_size),\n",
    "    A.PadIfNeeded(min_height=img_size, min_width=img_size, \n",
    "                  border_mode=0, value=0),\n",
    "    \n",
    "    # ë¬¸ì„œ íŠ¹í™” íšŒì „ + ë¯¸ì„¸ íšŒì „ ì¶”ê°€\n",
    "    A.OneOf([\n",
    "        A.Rotate(limit=[90,90], p=1.0),\n",
    "        A.Rotate(limit=[180,180], p=1.0),\n",
    "        A.Rotate(limit=[270,270], p=1.0),\n",
    "        A.Rotate(limit=(-15, 15), p=1.0),  # ë¯¸ì„¸ íšŒì „ ì¶”ê°€\n",
    "    ], p=0.7),\n",
    "    \n",
    "    # ê¸°í•˜í•™ì  ë³€í™˜ ê°•í™”\n",
    "    A.OneOf([\n",
    "        A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.2, rotate_limit=5, p=1.0),\n",
    "        A.ElasticTransform(alpha=50, sigma=5, p=1.0),\n",
    "        A.GridDistortion(num_steps=5, distort_limit=0.2, p=1.0),\n",
    "        A.OpticalDistortion(distort_limit=0.2, shift_limit=0.1, p=1.0),\n",
    "    ], p=0.6),\n",
    "    \n",
    "    # ìƒ‰ìƒ ë° ì¡°ëª… ë³€í™˜ ê°•í™”\n",
    "    A.OneOf([\n",
    "        A.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.3, hue=0.1, p=1.0),\n",
    "        A.RandomBrightnessContrast(brightness_limit=0.4, contrast_limit=0.4, p=1.0),\n",
    "        A.CLAHE(clip_limit=4.0, tile_grid_size=(8, 8), p=1.0),\n",
    "        A.RandomGamma(gamma_limit=(70, 130), p=1.0),\n",
    "    ], p=0.9),\n",
    "    \n",
    "    # ë¸”ëŸ¬ ë° ë…¸ì´ì¦ˆ ê°•í™”\n",
    "    A.OneOf([\n",
    "        A.MotionBlur(blur_limit=(5, 15), p=1.0),\n",
    "        A.GaussianBlur(blur_limit=(3, 15), p=1.0),\n",
    "        A.MedianBlur(blur_limit=7, p=1.0),\n",
    "        A.Blur(blur_limit=7, p=1.0),\n",
    "    ], p=0.8),\n",
    "    \n",
    "    # ë‹¤ì–‘í•œ ë…¸ì´ì¦ˆ ì¶”ê°€\n",
    "    A.OneOf([\n",
    "        A.GaussNoise(var_limit=(10.0, 150.0), p=1.0),\n",
    "        A.ISONoise(color_shift=(0.01, 0.08), intensity=(0.1, 0.8), p=1.0),\n",
    "        A.MultiplicativeNoise(multiplier=(0.9, 1.1), p=1.0),\n",
    "    ], p=0.8),\n",
    "    \n",
    "    # ë¬¸ì„œ í’ˆì§ˆ ì‹œë®¬ë ˆì´ì…˜ (ìŠ¤ìº”/ë³µì‚¬ íš¨ê³¼)\n",
    "    A.OneOf([\n",
    "        A.Downscale(scale_min=0.7, scale_max=0.9, p=1.0),\n",
    "        A.ImageCompression(quality_lower=60, quality_upper=95, p=1.0),\n",
    "        A.Posterize(num_bits=6, p=1.0),\n",
    "    ], p=0.5),\n",
    "    \n",
    "    # í”½ì…€ ë ˆë²¨ ë³€í™˜\n",
    "    A.OneOf([\n",
    "        A.ChannelShuffle(p=1.0),\n",
    "        A.InvertImg(p=1.0),\n",
    "        A.Solarize(threshold=128, p=1.0),\n",
    "        A.Equalize(p=1.0),\n",
    "    ], p=0.3),\n",
    "    \n",
    "    # ê³µê°„ ë³€í™˜\n",
    "    A.OneOf([\n",
    "        A.HorizontalFlip(p=1.0),\n",
    "        A.VerticalFlip(p=1.0),  # ë¬¸ì„œì—ì„œë„ ìœ ìš©í•  ìˆ˜ ìˆìŒ\n",
    "        A.Transpose(p=1.0),\n",
    "    ], p=0.6),\n",
    "    \n",
    "    # ì¡°ê° ì œê±° (Cutout ê³„ì—´)\n",
    "    A.OneOf([\n",
    "        A.CoarseDropout(max_holes=8, max_height=32, max_width=32, \n",
    "                       min_holes=1, min_height=8, min_width=8, \n",
    "                       fill_value=0, p=1.0),\n",
    "        A.GridDropout(ratio=0.3, unit_size_min=8, unit_size_max=32, \n",
    "                     holes_number_x=5, holes_number_y=5, p=1.0),\n",
    "    ], p=0.4),\n",
    "    \n",
    "    # ìµœì¢… ì •ê·œí™”\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "# test image ë³€í™˜ì„ ìœ„í•œ transform ì½”ë“œ\n",
    "tst_transform = A.Compose([\n",
    "    A.LongestMaxSize(max_size=img_size),\n",
    "    A.PadIfNeeded(min_height=img_size, min_width=img_size, \n",
    "                  border_mode=0, value=0),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "print(\"âœ… ë°ì´í„° ë³€í™˜ ì„¤ì • ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c320bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í•™ìŠµ ë°ì´í„°: 1570ê°œ ìƒ˜í”Œ\n",
      " í´ë˜ìŠ¤ ë¶„í¬: {0: 100, 1: 46, 2: 100, 3: 100, 4: 100, 5: 100, 6: 100, 7: 100, 8: 100, 9: 100, 10: 100, 11: 100, 12: 100, 13: 74, 14: 50, 15: 100, 16: 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkimsunmin0227\u001b[0m (\u001b[33mkimsunmin0227-hufs\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "creating run (0.2s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/ephemeral/home/computervisioncompetition-cv-1/wandb/wandb/run-20250904_134143-mdvqqydn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/mdvqqydn' target=\"_blank\">efficientnet-b3-baseline-0904-1341</a></strong> to <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/mdvqqydn' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/mdvqqydn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ WandB ì‹¤í—˜ ì‹œì‘!\n",
      "ğŸ“Š ëŒ€ì‹œë³´ë“œ: https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/mdvqqydn\n",
      "ğŸ“‹ ì‹¤í—˜ëª…: efficientnet-b3-baseline-0904-1341\n",
      "\n",
      "============================================================\n",
      "ğŸ¯ 5-FOLD CROSS VALIDATION ì‹œì‘\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 9. Load Data & Start K-Fold Cross Validation with WandB\n",
    "# =============================================================================\n",
    "\n",
    "# ì „ì²´ í•™ìŠµ ë°ì´í„° ë¡œë“œ\n",
    "train_df = pd.read_csv(\"../data/train.csv\")\n",
    "print(f\"í•™ìŠµ ë°ì´í„°: {len(train_df)}ê°œ ìƒ˜í”Œ\")\n",
    "\n",
    "# í´ë˜ìŠ¤ ë¶„í¬ í™•ì¸\n",
    "class_counts = train_df['target'].value_counts().sort_index()\n",
    "print(f\" í´ë˜ìŠ¤ ë¶„í¬: {dict(class_counts)}\")\n",
    "\n",
    "# K-Fold ì„¤ì •\n",
    "skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)\n",
    "\n",
    "# K-Fold ê²°ê³¼ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸\n",
    "fold_results = []\n",
    "fold_models = []  # ê° foldì˜ ìµœê³  ì„±ëŠ¥ ëª¨ë¸ì„ ì €ì¥\n",
    "\n",
    "#  WandB ë©”ì¸ ì‹¤í—˜ ì‹œì‘\n",
    "main_run = wandb.init(\n",
    "    project=PROJECT_NAME,\n",
    "    entity=ENTITY,\n",
    "    name=f\"{EXPERIMENT_NAME}-{datetime.now().strftime('%m%d-%H%M')}\",\n",
    "    config=config,\n",
    "    tags=[\"k-fold-cv\", \"ensemble\", model_name, \"baseline\", \"main-experiment\"],\n",
    "    group=\"k-fold-experiment\",\n",
    "    job_type=\"cross-validation\",\n",
    "    notes=f\"{N_FOLDS}-Fold Cross Validation with {model_name}\"\n",
    ")\n",
    "\n",
    "print(f\"\\nğŸš€ WandB ì‹¤í—˜ ì‹œì‘!\")\n",
    "print(f\"ğŸ“Š ëŒ€ì‹œë³´ë“œ: {main_run.url}\")\n",
    "print(f\"ğŸ“‹ ì‹¤í—˜ëª…: {main_run.name}\")\n",
    "\n",
    "#  ë°ì´í„°ì…‹ ì •ë³´ ë¡œê¹…\n",
    "wandb.log({\n",
    "    \"dataset/total_samples\": len(train_df),\n",
    "    \"dataset/num_classes\": 17,\n",
    "    \"dataset/samples_per_fold\": len(train_df) // N_FOLDS,\n",
    "})\n",
    "\n",
    "# í´ë˜ìŠ¤ ë¶„í¬ ì‹œê°í™”\n",
    "class_dist_data = [[f\"Class_{i}\", count] for i, count in enumerate(class_counts)]\n",
    "wandb.log({\n",
    "    \"dataset/class_distribution\": wandb.plot.bar(\n",
    "        wandb.Table(data=class_dist_data, columns=[\"Class\", \"Count\"]),\n",
    "        \"Class\", \"Count\", \n",
    "        title=\"Training Data Class Distribution\"\n",
    "    )\n",
    "})\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"ğŸ¯ {N_FOLDS}-FOLD CROSS VALIDATION ì‹œì‘\")\n",
    "print(f\"{'='*60}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1675898e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      " FOLD 1/5\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to True."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>dataset/num_classes</td><td>â–</td></tr><tr><td>dataset/samples_per_fold</td><td>â–</td></tr><tr><td>dataset/total_samples</td><td>â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>dataset/num_classes</td><td>17</td></tr><tr><td>dataset/samples_per_fold</td><td>314</td></tr><tr><td>dataset/total_samples</td><td>1570</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">efficientnet-b3-baseline-0904-1341</strong> at: <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/mdvqqydn' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/mdvqqydn</a><br> View project at: <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team</a><br>Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250904_134143-mdvqqydn/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "creating run (0.2s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/ephemeral/home/computervisioncompetition-cv-1/wandb/wandb/run-20250904_134145-bx5b6hog</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/bx5b6hog' target=\"_blank\">fold-1-efficientnet_b3-1341</a></strong> to <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/bx5b6hog' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/bx5b6hog</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Fold 1 Dashboard: https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/bx5b6hog\n",
      "Train samples: 1256, Validation samples: 314\n",
      " ëª¨ë¸ í•™ìŠµ ì‹œì‘ - Fold 1\n",
      "\n",
      "ğŸ“ˆ Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.9688, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:22<00:00,  1.78it/s]\n",
      "Val Loss: 1.8446: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:02<00:00,  4.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  1 | Train Loss: 2.6804 | Train F1: 0.2319 | Val Loss: 1.7305 | Val F1: 0.6661 | LR: 5.00e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.6661\n",
      "\n",
      "ğŸ“ˆ Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.4531, Mixup: False, Cutout: True, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.42it/s]\n",
      "Val Loss: 1.5317: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  6.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  2 | Train Loss: 2.0021 | Train F1: 0.4900 | Val Loss: 1.4795 | Val F1: 0.7949 | LR: 5.00e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.7949\n",
      "\n",
      "ğŸ“ˆ Epoch 3/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.5195, Mixup: False, Cutout: True, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.43it/s]\n",
      "Val Loss: 1.4500: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  6.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  3 | Train Loss: 1.7830 | Train F1: 0.5823 | Val Loss: 1.3833 | Val F1: 0.8436 | LR: 4.98e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.8436\n",
      "\n",
      "ğŸ“ˆ Epoch 4/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.6338, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.46it/s]\n",
      "Val Loss: 1.3547: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  4 | Train Loss: 1.7137 | Train F1: 0.6073 | Val Loss: 1.3095 | Val F1: 0.8674 | LR: 4.96e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.8674\n",
      "\n",
      "ğŸ“ˆ Epoch 5/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3613, Mixup: False, Cutout: True, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.45it/s]\n",
      "Val Loss: 1.3083: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  6.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  5 | Train Loss: 1.6229 | Train F1: 0.6758 | Val Loss: 1.2937 | Val F1: 0.8725 | LR: 4.92e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.8725\n",
      "\n",
      "ğŸ“ˆ Epoch 6/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.6377, Mixup: False, Cutout: True, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.34it/s]\n",
      "Val Loss: 1.2638: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  6 | Train Loss: 1.5749 | Train F1: 0.7083 | Val Loss: 1.3079 | Val F1: 0.8428 | LR: 4.88e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 7/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2383, Mixup: False, Cutout: True, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.47it/s]\n",
      "Val Loss: 1.2842: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  6.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  7 | Train Loss: 1.5315 | Train F1: 0.7010 | Val Loss: 1.2491 | Val F1: 0.8710 | LR: 4.82e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 8/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.5859, Mixup: False, Cutout: True, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.48it/s]\n",
      "Val Loss: 1.2566: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  8 | Train Loss: 1.4285 | Train F1: 0.7979 | Val Loss: 1.2430 | Val F1: 0.9007 | LR: 4.76e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.9007\n",
      "\n",
      "ğŸ“ˆ Epoch 9/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.6748, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.51it/s]\n",
      "Val Loss: 1.3260: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  9 | Train Loss: 1.4779 | Train F1: 0.7788 | Val Loss: 1.2688 | Val F1: 0.8666 | LR: 4.69e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 10/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3213, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.38it/s]\n",
      "Val Loss: 1.2989: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  6.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 10 | Train Loss: 1.3983 | Train F1: 0.7824 | Val Loss: 1.2484 | Val F1: 0.8500 | LR: 4.61e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 11/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.5703, Mixup: True, Cutout: False, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.45it/s]\n",
      "Val Loss: 1.2096: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 11 | Train Loss: 1.3786 | Train F1: 0.7555 | Val Loss: 1.1950 | Val F1: 0.9168 | LR: 4.52e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.9168\n",
      "\n",
      "ğŸ“ˆ Epoch 12/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2490, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.37it/s]\n",
      "Val Loss: 1.2226: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 12 | Train Loss: 1.3692 | Train F1: 0.7847 | Val Loss: 1.2061 | Val F1: 0.8956 | LR: 4.43e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 13/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1934, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.54it/s]\n",
      "Val Loss: 1.1941: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  6.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 13 | Train Loss: 1.3136 | Train F1: 0.8023 | Val Loss: 1.1767 | Val F1: 0.9271 | LR: 4.32e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.9271\n",
      "\n",
      "ğŸ“ˆ Epoch 14/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.7422, Mixup: True, Cutout: False, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.36it/s]\n",
      "Val Loss: 1.1871: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 14 | Train Loss: 1.4536 | Train F1: 0.7564 | Val Loss: 1.1917 | Val F1: 0.9049 | LR: 4.21e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 15/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3037, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.48it/s]\n",
      "Val Loss: 1.1767: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 15 | Train Loss: 1.3691 | Train F1: 0.8426 | Val Loss: 1.1875 | Val F1: 0.9231 | LR: 4.09e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 16/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1533, Mixup: False, Cutout: True, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.45it/s]\n",
      "Val Loss: 1.2072: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  6.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 16 | Train Loss: 1.3260 | Train F1: 0.8188 | Val Loss: 1.1818 | Val F1: 0.9087 | LR: 3.97e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 17/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1641, Mixup: False, Cutout: True, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:12<00:00,  3.28it/s]\n",
      "Val Loss: 1.2108: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 17 | Train Loss: 1.3163 | Train F1: 0.7983 | Val Loss: 1.1732 | Val F1: 0.9185 | LR: 3.84e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 18/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1523, Mixup: False, Cutout: True, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.48it/s]\n",
      "Val Loss: 1.1906: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  6.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 18 | Train Loss: 1.3462 | Train F1: 0.7872 | Val Loss: 1.1606 | Val F1: 0.9234 | LR: 3.70e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 19/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2734, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.39it/s]\n",
      "Val Loss: 1.2322: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  6.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 19 | Train Loss: 1.3168 | Train F1: 0.8193 | Val Loss: 1.1822 | Val F1: 0.9067 | LR: 3.56e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 20/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1250, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.51it/s]\n",
      "Val Loss: 1.2293: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  6.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 20 | Train Loss: 1.3624 | Train F1: 0.7609 | Val Loss: 1.1740 | Val F1: 0.9221 | LR: 3.42e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 21/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.0986, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.43it/s]\n",
      "Val Loss: 1.2336: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  6.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 21 | Train Loss: 1.3597 | Train F1: 0.7303 | Val Loss: 1.1788 | Val F1: 0.9191 | LR: 3.27e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 22/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.0859, Mixup: True, Cutout: False, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.44it/s]\n",
      "Val Loss: 1.1930: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 22 | Train Loss: 1.3475 | Train F1: 0.7922 | Val Loss: 1.1696 | Val F1: 0.9258 | LR: 3.12e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 23/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3496, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.47it/s]\n",
      "Val Loss: 1.2118: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 23 | Train Loss: 1.2773 | Train F1: 0.8016 | Val Loss: 1.1707 | Val F1: 0.9205 | LR: 2.97e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 24/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3613, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.39it/s]\n",
      "Val Loss: 1.1907: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 24 | Train Loss: 1.3701 | Train F1: 0.7768 | Val Loss: 1.1688 | Val F1: 0.9114 | LR: 2.81e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 25/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2998, Mixup: False, Cutout: True, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.42it/s]\n",
      "Val Loss: 1.2012: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  6.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 25 | Train Loss: 1.3299 | Train F1: 0.8090 | Val Loss: 1.1698 | Val F1: 0.9100 | LR: 2.66e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 26/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2471, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.47it/s]\n",
      "Val Loss: 1.1948: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 26 | Train Loss: 1.2779 | Train F1: 0.7892 | Val Loss: 1.1699 | Val F1: 0.9187 | LR: 2.50e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 27/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.7148, Mixup: False, Cutout: True, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.42it/s]\n",
      "Val Loss: 1.1796: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  6.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 27 | Train Loss: 1.2916 | Train F1: 0.8318 | Val Loss: 1.1642 | Val F1: 0.9141 | LR: 2.34e-04\n",
      "â¸ï¸ Early stopping at epoch 27 (patience: 14)\n",
      "\n",
      " Fold 1 ì™„ë£Œ!\n",
      " ìµœê³  Validation F1: 0.9271\n",
      " í•™ìŠµëœ ì—í­: 27/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>best_performance/epoch</td><td>â–â–‚â–‚â–ƒâ–ƒâ–…â–‡â–ˆ</td></tr><tr><td>best_performance/val_acc</td><td>â–â–…â–†â–‡â–‡â–‡â–ˆâ–ˆ</td></tr><tr><td>best_performance/val_f1</td><td>â–â–„â–†â–†â–‡â–‡â–ˆâ–ˆ</td></tr><tr><td>best_performance/val_loss</td><td>â–ˆâ–…â–„â–ƒâ–‚â–‚â–â–</td></tr><tr><td>early_stopping/epoch</td><td>â–</td></tr><tr><td>epoch</td><td>â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆ</td></tr><tr><td>fold</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>fold_1/batch_step</td><td>â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆ</td></tr><tr><td>fold_1/cutout_applied</td><td>â–â–ˆâ–ˆâ–â–â–ˆâ–â–ˆâ–ˆâ–â–â–ˆâ–ˆâ–â–â–ˆâ–ˆâ–ˆâ–â–â–â–â–â–â–â–ˆâ–</td></tr><tr><td>fold_1/mixup_applied</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–ˆâ–ˆâ–â–â–ˆâ–â–</td></tr><tr><td>+22</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_performance/epoch</td><td>13</td></tr><tr><td>best_performance/val_acc</td><td>0.92994</td></tr><tr><td>best_performance/val_f1</td><td>0.92706</td></tr><tr><td>best_performance/val_loss</td><td>1.17669</td></tr><tr><td>early_stopping/epoch</td><td>27</td></tr><tr><td>epoch</td><td>27</td></tr><tr><td>fold</td><td>1</td></tr><tr><td>fold_1/batch_step</td><td>1040</td></tr><tr><td>fold_1/cutout_applied</td><td>0</td></tr><tr><td>fold_1/mixup_applied</td><td>0</td></tr><tr><td>+23</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fold-1-efficientnet_b3-1341</strong> at: <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/bx5b6hog' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/bx5b6hog</a><br> View project at: <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250904_134145-bx5b6hog/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      " FOLD 2/5\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "creating run (0.0s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/ephemeral/home/computervisioncompetition-cv-1/wandb/wandb/run-20250904_134802-6ezm341t</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/6ezm341t' target=\"_blank\">fold-2-efficientnet_b3-1348</a></strong> to <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/6ezm341t' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/6ezm341t</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Fold 2 Dashboard: https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/6ezm341t\n",
      "Train samples: 1256, Validation samples: 314\n",
      " ëª¨ë¸ í•™ìŠµ ì‹œì‘ - Fold 2\n",
      "\n",
      "ğŸ“ˆ Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.7383, Mixup: True, Cutout: False, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.38it/s]\n",
      "Val Loss: 1.7013: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  1 | Train Loss: 2.7039 | Train F1: 0.2769 | Val Loss: 1.7919 | Val F1: 0.6296 | LR: 5.00e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.6296\n",
      "\n",
      "ğŸ“ˆ Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.5049, Mixup: False, Cutout: True, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.43it/s]\n",
      "Val Loss: 1.4894: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  6.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  2 | Train Loss: 1.9208 | Train F1: 0.5250 | Val Loss: 1.5198 | Val F1: 0.7612 | LR: 5.00e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.7612\n",
      "\n",
      "ğŸ“ˆ Epoch 3/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.7480, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:12<00:00,  3.32it/s]\n",
      "Val Loss: 1.3445: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  3 | Train Loss: 1.7352 | Train F1: 0.6231 | Val Loss: 1.4037 | Val F1: 0.8230 | LR: 4.98e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.8230\n",
      "\n",
      "ğŸ“ˆ Epoch 4/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.5986, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.34it/s]\n",
      "Val Loss: 1.3615: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  4 | Train Loss: 1.6092 | Train F1: 0.6809 | Val Loss: 1.3748 | Val F1: 0.8011 | LR: 4.96e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 5/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3613, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.39it/s]\n",
      "Val Loss: 1.2736: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  5 | Train Loss: 1.5628 | Train F1: 0.7028 | Val Loss: 1.3066 | Val F1: 0.8416 | LR: 4.92e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.8416\n",
      "\n",
      "ğŸ“ˆ Epoch 6/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.4541, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.37it/s]\n",
      "Val Loss: 1.2514: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  6.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  6 | Train Loss: 1.5157 | Train F1: 0.7432 | Val Loss: 1.2686 | Val F1: 0.8586 | LR: 4.88e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.8586\n",
      "\n",
      "ğŸ“ˆ Epoch 7/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.4922, Mixup: False, Cutout: True, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.42it/s]\n",
      "Val Loss: 1.2196: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  7 | Train Loss: 1.5309 | Train F1: 0.6739 | Val Loss: 1.2613 | Val F1: 0.8684 | LR: 4.82e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.8684\n",
      "\n",
      "ğŸ“ˆ Epoch 8/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2236, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.42it/s]\n",
      "Val Loss: 1.2344: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  8 | Train Loss: 1.4564 | Train F1: 0.7748 | Val Loss: 1.2425 | Val F1: 0.8921 | LR: 4.76e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.8921\n",
      "\n",
      "ğŸ“ˆ Epoch 9/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2363, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.44it/s]\n",
      "Val Loss: 1.2433: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  9 | Train Loss: 1.3925 | Train F1: 0.8080 | Val Loss: 1.2671 | Val F1: 0.8778 | LR: 4.69e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 10/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.0820, Mixup: True, Cutout: False, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:12<00:00,  3.31it/s]\n",
      "Val Loss: 1.2524: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  6.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 10 | Train Loss: 1.4148 | Train F1: 0.8086 | Val Loss: 1.2622 | Val F1: 0.8826 | LR: 4.61e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 11/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.6719, Mixup: True, Cutout: False, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.39it/s]\n",
      "Val Loss: 1.1820: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  6.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 11 | Train Loss: 1.3909 | Train F1: 0.7425 | Val Loss: 1.2268 | Val F1: 0.8949 | LR: 4.52e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.8949\n",
      "\n",
      "ğŸ“ˆ Epoch 12/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.5020, Mixup: True, Cutout: False, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.40it/s]\n",
      "Val Loss: 1.2283: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 12 | Train Loss: 1.4071 | Train F1: 0.8106 | Val Loss: 1.2381 | Val F1: 0.8932 | LR: 4.43e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 13/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2559, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.34it/s]\n",
      "Val Loss: 1.2030: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  6.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 13 | Train Loss: 1.3826 | Train F1: 0.8115 | Val Loss: 1.2157 | Val F1: 0.9040 | LR: 4.32e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.9040\n",
      "\n",
      "ğŸ“ˆ Epoch 14/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.4326, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.40it/s]\n",
      "Val Loss: 1.2870: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 14 | Train Loss: 1.4295 | Train F1: 0.7752 | Val Loss: 1.2623 | Val F1: 0.8405 | LR: 4.21e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 15/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1934, Mixup: False, Cutout: True, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.45it/s]\n",
      "Val Loss: 1.1919: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 15 | Train Loss: 1.3763 | Train F1: 0.7760 | Val Loss: 1.2058 | Val F1: 0.8816 | LR: 4.09e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 16/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.7598, Mixup: True, Cutout: False, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.39it/s]\n",
      "Val Loss: 1.1895: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 16 | Train Loss: 1.4502 | Train F1: 0.6776 | Val Loss: 1.1864 | Val F1: 0.9099 | LR: 3.97e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.9099\n",
      "\n",
      "ğŸ“ˆ Epoch 17/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1348, Mixup: False, Cutout: True, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.40it/s]\n",
      "Val Loss: 1.2520: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  6.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 17 | Train Loss: 1.3274 | Train F1: 0.8389 | Val Loss: 1.2224 | Val F1: 0.8931 | LR: 3.84e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 18/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.9785, Mixup: True, Cutout: False, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.51it/s]\n",
      "Val Loss: 1.2048: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 18 | Train Loss: 1.3719 | Train F1: 0.8212 | Val Loss: 1.1901 | Val F1: 0.8985 | LR: 3.70e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 19/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2842, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.39it/s]\n",
      "Val Loss: 1.1518: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 19 | Train Loss: 1.3176 | Train F1: 0.7398 | Val Loss: 1.1886 | Val F1: 0.8868 | LR: 3.56e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 20/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.0918, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.42it/s]\n",
      "Val Loss: 1.1585: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  6.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 20 | Train Loss: 1.3726 | Train F1: 0.8114 | Val Loss: 1.1724 | Val F1: 0.9129 | LR: 3.42e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.9129\n",
      "\n",
      "ğŸ“ˆ Epoch 21/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1113, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.35it/s]\n",
      "Val Loss: 1.2178: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 21 | Train Loss: 1.2536 | Train F1: 0.8151 | Val Loss: 1.1816 | Val F1: 0.9080 | LR: 3.27e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 22/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1611, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:12<00:00,  3.23it/s]\n",
      "Val Loss: 1.1300: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 22 | Train Loss: 1.2417 | Train F1: 0.9141 | Val Loss: 1.1766 | Val F1: 0.9030 | LR: 3.12e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 23/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2197, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.34it/s]\n",
      "Val Loss: 1.1440: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  6.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 23 | Train Loss: 1.3416 | Train F1: 0.7600 | Val Loss: 1.1720 | Val F1: 0.9136 | LR: 2.97e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.9136\n",
      "\n",
      "ğŸ“ˆ Epoch 24/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.8691, Mixup: True, Cutout: False, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.43it/s]\n",
      "Val Loss: 1.1511: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  6.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 24 | Train Loss: 1.3341 | Train F1: 0.8095 | Val Loss: 1.1764 | Val F1: 0.9068 | LR: 2.81e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 25/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1543, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.45it/s]\n",
      "Val Loss: 1.1747: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 25 | Train Loss: 1.3416 | Train F1: 0.7703 | Val Loss: 1.1735 | Val F1: 0.8994 | LR: 2.66e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 26/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.8086, Mixup: True, Cutout: False, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.52it/s]\n",
      "Val Loss: 1.1886: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 26 | Train Loss: 1.2959 | Train F1: 0.8043 | Val Loss: 1.1677 | Val F1: 0.9168 | LR: 2.50e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.9168\n",
      "\n",
      "ğŸ“ˆ Epoch 27/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.0508, Mixup: False, Cutout: True, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.39it/s]\n",
      "Val Loss: 1.1333: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 27 | Train Loss: 1.2736 | Train F1: 0.8329 | Val Loss: 1.1671 | Val F1: 0.9279 | LR: 2.34e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.9279\n",
      "\n",
      "ğŸ“ˆ Epoch 28/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1328, Mixup: False, Cutout: True, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.39it/s]\n",
      "Val Loss: 1.1440: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 28 | Train Loss: 1.3010 | Train F1: 0.7823 | Val Loss: 1.1631 | Val F1: 0.9204 | LR: 2.19e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 29/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1201, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.48it/s]\n",
      "Val Loss: 1.1710: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  6.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 29 | Train Loss: 1.3069 | Train F1: 0.8128 | Val Loss: 1.1637 | Val F1: 0.9115 | LR: 2.03e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 30/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2383, Mixup: False, Cutout: True, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.36it/s]\n",
      "Val Loss: 1.1294: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 30 | Train Loss: 1.3378 | Train F1: 0.7996 | Val Loss: 1.1463 | Val F1: 0.9291 | LR: 1.88e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.9291\n",
      "\n",
      "ğŸ“ˆ Epoch 31/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.8877, Mixup: True, Cutout: False, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.45it/s]\n",
      "Val Loss: 1.1387: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 31 | Train Loss: 1.2434 | Train F1: 0.8706 | Val Loss: 1.1447 | Val F1: 0.9297 | LR: 1.73e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.9297\n",
      "\n",
      "ğŸ“ˆ Epoch 32/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2598, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.46it/s]\n",
      "Val Loss: 1.1190: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  6.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 32 | Train Loss: 1.2548 | Train F1: 0.8861 | Val Loss: 1.1525 | Val F1: 0.9306 | LR: 1.58e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.9306\n",
      "\n",
      "ğŸ“ˆ Epoch 33/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.0293, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.43it/s]\n",
      "Val Loss: 1.1494: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 33 | Train Loss: 1.2109 | Train F1: 0.9142 | Val Loss: 1.1471 | Val F1: 0.9211 | LR: 1.44e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 34/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1338, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.37it/s]\n",
      "Val Loss: 1.1696: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  6.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 34 | Train Loss: 1.3375 | Train F1: 0.8074 | Val Loss: 1.1533 | Val F1: 0.9299 | LR: 1.30e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 35/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1211, Mixup: False, Cutout: True, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.36it/s]\n",
      "Val Loss: 1.1442: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 35 | Train Loss: 1.2594 | Train F1: 0.8288 | Val Loss: 1.1445 | Val F1: 0.9299 | LR: 1.16e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 36/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1094, Mixup: True, Cutout: False, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.39it/s]\n",
      "Val Loss: 1.1601: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 36 | Train Loss: 1.3014 | Train F1: 0.7933 | Val Loss: 1.1483 | Val F1: 0.9353 | LR: 1.03e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.9353\n",
      "\n",
      "ğŸ“ˆ Epoch 37/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.0439, Mixup: False, Cutout: True, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.40it/s]\n",
      "Val Loss: 1.1495: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 37 | Train Loss: 1.2059 | Train F1: 0.8544 | Val Loss: 1.1460 | Val F1: 0.9411 | LR: 9.06e-05\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.9411\n",
      "\n",
      "ğŸ“ˆ Epoch 38/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1621, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.41it/s]\n",
      "Val Loss: 1.1391: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 38 | Train Loss: 1.2677 | Train F1: 0.8281 | Val Loss: 1.1512 | Val F1: 0.9267 | LR: 7.89e-05\n",
      "\n",
      "ğŸ“ˆ Epoch 39/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1699, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.45it/s]\n",
      "Val Loss: 1.1456: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  6.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 39 | Train Loss: 1.2675 | Train F1: 0.7464 | Val Loss: 1.1475 | Val F1: 0.9310 | LR: 6.78e-05\n",
      "\n",
      "ğŸ“ˆ Epoch 40/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.8945, Mixup: True, Cutout: False, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.48it/s]\n",
      "Val Loss: 1.1321: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 40 | Train Loss: 1.2760 | Train F1: 0.8662 | Val Loss: 1.1466 | Val F1: 0.9344 | LR: 5.74e-05\n",
      "\n",
      "ğŸ“ˆ Epoch 41/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.9482, Mixup: False, Cutout: True, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:12<00:00,  3.33it/s]\n",
      "Val Loss: 1.1380: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  6.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 41 | Train Loss: 1.2532 | Train F1: 0.8403 | Val Loss: 1.1404 | Val F1: 0.9412 | LR: 4.77e-05\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.9412\n",
      "\n",
      "ğŸ“ˆ Epoch 42/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.8887, Mixup: True, Cutout: False, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:12<00:00,  3.23it/s]\n",
      "Val Loss: 1.1778: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  6.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 42 | Train Loss: 1.2611 | Train F1: 0.8900 | Val Loss: 1.1563 | Val F1: 0.9317 | LR: 3.89e-05\n",
      "\n",
      "ğŸ“ˆ Epoch 43/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1035, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.40it/s]\n",
      "Val Loss: 1.1334: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  6.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 43 | Train Loss: 1.1909 | Train F1: 0.8800 | Val Loss: 1.1464 | Val F1: 0.9302 | LR: 3.09e-05\n",
      "\n",
      "ğŸ“ˆ Epoch 44/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.7578, Mixup: True, Cutout: False, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:12<00:00,  3.31it/s]\n",
      "Val Loss: 1.1545: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  6.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 44 | Train Loss: 1.2135 | Train F1: 0.8979 | Val Loss: 1.1519 | Val F1: 0.9329 | LR: 2.38e-05\n",
      "\n",
      "ğŸ“ˆ Epoch 45/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.9961, Mixup: True, Cutout: False, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.51it/s]\n",
      "Val Loss: 1.1447: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 45 | Train Loss: 1.2069 | Train F1: 0.8663 | Val Loss: 1.1511 | Val F1: 0.9411 | LR: 1.76e-05\n",
      "\n",
      "ğŸ“ˆ Epoch 46/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3447, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.36it/s]\n",
      "Val Loss: 1.1488: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 46 | Train Loss: 1.2337 | Train F1: 0.8611 | Val Loss: 1.1528 | Val F1: 0.9409 | LR: 1.22e-05\n",
      "\n",
      "ğŸ“ˆ Epoch 47/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2334, Mixup: False, Cutout: True, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.39it/s]\n",
      "Val Loss: 1.1423: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 47 | Train Loss: 1.2268 | Train F1: 0.8626 | Val Loss: 1.1484 | Val F1: 0.9409 | LR: 7.85e-06\n",
      "\n",
      "ğŸ“ˆ Epoch 48/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.5225, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.43it/s]\n",
      "Val Loss: 1.1531: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 48 | Train Loss: 1.2988 | Train F1: 0.7891 | Val Loss: 1.1527 | Val F1: 0.9409 | LR: 4.43e-06\n",
      "â¸ï¸ Early stopping at epoch 48 (patience: 7)\n",
      "\n",
      " Fold 2 ì™„ë£Œ!\n",
      " ìµœê³  Validation F1: 0.9412\n",
      " í•™ìŠµëœ ì—í­: 48/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>best_performance/epoch</td><td>â–â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–„â–„â–…â–…â–†â–†â–†â–†â–‡â–‡â–ˆ</td></tr><tr><td>best_performance/val_acc</td><td>â–â–„â–…â–†â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>best_performance/val_f1</td><td>â–â–„â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>best_performance/val_loss</td><td>â–ˆâ–…â–„â–ƒâ–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>early_stopping/epoch</td><td>â–</td></tr><tr><td>epoch</td><td>â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>fold</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>fold_2/batch_step</td><td>â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>fold_2/cutout_applied</td><td>â–â–ˆâ–ˆâ–â–ˆâ–â–â–â–â–â–â–â–ˆâ–â–â–â–â–ˆâ–â–â–ˆâ–â–ˆâ–ˆâ–â–â–ˆâ–â–â–â–ˆâ–â–â–ˆâ–ˆâ–â–â–â–â–</td></tr><tr><td>fold_2/mixup_applied</td><td>â–ˆâ–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–ˆâ–â–ˆâ–â–ˆâ–â–â–â–ˆâ–ˆâ–â–â–</td></tr><tr><td>+22</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_performance/epoch</td><td>41</td></tr><tr><td>best_performance/val_acc</td><td>0.94586</td></tr><tr><td>best_performance/val_f1</td><td>0.94124</td></tr><tr><td>best_performance/val_loss</td><td>1.14038</td></tr><tr><td>early_stopping/epoch</td><td>48</td></tr><tr><td>epoch</td><td>48</td></tr><tr><td>fold</td><td>2</td></tr><tr><td>fold_2/batch_step</td><td>1880</td></tr><tr><td>fold_2/cutout_applied</td><td>0</td></tr><tr><td>fold_2/mixup_applied</td><td>0</td></tr><tr><td>+23</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fold-2-efficientnet_b3-1348</strong> at: <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/6ezm341t' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/6ezm341t</a><br> View project at: <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250904_134802-6ezm341t/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      " FOLD 3/5\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "creating run (0.1s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/ephemeral/home/computervisioncompetition-cv-1/wandb/wandb/run-20250904_135854-ailr3rai</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/ailr3rai' target=\"_blank\">fold-3-efficientnet_b3-1358</a></strong> to <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/ailr3rai' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/ailr3rai</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Fold 3 Dashboard: https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/ailr3rai\n",
      "Train samples: 1256, Validation samples: 314\n",
      " ëª¨ë¸ í•™ìŠµ ì‹œì‘ - Fold 3\n",
      "\n",
      "ğŸ“ˆ Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.0195, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:12<00:00,  3.22it/s]\n",
      "Val Loss: 1.6158: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  1 | Train Loss: 2.7335 | Train F1: 0.2469 | Val Loss: 1.7240 | Val F1: 0.6256 | LR: 5.00e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.6256\n",
      "\n",
      "ğŸ“ˆ Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.9424, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.43it/s]\n",
      "Val Loss: 1.4114: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  6.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  2 | Train Loss: 2.0801 | Train F1: 0.4753 | Val Loss: 1.5084 | Val F1: 0.7141 | LR: 5.00e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.7141\n",
      "\n",
      "ğŸ“ˆ Epoch 3/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.0898, Mixup: True, Cutout: False, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.38it/s]\n",
      "Val Loss: 1.3176: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  3 | Train Loss: 1.8310 | Train F1: 0.6225 | Val Loss: 1.3955 | Val F1: 0.8199 | LR: 4.98e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.8199\n",
      "\n",
      "ğŸ“ˆ Epoch 4/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.3984, Mixup: True, Cutout: False, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:12<00:00,  3.32it/s]\n",
      "Val Loss: 1.3669: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  6.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  4 | Train Loss: 1.7421 | Train F1: 0.6532 | Val Loss: 1.3824 | Val F1: 0.8150 | LR: 4.96e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 5/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.7676, Mixup: False, Cutout: True, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.41it/s]\n",
      "Val Loss: 1.3001: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  5 | Train Loss: 1.6742 | Train F1: 0.6656 | Val Loss: 1.3280 | Val F1: 0.8546 | LR: 4.92e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.8546\n",
      "\n",
      "ğŸ“ˆ Epoch 6/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3730, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.41it/s]\n",
      "Val Loss: 1.2144: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  6 | Train Loss: 1.6762 | Train F1: 0.5853 | Val Loss: 1.2911 | Val F1: 0.8739 | LR: 4.88e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.8739\n",
      "\n",
      "ğŸ“ˆ Epoch 7/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.7373, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.43it/s]\n",
      "Val Loss: 1.1905: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  7 | Train Loss: 1.5459 | Train F1: 0.6935 | Val Loss: 1.2620 | Val F1: 0.8705 | LR: 4.82e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 8/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.4238, Mixup: False, Cutout: True, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.39it/s]\n",
      "Val Loss: 1.1545: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  6.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  8 | Train Loss: 1.5054 | Train F1: 0.7209 | Val Loss: 1.2725 | Val F1: 0.8658 | LR: 4.76e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 9/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3438, Mixup: False, Cutout: True, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.34it/s]\n",
      "Val Loss: 1.1503: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  9 | Train Loss: 1.5068 | Train F1: 0.7456 | Val Loss: 1.2382 | Val F1: 0.8726 | LR: 4.69e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 10/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.6963, Mixup: True, Cutout: False, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.48it/s]\n",
      "Val Loss: 1.1860: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 10 | Train Loss: 1.4159 | Train F1: 0.7679 | Val Loss: 1.2363 | Val F1: 0.8595 | LR: 4.61e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 11/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.4912, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.40it/s]\n",
      "Val Loss: 1.1411: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 11 | Train Loss: 1.5120 | Train F1: 0.7667 | Val Loss: 1.2178 | Val F1: 0.8845 | LR: 4.52e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.8845\n",
      "\n",
      "ğŸ“ˆ Epoch 12/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1562, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.42it/s]\n",
      "Val Loss: 1.1331: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 12 | Train Loss: 1.4401 | Train F1: 0.7768 | Val Loss: 1.2193 | Val F1: 0.8847 | LR: 4.43e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.8847\n",
      "\n",
      "ğŸ“ˆ Epoch 13/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1533, Mixup: False, Cutout: True, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:12<00:00,  3.31it/s]\n",
      "Val Loss: 1.2241: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  6.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 13 | Train Loss: 1.4414 | Train F1: 0.7794 | Val Loss: 1.2362 | Val F1: 0.8665 | LR: 4.32e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 14/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.0957, Mixup: False, Cutout: True, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.40it/s]\n",
      "Val Loss: 1.2325: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 14 | Train Loss: 1.4276 | Train F1: 0.7370 | Val Loss: 1.2252 | Val F1: 0.8580 | LR: 4.21e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 15/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3086, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:12<00:00,  3.31it/s]\n",
      "Val Loss: 1.1886: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 15 | Train Loss: 1.4661 | Train F1: 0.7212 | Val Loss: 1.2027 | Val F1: 0.8873 | LR: 4.09e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.8873\n",
      "\n",
      "ğŸ“ˆ Epoch 16/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1152, Mixup: False, Cutout: True, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.37it/s]\n",
      "Val Loss: 1.1960: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  6.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 16 | Train Loss: 1.4054 | Train F1: 0.7872 | Val Loss: 1.2021 | Val F1: 0.8855 | LR: 3.97e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 17/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3242, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.46it/s]\n",
      "Val Loss: 1.1524: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  6.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 17 | Train Loss: 1.3555 | Train F1: 0.7900 | Val Loss: 1.1981 | Val F1: 0.8858 | LR: 3.84e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 18/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2158, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.48it/s]\n",
      "Val Loss: 1.1305: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 18 | Train Loss: 1.3076 | Train F1: 0.8421 | Val Loss: 1.1914 | Val F1: 0.8860 | LR: 3.70e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 19/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3643, Mixup: True, Cutout: False, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.37it/s]\n",
      "Val Loss: 1.1450: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  6.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 19 | Train Loss: 1.3802 | Train F1: 0.7942 | Val Loss: 1.1984 | Val F1: 0.8869 | LR: 3.56e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 20/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.7148, Mixup: True, Cutout: False, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.40it/s]\n",
      "Val Loss: 1.2077: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 20 | Train Loss: 1.4547 | Train F1: 0.7239 | Val Loss: 1.2104 | Val F1: 0.8830 | LR: 3.42e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 21/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.4395, Mixup: True, Cutout: False, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.43it/s]\n",
      "Val Loss: 1.0888: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 21 | Train Loss: 1.3839 | Train F1: 0.8348 | Val Loss: 1.1666 | Val F1: 0.9231 | LR: 3.27e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.9231\n",
      "\n",
      "ğŸ“ˆ Epoch 22/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1934, Mixup: False, Cutout: True, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:12<00:00,  3.25it/s]\n",
      "Val Loss: 1.0886: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  6.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 22 | Train Loss: 1.4253 | Train F1: 0.7684 | Val Loss: 1.1690 | Val F1: 0.9239 | LR: 3.12e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.9239\n",
      "\n",
      "ğŸ“ˆ Epoch 23/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.4941, Mixup: True, Cutout: False, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.52it/s]\n",
      "Val Loss: 1.0868: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 23 | Train Loss: 1.2829 | Train F1: 0.8522 | Val Loss: 1.1708 | Val F1: 0.9129 | LR: 2.97e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 24/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.4971, Mixup: True, Cutout: False, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.39it/s]\n",
      "Val Loss: 1.0769: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  6.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 24 | Train Loss: 1.3591 | Train F1: 0.8317 | Val Loss: 1.1736 | Val F1: 0.9198 | LR: 2.81e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 25/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.0625, Mixup: True, Cutout: False, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.43it/s]\n",
      "Val Loss: 1.1236: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  6.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 25 | Train Loss: 1.3041 | Train F1: 0.8332 | Val Loss: 1.1923 | Val F1: 0.8958 | LR: 2.66e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 26/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3125, Mixup: False, Cutout: True, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.34it/s]\n",
      "Val Loss: 1.1370: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 26 | Train Loss: 1.2892 | Train F1: 0.8078 | Val Loss: 1.2187 | Val F1: 0.8843 | LR: 2.50e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 27/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1719, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.48it/s]\n",
      "Val Loss: 1.0847: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 27 | Train Loss: 1.3556 | Train F1: 0.7769 | Val Loss: 1.1579 | Val F1: 0.9322 | LR: 2.34e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.9322\n",
      "\n",
      "ğŸ“ˆ Epoch 28/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.8916, Mixup: True, Cutout: False, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.33it/s]\n",
      "Val Loss: 1.1194: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 28 | Train Loss: 1.3063 | Train F1: 0.8141 | Val Loss: 1.1709 | Val F1: 0.8969 | LR: 2.19e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 29/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1631, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.40it/s]\n",
      "Val Loss: 1.1441: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 29 | Train Loss: 1.2996 | Train F1: 0.8206 | Val Loss: 1.1778 | Val F1: 0.9135 | LR: 2.03e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 30/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2148, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.42it/s]\n",
      "Val Loss: 1.1192: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 30 | Train Loss: 1.2784 | Train F1: 0.8766 | Val Loss: 1.1757 | Val F1: 0.8834 | LR: 1.88e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 31/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1797, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.45it/s]\n",
      "Val Loss: 1.1190: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 31 | Train Loss: 1.2979 | Train F1: 0.8098 | Val Loss: 1.1735 | Val F1: 0.9044 | LR: 1.73e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 32/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1201, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.37it/s]\n",
      "Val Loss: 1.1129: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 32 | Train Loss: 1.3110 | Train F1: 0.7717 | Val Loss: 1.1739 | Val F1: 0.9192 | LR: 1.58e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 33/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1074, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.40it/s]\n",
      "Val Loss: 1.1015: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 33 | Train Loss: 1.2138 | Train F1: 0.9255 | Val Loss: 1.1707 | Val F1: 0.9161 | LR: 1.44e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 34/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2246, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.39it/s]\n",
      "Val Loss: 1.0987: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 34 | Train Loss: 1.1834 | Train F1: 0.9057 | Val Loss: 1.1763 | Val F1: 0.9155 | LR: 1.30e-04\n",
      "â¸ï¸ Early stopping at epoch 34 (patience: 7)\n",
      "\n",
      " Fold 3 ì™„ë£Œ!\n",
      " ìµœê³  Validation F1: 0.9322\n",
      " í•™ìŠµëœ ì—í­: 34/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>best_performance/epoch</td><td>â–â–â–‚â–‚â–‚â–„â–„â–…â–†â–‡â–ˆ</td></tr><tr><td>best_performance/val_acc</td><td>â–â–„â–…â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>best_performance/val_f1</td><td>â–â–ƒâ–…â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>best_performance/val_loss</td><td>â–ˆâ–…â–„â–ƒâ–ƒâ–‚â–‚â–‚â–â–â–</td></tr><tr><td>early_stopping/epoch</td><td>â–</td></tr><tr><td>epoch</td><td>â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>fold</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>fold_3/batch_step</td><td>â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>fold_3/cutout_applied</td><td>â–â–â–ˆâ–ˆâ–â–â–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–â–â–â–â–â–â–ˆâ–â–ˆâ–â–â–ˆâ–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>fold_3/mixup_applied</td><td>â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–ˆâ–ˆâ–ˆâ–â–â–â–â–ˆâ–â–â–â–â–ˆâ–ˆâ–â–â–ˆâ–â–ˆâ–ˆâ–â–</td></tr><tr><td>+22</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_performance/epoch</td><td>27</td></tr><tr><td>best_performance/val_acc</td><td>0.93631</td></tr><tr><td>best_performance/val_f1</td><td>0.93221</td></tr><tr><td>best_performance/val_loss</td><td>1.1579</td></tr><tr><td>early_stopping/epoch</td><td>34</td></tr><tr><td>epoch</td><td>34</td></tr><tr><td>fold</td><td>3</td></tr><tr><td>fold_3/batch_step</td><td>1320</td></tr><tr><td>fold_3/cutout_applied</td><td>0</td></tr><tr><td>fold_3/mixup_applied</td><td>0</td></tr><tr><td>+23</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fold-3-efficientnet_b3-1358</strong> at: <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/ailr3rai' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/ailr3rai</a><br> View project at: <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250904_135854-ailr3rai/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      " FOLD 4/5\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "creating run (0.1s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/ephemeral/home/computervisioncompetition-cv-1/wandb/wandb/run-20250904_140636-j75cyh6j</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/j75cyh6j' target=\"_blank\">fold-4-efficientnet_b3-1406</a></strong> to <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/j75cyh6j' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/j75cyh6j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Fold 4 Dashboard: https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/j75cyh6j\n",
      "Train samples: 1256, Validation samples: 314\n",
      " ëª¨ë¸ í•™ìŠµ ì‹œì‘ - Fold 4\n",
      "\n",
      "ğŸ“ˆ Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.1738, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:12<00:00,  3.30it/s]\n",
      "Val Loss: 1.7969: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  6.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  1 | Train Loss: 2.6602 | Train F1: 0.2756 | Val Loss: 1.8156 | Val F1: 0.6188 | LR: 5.00e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.6188\n",
      "\n",
      "ğŸ“ˆ Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.9053, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.39it/s]\n",
      "Val Loss: 1.5285: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  6.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  2 | Train Loss: 2.0823 | Train F1: 0.4941 | Val Loss: 1.6167 | Val F1: 0.6888 | LR: 5.00e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.6888\n",
      "\n",
      "ğŸ“ˆ Epoch 3/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.4668, Mixup: True, Cutout: False, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.43it/s]\n",
      "Val Loss: 1.4568: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  3 | Train Loss: 1.8359 | Train F1: 0.5858 | Val Loss: 1.4577 | Val F1: 0.7760 | LR: 4.98e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.7760\n",
      "\n",
      "ğŸ“ˆ Epoch 4/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.1855, Mixup: True, Cutout: False, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.42it/s]\n",
      "Val Loss: 1.3671: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  6.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  4 | Train Loss: 1.7341 | Train F1: 0.6738 | Val Loss: 1.4228 | Val F1: 0.7978 | LR: 4.96e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.7978\n",
      "\n",
      "ğŸ“ˆ Epoch 5/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.5645, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.46it/s]\n",
      "Val Loss: 1.3733: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  5 | Train Loss: 1.6048 | Train F1: 0.7126 | Val Loss: 1.3962 | Val F1: 0.8097 | LR: 4.92e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.8097\n",
      "\n",
      "ğŸ“ˆ Epoch 6/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.9434, Mixup: True, Cutout: False, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:12<00:00,  3.32it/s]\n",
      "Val Loss: 1.2597: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  6 | Train Loss: 1.5595 | Train F1: 0.7029 | Val Loss: 1.2902 | Val F1: 0.8788 | LR: 4.88e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.8788\n",
      "\n",
      "ğŸ“ˆ Epoch 7/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.7773, Mixup: True, Cutout: False, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.38it/s]\n",
      "Val Loss: 1.1641: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  7 | Train Loss: 1.5495 | Train F1: 0.7114 | Val Loss: 1.2950 | Val F1: 0.8704 | LR: 4.82e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 8/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.4316, Mixup: True, Cutout: False, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:12<00:00,  3.33it/s]\n",
      "Val Loss: 1.1469: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  8 | Train Loss: 1.5168 | Train F1: 0.7492 | Val Loss: 1.2717 | Val F1: 0.8930 | LR: 4.76e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.8930\n",
      "\n",
      "ğŸ“ˆ Epoch 9/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.8555, Mixup: True, Cutout: False, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.35it/s]\n",
      "Val Loss: 1.1919: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  9 | Train Loss: 1.4769 | Train F1: 0.7197 | Val Loss: 1.2700 | Val F1: 0.8667 | LR: 4.69e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 10/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.4424, Mixup: False, Cutout: True, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.43it/s]\n",
      "Val Loss: 1.1624: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 10 | Train Loss: 1.4061 | Train F1: 0.8062 | Val Loss: 1.2701 | Val F1: 0.8628 | LR: 4.61e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 11/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.2031, Mixup: True, Cutout: False, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.43it/s]\n",
      "Val Loss: 1.1593: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 11 | Train Loss: 1.3684 | Train F1: 0.8197 | Val Loss: 1.2775 | Val F1: 0.8751 | LR: 4.52e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 12/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3945, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:12<00:00,  3.32it/s]\n",
      "Val Loss: 1.2008: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  6.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 12 | Train Loss: 1.4177 | Train F1: 0.7813 | Val Loss: 1.2565 | Val F1: 0.8782 | LR: 4.43e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 13/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.2578, Mixup: True, Cutout: False, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.36it/s]\n",
      "Val Loss: 1.1980: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  6.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 13 | Train Loss: 1.3983 | Train F1: 0.7757 | Val Loss: 1.2477 | Val F1: 0.8965 | LR: 4.32e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.8965\n",
      "\n",
      "ğŸ“ˆ Epoch 14/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.9336, Mixup: True, Cutout: False, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.37it/s]\n",
      "Val Loss: 1.2150: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 14 | Train Loss: 1.4695 | Train F1: 0.7742 | Val Loss: 1.2734 | Val F1: 0.8575 | LR: 4.21e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 15/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1240, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.48it/s]\n",
      "Val Loss: 1.1742: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  6.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 15 | Train Loss: 1.3552 | Train F1: 0.8280 | Val Loss: 1.2583 | Val F1: 0.8720 | LR: 4.09e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 16/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.5195, Mixup: True, Cutout: False, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.42it/s]\n",
      "Val Loss: 1.1152: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 16 | Train Loss: 1.3580 | Train F1: 0.8432 | Val Loss: 1.2324 | Val F1: 0.8910 | LR: 3.97e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 17/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.0918, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.39it/s]\n",
      "Val Loss: 1.1001: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  6.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 17 | Train Loss: 1.4179 | Train F1: 0.7912 | Val Loss: 1.2253 | Val F1: 0.8996 | LR: 3.84e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.8996\n",
      "\n",
      "ğŸ“ˆ Epoch 18/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2471, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.46it/s]\n",
      "Val Loss: 1.1285: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  6.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 18 | Train Loss: 1.3389 | Train F1: 0.8120 | Val Loss: 1.2211 | Val F1: 0.8898 | LR: 3.70e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 19/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.5547, Mixup: True, Cutout: False, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.43it/s]\n",
      "Val Loss: 1.0848: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 19 | Train Loss: 1.3760 | Train F1: 0.7950 | Val Loss: 1.1977 | Val F1: 0.9180 | LR: 3.56e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.9180\n",
      "\n",
      "ğŸ“ˆ Epoch 20/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.3457, Mixup: True, Cutout: False, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.46it/s]\n",
      "Val Loss: 1.0789: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 20 | Train Loss: 1.3668 | Train F1: 0.8050 | Val Loss: 1.2020 | Val F1: 0.9186 | LR: 3.42e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.9186\n",
      "\n",
      "ğŸ“ˆ Epoch 21/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.5039, Mixup: False, Cutout: True, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.45it/s]\n",
      "Val Loss: 1.1250: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  6.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 21 | Train Loss: 1.2681 | Train F1: 0.8433 | Val Loss: 1.2022 | Val F1: 0.8832 | LR: 3.27e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 22/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3330, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.33it/s]\n",
      "Val Loss: 1.1183: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 22 | Train Loss: 1.4544 | Train F1: 0.7468 | Val Loss: 1.2104 | Val F1: 0.8921 | LR: 3.12e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 23/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.4307, Mixup: True, Cutout: False, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.42it/s]\n",
      "Val Loss: 1.1109: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  6.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 23 | Train Loss: 1.3735 | Train F1: 0.7513 | Val Loss: 1.2019 | Val F1: 0.8948 | LR: 2.97e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 24/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2803, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.34it/s]\n",
      "Val Loss: 1.1070: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 24 | Train Loss: 1.2853 | Train F1: 0.8700 | Val Loss: 1.1978 | Val F1: 0.8894 | LR: 2.81e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 25/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1641, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:12<00:00,  3.31it/s]\n",
      "Val Loss: 1.1027: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 25 | Train Loss: 1.2914 | Train F1: 0.8279 | Val Loss: 1.2148 | Val F1: 0.8887 | LR: 2.66e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 26/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1719, Mixup: False, Cutout: True, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.34it/s]\n",
      "Val Loss: 1.1122: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 26 | Train Loss: 1.3821 | Train F1: 0.7635 | Val Loss: 1.2130 | Val F1: 0.8846 | LR: 2.50e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 27/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1914, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.48it/s]\n",
      "Val Loss: 1.0910: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 27 | Train Loss: 1.2598 | Train F1: 0.8366 | Val Loss: 1.2013 | Val F1: 0.8904 | LR: 2.34e-04\n",
      "â¸ï¸ Early stopping at epoch 27 (patience: 7)\n",
      "\n",
      " Fold 4 ì™„ë£Œ!\n",
      " ìµœê³  Validation F1: 0.9186\n",
      " í•™ìŠµëœ ì—í­: 27/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>best_performance/epoch</td><td>â–â–â–‚â–‚â–‚â–ƒâ–„â–…â–‡â–ˆâ–ˆ</td></tr><tr><td>best_performance/val_acc</td><td>â–â–ƒâ–…â–†â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>best_performance/val_f1</td><td>â–â–ƒâ–…â–…â–…â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>best_performance/val_loss</td><td>â–ˆâ–†â–„â–„â–ƒâ–‚â–‚â–‚â–â–â–</td></tr><tr><td>early_stopping/epoch</td><td>â–</td></tr><tr><td>epoch</td><td>â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆ</td></tr><tr><td>fold</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>fold_4/batch_step</td><td>â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆ</td></tr><tr><td>fold_4/cutout_applied</td><td>â–â–ˆâ–â–â–â–â–â–â–ˆâ–â–ˆâ–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>fold_4/mixup_applied</td><td>â–ˆâ–â–â–ˆâ–â–â–ˆâ–ˆâ–â–â–â–â–â–â–ˆâ–ˆâ–â–â–ˆâ–ˆâ–â–â–ˆâ–â–â–ˆâ–ˆ</td></tr><tr><td>+22</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_performance/epoch</td><td>20</td></tr><tr><td>best_performance/val_acc</td><td>0.92675</td></tr><tr><td>best_performance/val_f1</td><td>0.91859</td></tr><tr><td>best_performance/val_loss</td><td>1.20204</td></tr><tr><td>early_stopping/epoch</td><td>27</td></tr><tr><td>epoch</td><td>27</td></tr><tr><td>fold</td><td>4</td></tr><tr><td>fold_4/batch_step</td><td>1040</td></tr><tr><td>fold_4/cutout_applied</td><td>0</td></tr><tr><td>fold_4/mixup_applied</td><td>1</td></tr><tr><td>+23</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fold-4-efficientnet_b3-1406</strong> at: <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/j75cyh6j' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/j75cyh6j</a><br> View project at: <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250904_140636-j75cyh6j/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      " FOLD 5/5\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "creating run (0.2s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/ephemeral/home/computervisioncompetition-cv-1/wandb/wandb/run-20250904_141244-bv3qvohp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/bv3qvohp' target=\"_blank\">fold-5-efficientnet_b3-1412</a></strong> to <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/bv3qvohp' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/bv3qvohp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Fold 5 Dashboard: https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/bv3qvohp\n",
      "Train samples: 1256, Validation samples: 314\n",
      " ëª¨ë¸ í•™ìŠµ ì‹œì‘ - Fold 5\n",
      "\n",
      "ğŸ“ˆ Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.9355, Mixup: False, Cutout: True, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:12<00:00,  3.30it/s]\n",
      "Val Loss: 1.6529: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  6.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  1 | Train Loss: 2.7624 | Train F1: 0.2126 | Val Loss: 1.7412 | Val F1: 0.6563 | LR: 5.00e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.6563\n",
      "\n",
      "ğŸ“ˆ Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.8926, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:12<00:00,  3.23it/s]\n",
      "Val Loss: 1.3612: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  2 | Train Loss: 2.0261 | Train F1: 0.4909 | Val Loss: 1.5387 | Val F1: 0.7353 | LR: 5.00e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.7353\n",
      "\n",
      "ğŸ“ˆ Epoch 3/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.2969, Mixup: True, Cutout: False, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.34it/s]\n",
      "Val Loss: 1.3089: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  3 | Train Loss: 1.7352 | Train F1: 0.6192 | Val Loss: 1.3878 | Val F1: 0.8100 | LR: 4.98e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.8100\n",
      "\n",
      "ğŸ“ˆ Epoch 4/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.5361, Mixup: False, Cutout: True, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.37it/s]\n",
      "Val Loss: 1.3109: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  6.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  4 | Train Loss: 1.7112 | Train F1: 0.6303 | Val Loss: 1.3461 | Val F1: 0.8285 | LR: 4.96e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.8285\n",
      "\n",
      "ğŸ“ˆ Epoch 5/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3574, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.47it/s]\n",
      "Val Loss: 1.2812: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  6.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  5 | Train Loss: 1.7267 | Train F1: 0.5866 | Val Loss: 1.3307 | Val F1: 0.8148 | LR: 4.92e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 6/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1572, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.42it/s]\n",
      "Val Loss: 1.2379: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  6.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  6 | Train Loss: 1.5679 | Train F1: 0.6875 | Val Loss: 1.2918 | Val F1: 0.8517 | LR: 4.88e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.8517\n",
      "\n",
      "ğŸ“ˆ Epoch 7/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2529, Mixup: False, Cutout: True, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.37it/s]\n",
      "Val Loss: 1.2492: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  7 | Train Loss: 1.4795 | Train F1: 0.7540 | Val Loss: 1.2708 | Val F1: 0.8522 | LR: 4.82e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.8522\n",
      "\n",
      "ğŸ“ˆ Epoch 8/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.4697, Mixup: False, Cutout: True, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.39it/s]\n",
      "Val Loss: 1.1615: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  6.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  8 | Train Loss: 1.4629 | Train F1: 0.7565 | Val Loss: 1.2640 | Val F1: 0.8596 | LR: 4.76e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.8596\n",
      "\n",
      "ğŸ“ˆ Epoch 9/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2588, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.35it/s]\n",
      "Val Loss: 1.1963: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  9 | Train Loss: 1.5054 | Train F1: 0.7526 | Val Loss: 1.2469 | Val F1: 0.8741 | LR: 4.69e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.8741\n",
      "\n",
      "ğŸ“ˆ Epoch 10/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.6211, Mixup: True, Cutout: False, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.40it/s]\n",
      "Val Loss: 1.1633: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 10 | Train Loss: 1.4817 | Train F1: 0.7619 | Val Loss: 1.2535 | Val F1: 0.8869 | LR: 4.61e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.8869\n",
      "\n",
      "ğŸ“ˆ Epoch 11/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3750, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.35it/s]\n",
      "Val Loss: 1.3525: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  6.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 11 | Train Loss: 1.3997 | Train F1: 0.7585 | Val Loss: 1.2848 | Val F1: 0.8614 | LR: 4.52e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 12/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2695, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.46it/s]\n",
      "Val Loss: 1.1373: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 12 | Train Loss: 1.4763 | Train F1: 0.7161 | Val Loss: 1.2270 | Val F1: 0.9088 | LR: 4.43e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.9088\n",
      "\n",
      "ğŸ“ˆ Epoch 13/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2090, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:12<00:00,  3.32it/s]\n",
      "Val Loss: 1.1939: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  6.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 13 | Train Loss: 1.3528 | Train F1: 0.7743 | Val Loss: 1.2157 | Val F1: 0.8764 | LR: 4.32e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 14/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3164, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.43it/s]\n",
      "Val Loss: 1.1363: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 14 | Train Loss: 1.4643 | Train F1: 0.7641 | Val Loss: 1.2076 | Val F1: 0.9108 | LR: 4.21e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.9108\n",
      "\n",
      "ğŸ“ˆ Epoch 15/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2383, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.38it/s]\n",
      "Val Loss: 1.1220: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 15 | Train Loss: 1.3732 | Train F1: 0.7885 | Val Loss: 1.1908 | Val F1: 0.8974 | LR: 4.09e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 16/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.4346, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.36it/s]\n",
      "Val Loss: 1.1410: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 16 | Train Loss: 1.3068 | Train F1: 0.8598 | Val Loss: 1.1995 | Val F1: 0.8938 | LR: 3.97e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 17/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3174, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.36it/s]\n",
      "Val Loss: 1.1914: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  6.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 17 | Train Loss: 1.3110 | Train F1: 0.8232 | Val Loss: 1.2235 | Val F1: 0.8738 | LR: 3.84e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 18/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2949, Mixup: False, Cutout: True, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.45it/s]\n",
      "Val Loss: 1.2511: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 18 | Train Loss: 1.3556 | Train F1: 0.7465 | Val Loss: 1.2125 | Val F1: 0.8836 | LR: 3.70e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 19/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.8818, Mixup: True, Cutout: False, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.51it/s]\n",
      "Val Loss: 1.0786: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  6.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 19 | Train Loss: 1.2831 | Train F1: 0.8257 | Val Loss: 1.1860 | Val F1: 0.9187 | LR: 3.56e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.9187\n",
      "\n",
      "ğŸ“ˆ Epoch 20/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.9238, Mixup: True, Cutout: False, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.40it/s]\n",
      "Val Loss: 1.1844: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 20 | Train Loss: 1.3251 | Train F1: 0.8176 | Val Loss: 1.1817 | Val F1: 0.8994 | LR: 3.42e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 21/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1494, Mixup: False, Cutout: True, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.45it/s]\n",
      "Val Loss: 1.1569: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  6.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 21 | Train Loss: 1.2949 | Train F1: 0.8863 | Val Loss: 1.2017 | Val F1: 0.8950 | LR: 3.27e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 22/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3594, Mixup: False, Cutout: True, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.40it/s]\n",
      "Val Loss: 1.1078: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 22 | Train Loss: 1.2776 | Train F1: 0.8350 | Val Loss: 1.1853 | Val F1: 0.9085 | LR: 3.12e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 23/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3389, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.42it/s]\n",
      "Val Loss: 1.1106: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 23 | Train Loss: 1.2519 | Train F1: 0.8617 | Val Loss: 1.1949 | Val F1: 0.9064 | LR: 2.97e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 24/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.0781, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:12<00:00,  3.33it/s]\n",
      "Val Loss: 1.0949: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  6.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 24 | Train Loss: 1.2630 | Train F1: 0.8128 | Val Loss: 1.1796 | Val F1: 0.9051 | LR: 2.81e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 25/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1357, Mixup: False, Cutout: True, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:12<00:00,  3.32it/s]\n",
      "Val Loss: 1.2270: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 25 | Train Loss: 1.3744 | Train F1: 0.7528 | Val Loss: 1.2108 | Val F1: 0.9086 | LR: 2.66e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 26/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.0850, Mixup: False, Cutout: True, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.39it/s]\n",
      "Val Loss: 1.0883: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 26 | Train Loss: 1.2285 | Train F1: 0.8618 | Val Loss: 1.1746 | Val F1: 0.9107 | LR: 2.50e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 27/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1123, Mixup: False, Cutout: True, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.42it/s]\n",
      "Val Loss: 1.1326: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 27 | Train Loss: 1.2462 | Train F1: 0.8905 | Val Loss: 1.1680 | Val F1: 0.9225 | LR: 2.34e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.9225\n",
      "\n",
      "ğŸ“ˆ Epoch 28/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2061, Mixup: False, Cutout: True, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.48it/s]\n",
      "Val Loss: 1.1289: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 28 | Train Loss: 1.3409 | Train F1: 0.8292 | Val Loss: 1.1839 | Val F1: 0.9176 | LR: 2.19e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 29/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.0215, Mixup: True, Cutout: False, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.48it/s]\n",
      "Val Loss: 1.1152: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 29 | Train Loss: 1.2753 | Train F1: 0.8468 | Val Loss: 1.1763 | Val F1: 0.9197 | LR: 2.03e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 30/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2578, Mixup: False, Cutout: True, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.45it/s]\n",
      "Val Loss: 1.1309: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 30 | Train Loss: 1.2594 | Train F1: 0.8682 | Val Loss: 1.1656 | Val F1: 0.9186 | LR: 1.88e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 31/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3359, Mixup: True, Cutout: False, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.40it/s]\n",
      "Val Loss: 1.0970: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 31 | Train Loss: 1.2802 | Train F1: 0.8409 | Val Loss: 1.1863 | Val F1: 0.9024 | LR: 1.73e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 32/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2568, Mixup: False, Cutout: True, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.39it/s]\n",
      "Val Loss: 1.1469: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 32 | Train Loss: 1.3748 | Train F1: 0.7990 | Val Loss: 1.1905 | Val F1: 0.9157 | LR: 1.58e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 33/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2646, Mixup: True, Cutout: False, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.42it/s]\n",
      "Val Loss: 1.1174: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 33 | Train Loss: 1.2042 | Train F1: 0.9241 | Val Loss: 1.1716 | Val F1: 0.9141 | LR: 1.44e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 34/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2031, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.42it/s]\n",
      "Val Loss: 1.1391: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  6.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 34 | Train Loss: 1.2345 | Train F1: 0.8598 | Val Loss: 1.1756 | Val F1: 0.9033 | LR: 1.30e-04\n",
      "â¸ï¸ Early stopping at epoch 34 (patience: 7)\n",
      "\n",
      " Fold 5 ì™„ë£Œ!\n",
      " ìµœê³  Validation F1: 0.9225\n",
      " í•™ìŠµëœ ì—í­: 34/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>best_performance/epoch</td><td>â–â–â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–…â–†â–ˆ</td></tr><tr><td>best_performance/val_acc</td><td>â–â–ƒâ–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–ˆâ–ˆ</td></tr><tr><td>best_performance/val_f1</td><td>â–â–ƒâ–…â–†â–†â–†â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>best_performance/val_loss</td><td>â–ˆâ–†â–„â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–â–</td></tr><tr><td>early_stopping/epoch</td><td>â–</td></tr><tr><td>epoch</td><td>â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>fold</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>fold_5/batch_step</td><td>â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>fold_5/cutout_applied</td><td>â–ˆâ–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–</td></tr><tr><td>fold_5/mixup_applied</td><td>â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–ˆâ–â–ˆâ–â–â–â–ˆâ–â–â–â–â–â–ˆâ–â–ˆâ–â–â–â–â–â–â–</td></tr><tr><td>+22</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_performance/epoch</td><td>27</td></tr><tr><td>best_performance/val_acc</td><td>0.92994</td></tr><tr><td>best_performance/val_f1</td><td>0.92248</td></tr><tr><td>best_performance/val_loss</td><td>1.16797</td></tr><tr><td>early_stopping/epoch</td><td>34</td></tr><tr><td>epoch</td><td>34</td></tr><tr><td>fold</td><td>5</td></tr><tr><td>fold_5/batch_step</td><td>1320</td></tr><tr><td>fold_5/cutout_applied</td><td>0</td></tr><tr><td>fold_5/mixup_applied</td><td>0</td></tr><tr><td>+23</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fold-5-efficientnet_b3-1412</strong> at: <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/bv3qvohp' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/bv3qvohp</a><br> View project at: <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250904_141244-bv3qvohp/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# 10. K-Fold Cross Validation Loop with WandB\n",
    "# =============================================================================\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(train_df, train_df['target'])):\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\" FOLD {fold + 1}/{N_FOLDS}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    # ê° foldë³„ child run ìƒì„±\n",
    "    fold_run = wandb.init(\n",
    "        project=PROJECT_NAME,\n",
    "        entity=ENTITY,\n",
    "        name=f\"fold-{fold+1}-{model_name}-{datetime.now().strftime('%H%M')}\",\n",
    "        config=config,\n",
    "        tags=[\"fold\", f\"fold-{fold+1}\", model_name, \"child-run\"],\n",
    "        group=\"k-fold-experiment\",\n",
    "        job_type=f\"fold-{fold+1}\",\n",
    "        reinit=True  # ìƒˆë¡œìš´ run ì‹œì‘ í—ˆìš©\n",
    "    )\n",
    "    \n",
    "    print(f\"ğŸ“Š Fold {fold+1} Dashboard: {fold_run.url}\")\n",
    "    \n",
    "    # í˜„ì¬ foldì˜ train/validation ë°ì´í„° ë¶„í• \n",
    "    train_fold_df = train_df.iloc[train_idx].reset_index(drop=True)\n",
    "    val_fold_df = train_df.iloc[val_idx].reset_index(drop=True)\n",
    "    \n",
    "    # ë°ì´í„° ë¶„í•  ì •ë³´ ë¡œê¹…\n",
    "    wandb.log({\n",
    "        \"fold_info/fold_number\": fold + 1,\n",
    "        \"fold_info/train_samples\": len(train_fold_df),\n",
    "        \"fold_info/val_samples\": len(val_fold_df),\n",
    "        \"fold_info/train_ratio\": len(train_fold_df) / len(train_df),\n",
    "        \"fold_info/val_ratio\": len(val_fold_df) / len(train_df)\n",
    "    })\n",
    "    \n",
    "    # í˜„ì¬ foldì˜ Dataset ìƒì„±\n",
    "    trn_dataset = ImageDataset(\n",
    "        train_fold_df,\n",
    "        \"../data/train/\",\n",
    "        transform=trn_transform\n",
    "    )\n",
    "    \n",
    "    val_dataset = ImageDataset(\n",
    "        val_fold_df,\n",
    "        \"../data/train/\",\n",
    "        transform=tst_transform  # ê²€ì¦ì—ëŠ” ì¦ê°• ì ìš© ì•ˆí•¨\n",
    "    )\n",
    "    \n",
    "    # í˜„ì¬ foldì˜ DataLoader ìƒì„±\n",
    "    trn_loader = DataLoader(\n",
    "        trn_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=False\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    print(f\"Train samples: {len(trn_dataset)}, Validation samples: {len(val_dataset)}\")\n",
    "    \n",
    "    # ëª¨ë¸ ì´ˆê¸°í™” (ê° foldë§ˆë‹¤ ìƒˆë¡œìš´ ëª¨ë¸)\n",
    "    model = timm.create_model(\n",
    "        model_name,\n",
    "        pretrained=True,\n",
    "        num_classes=17\n",
    "    ).to(device)\n",
    "    \n",
    "    loss_fn = nn.CrossEntropyLoss(label_smoothing=0.2)  # Label Smoothing ì ìš©\n",
    "    optimizer = Adam(model.parameters(), lr=LR)\n",
    "    \n",
    "    # Learning Rate Scheduler ì¶”ê°€\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "    \n",
    "    # í˜„ì¬ foldì˜ ìµœê³  ì„±ëŠ¥ ì¶”ì \n",
    "    best_val_f1 = 0.0\n",
    "    best_model = None\n",
    "    patience = 0\n",
    "    max_patience = 7\n",
    "    \n",
    "    print(f\" ëª¨ë¸ í•™ìŠµ ì‹œì‘ - Fold {fold+1}\")\n",
    "    \n",
    "    # =============================================================================\n",
    "    # 11. Training Loop for Current Fold\n",
    "    # =============================================================================\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        print(f\"\\nğŸ“ˆ Epoch {epoch+1}/{EPOCHS}\")\n",
    "        \n",
    "        # Training\n",
    "        train_ret = train_one_epoch(\n",
    "            trn_loader, model, optimizer, loss_fn, device, \n",
    "            epoch=epoch, fold=fold+1\n",
    "        )\n",
    "        \n",
    "        # Validation\n",
    "        val_ret = validate_one_epoch(\n",
    "            val_loader, model, loss_fn, device, \n",
    "            epoch=epoch, fold=fold+1,\n",
    "            log_confusion=(epoch == EPOCHS-1)  # ë§ˆì§€ë§‰ epochì—ë§Œ confusion matrix\n",
    "        )\n",
    "        \n",
    "        # Learning rate ë¡œê¹…\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        \n",
    "        # WandBì— metrics ë¡œê¹…\n",
    "        log_data = {\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"fold\": fold + 1,\n",
    "            \"train/loss\": train_ret['train_loss'],\n",
    "            \"train/accuracy\": train_ret['train_acc'], \n",
    "            \"train/f1\": train_ret['train_f1'],\n",
    "            \"val/loss\": val_ret['val_loss'],\n",
    "            \"val/accuracy\": val_ret['val_acc'],\n",
    "            \"val/f1\": val_ret['val_f1'],\n",
    "            \"learning_rate\": current_lr,\n",
    "            \"optimizer/lr\": current_lr\n",
    "        }\n",
    "        \n",
    "        # GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë¡œê¹…\n",
    "        if torch.cuda.is_available():\n",
    "            gpu_memory_used = torch.cuda.memory_allocated(0) / 1e9\n",
    "            gpu_memory_total = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "            log_data.update({\n",
    "                \"system/gpu_memory_used_gb\": gpu_memory_used,\n",
    "                \"system/gpu_memory_total_gb\": gpu_memory_total,\n",
    "                \"system/gpu_utilization_pct\": (gpu_memory_used / gpu_memory_total) * 100\n",
    "            })\n",
    "        \n",
    "        wandb.log(log_data)\n",
    "        \n",
    "        # Scheduler step\n",
    "        scheduler.step()\n",
    "        \n",
    "        print(f\" Epoch {epoch+1:2d} | \"\n",
    "              f\"Train Loss: {train_ret['train_loss']:.4f} | \"\n",
    "              f\"Train F1: {train_ret['train_f1']:.4f} | \"\n",
    "              f\"Val Loss: {val_ret['val_loss']:.4f} | \"\n",
    "              f\"Val F1: {val_ret['val_f1']:.4f} | \"\n",
    "              f\"LR: {current_lr:.2e}\")\n",
    "        \n",
    "        # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥\n",
    "        if val_ret['val_f1'] > best_val_f1:\n",
    "            best_val_f1 = val_ret['val_f1']\n",
    "            best_model = copy.deepcopy(model.state_dict())\n",
    "            patience = 0\n",
    "            \n",
    "            # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì•„í‹°íŒ©íŠ¸ë¡œ ì €ì¥\n",
    "            model_path = f'best_model_fold_{fold+1}.pth'\n",
    "            torch.save(best_model, model_path)\n",
    "            wandb.save(model_path, policy=\"now\")\n",
    "            \n",
    "            # ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥ ë¡œê¹…\n",
    "            wandb.log({\n",
    "                f\"best_performance/epoch\": epoch + 1,\n",
    "                f\"best_performance/val_f1\": best_val_f1,\n",
    "                f\"best_performance/val_acc\": val_ret['val_acc'],\n",
    "                f\"best_performance/val_loss\": val_ret['val_loss'],\n",
    "            })\n",
    "            \n",
    "            print(f\"ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: {best_val_f1:.4f}\")\n",
    "        else:\n",
    "            patience += 1\n",
    "            \n",
    "        # Early stopping (ì„ íƒì )\n",
    "        if patience >= max_patience and epoch > EPOCHS // 2:\n",
    "            print(f\"â¸ï¸ Early stopping at epoch {epoch+1} (patience: {patience})\")\n",
    "            wandb.log({\"early_stopping/epoch\": epoch + 1})\n",
    "            break\n",
    "    \n",
    "    # =============================================================================\n",
    "    # 12. Fold Results Summary\n",
    "    # =============================================================================\n",
    "    \n",
    "    # í˜„ì¬ fold ê²°ê³¼ ì €ì¥\n",
    "    fold_result = {\n",
    "        'fold': fold + 1,\n",
    "        'best_val_f1': best_val_f1,\n",
    "        'final_train_f1': train_ret['train_f1'],\n",
    "        'train_samples': len(trn_dataset),\n",
    "        'val_samples': len(val_dataset),\n",
    "        'epochs_trained': epoch + 1,\n",
    "        'early_stopped': patience >= max_patience\n",
    "    }\n",
    "    \n",
    "    fold_results.append(fold_result)\n",
    "    fold_models.append(best_model)\n",
    "    \n",
    "    # Fold ìµœì¢… ìš”ì•½ ë¡œê¹…\n",
    "    wandb.log({\n",
    "        \"fold_summary/best_val_f1\": best_val_f1,\n",
    "        \"fold_summary/final_train_f1\": train_ret['train_f1'],\n",
    "        \"fold_summary/epochs_trained\": epoch + 1,\n",
    "        \"fold_summary/improvement\": best_val_f1 - val_ret['val_f1'],\n",
    "        \"fold_summary/early_stopped\": patience >= max_patience\n",
    "    })\n",
    "    \n",
    "    print(f\"\\n Fold {fold + 1} ì™„ë£Œ!\")\n",
    "    print(f\" ìµœê³  Validation F1: {best_val_f1:.4f}\")\n",
    "    print(f\" í•™ìŠµëœ ì—í­: {epoch + 1}/{EPOCHS}\")\n",
    "    \n",
    "    # Fold run ì¢…ë£Œ\n",
    "    wandb.finish()\n",
    "    \n",
    "    # ë©”ëª¨ë¦¬ ì •ë¦¬\n",
    "    del model, optimizer, scheduler, trn_loader, val_loader\n",
    "    torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5545246d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      " K-FOLD CROSS VALIDATION ìµœì¢… ê²°ê³¼\n",
      "============================================================\n",
      " í™œì„±í™”ëœ runì´ ì—†ì–´ ìƒˆë¡œìš´ summary runì„ ìƒì„±í•©ë‹ˆë‹¤.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "creating run (0.1s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/ephemeral/home/computervisioncompetition-cv-1/wandb/wandb/run-20250904_142047-j2u6fpe8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/j2u6fpe8' target=\"_blank\">SUMMARY-efficientnet-b3-baseline-0904-1420</a></strong> to <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/j2u6fpe8' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/j2u6fpe8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " CV ê²°ê³¼ ë¡œê¹… ì™„ë£Œ!\n",
      "Fold 1: 0.9271 (27 epochs)  Early Stopped\n",
      "Fold 2: 0.9412 (48 epochs)  Early Stopped\n",
      "Fold 3: 0.9322 (34 epochs)  Early Stopped\n",
      "Fold 4: 0.9186 (27 epochs)  Early Stopped\n",
      "Fold 5: 0.9225 (34 epochs)  Early Stopped\n",
      "\n",
      " í‰ê·  CV F1: 0.9283 Â± 0.0079\n",
      " ìµœê³  Fold: 0.9412\n",
      " ìµœì•… Fold: 0.9186\n",
      " ì„±ëŠ¥ ë²”ìœ„: 0.0227\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 13. K-Fold Cross Validation Results Summary\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\" K-FOLD CROSS VALIDATION ìµœì¢… ê²°ê³¼\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "val_f1_scores = [result['best_val_f1'] for result in fold_results]\n",
    "mean_f1 = np.mean(val_f1_scores)\n",
    "std_f1 = np.std(val_f1_scores)\n",
    "\n",
    "try:\n",
    "    # wandb.runì´ í˜„ì¬ í™œì„±í™”ëœ runì„ ê°€ë¦¬í‚´\n",
    "    if wandb.run is None:\n",
    "        print(\" í™œì„±í™”ëœ runì´ ì—†ì–´ ìƒˆë¡œìš´ summary runì„ ìƒì„±í•©ë‹ˆë‹¤.\")\n",
    "        active_run = wandb.init(\n",
    "            project=PROJECT_NAME,\n",
    "            name=f\"SUMMARY-{EXPERIMENT_NAME}-{datetime.now().strftime('%m%d-%H%M')}\",\n",
    "            config=config,\n",
    "            tags=[\"summary\", \"cv-results\", model_name],\n",
    "            group=\"k-fold-experiment\",\n",
    "            job_type=\"summary\",\n",
    "            reinit=True\n",
    "        )\n",
    "    else:\n",
    "        print(\" ê¸°ì¡´ runì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\")\n",
    "        active_run = wandb.run\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\" Run ìƒíƒœ í™•ì¸ ì¤‘ ì—ëŸ¬: {e}\")\n",
    "    # ìƒˆë¡œìš´ run ìƒì„±\n",
    "    active_run = wandb.init(\n",
    "        project=PROJECT_NAME,\n",
    "        name=f\"SUMMARY-{EXPERIMENT_NAME}-{datetime.now().strftime('%m%d-%H%M')}\",\n",
    "        config=config,\n",
    "        tags=[\"summary\", \"cv-results\", model_name],\n",
    "        group=\"k-fold-experiment\",\n",
    "        job_type=\"summary\",\n",
    "        reinit=True\n",
    "    )\n",
    "\n",
    "# CV ìš”ì•½ í…Œì´ë¸” ìƒì„±\n",
    "fold_table = wandb.Table(columns=[\n",
    "    \"Fold\", \"Best_Val_F1\", \"Final_Train_F1\", \"Train_Samples\", \n",
    "    \"Val_Samples\", \"Epochs_Trained\", \"Early_Stopped\"\n",
    "])\n",
    "\n",
    "for result in fold_results:\n",
    "    fold_table.add_data(\n",
    "        result['fold'], \n",
    "        result['best_val_f1'], \n",
    "        result['final_train_f1'],\n",
    "        result['train_samples'], \n",
    "        result['val_samples'],\n",
    "        result['epochs_trained'],\n",
    "        result['early_stopped']\n",
    "    )\n",
    "\n",
    "# ì•ˆì „í•œ ë¡œê¹…\n",
    "try:\n",
    "    active_run.log({\n",
    "        \"cv_results/mean_f1\": mean_f1,\n",
    "        \"cv_results/std_f1\": std_f1,\n",
    "        \"cv_results/best_fold_f1\": max(val_f1_scores),\n",
    "        \"cv_results/worst_fold_f1\": min(val_f1_scores),\n",
    "        \"cv_results/f1_range\": max(val_f1_scores) - min(val_f1_scores),\n",
    "        \"cv_results/fold_results_table\": fold_table,\n",
    "        \"cv_results/n_folds\": N_FOLDS,\n",
    "        \"cv_results/total_epochs\": sum([r['epochs_trained'] for r in fold_results]),\n",
    "        \"cv_results/avg_epochs_per_fold\": np.mean([r['epochs_trained'] for r in fold_results]),\n",
    "        \"cv_results/early_stopped_folds\": sum([r['early_stopped'] for r in fold_results])\n",
    "    })\n",
    "    \n",
    "    # Foldë³„ ì„±ëŠ¥ ë°”ì°¨íŠ¸ ìƒì„±\n",
    "    fold_performance_data = [[f\"Fold {i+1}\", score] for i, score in enumerate(val_f1_scores)]\n",
    "    active_run.log({\n",
    "        \"cv_results/fold_performance_chart\": wandb.plot.bar(\n",
    "            wandb.Table(data=fold_performance_data, columns=[\"Fold\", \"F1_Score\"]),\n",
    "            \"Fold\", \"F1_Score\", \n",
    "            title=\"K-Fold Cross Validation Performance\"\n",
    "        )\n",
    "    })\n",
    "    \n",
    "    print(\" CV ê²°ê³¼ ë¡œê¹… ì™„ë£Œ!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\" WandB ë¡œê¹… ì¤‘ ì—ëŸ¬: {e}\")\n",
    "    print(\" ê²°ê³¼ë¥¼ ì½˜ì†”ì— ì¶œë ¥í•©ë‹ˆë‹¤:\")\n",
    "\n",
    "# ì–´ë–¤ ê²½ìš°ë“  ì½˜ì†”ì—ëŠ” ê²°ê³¼ ì¶œë ¥\n",
    "for result in fold_results:\n",
    "    status = \" Early Stopped\" if result['early_stopped'] else \" Completed\"\n",
    "    print(f\"Fold {result['fold']}: {result['best_val_f1']:.4f} \"\n",
    "          f\"({result['epochs_trained']} epochs) {status}\")\n",
    "\n",
    "print(f\"\\n í‰ê·  CV F1: {mean_f1:.4f} Â± {std_f1:.4f}\")\n",
    "print(f\" ìµœê³  Fold: {max(val_f1_scores):.4f}\")\n",
    "print(f\" ìµœì•… Fold: {min(val_f1_scores):.4f}\")\n",
    "print(f\" ì„±ëŠ¥ ë²”ìœ„: {max(val_f1_scores) - min(val_f1_scores):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0c1ddb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”§ ì•™ìƒë¸” ëª¨ë¸ ì¤€ë¹„ ì¤‘...\n",
      "Fold 1 ëª¨ë¸ ë¡œë“œ ì™„ë£Œ\n",
      "Fold 2 ëª¨ë¸ ë¡œë“œ ì™„ë£Œ\n",
      "Fold 3 ëª¨ë¸ ë¡œë“œ ì™„ë£Œ\n",
      "Fold 4 ëª¨ë¸ ë¡œë“œ ì™„ë£Œ\n",
      "Fold 5 ëª¨ë¸ ë¡œë“œ ì™„ë£Œ\n",
      " ì´ 5ê°œ ëª¨ë¸ë¡œ ì•™ìƒë¸” êµ¬ì„±\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# 14. Ensemble Models Preparation\n",
    "# =============================================================================\n",
    "\n",
    "# 5-Fold ì•™ìƒë¸” ëª¨ë¸ ì¤€ë¹„\n",
    "ensemble_models = []\n",
    "print(f\"\\nğŸ”§ ì•™ìƒë¸” ëª¨ë¸ ì¤€ë¹„ ì¤‘...\")\n",
    "\n",
    "for i, state_dict in enumerate(fold_models):\n",
    "    fold_model = timm.create_model(model_name, pretrained=True, num_classes=17).to(device)\n",
    "    fold_model.load_state_dict(state_dict)\n",
    "    fold_model.eval()\n",
    "    ensemble_models.append(fold_model)\n",
    "    print(f\"Fold {i+1} ëª¨ë¸ ë¡œë“œ ì™„ë£Œ\")\n",
    "\n",
    "print(f\" ì´ {len(ensemble_models)}ê°œ ëª¨ë¸ë¡œ ì•™ìƒë¸” êµ¬ì„±\")\n",
    "\n",
    "try:\n",
    "    if wandb.run is not None:\n",
    "        wandb.run.log({\n",
    "            \"ensemble/num_models\": len(ensemble_models),\n",
    "            \"ensemble/model_architecture\": model_name,\n",
    "            \"ensemble/ensemble_type\": \"simple_average\"\n",
    "        })\n",
    "    else:\n",
    "        print(\"ğŸ“Š ì•™ìƒë¸” ì •ë³´:\")\n",
    "        print(f\"  - ëª¨ë¸ ê°œìˆ˜: {len(ensemble_models)}\")\n",
    "        print(f\"  - ì•„í‚¤í…ì²˜: {model_name}\")\n",
    "        print(f\"  - ì•™ìƒë¸” íƒ€ì…: simple_average\")\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ ì•™ìƒë¸” ì •ë³´ ë¡œê¹… ì‹¤íŒ¨: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c98e388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " TTA (Test Time Augmentation) ì„¤ì •...\n",
      "TTA ë³€í™˜ 5ê°œ ì¤€ë¹„ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# 15. TTA (Test Time Augmentation) Setup\n",
    "# =============================================================================\n",
    "\n",
    "# Temperature Scaling í´ë˜ìŠ¤ ì •ì˜\n",
    "class TemperatureScaling(nn.Module):\n",
    "    def __init__(self, temperature=1.5):\n",
    "        super().__init__()\n",
    "        self.temperature = nn.Parameter(torch.ones(1) * temperature)\n",
    "    \n",
    "    def forward(self, logits):\n",
    "        return logits / self.temperature\n",
    "\n",
    "print(f\"\\n TTA (Test Time Augmentation) ì„¤ì •...\")\n",
    "\n",
    "# Essential TTA transforms\n",
    "essential_tta_transforms = [\n",
    "    # ì›ë³¸\n",
    "    A.Compose([\n",
    "        A.LongestMaxSize(max_size=img_size),\n",
    "        A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "    # 90ë„ íšŒì „ë“¤\n",
    "    A.Compose([\n",
    "        A.LongestMaxSize(max_size=img_size),\n",
    "        A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "        A.Rotate(limit=[90, 90], p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "    A.Compose([\n",
    "        A.LongestMaxSize(max_size=img_size),\n",
    "        A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "        A.Rotate(limit=[180, 180], p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "    A.Compose([\n",
    "        A.LongestMaxSize(max_size=img_size),\n",
    "        A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "        A.Rotate(limit=[-90, -90], p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "    # ë°ê¸° ê°œì„ \n",
    "    A.Compose([\n",
    "        A.LongestMaxSize(max_size=img_size),\n",
    "        A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "        A.RandomBrightnessContrast(brightness_limit=[0.3, 0.3], contrast_limit=[0.3, 0.3], p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "]\n",
    "\n",
    "print(f\"TTA ë³€í™˜ {len(essential_tta_transforms)}ê°œ ì¤€ë¹„ ì™„ë£Œ\")\n",
    "\n",
    "try:\n",
    "    if wandb.run is not None:\n",
    "        wandb.run.log({\n",
    "            \"tta/num_transforms\": len(essential_tta_transforms),\n",
    "            \"tta/transforms_used\": [\"original\", \"rot_90\", \"rot_180\", \"rot_270\", \"brightness\"],\n",
    "            \"tta/batch_size\": 64  # TTAìš© ë°°ì¹˜ í¬ê¸°\n",
    "        })\n",
    "    else:\n",
    "        print(\"ğŸ“Š TTA ì„¤ì • ì •ë³´:\")\n",
    "        print(f\"  - ë³€í˜• ê°œìˆ˜: {len(essential_tta_transforms)}\")\n",
    "        print(f\"  - ë³€í˜• ì¢…ë¥˜: original, rot_90, rot_180, rot_270, brightness\")\n",
    "        print(f\"  - ë°°ì¹˜ í¬ê¸°: 64\")\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ TTA ì„¤ì • ë¡œê¹… ì‹¤íŒ¨: {e}\")\n",
    "    print(\"ğŸ“Š TTA ì„¤ì • ì •ë³´:\")\n",
    "    print(f\"  - ë³€í˜• ê°œìˆ˜: {len(essential_tta_transforms)}\")\n",
    "    print(f\"  - ë°°ì¹˜ í¬ê¸°: 64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5f6fc07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " TTA Dataset: 3140ê°œ í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 16. TTA Dataset and DataLoader\n",
    "# =============================================================================\n",
    "\n",
    "class TTAImageDataset(Dataset):\n",
    "    def __init__(self, data, path, transforms):\n",
    "        if isinstance(data, str):\n",
    "            self.df = pd.read_csv(data).values\n",
    "        else:\n",
    "            self.df = data.values\n",
    "        self.path = path\n",
    "        self.transforms = transforms  # ì—¬ëŸ¬ transformì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë°›ìŒ\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        name, target = self.df[idx]\n",
    "        img = np.array(Image.open(os.path.join(self.path, name)))\n",
    "        \n",
    "        # ëª¨ë“  transformì„ ì ìš©í•œ ê²°ê³¼ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜\n",
    "        augmented_images = []\n",
    "        for transform in self.transforms:\n",
    "            aug_img = transform(image=img)['image']\n",
    "            augmented_images.append(aug_img)\n",
    "        \n",
    "        return augmented_images, target\n",
    "\n",
    "# TTA Dataset ìƒì„±\n",
    "tta_dataset = TTAImageDataset(\n",
    "    \"../data/sample_submission.csv\",\n",
    "    \"../data/test/\",\n",
    "    essential_tta_transforms\n",
    ")\n",
    "\n",
    "# TTA DataLoader (ë°°ì¹˜ í¬ê¸°ë¥¼ ì¤„ì—¬ì„œ ë©”ëª¨ë¦¬ ì ˆì•½)\n",
    "tta_loader = DataLoader(\n",
    "    tta_dataset,\n",
    "    batch_size=64,  # TTAëŠ” ë©”ëª¨ë¦¬ë¥¼ ë§ì´ ì‚¬ìš©í•˜ë¯€ë¡œ ë°°ì¹˜ í¬ê¸° ì¤„ì„\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\" TTA Dataset: {len(tta_dataset)}ê°œ í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "45382398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      " ìµœì¢… ì¶”ë¡  - ì•™ìƒë¸” + TTA\n",
      "============================================================\n",
      "ì•™ìƒë¸” TTA ì¶”ë¡  ì‹œì‘...\n",
      "5ê°œ ëª¨ë¸ Ã— 5ê°œ TTA ë³€í˜• = 25ê°œ ì˜ˆì¸¡ í‰ê· \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ensemble TTA: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [02:51<00:00,  3.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ì•™ìƒë¸” TTA ì¶”ë¡  ì™„ë£Œ!\n",
      "ì´ ì†Œìš”ì‹œê°„: 2.9ë¶„\n",
      " í‰ê·  ì‹ ë¢°ë„: 0.4164 Â± 0.0929\n",
      " ê³ ì‹ ë¢°ë„ ìƒ˜í”Œ: 0/3140 (0.0%)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# 17. Ensemble + TTA Inference with WandB Logging\n",
    "# =============================================================================\n",
    "\n",
    "def ensemble_tta_inference_with_logging(models, loader, transforms, confidence_threshold=0.9):\n",
    "    \"\"\"5-Fold ëª¨ë¸ ì•™ìƒë¸” + TTA ì¶”ë¡  with WandB ë¡œê¹…\"\"\"\n",
    "    all_predictions = []\n",
    "    all_confidences = []\n",
    "    \n",
    "    # TTA ì§„í–‰ìƒí™© ë¡œê¹…ì„ ìœ„í•œ í…Œì´ë¸”\n",
    "    tta_progress = wandb.Table(columns=[\"Batch\", \"Avg_Confidence\", \"Low_Conf_Count\", \"High_Conf_Count\"])\n",
    "    \n",
    "    # Temperature scaling ì´ˆê¸°í™”\n",
    "    temp_scaling = TemperatureScaling().to(device)\n",
    "    \n",
    "    print(f\"ì•™ìƒë¸” TTA ì¶”ë¡  ì‹œì‘...\")\n",
    "    print(f\"{len(models)}ê°œ ëª¨ë¸ Ã— {len(transforms)}ê°œ TTA ë³€í˜• = {len(models) * len(transforms)}ê°œ ì˜ˆì¸¡ í‰ê· \")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    for batch_idx, (images_list, _) in enumerate(tqdm(loader, desc=\"Ensemble TTA\")):\n",
    "        batch_size = images_list[0].size(0)\n",
    "        ensemble_probs = torch.zeros(batch_size, 17).to(device)\n",
    "        \n",
    "        # ê° fold ëª¨ë¸ë³„ ì˜ˆì¸¡\n",
    "        for model_idx, model in enumerate(models):\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                # ê° TTA ë³€í˜•ë³„ ì˜ˆì¸¡\n",
    "                for tta_idx, images in enumerate(images_list):\n",
    "                    images = images.to(device)\n",
    "                    preds = model(images)\n",
    "                    \n",
    "                    # Temperature scaling ì ìš©\n",
    "                    preds = temp_scaling(preds)\n",
    "                    probs = torch.softmax(preds, dim=1)\n",
    "                    \n",
    "                    # ì•™ìƒë¸” í™•ë¥ ì— ëˆ„ì  (í‰ê· )\n",
    "                    ensemble_probs += probs / (len(models) * len(images_list))\n",
    "        \n",
    "        # ì‹ ë¢°ë„ ê³„ì‚°\n",
    "        max_probs = torch.max(ensemble_probs, dim=1)[0]\n",
    "        batch_confidences = max_probs.cpu().numpy()\n",
    "        all_confidences.extend(batch_confidences)\n",
    "        \n",
    "        final_preds = torch.argmax(ensemble_probs, dim=1)\n",
    "        all_predictions.extend(final_preds.cpu().numpy())\n",
    "        \n",
    "        # ë°°ì¹˜ë³„ ì‹ ë¢°ë„ ë¶„ì„\n",
    "        high_conf_count = np.sum(batch_confidences >= confidence_threshold)\n",
    "        low_conf_count = batch_size - high_conf_count\n",
    "        avg_confidence = np.mean(batch_confidences)\n",
    "        \n",
    "        # ì§„í–‰ìƒí™© í…Œì´ë¸”ì— ì¶”ê°€\n",
    "        tta_progress.add_data(batch_idx, avg_confidence, low_conf_count, high_conf_count)\n",
    "        \n",
    "        # ë°°ì¹˜ë³„ ìƒì„¸ ë¡œê¹… (20ë°°ì¹˜ë§ˆë‹¤)\n",
    "        if batch_idx % 20 == 0:\n",
    "            elapsed_time = time.time() - start_time\n",
    "            estimated_total = elapsed_time * len(loader) / (batch_idx + 1)\n",
    "            remaining_time = estimated_total - elapsed_time\n",
    "            \n",
    "            wandb.log({\n",
    "                \"tta_progress/batch\": batch_idx,\n",
    "                \"tta_progress/avg_confidence\": avg_confidence,\n",
    "                \"tta_progress/high_confidence_ratio\": high_conf_count / batch_size,\n",
    "                \"tta_progress/low_confidence_count\": low_conf_count,\n",
    "                \"tta_progress/elapsed_time_min\": elapsed_time / 60,\n",
    "                \"tta_progress/estimated_remaining_min\": remaining_time / 60,\n",
    "                \"tta_progress/samples_processed\": (batch_idx + 1) * batch_size,\n",
    "            })\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    \n",
    "    # TTA ìµœì¢… ê²°ê³¼ ë¡œê¹…\n",
    "    final_avg_confidence = np.mean(all_confidences)\n",
    "    confidence_std = np.std(all_confidences)\n",
    "    high_conf_samples = np.sum(np.array(all_confidences) >= confidence_threshold)\n",
    "    \n",
    "    wandb.log({\n",
    "        \"tta_results/total_time_min\": total_time / 60,\n",
    "        \"tta_results/samples_per_second\": len(all_predictions) / total_time,\n",
    "        \"tta_results/final_avg_confidence\": final_avg_confidence,\n",
    "        \"tta_results/confidence_std\": confidence_std,\n",
    "        \"tta_results/high_confidence_samples\": high_conf_samples,\n",
    "        \"tta_results/high_confidence_ratio\": high_conf_samples / len(all_predictions),\n",
    "        \"tta_results/total_predictions\": len(all_predictions),\n",
    "        \"tta_results/confidence_histogram\": wandb.Histogram(all_confidences),\n",
    "        \"tta_results/progress_table\": tta_progress\n",
    "    })\n",
    "    \n",
    "    print(f\"\\n ì•™ìƒë¸” TTA ì¶”ë¡  ì™„ë£Œ!\")\n",
    "    print(f\"ì´ ì†Œìš”ì‹œê°„: {total_time/60:.1f}ë¶„\")\n",
    "    print(f\" í‰ê·  ì‹ ë¢°ë„: {final_avg_confidence:.4f} Â± {confidence_std:.4f}\")\n",
    "    print(f\" ê³ ì‹ ë¢°ë„ ìƒ˜í”Œ: {high_conf_samples}/{len(all_predictions)} ({high_conf_samples/len(all_predictions)*100:.1f}%)\")\n",
    "    \n",
    "    return all_predictions, all_confidences\n",
    "\n",
    "# ì•™ìƒë¸” TTA ì‹¤í–‰\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\" ìµœì¢… ì¶”ë¡  - ì•™ìƒë¸” + TTA\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "tta_predictions, confidences = ensemble_tta_inference_with_logging(\n",
    "    models=ensemble_models, \n",
    "    loader=tta_loader, \n",
    "    transforms=essential_tta_transforms,\n",
    "    confidence_threshold=0.9\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6e9072c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ìµœì¢… ê²°ê³¼ ì •ë¦¬ ì¤‘...\n",
      "\n",
      "ğŸ“Š ì˜ˆì¸¡ ê²°ê³¼ ë¶„í¬:\n",
      "Class  0:  200 (  6.4%)\n",
      "Class  1:   91 (  2.9%)\n",
      "Class  2:  200 (  6.4%)\n",
      "Class  3:  258 (  8.2%)\n",
      "Class  4:  199 (  6.3%)\n",
      "Class  5:  200 (  6.4%)\n",
      "Class  6:  203 (  6.5%)\n",
      "Class  7:  142 (  4.5%)\n",
      "Class  8:  200 (  6.4%)\n",
      "Class  9:  200 (  6.4%)\n",
      "Class 10:  210 (  6.7%)\n",
      "Class 11:  191 (  6.1%)\n",
      "Class 12:  199 (  6.3%)\n",
      "Class 13:  158 (  5.0%)\n",
      "Class 14:   89 (  2.8%)\n",
      "Class 15:  200 (  6.4%)\n",
      "Class 16:  200 (  6.4%)\n",
      "ìµœì¢… ê²°ê³¼ WandB ë¡œê¹… ì™„ë£Œ!\n",
      "ì´ ì˜ˆì¸¡ ìˆ˜: 3140\n",
      "ì˜ˆì¸¡ëœ í´ë˜ìŠ¤ ìˆ˜: 17\n",
      "í‰ê·  ì‹ ë¢°ë„: 0.4164\n",
      "ì‹ ë¢°ë„ ë²”ìœ„: 0.1129 ~ 0.6469\n",
      "ì˜ˆì¸¡ ë¶„í¬ ì°¨íŠ¸ ë¡œê¹… ì™„ë£Œ!\n",
      "ì‹¤í—˜ ìš”ì•½ ë¡œê¹… ì™„ë£Œ!\n",
      "\n",
      " ìµœì¢… ê²°ê³¼ ì €ì¥ ì™„ë£Œ!\n",
      " íŒŒì¼ ìœ„ì¹˜: ../output/choice4.csv\n",
      " ì´ ì˜ˆì¸¡ ìˆ˜: 3140\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 18. Final Results and Submission\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\n ìµœì¢… ê²°ê³¼ ì •ë¦¬ ì¤‘...\")\n",
    "\n",
    "# TTA ê²°ê³¼ë¡œ submission íŒŒì¼ ìƒì„±\n",
    "tta_pred_df = pd.DataFrame(tta_dataset.df, columns=['ID', 'target'])\n",
    "tta_pred_df['target'] = tta_predictions\n",
    "\n",
    "# ê¸°ì¡´ submissionê³¼ ë™ì¼í•œ ìˆœì„œì¸ì§€ í™•ì¸\n",
    "sample_submission_df = pd.read_csv(\"../data/sample_submission.csv\")\n",
    "assert (sample_submission_df['ID'] == tta_pred_df['ID']).all(), \"ID ìˆœì„œ ë¶ˆì¼ì¹˜!\"\n",
    "\n",
    "# ì˜ˆì¸¡ ë¶„í¬ ë¶„ì„\n",
    "pred_distribution = tta_pred_df['target'].value_counts().sort_index()\n",
    "pred_table = wandb.Table(columns=[\"Class\", \"Count\", \"Percentage\"])\n",
    "\n",
    "print(f\"\\nğŸ“Š ì˜ˆì¸¡ ê²°ê³¼ ë¶„í¬:\")\n",
    "for class_id in range(17):\n",
    "    count = pred_distribution.get(class_id, 0)\n",
    "    percentage = count / len(tta_pred_df) * 100\n",
    "    pred_table.add_data(class_id, count, percentage)\n",
    "    print(f\"Class {class_id:2d}: {count:4d} ({percentage:5.1f}%)\")\n",
    "\n",
    "# ì‹ ë¢°ë„ ë¶„ì„\n",
    "confidence_bins = [0.5, 0.7, 0.8, 0.9, 0.95, 1.0]\n",
    "confidence_analysis = {}\n",
    "for i, threshold in enumerate(confidence_bins):\n",
    "    if i == 0:\n",
    "        count = np.sum(np.array(confidences) >= threshold)\n",
    "    else:\n",
    "        prev_threshold = confidence_bins[i-1]\n",
    "        count = np.sum((np.array(confidences) >= prev_threshold) & (np.array(confidences) < threshold))\n",
    "    confidence_analysis[f\"conf_{threshold}\"] = count\n",
    "\n",
    "# ìµœì¢… ê²°ê³¼ ë¡œê¹…\n",
    "try:\n",
    "    if wandb.run is not None:\n",
    "        wandb.run.log({\n",
    "            \"final_results/total_predictions\": len(tta_predictions),\n",
    "            \"final_results/unique_classes_predicted\": len(np.unique(tta_predictions)),\n",
    "            \"final_results/prediction_distribution_table\": pred_table,\n",
    "            \"final_results/avg_confidence\": np.mean(confidences),\n",
    "            \"final_results/median_confidence\": np.median(confidences),\n",
    "            \"final_results/min_confidence\": np.min(confidences),\n",
    "            \"final_results/max_confidence\": np.max(confidences),\n",
    "            \"final_results/confidence_distribution\": wandb.Histogram(confidences),\n",
    "            **confidence_analysis\n",
    "        })\n",
    "        print(\"ìµœì¢… ê²°ê³¼ WandB ë¡œê¹… ì™„ë£Œ!\")\n",
    "    else:\n",
    "        print(\"í™œì„±í™”ëœ runì´ ì—†ì–´ ë¡œê¹…ì„ ê±´ë„ˆëœë‹ˆë‹¤.\")\n",
    "except Exception as e:\n",
    "    print(f\"WandB ë¡œê¹… ì¤‘ ì—ëŸ¬: {e}\")\n",
    "\n",
    "# ì½˜ì†” ì¶œë ¥ì€ í•­ìƒ ì‹¤í–‰\n",
    "print(f\"ì´ ì˜ˆì¸¡ ìˆ˜: {len(tta_predictions)}\")\n",
    "print(f\"ì˜ˆì¸¡ëœ í´ë˜ìŠ¤ ìˆ˜: {len(np.unique(tta_predictions))}\")\n",
    "print(f\"í‰ê·  ì‹ ë¢°ë„: {np.mean(confidences):.4f}\")\n",
    "print(f\"ì‹ ë¢°ë„ ë²”ìœ„: {np.min(confidences):.4f} ~ {np.max(confidences):.4f}\")\n",
    "\n",
    "\n",
    "# ì˜ˆì¸¡ ë¶„í¬ ë°”ì°¨íŠ¸\n",
    "try:\n",
    "    if wandb.run is not None:\n",
    "        pred_dist_data = [[f\"Class_{i}\", pred_distribution.get(i, 0)] for i in range(17)]\n",
    "        wandb.run.log({\n",
    "            \"final_results/prediction_distribution_chart\": wandb.plot.bar(\n",
    "                wandb.Table(data=pred_dist_data, columns=[\"Class\", \"Count\"]),\n",
    "                \"Class\", \"Count\", \n",
    "                title=\"Final Prediction Distribution\"\n",
    "            )\n",
    "        })\n",
    "        print(\"ì˜ˆì¸¡ ë¶„í¬ ì°¨íŠ¸ ë¡œê¹… ì™„ë£Œ!\")\n",
    "    else:\n",
    "        print(\"ì°¨íŠ¸ ë¡œê¹…ì„ ê±´ë„ˆëœë‹ˆë‹¤.\")\n",
    "except Exception as e:\n",
    "    print(f\"ì°¨íŠ¸ ë¡œê¹… ì¤‘ ì—ëŸ¬: {e}\")\n",
    "\n",
    "# ê²°ê³¼ ì €ì¥\n",
    "output_path = \"../output/choice4.csv\"\n",
    "tta_pred_df.to_csv(output_path, index=False)\n",
    "\n",
    "# ê²°ê³¼ íŒŒì¼ì„ WandB ì•„í‹°íŒ©íŠ¸ë¡œ ì €ì¥\n",
    "artifact = wandb.Artifact(\n",
    "    name=\"final_predictions\",\n",
    "    type=\"predictions\",\n",
    "    description=f\"Final ensemble predictions with {N_FOLDS}-fold CV + TTA\"\n",
    ")\n",
    "artifact.add_file(output_path)\n",
    "\n",
    "try:\n",
    "    if wandb.run is not None:\n",
    "        wandb.run.log_artifact(artifact)\n",
    "        print(\"ì‹¤í—˜ ìš”ì•½ ë¡œê¹… ì™„ë£Œ!\")\n",
    "    else:\n",
    "        print(\"í™œì„±í™”ëœ runì´ ì—†ì–´ ì‹¤í—˜ ìš”ì•½ ë¡œê¹…ì„ ê±´ë„ˆëœë‹ˆë‹¤.\")\n",
    "except Exception as e:\n",
    "    print(f\"ì‹¤í—˜ ìš”ì•½ ë¡œê¹… ì¤‘ ì—ëŸ¬: {e}\")\n",
    "\n",
    "\n",
    "print(f\"\\n ìµœì¢… ê²°ê³¼ ì €ì¥ ì™„ë£Œ!\")\n",
    "print(f\" íŒŒì¼ ìœ„ì¹˜: {output_path}\")\n",
    "print(f\" ì´ ì˜ˆì¸¡ ìˆ˜: {len(tta_predictions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "30990203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì‹¤í—˜ ìš”ì•½ ë¡œê¹… ì™„ë£Œ!\n",
      "ìµœì¢… ìƒíƒœ ì—…ë°ì´íŠ¸ ì™„ë£Œ!\n",
      "\n",
      "ì‹¤í—˜ ì™„ë£Œ ì‹œê°„: 2025-09-04 14:24:08\n",
      "\n",
      "============================================================\n",
      "ì‹¤í—˜ ì™„ë£Œ!\n",
      "============================================================\n",
      " K-Fold CV ê²°ê³¼: 0.9283 Â± 0.0079\n",
      " ìµœê³  ì„±ëŠ¥ Fold: 0.9412\n",
      " ì•™ìƒë¸” ëª¨ë¸: 5ê°œ\n",
      " TTA ë³€í˜•: 5ê°œ\n",
      " í‰ê·  ì˜ˆì¸¡ ì‹ ë¢°ë„: 0.4164\n",
      " WandB ëŒ€ì‹œë³´ë“œ: https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/mdvqqydn\n",
      "\n",
      " ì˜ˆì¸¡ ê²°ê³¼ ìƒ˜í”Œ:\n",
      "                     ID  target\n",
      "0  0008fdb22ddce0ce.jpg       2\n",
      "1  00091bffdffd83de.jpg      12\n",
      "2  00396fbc1f6cc21d.jpg       5\n",
      "3  00471f8038d9c4b6.jpg      12\n",
      "4  00901f504008d884.jpg       2\n",
      "5  009b22decbc7220c.jpg      15\n",
      "6  00b33e0ee6d59427.jpg       0\n",
      "7  00bbdcfbbdb3e131.jpg       8\n",
      "8  00c03047e0fbef40.jpg      15\n",
      "9  00c0dabb63ca7a16.jpg      11\n",
      "\n",
      " ëª¨ë“  ì‘ì—… ì™„ë£Œ!\n",
      " ê²°ê³¼ íŒŒì¼: ../output/choice4.csv\n",
      " WandBì—ì„œ ì „ì²´ ì‹¤í—˜ ê²°ê³¼ë¥¼ í™•ì¸í•˜ì„¸ìš”!\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 19. Experiment Summary and Cleanup\n",
    "# =============================================================================\n",
    "\n",
    "# ì‹¤í—˜ ìš”ì•½ ìƒì„±\n",
    "experiment_summary = {\n",
    "    \"experiment_name\": main_run.name,\n",
    "    \"model_architecture\": model_name,\n",
    "    \"image_size\": img_size,\n",
    "    \"cv_strategy\": f\"{N_FOLDS}-Fold StratifiedKFold\",\n",
    "    \"cv_mean_f1\": mean_f1,\n",
    "    \"cv_std_f1\": std_f1,\n",
    "    \"cv_best_fold\": max(val_f1_scores),\n",
    "    \"ensemble_models\": len(ensemble_models),\n",
    "    \"tta_transforms\": len(essential_tta_transforms),\n",
    "    \"total_training_time_min\": sum([r['epochs_trained'] for r in fold_results]) * 2,  # ì¶”ì •ì¹˜\n",
    "    \"avg_prediction_confidence\": np.mean(confidences),\n",
    "    \"high_confidence_predictions\": np.sum(np.array(confidences) >= 0.9),\n",
    "    \"experiment_tags\": [\"baseline\", \"efficientnet-b3\", \"k-fold-cv\", \"tta\", \"ensemble\"]\n",
    "}\n",
    "\n",
    "# ì‹¤í—˜ ìš”ì•½\n",
    "try:\n",
    "    if wandb.run is not None:\n",
    "        wandb.run.log({\"experiment_summary\": experiment_summary})\n",
    "        print(\"ì‹¤í—˜ ìš”ì•½ ë¡œê¹… ì™„ë£Œ!\")\n",
    "    else:\n",
    "        print(\"í™œì„±í™”ëœ runì´ ì—†ì–´ ì‹¤í—˜ ìš”ì•½ ë¡œê¹…ì„ ê±´ë„ˆëœë‹ˆë‹¤.\")\n",
    "except Exception as e:\n",
    "    print(f\"ì‹¤í—˜ ìš”ì•½ ë¡œê¹… ì¤‘ ì—ëŸ¬: {e}\")\n",
    "\n",
    "\n",
    "# ë§ˆì§€ë§‰ ìƒíƒœ ì—…ë°ì´íŠ¸\n",
    "try:\n",
    "    if wandb.run is not None:\n",
    "        wandb.run.log({\n",
    "            \"status\": \"completed\",\n",
    "            \"completion_time\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "            \"total_runtime_hours\": 0  # start_time ì†ì„± ë¬¸ì œë¡œ ì¼ë‹¨ 0ìœ¼ë¡œ ì„¤ì •\n",
    "        })\n",
    "        print(\"ìµœì¢… ìƒíƒœ ì—…ë°ì´íŠ¸ ì™„ë£Œ!\")\n",
    "    else:\n",
    "        print(\"í™œì„±í™”ëœ runì´ ì—†ì–´ ìƒíƒœ ì—…ë°ì´íŠ¸ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.\")\n",
    "except Exception as e:\n",
    "    print(f\"ìƒíƒœ ì—…ë°ì´íŠ¸ ì¤‘ ì—ëŸ¬: {e}\")\n",
    "\n",
    "print(f\"\\nì‹¤í—˜ ì™„ë£Œ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"ì‹¤í—˜ ì™„ë£Œ!\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "print(f\" K-Fold CV ê²°ê³¼: {mean_f1:.4f} Â± {std_f1:.4f}\")\n",
    "print(f\" ìµœê³  ì„±ëŠ¥ Fold: {max(val_f1_scores):.4f}\")\n",
    "print(f\" ì•™ìƒë¸” ëª¨ë¸: {len(ensemble_models)}ê°œ\")\n",
    "print(f\" TTA ë³€í˜•: {len(essential_tta_transforms)}ê°œ\")\n",
    "print(f\" í‰ê·  ì˜ˆì¸¡ ì‹ ë¢°ë„: {np.mean(confidences):.4f}\")\n",
    "print(f\" WandB ëŒ€ì‹œë³´ë“œ: {main_run.url}\")\n",
    "\n",
    "# Sample predictions ì¶œë ¥\n",
    "print(f\"\\n ì˜ˆì¸¡ ê²°ê³¼ ìƒ˜í”Œ:\")\n",
    "print(tta_pred_df.head(10))\n",
    "\n",
    "# ë©”ì¸ run ì¢…ë£Œ\n",
    "main_run.finish()\n",
    "\n",
    "print(f\"\\n ëª¨ë“  ì‘ì—… ì™„ë£Œ!\")\n",
    "print(f\" ê²°ê³¼ íŒŒì¼: {output_path}\")\n",
    "print(f\" WandBì—ì„œ ì „ì²´ ì‹¤í—˜ ê²°ê³¼ë¥¼ í™•ì¸í•˜ì„¸ìš”!\")\n",
    "\n",
    "# ë©”ëª¨ë¦¬ ì •ë¦¬\n",
    "del ensemble_models\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b07f9c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
