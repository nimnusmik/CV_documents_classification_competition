{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18bbe02e",
   "metadata": {},
   "source": [
    "# 📄 Document type classification baseline code with WandB Integration\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92dc69ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: albumentations==1.3.1 in /opt/conda/lib/python3.10/site-packages (from -r ../requirements.txt (line 1)) (1.3.1)\n",
      "Requirement already satisfied: ipykernel==6.27.1 in /opt/conda/lib/python3.10/site-packages (from -r ../requirements.txt (line 2)) (6.27.1)\n",
      "Requirement already satisfied: ipython==8.15.0 in /opt/conda/lib/python3.10/site-packages (from -r ../requirements.txt (line 3)) (8.15.0)\n",
      "Requirement already satisfied: ipywidgets==8.1.1 in /opt/conda/lib/python3.10/site-packages (from -r ../requirements.txt (line 4)) (8.1.1)\n",
      "Requirement already satisfied: jupyter==1.0.0 in /opt/conda/lib/python3.10/site-packages (from -r ../requirements.txt (line 5)) (1.0.0)\n",
      "Requirement already satisfied: matplotlib-inline==0.1.6 in /opt/conda/lib/python3.10/site-packages (from -r ../requirements.txt (line 6)) (0.1.6)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from -r ../requirements.txt (line 7)) (1.26.0)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from -r ../requirements.txt (line 8)) (2.1.4)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from -r ../requirements.txt (line 9)) (9.4.0)\n",
      "Requirement already satisfied: seaborn in /opt/conda/lib/python3.10/site-packages (from -r ../requirements.txt (line 10)) (0.13.2)\n",
      "Requirement already satisfied: timm==0.9.12 in /opt/conda/lib/python3.10/site-packages (from -r ../requirements.txt (line 11)) (0.9.12)\n",
      "Requirement already satisfied: plotly in /opt/conda/lib/python3.10/site-packages (from -r ../requirements.txt (line 12)) (6.3.0)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from -r ../requirements.txt (line 13)) (3.10.6)\n",
      "Requirement already satisfied: optuna in /opt/conda/lib/python3.10/site-packages (from -r ../requirements.txt (line 14)) (4.5.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from albumentations==1.3.1->-r ../requirements.txt (line 1)) (1.11.4)\n",
      "Requirement already satisfied: scikit-image>=0.16.1 in /opt/conda/lib/python3.10/site-packages (from albumentations==1.3.1->-r ../requirements.txt (line 1)) (0.22.0)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from albumentations==1.3.1->-r ../requirements.txt (line 1)) (6.0.2)\n",
      "Requirement already satisfied: qudida>=0.0.4 in /opt/conda/lib/python3.10/site-packages (from albumentations==1.3.1->-r ../requirements.txt (line 1)) (0.0.4)\n",
      "Requirement already satisfied: opencv-python-headless>=4.1.1 in /opt/conda/lib/python3.10/site-packages (from albumentations==1.3.1->-r ../requirements.txt (line 1)) (4.8.1.78)\n",
      "Requirement already satisfied: comm>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from ipykernel==6.27.1->-r ../requirements.txt (line 2)) (0.2.0)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /opt/conda/lib/python3.10/site-packages (from ipykernel==6.27.1->-r ../requirements.txt (line 2)) (1.8.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /opt/conda/lib/python3.10/site-packages (from ipykernel==6.27.1->-r ../requirements.txt (line 2)) (8.6.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /opt/conda/lib/python3.10/site-packages (from ipykernel==6.27.1->-r ../requirements.txt (line 2)) (5.5.0)\n",
      "Requirement already satisfied: nest-asyncio in /opt/conda/lib/python3.10/site-packages (from ipykernel==6.27.1->-r ../requirements.txt (line 2)) (1.5.8)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from ipykernel==6.27.1->-r ../requirements.txt (line 2)) (23.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from ipykernel==6.27.1->-r ../requirements.txt (line 2)) (5.9.0)\n",
      "Requirement already satisfied: pyzmq>=20 in /opt/conda/lib/python3.10/site-packages (from ipykernel==6.27.1->-r ../requirements.txt (line 2)) (25.1.2)\n",
      "Requirement already satisfied: tornado>=6.1 in /opt/conda/lib/python3.10/site-packages (from ipykernel==6.27.1->-r ../requirements.txt (line 2)) (6.4)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in /opt/conda/lib/python3.10/site-packages (from ipykernel==6.27.1->-r ../requirements.txt (line 2)) (5.7.1)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.10/site-packages (from ipython==8.15.0->-r ../requirements.txt (line 3)) (0.2.0)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.10/site-packages (from ipython==8.15.0->-r ../requirements.txt (line 3)) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.10/site-packages (from ipython==8.15.0->-r ../requirements.txt (line 3)) (0.18.1)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.10/site-packages (from ipython==8.15.0->-r ../requirements.txt (line 3)) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /opt/conda/lib/python3.10/site-packages (from ipython==8.15.0->-r ../requirements.txt (line 3)) (3.0.36)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.10/site-packages (from ipython==8.15.0->-r ../requirements.txt (line 3)) (2.15.1)\n",
      "Requirement already satisfied: stack-data in /opt/conda/lib/python3.10/site-packages (from ipython==8.15.0->-r ../requirements.txt (line 3)) (0.2.0)\n",
      "Requirement already satisfied: exceptiongroup in /opt/conda/lib/python3.10/site-packages (from ipython==8.15.0->-r ../requirements.txt (line 3)) (1.0.4)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.10/site-packages (from ipython==8.15.0->-r ../requirements.txt (line 3)) (4.8.0)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.9 in /opt/conda/lib/python3.10/site-packages (from ipywidgets==8.1.1->-r ../requirements.txt (line 4)) (4.0.9)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.9 in /opt/conda/lib/python3.10/site-packages (from ipywidgets==8.1.1->-r ../requirements.txt (line 4)) (3.0.9)\n",
      "Requirement already satisfied: notebook in /opt/conda/lib/python3.10/site-packages (from jupyter==1.0.0->-r ../requirements.txt (line 5)) (7.0.6)\n",
      "Requirement already satisfied: qtconsole in /opt/conda/lib/python3.10/site-packages (from jupyter==1.0.0->-r ../requirements.txt (line 5)) (5.5.1)\n",
      "Requirement already satisfied: jupyter-console in /opt/conda/lib/python3.10/site-packages (from jupyter==1.0.0->-r ../requirements.txt (line 5)) (6.6.3)\n",
      "Requirement already satisfied: nbconvert in /opt/conda/lib/python3.10/site-packages (from jupyter==1.0.0->-r ../requirements.txt (line 5)) (7.12.0)\n",
      "Requirement already satisfied: torch>=1.7 in /opt/conda/lib/python3.10/site-packages (from timm==0.9.12->-r ../requirements.txt (line 11)) (2.1.0)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from timm==0.9.12->-r ../requirements.txt (line 11)) (0.16.0)\n",
      "Requirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from timm==0.9.12->-r ../requirements.txt (line 11)) (0.19.4)\n",
      "Requirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from timm==0.9.12->-r ../requirements.txt (line 11)) (0.4.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->-r ../requirements.txt (line 8)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->-r ../requirements.txt (line 8)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->-r ../requirements.txt (line 8)) (2023.3)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in /opt/conda/lib/python3.10/site-packages (from plotly->-r ../requirements.txt (line 12)) (2.3.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->-r ../requirements.txt (line 13)) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->-r ../requirements.txt (line 13)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->-r ../requirements.txt (line 13)) (4.59.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->-r ../requirements.txt (line 13)) (1.4.9)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->-r ../requirements.txt (line 13)) (3.2.3)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /opt/conda/lib/python3.10/site-packages (from optuna->-r ../requirements.txt (line 14)) (1.16.5)\n",
      "Requirement already satisfied: colorlog in /opt/conda/lib/python3.10/site-packages (from optuna->-r ../requirements.txt (line 14)) (6.9.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in /opt/conda/lib/python3.10/site-packages (from optuna->-r ../requirements.txt (line 14)) (2.0.43)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from optuna->-r ../requirements.txt (line 14)) (4.65.0)\n",
      "Requirement already satisfied: Mako in /opt/conda/lib/python3.10/site-packages (from alembic>=1.5.0->optuna->-r ../requirements.txt (line 14)) (1.3.10)\n",
      "Requirement already satisfied: typing-extensions>=4.12 in /opt/conda/lib/python3.10/site-packages (from alembic>=1.5.0->optuna->-r ../requirements.txt (line 14)) (4.15.0)\n",
      "Requirement already satisfied: tomli in /opt/conda/lib/python3.10/site-packages (from alembic>=1.5.0->optuna->-r ../requirements.txt (line 14)) (2.0.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from jedi>=0.16->ipython==8.15.0->-r ../requirements.txt (line 3)) (0.8.3)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /opt/conda/lib/python3.10/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel==6.27.1->-r ../requirements.txt (line 2)) (4.1.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.10/site-packages (from pexpect>4.3->ipython==8.15.0->-r ../requirements.txt (line 3)) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython==8.15.0->-r ../requirements.txt (line 3)) (0.2.5)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->-r ../requirements.txt (line 8)) (1.10.0)\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in /opt/conda/lib/python3.10/site-packages (from qudida>=0.0.4->albumentations==1.3.1->-r ../requirements.txt (line 1)) (1.3.2)\n",
      "Requirement already satisfied: networkx>=2.8 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.16.1->albumentations==1.3.1->-r ../requirements.txt (line 1)) (3.1)\n",
      "Requirement already satisfied: imageio>=2.27 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.16.1->albumentations==1.3.1->-r ../requirements.txt (line 1)) (2.33.1)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.16.1->albumentations==1.3.1->-r ../requirements.txt (line 1)) (2023.12.9)\n",
      "Requirement already satisfied: lazy_loader>=0.3 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.16.1->albumentations==1.3.1->-r ../requirements.txt (line 1)) (0.3)\n",
      "Requirement already satisfied: greenlet>=1 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy>=1.4.2->optuna->-r ../requirements.txt (line 14)) (3.2.4)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->timm==0.9.12->-r ../requirements.txt (line 11)) (3.9.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->timm==0.9.12->-r ../requirements.txt (line 11)) (1.11.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->timm==0.9.12->-r ../requirements.txt (line 11)) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->timm==0.9.12->-r ../requirements.txt (line 11)) (2023.9.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->timm==0.9.12->-r ../requirements.txt (line 11)) (2.31.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from nbconvert->jupyter==1.0.0->-r ../requirements.txt (line 5)) (4.12.2)\n",
      "Requirement already satisfied: bleach!=5.0.0 in /opt/conda/lib/python3.10/site-packages (from nbconvert->jupyter==1.0.0->-r ../requirements.txt (line 5)) (6.1.0)\n",
      "Requirement already satisfied: defusedxml in /opt/conda/lib/python3.10/site-packages (from nbconvert->jupyter==1.0.0->-r ../requirements.txt (line 5)) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in /opt/conda/lib/python3.10/site-packages (from nbconvert->jupyter==1.0.0->-r ../requirements.txt (line 5)) (0.3.0)\n",
      "Requirement already satisfied: markupsafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from nbconvert->jupyter==1.0.0->-r ../requirements.txt (line 5)) (3.0.2)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in /opt/conda/lib/python3.10/site-packages (from nbconvert->jupyter==1.0.0->-r ../requirements.txt (line 5)) (3.0.2)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /opt/conda/lib/python3.10/site-packages (from nbconvert->jupyter==1.0.0->-r ../requirements.txt (line 5)) (0.9.0)\n",
      "Requirement already satisfied: nbformat>=5.7 in /opt/conda/lib/python3.10/site-packages (from nbconvert->jupyter==1.0.0->-r ../requirements.txt (line 5)) (5.9.2)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/lib/python3.10/site-packages (from nbconvert->jupyter==1.0.0->-r ../requirements.txt (line 5)) (1.5.0)\n",
      "Requirement already satisfied: tinycss2 in /opt/conda/lib/python3.10/site-packages (from nbconvert->jupyter==1.0.0->-r ../requirements.txt (line 5)) (1.2.1)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in /opt/conda/lib/python3.10/site-packages (from notebook->jupyter==1.0.0->-r ../requirements.txt (line 5)) (2.12.1)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.22.1 in /opt/conda/lib/python3.10/site-packages (from notebook->jupyter==1.0.0->-r ../requirements.txt (line 5)) (2.25.2)\n",
      "Requirement already satisfied: jupyterlab<5,>=4.0.2 in /opt/conda/lib/python3.10/site-packages (from notebook->jupyter==1.0.0->-r ../requirements.txt (line 5)) (4.0.9)\n",
      "Requirement already satisfied: notebook-shim<0.3,>=0.2 in /opt/conda/lib/python3.10/site-packages (from notebook->jupyter==1.0.0->-r ../requirements.txt (line 5)) (0.2.3)\n",
      "Requirement already satisfied: qtpy>=2.4.0 in /opt/conda/lib/python3.10/site-packages (from qtconsole->jupyter==1.0.0->-r ../requirements.txt (line 5)) (2.4.1)\n",
      "Requirement already satisfied: executing in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython==8.15.0->-r ../requirements.txt (line 3)) (0.8.3)\n",
      "Requirement already satisfied: asttokens in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython==8.15.0->-r ../requirements.txt (line 3)) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython==8.15.0->-r ../requirements.txt (line 3)) (0.2.2)\n",
      "Requirement already satisfied: webencodings in /opt/conda/lib/python3.10/site-packages (from bleach!=5.0.0->nbconvert->jupyter==1.0.0->-r ../requirements.txt (line 5)) (0.5.1)\n",
      "Requirement already satisfied: anyio>=3.1.0 in /opt/conda/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->-r ../requirements.txt (line 5)) (4.1.0)\n",
      "Requirement already satisfied: argon2-cffi in /opt/conda/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->-r ../requirements.txt (line 5)) (23.1.0)\n",
      "Requirement already satisfied: jupyter-events>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->-r ../requirements.txt (line 5)) (0.9.0)\n",
      "Requirement already satisfied: jupyter-server-terminals in /opt/conda/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->-r ../requirements.txt (line 5)) (0.5.0)\n",
      "Requirement already satisfied: overrides in /opt/conda/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->-r ../requirements.txt (line 5)) (7.4.0)\n",
      "Requirement already satisfied: prometheus-client in /opt/conda/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->-r ../requirements.txt (line 5)) (0.19.0)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in /opt/conda/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->-r ../requirements.txt (line 5)) (1.8.2)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /opt/conda/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->-r ../requirements.txt (line 5)) (0.18.0)\n",
      "Requirement already satisfied: websocket-client in /opt/conda/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->-r ../requirements.txt (line 5)) (1.7.0)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from jupyterlab<5,>=4.0.2->notebook->jupyter==1.0.0->-r ../requirements.txt (line 5)) (2.0.4)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from jupyterlab<5,>=4.0.2->notebook->jupyter==1.0.0->-r ../requirements.txt (line 5)) (2.2.1)\n",
      "Requirement already satisfied: babel>=2.10 in /opt/conda/lib/python3.10/site-packages (from jupyterlab-server<3,>=2.22.1->notebook->jupyter==1.0.0->-r ../requirements.txt (line 5)) (2.17.0)\n",
      "Requirement already satisfied: json5>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from jupyterlab-server<3,>=2.22.1->notebook->jupyter==1.0.0->-r ../requirements.txt (line 5)) (0.9.14)\n",
      "Requirement already satisfied: jsonschema>=4.18.0 in /opt/conda/lib/python3.10/site-packages (from jupyterlab-server<3,>=2.22.1->notebook->jupyter==1.0.0->-r ../requirements.txt (line 5)) (4.20.0)\n",
      "Requirement already satisfied: fastjsonschema in /opt/conda/lib/python3.10/site-packages (from nbformat>=5.7->nbconvert->jupyter==1.0.0->-r ../requirements.txt (line 5)) (2.19.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->timm==0.9.12->-r ../requirements.txt (line 11)) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->timm==0.9.12->-r ../requirements.txt (line 11)) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->timm==0.9.12->-r ../requirements.txt (line 11)) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->timm==0.9.12->-r ../requirements.txt (line 11)) (2023.7.22)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations==1.3.1->-r ../requirements.txt (line 1)) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations==1.3.1->-r ../requirements.txt (line 1)) (3.2.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->nbconvert->jupyter==1.0.0->-r ../requirements.txt (line 5)) (2.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.7->timm==0.9.12->-r ../requirements.txt (line 11)) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->-r ../requirements.txt (line 5)) (1.3.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook->jupyter==1.0.0->-r ../requirements.txt (line 5)) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook->jupyter==1.0.0->-r ../requirements.txt (line 5)) (2023.11.2)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook->jupyter==1.0.0->-r ../requirements.txt (line 5)) (0.32.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook->jupyter==1.0.0->-r ../requirements.txt (line 5)) (0.13.2)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in /opt/conda/lib/python3.10/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->-r ../requirements.txt (line 5)) (2.0.7)\n",
      "Requirement already satisfied: rfc3339-validator in /opt/conda/lib/python3.10/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->-r ../requirements.txt (line 5)) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->-r ../requirements.txt (line 5)) (0.1.1)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /opt/conda/lib/python3.10/site-packages (from argon2-cffi->jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->-r ../requirements.txt (line 5)) (21.2.0)\n",
      "Requirement already satisfied: fqdn in /opt/conda/lib/python3.10/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook->jupyter==1.0.0->-r ../requirements.txt (line 5)) (1.5.1)\n",
      "Requirement already satisfied: isoduration in /opt/conda/lib/python3.10/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook->jupyter==1.0.0->-r ../requirements.txt (line 5)) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook->jupyter==1.0.0->-r ../requirements.txt (line 5)) (2.1)\n",
      "Requirement already satisfied: uri-template in /opt/conda/lib/python3.10/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook->jupyter==1.0.0->-r ../requirements.txt (line 5)) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=1.11 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook->jupyter==1.0.0->-r ../requirements.txt (line 5)) (1.13)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from argon2-cffi-bindings->argon2-cffi->jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->-r ../requirements.txt (line 5)) (1.15.1)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->-r ../requirements.txt (line 5)) (2.21)\n",
      "Requirement already satisfied: arrow>=0.15.0 in /opt/conda/lib/python3.10/site-packages (from isoduration->jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook->jupyter==1.0.0->-r ../requirements.txt (line 5)) (1.3.0)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in /opt/conda/lib/python3.10/site-packages (from arrow>=0.15.0->isoduration->jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook->jupyter==1.0.0->-r ../requirements.txt (line 5)) (2.8.19.14)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# 0. Prepare Environments & Install Libraries\n",
    "# =============================================================================\n",
    "\n",
    "# 필요한 라이브러리를 설치합니다.\n",
    "!pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "773408ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 1. Import Libraries & Define Functions\n",
    "# =============================================================================\n",
    "\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import copy\n",
    "\n",
    "import optuna, math\n",
    "import timm\n",
    "import torch\n",
    "import albumentations as A\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.optim import Adam\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.cuda.amp import autocast, GradScaler  # Mixed Precision용\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# WandB 관련 import 추가\n",
    "import wandb\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e142354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WandB 로그인 상태: kimsunmin0227\n",
      "프로젝트: document-classification-team\n",
      "실험명: efficientnet-b3-baseline\n",
      "팀원들은 EXPERIMENT_NAME을 각자 다르게 변경해주세요!\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 1-1. WandB Login and Configuration\n",
    "# =============================================================================\n",
    "\"\"\"\n",
    "🚀 팀원 사용 가이드:\n",
    "\n",
    "1. WandB 계정 생성: https://wandb.ai/signup\n",
    "2. 이 셀 실행 시 로그인 프롬프트가 나타나면 개인 API 키 입력\n",
    "3. EXPERIMENT_NAME을 다음과 같이 변경:\n",
    "   - \"member1-baseline\"\n",
    "   - \"member2-augmentation-test\"  \n",
    "   - \"member3-hyperparameter-tuning\"\n",
    "   등등 각자 다른 이름 사용\n",
    "\n",
    "4. 팀 대시보드 URL: [여기에 당신의 프로젝트 URL 추가]\n",
    "\n",
    "⚠️ 주의사항:\n",
    "- 절대 API 키를 코드에 하드코딩하지 마세요\n",
    "- EXPERIMENT_NAME만 변경하고 PROJECT_NAME은 그대로 두세요\n",
    "- 각자 개인 계정으로 로그인해서 실험을 추가하세요\n",
    "\"\"\"\n",
    "\n",
    "# WandB 로그인 (각자 실행)\n",
    "try:\n",
    "    if wandb.api.api_key is None:\n",
    "        print(\"WandB에 로그인이 필요합니다.\")\n",
    "        wandb.login()\n",
    "    else:\n",
    "        print(f\"WandB 로그인 상태: {wandb.api.viewer()['username']}\")\n",
    "except:\n",
    "    print(\"WandB 로그인을 진행합니다...\")\n",
    "    wandb.login()\n",
    "\n",
    "# 프로젝트 설정 (각자 수정할 부분)\n",
    "PROJECT_NAME = \"document-classification-team\"  # 모든 팀원 동일\n",
    "ENTITY = None  # 각자 개인 계정 사용\n",
    "EXPERIMENT_NAME = \"efficientnet-b3-baseline\"  # 팀원별로 변경 (예: \"member1-hyperopt\", \"member2-augmentation\")\n",
    "\n",
    "print(f\"프로젝트: {PROJECT_NAME}\")\n",
    "print(f\"실험명: {EXPERIMENT_NAME}\")\n",
    "print(\"팀원들은 EXPERIMENT_NAME을 각자 다르게 변경해주세요!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "448a2f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 3. Seed & basic augmentations (Mixup)\n",
    "# =============================================================================\n",
    "\n",
    "# 시드를 고정합니다.\n",
    "SEED = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.benchmark = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f9d1a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# 4. Dataset Class\n",
    "# =============================================================================\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, data, path, transform=None):\n",
    "        # CSV 파일이면 읽고, DataFrame이면 그대로 사용\n",
    "        if isinstance(data, str):\n",
    "            self.df = pd.read_csv(data).values\n",
    "        else:\n",
    "            self.df = data.values  # DataFrame을 numpy array로 변환\n",
    "        self.path = path\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        name, target = self.df[idx]\n",
    "        img = np.array(Image.open(os.path.join(self.path, name)))\n",
    "        if self.transform:\n",
    "            img = self.transform(image=img)['image']\n",
    "        return img, target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0cacecd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import wandb\n",
    "\n",
    "# Cutout (Random Erasing) 함수 정의\n",
    "def random_erasing(image, p=0.5, scale=(0.02, 0.33), ratio=(0.3, 3.3)):\n",
    "    if random.random() > p:\n",
    "        return image\n",
    "    img_c, img_h, img_w = image.shape[1], image.shape[2], image.shape[3]\n",
    "    area = img_h * img_w\n",
    "    \n",
    "    target_area = random.uniform(scale[0], scale[1]) * area\n",
    "    aspect_ratio = random.uniform(ratio[0], ratio[1])\n",
    "    h = int(round(math.sqrt(target_area * aspect_ratio)))\n",
    "    w = int(round(math.sqrt(target_area / aspect_ratio)))\n",
    "    \n",
    "    if h < img_h and w < img_w:\n",
    "        x = random.randint(0, img_w - w)\n",
    "        y = random.randint(0, img_h - h)\n",
    "        image[:, :, y:y+h, x:x+w] = 0.0  # 제거된 영역을 0으로 설정\n",
    "    return image\n",
    "\n",
    "# RandomCrop 함수 정의\n",
    "def random_crop(image, crop_size=0.8):\n",
    "    img_c, img_h, img_w = image.shape[1], image.shape[2], image.shape[3]\n",
    "    crop_h = int(img_h * crop_size)\n",
    "    crop_w = int(img_w * crop_size)\n",
    "    \n",
    "    if crop_h >= img_h or crop_w >= img_w:\n",
    "        return image\n",
    "    \n",
    "    x = random.randint(0, img_w - crop_w)\n",
    "    y = random.randint(0, img_h - crop_h)\n",
    "    cropped_image = image[:, :, y:y+crop_h, x:x+crop_w]\n",
    "    \n",
    "    # 원래 이미지 크기로 복원 (패딩 또는 리사이즈)\n",
    "    cropped_image = torch.nn.functional.interpolate(cropped_image, size=(img_h, img_w), mode='bilinear', align_corners=False)\n",
    "    return cropped_image\n",
    "\n",
    "# Mixup 함수 정의\n",
    "def mixup_data(x, y, alpha=1.0):\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "    batch_size = x.size()[0]\n",
    "    index = torch.randperm(batch_size).cuda()\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "def train_one_epoch(loader, model, optimizer, loss_fn, device, epoch=None, fold=None):\n",
    "    scaler = GradScaler()\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    preds_list = []\n",
    "    targets_list = []\n",
    "\n",
    "    pbar = tqdm(loader, desc=f\"Training Epoch {epoch+1 if epoch else '?'}\")\n",
    "    batch_count = 0\n",
    "    \n",
    "    for image, targets in pbar:\n",
    "        image = image.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        # 증강 기법 선택 (Mixup 25%, Cutout 25%, RandomCrop 25%, None 25%) -> (Mixup 25%, Cutout 25%, RandomCrop 50%)\n",
    "        aug_type = random.choices(['mixup', 'cutout', 'random_crop'], weights=[0.25, 0.25, 0.5])[0]\n",
    "        mixup_applied = False\n",
    "        cutout_applied = False\n",
    "        random_crop_applied = False\n",
    "        \n",
    "        if aug_type == 'mixup':\n",
    "            mixed_x, y_a, y_b, lam = mixup_data(image, targets, alpha=1.0)\n",
    "            with autocast(): \n",
    "                preds = model(mixed_x)\n",
    "            loss = lam * loss_fn(preds, y_a) + (1 - lam) * loss_fn(preds, y_b)\n",
    "            mixup_applied = True\n",
    "        elif aug_type == 'cutout':\n",
    "            image = random_erasing(image, p=0.5, scale=(0.02, 0.33), ratio=(0.3, 3.3))\n",
    "            with autocast(): \n",
    "                preds = model(image)\n",
    "            loss = loss_fn(preds, targets)\n",
    "            cutout_applied = True\n",
    "        elif aug_type == 'random_crop':\n",
    "            image = random_crop(image, crop_size=0.8)\n",
    "            with autocast(): \n",
    "                preds = model(image)\n",
    "            loss = loss_fn(preds, targets)\n",
    "            random_crop_applied = True\n",
    "        else:\n",
    "            with autocast(): \n",
    "                preds = model(image)\n",
    "            loss = loss_fn(preds, targets)\n",
    "\n",
    "        model.zero_grad(set_to_none=True)\n",
    "        scaler.scale(loss).backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
    "        targets_list.extend(targets.detach().cpu().numpy())\n",
    "\n",
    "        # 배치별 상세 로깅 (100 배치마다)\n",
    "        if batch_count % 100 == 0 and wandb.run is not None:\n",
    "            step = epoch * len(loader) + batch_count if epoch is not None else batch_count\n",
    "            wandb.log({\n",
    "                f\"fold_{fold}/train_batch_loss\": loss.item(),\n",
    "                f\"fold_{fold}/mixup_applied\": int(mixup_applied),\n",
    "                f\"fold_{fold}/cutout_applied\": int(cutout_applied),\n",
    "                f\"fold_{fold}/random_crop_applied\": int(random_crop_applied),\n",
    "                f\"fold_{fold}/batch_step\": step\n",
    "            })\n",
    "        \n",
    "        batch_count += 1\n",
    "        pbar.set_description(f\"Loss: {loss.item():.4f}, Mixup: {mixup_applied}, Cutout: {cutout_applied}, RandomCrop: {random_crop_applied}\")\n",
    "\n",
    "    train_loss /= len(loader)\n",
    "    train_acc = accuracy_score(targets_list, preds_list)\n",
    "    train_f1 = f1_score(targets_list, preds_list, average='macro')\n",
    "\n",
    "    ret = {\n",
    "        \"train_loss\": train_loss,\n",
    "        \"train_acc\": train_acc,\n",
    "        \"train_f1\": train_f1,\n",
    "    }\n",
    "\n",
    "    return ret\n",
    "\n",
    "def validate_one_epoch(loader, model, loss_fn, device, epoch=None, fold=None, log_confusion=False):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    preds_list = []\n",
    "    targets_list = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(loader, desc=f\"Validating Epoch {epoch+1 if epoch else '?'}\")\n",
    "        for image, targets in pbar:\n",
    "            image = image.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            preds = model(image)\n",
    "            loss = loss_fn(preds, targets)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
    "            targets_list.extend(targets.detach().cpu().numpy())\n",
    "            \n",
    "            pbar.set_description(f\"Val Loss: {loss.item():.4f}\")\n",
    "    \n",
    "    val_loss /= len(loader)\n",
    "    val_acc = accuracy_score(targets_list, preds_list)\n",
    "    val_f1 = f1_score(targets_list, preds_list, average='macro')\n",
    "    \n",
    "    # Confusion Matrix 로깅 (마지막 epoch에만)\n",
    "    if log_confusion and wandb.run is not None:\n",
    "        try:\n",
    "            wandb.log({\n",
    "                f\"fold_{fold}/confusion_matrix\": wandb.plot.confusion_matrix(\n",
    "                    probs=None,\n",
    "                    y_true=targets_list,\n",
    "                    preds=preds_list,\n",
    "                    class_names=[f\"Class_{i}\" for i in range(17)]\n",
    "                )\n",
    "            })\n",
    "            \n",
    "            # 클래스별 F1 스코어\n",
    "            class_f1_scores = f1_score(targets_list, preds_list, average=None)\n",
    "            for i, class_f1 in enumerate(class_f1_scores):\n",
    "                wandb.log({f\"fold_{fold}/class_{i}_f1\": class_f1})\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\" Confusion matrix 로깅 실패: {e}\")\n",
    "    \n",
    "    ret = {\n",
    "        \"val_loss\": val_loss,\n",
    "        \"val_acc\": val_acc,  \n",
    "        \"val_f1\": val_f1,\n",
    "    }\n",
    "    \n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "193dae06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Using device: cuda\n",
      " 하이퍼파라미터 설정 완료!\n",
      " 모델: efficientnet_b3\n",
      " 이미지 크기: 384x384\n",
      " 배치 크기: 32\n",
      " 학습률: 0.0005\n",
      " 에폭: 50\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 6. Hyper-parameters with WandB Config\n",
    "# =============================================================================\n",
    "\n",
    "# device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\" Using device: {device}\")\n",
    "\n",
    "# data config\n",
    "data_path = '../data/'\n",
    "\n",
    "# model config\n",
    "model_name = 'efficientnet_b3' # 'resnet50' 'efficientnet-b0', ...\n",
    "\n",
    "# training config\n",
    "img_size = 384\n",
    "LR = 5e-4\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 32\n",
    "num_workers = 30\n",
    "\n",
    "# K-Fold config\n",
    "N_FOLDS = 5  # 5-fold로 설정\n",
    "\n",
    "# WandB Config 설정\n",
    "config = {\n",
    "    # Model config\n",
    "    \"model_name\": model_name,\n",
    "    \"img_size\": img_size,\n",
    "    \"num_classes\": 17,\n",
    "    \"architecture\": \"EfficientNet-B3\",\n",
    "    \n",
    "    # Training config  \n",
    "    \"lr\": LR,\n",
    "    \"epochs\": EPOCHS,\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"num_workers\": num_workers,\n",
    "    \"device\": str(device),\n",
    "    \n",
    "    # K-Fold config\n",
    "    \"n_folds\": N_FOLDS,\n",
    "    \"seed\": SEED,\n",
    "    \"cv_strategy\": \"StratifiedKFold\",\n",
    "    \n",
    "    # Augmentation & Training techniques\n",
    "    \"mixup_alpha\": 1.0,\n",
    "    \"mixup_prob\": 0.3,\n",
    "    \"label_smoothing\": 0.2,\n",
    "    \"gradient_clipping\": 1.0,\n",
    "    \"mixed_precision\": True,\n",
    "    \n",
    "    # Optimizer & Scheduler\n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"scheduler\": \"CosineAnnealingLR\",\n",
    "    \n",
    "    # Data\n",
    "    \"data_path\": data_path,\n",
    "    \"train_transforms\": \"Advanced\",\n",
    "    \"test_transforms\": \"Basic\",\n",
    "}\n",
    "\n",
    "print(\" 하이퍼파라미터 설정 완료!\")\n",
    "print(f\" 모델: {model_name}\")\n",
    "print(f\" 이미지 크기: {img_size}x{img_size}\")\n",
    "print(f\" 배치 크기: {BATCH_SIZE}\")\n",
    "print(f\" 학습률: {LR}\")\n",
    "print(f\" 에폭: {EPOCHS}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a4e28f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏭️ Optuna 튜닝 건너뛰기 (USE_OPTUNA=False)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# 7. Optuna Hyperparameter Tuning (선택적)\n",
    "# =============================================================================\n",
    "\n",
    "USE_OPTUNA = False  # True로 바꾸면 튜닝 실행\n",
    "\n",
    "if USE_OPTUNA:\n",
    "    print(\"🔍 Optuna 하이퍼파라미터 튜닝 시작...\")\n",
    "    \n",
    "    def objective(trial):\n",
    "        lr = trial.suggest_loguniform('lr', 1e-5, 1e-2)\n",
    "        batch_size = trial.suggest_categorical('batch_size', [32, 64, 128])\n",
    "        \n",
    "        # WandB에 Optuna 시행 로깅\n",
    "        optuna_run = wandb.init(\n",
    "            project=PROJECT_NAME,\n",
    "            entity=ENTITY,\n",
    "            name=f\"optuna-trial-{trial.number}\",\n",
    "            config={**config, \"lr\": lr, \"batch_size\": batch_size},\n",
    "            tags=[\"optuna\", \"hyperparameter-tuning\"],\n",
    "            group=\"optuna-study\",\n",
    "            job_type=\"hyperparameter-optimization\",\n",
    "            reinit=True\n",
    "        )\n",
    "        \n",
    "        # 간단한 3-fold CV로 빠른 평가\n",
    "        skf_simple = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "        fold_scores = []\n",
    "        \n",
    "        # 간단한 평가 로직 (실제 구현에서는 더 단순화)\n",
    "        # ... (Optuna 로직은 복잡하므로 기본적으로 비활성화)\n",
    "        \n",
    "        optuna_run.finish()\n",
    "        return np.random.random()  # placeholder\n",
    "    \n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=10)\n",
    "    \n",
    "    # 최적 파라미터 적용\n",
    "    best_params = study.best_params\n",
    "    LR = best_params.get('lr', LR)\n",
    "    BATCH_SIZE = best_params.get('batch_size', BATCH_SIZE)\n",
    "    config.update(best_params)\n",
    "    print(f\"🎯 Optuna 최적 파라미터: {best_params}\")\n",
    "else:\n",
    "    print(\"⏭️ Optuna 튜닝 건너뛰기 (USE_OPTUNA=False)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6514acaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 데이터 변환 설정 완료!\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 8. Data Transforms\n",
    "# =============================================================================\n",
    "\n",
    "# augmentation을 위한 transform 코드\n",
    "trn_transform = A.Compose([\n",
    "    # 비율 보존 리사이징 (핵심 개선)\n",
    "    A.LongestMaxSize(max_size=img_size),\n",
    "    A.PadIfNeeded(min_height=img_size, min_width=img_size, \n",
    "                  border_mode=0, value=0),\n",
    "    \n",
    "    # 문서 특화 회전 + 미세 회전 추가\n",
    "    A.OneOf([\n",
    "        A.Rotate(limit=[90,90], p=1.0),\n",
    "        A.Rotate(limit=[180,180], p=1.0),\n",
    "        A.Rotate(limit=[270,270], p=1.0),\n",
    "        A.Rotate(limit=(-15, 15), p=1.0),  # 미세 회전 추가\n",
    "    ], p=0.7),\n",
    "    \n",
    "    # 기하학적 변환 강화\n",
    "    A.OneOf([\n",
    "        A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.2, rotate_limit=5, p=1.0),\n",
    "        A.ElasticTransform(alpha=50, sigma=5, p=1.0),\n",
    "        A.GridDistortion(num_steps=5, distort_limit=0.2, p=1.0),\n",
    "        A.OpticalDistortion(distort_limit=0.2, shift_limit=0.1, p=1.0),\n",
    "    ], p=0.6),\n",
    "    \n",
    "    # 색상 및 조명 변환 강화\n",
    "    A.OneOf([\n",
    "        A.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.3, hue=0.1, p=1.0),\n",
    "        A.RandomBrightnessContrast(brightness_limit=0.4, contrast_limit=0.4, p=1.0),\n",
    "        A.CLAHE(clip_limit=4.0, tile_grid_size=(8, 8), p=1.0),\n",
    "        A.RandomGamma(gamma_limit=(70, 130), p=1.0),\n",
    "    ], p=0.9),\n",
    "    \n",
    "    # 블러 및 노이즈 강화\n",
    "    A.OneOf([\n",
    "        A.MotionBlur(blur_limit=(5, 15), p=1.0),\n",
    "        A.GaussianBlur(blur_limit=(3, 15), p=1.0),\n",
    "        A.MedianBlur(blur_limit=7, p=1.0),\n",
    "        A.Blur(blur_limit=7, p=1.0),\n",
    "    ], p=0.8),\n",
    "    \n",
    "    # 다양한 노이즈 추가\n",
    "    A.OneOf([\n",
    "        A.GaussNoise(var_limit=(10.0, 150.0), p=1.0),\n",
    "        A.ISONoise(color_shift=(0.01, 0.08), intensity=(0.1, 0.8), p=1.0),\n",
    "        A.MultiplicativeNoise(multiplier=(0.9, 1.1), p=1.0),\n",
    "    ], p=0.8),\n",
    "    \n",
    "    # 문서 품질 시뮬레이션 (스캔/복사 효과)\n",
    "    A.OneOf([\n",
    "        A.Downscale(scale_min=0.7, scale_max=0.9, p=1.0),\n",
    "        A.ImageCompression(quality_lower=60, quality_upper=95, p=1.0),\n",
    "        A.Posterize(num_bits=6, p=1.0),\n",
    "    ], p=0.5),\n",
    "    \n",
    "    # 픽셀 레벨 변환\n",
    "    A.OneOf([\n",
    "        A.ChannelShuffle(p=1.0),\n",
    "        A.InvertImg(p=1.0),\n",
    "        A.Solarize(threshold=128, p=1.0),\n",
    "        A.Equalize(p=1.0),\n",
    "    ], p=0.3),\n",
    "    \n",
    "    # 공간 변환\n",
    "    A.OneOf([\n",
    "        A.HorizontalFlip(p=1.0),\n",
    "        A.VerticalFlip(p=1.0),  # 문서에서도 유용할 수 있음\n",
    "        A.Transpose(p=1.0),\n",
    "    ], p=0.6),\n",
    "    \n",
    "    # 조각 제거 (Cutout 계열)\n",
    "    A.OneOf([\n",
    "        A.CoarseDropout(max_holes=8, max_height=32, max_width=32, \n",
    "                       min_holes=1, min_height=8, min_width=8, \n",
    "                       fill_value=0, p=1.0),\n",
    "        A.GridDropout(ratio=0.3, unit_size_min=8, unit_size_max=32, \n",
    "                     holes_number_x=5, holes_number_y=5, p=1.0),\n",
    "    ], p=0.4),\n",
    "    \n",
    "    # 최종 정규화\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "# test image 변환을 위한 transform 코드\n",
    "tst_transform = A.Compose([\n",
    "    A.LongestMaxSize(max_size=img_size),\n",
    "    A.PadIfNeeded(min_height=img_size, min_width=img_size, \n",
    "                  border_mode=0, value=0),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "print(\"✅ 데이터 변환 설정 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c320bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 데이터: 1570개 샘플\n",
      " 클래스 분포: {0: 100, 1: 46, 2: 100, 3: 100, 4: 100, 5: 100, 6: 100, 7: 100, 8: 100, 9: 100, 10: 100, 11: 100, 12: 100, 13: 74, 14: 50, 15: 100, 16: 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkimsunmin0227\u001b[0m (\u001b[33mkimsunmin0227-hufs\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "creating run (0.2s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/ephemeral/home/computervisioncompetition-cv-1/wandb/wandb/run-20250904_134143-mdvqqydn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/mdvqqydn' target=\"_blank\">efficientnet-b3-baseline-0904-1341</a></strong> to <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/mdvqqydn' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/mdvqqydn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 WandB 실험 시작!\n",
      "📊 대시보드: https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/mdvqqydn\n",
      "📋 실험명: efficientnet-b3-baseline-0904-1341\n",
      "\n",
      "============================================================\n",
      "🎯 5-FOLD CROSS VALIDATION 시작\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 9. Load Data & Start K-Fold Cross Validation with WandB\n",
    "# =============================================================================\n",
    "\n",
    "# 전체 학습 데이터 로드\n",
    "train_df = pd.read_csv(\"../data/train.csv\")\n",
    "print(f\"학습 데이터: {len(train_df)}개 샘플\")\n",
    "\n",
    "# 클래스 분포 확인\n",
    "class_counts = train_df['target'].value_counts().sort_index()\n",
    "print(f\" 클래스 분포: {dict(class_counts)}\")\n",
    "\n",
    "# K-Fold 설정\n",
    "skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)\n",
    "\n",
    "# K-Fold 결과를 저장할 리스트\n",
    "fold_results = []\n",
    "fold_models = []  # 각 fold의 최고 성능 모델을 저장\n",
    "\n",
    "#  WandB 메인 실험 시작\n",
    "main_run = wandb.init(\n",
    "    project=PROJECT_NAME,\n",
    "    entity=ENTITY,\n",
    "    name=f\"{EXPERIMENT_NAME}-{datetime.now().strftime('%m%d-%H%M')}\",\n",
    "    config=config,\n",
    "    tags=[\"k-fold-cv\", \"ensemble\", model_name, \"baseline\", \"main-experiment\"],\n",
    "    group=\"k-fold-experiment\",\n",
    "    job_type=\"cross-validation\",\n",
    "    notes=f\"{N_FOLDS}-Fold Cross Validation with {model_name}\"\n",
    ")\n",
    "\n",
    "print(f\"\\n🚀 WandB 실험 시작!\")\n",
    "print(f\"📊 대시보드: {main_run.url}\")\n",
    "print(f\"📋 실험명: {main_run.name}\")\n",
    "\n",
    "#  데이터셋 정보 로깅\n",
    "wandb.log({\n",
    "    \"dataset/total_samples\": len(train_df),\n",
    "    \"dataset/num_classes\": 17,\n",
    "    \"dataset/samples_per_fold\": len(train_df) // N_FOLDS,\n",
    "})\n",
    "\n",
    "# 클래스 분포 시각화\n",
    "class_dist_data = [[f\"Class_{i}\", count] for i, count in enumerate(class_counts)]\n",
    "wandb.log({\n",
    "    \"dataset/class_distribution\": wandb.plot.bar(\n",
    "        wandb.Table(data=class_dist_data, columns=[\"Class\", \"Count\"]),\n",
    "        \"Class\", \"Count\", \n",
    "        title=\"Training Data Class Distribution\"\n",
    "    )\n",
    "})\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"🎯 {N_FOLDS}-FOLD CROSS VALIDATION 시작\")\n",
    "print(f\"{'='*60}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1675898e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      " FOLD 1/5\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to True."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>dataset/num_classes</td><td>▁</td></tr><tr><td>dataset/samples_per_fold</td><td>▁</td></tr><tr><td>dataset/total_samples</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>dataset/num_classes</td><td>17</td></tr><tr><td>dataset/samples_per_fold</td><td>314</td></tr><tr><td>dataset/total_samples</td><td>1570</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">efficientnet-b3-baseline-0904-1341</strong> at: <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/mdvqqydn' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/mdvqqydn</a><br> View project at: <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team</a><br>Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250904_134143-mdvqqydn/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "creating run (0.2s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/ephemeral/home/computervisioncompetition-cv-1/wandb/wandb/run-20250904_134145-bx5b6hog</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/bx5b6hog' target=\"_blank\">fold-1-efficientnet_b3-1341</a></strong> to <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/bx5b6hog' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/bx5b6hog</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Fold 1 Dashboard: https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/bx5b6hog\n",
      "Train samples: 1256, Validation samples: 314\n",
      " 모델 학습 시작 - Fold 1\n",
      "\n",
      "📈 Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.9688, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:22<00:00,  1.78it/s]\n",
      "Val Loss: 1.8446: 100%|██████████| 10/10 [00:02<00:00,  4.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  1 | Train Loss: 2.6804 | Train F1: 0.2319 | Val Loss: 1.7305 | Val F1: 0.6661 | LR: 5.00e-04\n",
      "🎉 새로운 최고 성능! F1: 0.6661\n",
      "\n",
      "📈 Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.4531, Mixup: False, Cutout: True, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.42it/s]\n",
      "Val Loss: 1.5317: 100%|██████████| 10/10 [00:01<00:00,  6.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  2 | Train Loss: 2.0021 | Train F1: 0.4900 | Val Loss: 1.4795 | Val F1: 0.7949 | LR: 5.00e-04\n",
      "🎉 새로운 최고 성능! F1: 0.7949\n",
      "\n",
      "📈 Epoch 3/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.5195, Mixup: False, Cutout: True, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.43it/s]\n",
      "Val Loss: 1.4500: 100%|██████████| 10/10 [00:01<00:00,  6.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  3 | Train Loss: 1.7830 | Train F1: 0.5823 | Val Loss: 1.3833 | Val F1: 0.8436 | LR: 4.98e-04\n",
      "🎉 새로운 최고 성능! F1: 0.8436\n",
      "\n",
      "📈 Epoch 4/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.6338, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:11<00:00,  3.46it/s]\n",
      "Val Loss: 1.3547: 100%|██████████| 10/10 [00:01<00:00,  5.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  4 | Train Loss: 1.7137 | Train F1: 0.6073 | Val Loss: 1.3095 | Val F1: 0.8674 | LR: 4.96e-04\n",
      "🎉 새로운 최고 성능! F1: 0.8674\n",
      "\n",
      "📈 Epoch 5/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3613, Mixup: False, Cutout: True, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.45it/s]\n",
      "Val Loss: 1.3083: 100%|██████████| 10/10 [00:01<00:00,  6.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  5 | Train Loss: 1.6229 | Train F1: 0.6758 | Val Loss: 1.2937 | Val F1: 0.8725 | LR: 4.92e-04\n",
      "🎉 새로운 최고 성능! F1: 0.8725\n",
      "\n",
      "📈 Epoch 6/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.6377, Mixup: False, Cutout: True, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.34it/s]\n",
      "Val Loss: 1.2638: 100%|██████████| 10/10 [00:01<00:00,  5.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  6 | Train Loss: 1.5749 | Train F1: 0.7083 | Val Loss: 1.3079 | Val F1: 0.8428 | LR: 4.88e-04\n",
      "\n",
      "📈 Epoch 7/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2383, Mixup: False, Cutout: True, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.47it/s]\n",
      "Val Loss: 1.2842: 100%|██████████| 10/10 [00:01<00:00,  6.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  7 | Train Loss: 1.5315 | Train F1: 0.7010 | Val Loss: 1.2491 | Val F1: 0.8710 | LR: 4.82e-04\n",
      "\n",
      "📈 Epoch 8/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.5859, Mixup: False, Cutout: True, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.48it/s]\n",
      "Val Loss: 1.2566: 100%|██████████| 10/10 [00:01<00:00,  5.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  8 | Train Loss: 1.4285 | Train F1: 0.7979 | Val Loss: 1.2430 | Val F1: 0.9007 | LR: 4.76e-04\n",
      "🎉 새로운 최고 성능! F1: 0.9007\n",
      "\n",
      "📈 Epoch 9/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.6748, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:11<00:00,  3.51it/s]\n",
      "Val Loss: 1.3260: 100%|██████████| 10/10 [00:01<00:00,  5.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  9 | Train Loss: 1.4779 | Train F1: 0.7788 | Val Loss: 1.2688 | Val F1: 0.8666 | LR: 4.69e-04\n",
      "\n",
      "📈 Epoch 10/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3213, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:11<00:00,  3.38it/s]\n",
      "Val Loss: 1.2989: 100%|██████████| 10/10 [00:01<00:00,  6.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 10 | Train Loss: 1.3983 | Train F1: 0.7824 | Val Loss: 1.2484 | Val F1: 0.8500 | LR: 4.61e-04\n",
      "\n",
      "📈 Epoch 11/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.5703, Mixup: True, Cutout: False, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.45it/s]\n",
      "Val Loss: 1.2096: 100%|██████████| 10/10 [00:01<00:00,  5.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 11 | Train Loss: 1.3786 | Train F1: 0.7555 | Val Loss: 1.1950 | Val F1: 0.9168 | LR: 4.52e-04\n",
      "🎉 새로운 최고 성능! F1: 0.9168\n",
      "\n",
      "📈 Epoch 12/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2490, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:11<00:00,  3.37it/s]\n",
      "Val Loss: 1.2226: 100%|██████████| 10/10 [00:01<00:00,  5.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 12 | Train Loss: 1.3692 | Train F1: 0.7847 | Val Loss: 1.2061 | Val F1: 0.8956 | LR: 4.43e-04\n",
      "\n",
      "📈 Epoch 13/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1934, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:11<00:00,  3.54it/s]\n",
      "Val Loss: 1.1941: 100%|██████████| 10/10 [00:01<00:00,  6.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 13 | Train Loss: 1.3136 | Train F1: 0.8023 | Val Loss: 1.1767 | Val F1: 0.9271 | LR: 4.32e-04\n",
      "🎉 새로운 최고 성능! F1: 0.9271\n",
      "\n",
      "📈 Epoch 14/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.7422, Mixup: True, Cutout: False, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.36it/s]\n",
      "Val Loss: 1.1871: 100%|██████████| 10/10 [00:01<00:00,  5.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 14 | Train Loss: 1.4536 | Train F1: 0.7564 | Val Loss: 1.1917 | Val F1: 0.9049 | LR: 4.21e-04\n",
      "\n",
      "📈 Epoch 15/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3037, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:11<00:00,  3.48it/s]\n",
      "Val Loss: 1.1767: 100%|██████████| 10/10 [00:01<00:00,  5.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 15 | Train Loss: 1.3691 | Train F1: 0.8426 | Val Loss: 1.1875 | Val F1: 0.9231 | LR: 4.09e-04\n",
      "\n",
      "📈 Epoch 16/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1533, Mixup: False, Cutout: True, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.45it/s]\n",
      "Val Loss: 1.2072: 100%|██████████| 10/10 [00:01<00:00,  6.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 16 | Train Loss: 1.3260 | Train F1: 0.8188 | Val Loss: 1.1818 | Val F1: 0.9087 | LR: 3.97e-04\n",
      "\n",
      "📈 Epoch 17/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1641, Mixup: False, Cutout: True, RandomCrop: False: 100%|██████████| 40/40 [00:12<00:00,  3.28it/s]\n",
      "Val Loss: 1.2108: 100%|██████████| 10/10 [00:01<00:00,  5.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 17 | Train Loss: 1.3163 | Train F1: 0.7983 | Val Loss: 1.1732 | Val F1: 0.9185 | LR: 3.84e-04\n",
      "\n",
      "📈 Epoch 18/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1523, Mixup: False, Cutout: True, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.48it/s]\n",
      "Val Loss: 1.1906: 100%|██████████| 10/10 [00:01<00:00,  6.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 18 | Train Loss: 1.3462 | Train F1: 0.7872 | Val Loss: 1.1606 | Val F1: 0.9234 | LR: 3.70e-04\n",
      "\n",
      "📈 Epoch 19/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2734, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:11<00:00,  3.39it/s]\n",
      "Val Loss: 1.2322: 100%|██████████| 10/10 [00:01<00:00,  6.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 19 | Train Loss: 1.3168 | Train F1: 0.8193 | Val Loss: 1.1822 | Val F1: 0.9067 | LR: 3.56e-04\n",
      "\n",
      "📈 Epoch 20/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1250, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:11<00:00,  3.51it/s]\n",
      "Val Loss: 1.2293: 100%|██████████| 10/10 [00:01<00:00,  6.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 20 | Train Loss: 1.3624 | Train F1: 0.7609 | Val Loss: 1.1740 | Val F1: 0.9221 | LR: 3.42e-04\n",
      "\n",
      "📈 Epoch 21/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.0986, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:11<00:00,  3.43it/s]\n",
      "Val Loss: 1.2336: 100%|██████████| 10/10 [00:01<00:00,  6.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 21 | Train Loss: 1.3597 | Train F1: 0.7303 | Val Loss: 1.1788 | Val F1: 0.9191 | LR: 3.27e-04\n",
      "\n",
      "📈 Epoch 22/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.0859, Mixup: True, Cutout: False, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.44it/s]\n",
      "Val Loss: 1.1930: 100%|██████████| 10/10 [00:01<00:00,  5.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 22 | Train Loss: 1.3475 | Train F1: 0.7922 | Val Loss: 1.1696 | Val F1: 0.9258 | LR: 3.12e-04\n",
      "\n",
      "📈 Epoch 23/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3496, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:11<00:00,  3.47it/s]\n",
      "Val Loss: 1.2118: 100%|██████████| 10/10 [00:01<00:00,  5.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 23 | Train Loss: 1.2773 | Train F1: 0.8016 | Val Loss: 1.1707 | Val F1: 0.9205 | LR: 2.97e-04\n",
      "\n",
      "📈 Epoch 24/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3613, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:11<00:00,  3.39it/s]\n",
      "Val Loss: 1.1907: 100%|██████████| 10/10 [00:01<00:00,  5.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 24 | Train Loss: 1.3701 | Train F1: 0.7768 | Val Loss: 1.1688 | Val F1: 0.9114 | LR: 2.81e-04\n",
      "\n",
      "📈 Epoch 25/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2998, Mixup: False, Cutout: True, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.42it/s]\n",
      "Val Loss: 1.2012: 100%|██████████| 10/10 [00:01<00:00,  6.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 25 | Train Loss: 1.3299 | Train F1: 0.8090 | Val Loss: 1.1698 | Val F1: 0.9100 | LR: 2.66e-04\n",
      "\n",
      "📈 Epoch 26/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2471, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:11<00:00,  3.47it/s]\n",
      "Val Loss: 1.1948: 100%|██████████| 10/10 [00:01<00:00,  5.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 26 | Train Loss: 1.2779 | Train F1: 0.7892 | Val Loss: 1.1699 | Val F1: 0.9187 | LR: 2.50e-04\n",
      "\n",
      "📈 Epoch 27/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.7148, Mixup: False, Cutout: True, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.42it/s]\n",
      "Val Loss: 1.1796: 100%|██████████| 10/10 [00:01<00:00,  6.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 27 | Train Loss: 1.2916 | Train F1: 0.8318 | Val Loss: 1.1642 | Val F1: 0.9141 | LR: 2.34e-04\n",
      "⏸️ Early stopping at epoch 27 (patience: 14)\n",
      "\n",
      " Fold 1 완료!\n",
      " 최고 Validation F1: 0.9271\n",
      " 학습된 에폭: 27/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>best_performance/epoch</td><td>▁▂▂▃▃▅▇█</td></tr><tr><td>best_performance/val_acc</td><td>▁▅▆▇▇▇██</td></tr><tr><td>best_performance/val_f1</td><td>▁▄▆▆▇▇██</td></tr><tr><td>best_performance/val_loss</td><td>█▅▄▃▂▂▁▁</td></tr><tr><td>early_stopping/epoch</td><td>▁</td></tr><tr><td>epoch</td><td>▁▁▂▂▂▂▃▃▃▃▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇██</td></tr><tr><td>fold</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>fold_1/batch_step</td><td>▁▁▂▂▂▂▃▃▃▃▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇██</td></tr><tr><td>fold_1/cutout_applied</td><td>▁██▁▁█▁██▁▁██▁▁███▁▁▁▁▁▁▁█▁</td></tr><tr><td>fold_1/mixup_applied</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁██▁▁█▁▁</td></tr><tr><td>+22</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_performance/epoch</td><td>13</td></tr><tr><td>best_performance/val_acc</td><td>0.92994</td></tr><tr><td>best_performance/val_f1</td><td>0.92706</td></tr><tr><td>best_performance/val_loss</td><td>1.17669</td></tr><tr><td>early_stopping/epoch</td><td>27</td></tr><tr><td>epoch</td><td>27</td></tr><tr><td>fold</td><td>1</td></tr><tr><td>fold_1/batch_step</td><td>1040</td></tr><tr><td>fold_1/cutout_applied</td><td>0</td></tr><tr><td>fold_1/mixup_applied</td><td>0</td></tr><tr><td>+23</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fold-1-efficientnet_b3-1341</strong> at: <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/bx5b6hog' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/bx5b6hog</a><br> View project at: <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250904_134145-bx5b6hog/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      " FOLD 2/5\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "creating run (0.0s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/ephemeral/home/computervisioncompetition-cv-1/wandb/wandb/run-20250904_134802-6ezm341t</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/6ezm341t' target=\"_blank\">fold-2-efficientnet_b3-1348</a></strong> to <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/6ezm341t' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/6ezm341t</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Fold 2 Dashboard: https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/6ezm341t\n",
      "Train samples: 1256, Validation samples: 314\n",
      " 모델 학습 시작 - Fold 2\n",
      "\n",
      "📈 Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.7383, Mixup: True, Cutout: False, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.38it/s]\n",
      "Val Loss: 1.7013: 100%|██████████| 10/10 [00:01<00:00,  5.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  1 | Train Loss: 2.7039 | Train F1: 0.2769 | Val Loss: 1.7919 | Val F1: 0.6296 | LR: 5.00e-04\n",
      "🎉 새로운 최고 성능! F1: 0.6296\n",
      "\n",
      "📈 Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.5049, Mixup: False, Cutout: True, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.43it/s]\n",
      "Val Loss: 1.4894: 100%|██████████| 10/10 [00:01<00:00,  6.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  2 | Train Loss: 1.9208 | Train F1: 0.5250 | Val Loss: 1.5198 | Val F1: 0.7612 | LR: 5.00e-04\n",
      "🎉 새로운 최고 성능! F1: 0.7612\n",
      "\n",
      "📈 Epoch 3/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.7480, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:12<00:00,  3.32it/s]\n",
      "Val Loss: 1.3445: 100%|██████████| 10/10 [00:01<00:00,  5.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  3 | Train Loss: 1.7352 | Train F1: 0.6231 | Val Loss: 1.4037 | Val F1: 0.8230 | LR: 4.98e-04\n",
      "🎉 새로운 최고 성능! F1: 0.8230\n",
      "\n",
      "📈 Epoch 4/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.5986, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:11<00:00,  3.34it/s]\n",
      "Val Loss: 1.3615: 100%|██████████| 10/10 [00:01<00:00,  5.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  4 | Train Loss: 1.6092 | Train F1: 0.6809 | Val Loss: 1.3748 | Val F1: 0.8011 | LR: 4.96e-04\n",
      "\n",
      "📈 Epoch 5/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3613, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:11<00:00,  3.39it/s]\n",
      "Val Loss: 1.2736: 100%|██████████| 10/10 [00:01<00:00,  5.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  5 | Train Loss: 1.5628 | Train F1: 0.7028 | Val Loss: 1.3066 | Val F1: 0.8416 | LR: 4.92e-04\n",
      "🎉 새로운 최고 성능! F1: 0.8416\n",
      "\n",
      "📈 Epoch 6/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.4541, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:11<00:00,  3.37it/s]\n",
      "Val Loss: 1.2514: 100%|██████████| 10/10 [00:01<00:00,  6.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  6 | Train Loss: 1.5157 | Train F1: 0.7432 | Val Loss: 1.2686 | Val F1: 0.8586 | LR: 4.88e-04\n",
      "🎉 새로운 최고 성능! F1: 0.8586\n",
      "\n",
      "📈 Epoch 7/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.4922, Mixup: False, Cutout: True, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.42it/s]\n",
      "Val Loss: 1.2196: 100%|██████████| 10/10 [00:01<00:00,  5.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  7 | Train Loss: 1.5309 | Train F1: 0.6739 | Val Loss: 1.2613 | Val F1: 0.8684 | LR: 4.82e-04\n",
      "🎉 새로운 최고 성능! F1: 0.8684\n",
      "\n",
      "📈 Epoch 8/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2236, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:11<00:00,  3.42it/s]\n",
      "Val Loss: 1.2344: 100%|██████████| 10/10 [00:01<00:00,  5.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  8 | Train Loss: 1.4564 | Train F1: 0.7748 | Val Loss: 1.2425 | Val F1: 0.8921 | LR: 4.76e-04\n",
      "🎉 새로운 최고 성능! F1: 0.8921\n",
      "\n",
      "📈 Epoch 9/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2363, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:11<00:00,  3.44it/s]\n",
      "Val Loss: 1.2433: 100%|██████████| 10/10 [00:01<00:00,  5.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  9 | Train Loss: 1.3925 | Train F1: 0.8080 | Val Loss: 1.2671 | Val F1: 0.8778 | LR: 4.69e-04\n",
      "\n",
      "📈 Epoch 10/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.0820, Mixup: True, Cutout: False, RandomCrop: False: 100%|██████████| 40/40 [00:12<00:00,  3.31it/s]\n",
      "Val Loss: 1.2524: 100%|██████████| 10/10 [00:01<00:00,  6.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 10 | Train Loss: 1.4148 | Train F1: 0.8086 | Val Loss: 1.2622 | Val F1: 0.8826 | LR: 4.61e-04\n",
      "\n",
      "📈 Epoch 11/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.6719, Mixup: True, Cutout: False, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.39it/s]\n",
      "Val Loss: 1.1820: 100%|██████████| 10/10 [00:01<00:00,  6.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 11 | Train Loss: 1.3909 | Train F1: 0.7425 | Val Loss: 1.2268 | Val F1: 0.8949 | LR: 4.52e-04\n",
      "🎉 새로운 최고 성능! F1: 0.8949\n",
      "\n",
      "📈 Epoch 12/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.5020, Mixup: True, Cutout: False, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.40it/s]\n",
      "Val Loss: 1.2283: 100%|██████████| 10/10 [00:01<00:00,  5.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 12 | Train Loss: 1.4071 | Train F1: 0.8106 | Val Loss: 1.2381 | Val F1: 0.8932 | LR: 4.43e-04\n",
      "\n",
      "📈 Epoch 13/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2559, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:11<00:00,  3.34it/s]\n",
      "Val Loss: 1.2030: 100%|██████████| 10/10 [00:01<00:00,  6.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 13 | Train Loss: 1.3826 | Train F1: 0.8115 | Val Loss: 1.2157 | Val F1: 0.9040 | LR: 4.32e-04\n",
      "🎉 새로운 최고 성능! F1: 0.9040\n",
      "\n",
      "📈 Epoch 14/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.4326, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:11<00:00,  3.40it/s]\n",
      "Val Loss: 1.2870: 100%|██████████| 10/10 [00:01<00:00,  5.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 14 | Train Loss: 1.4295 | Train F1: 0.7752 | Val Loss: 1.2623 | Val F1: 0.8405 | LR: 4.21e-04\n",
      "\n",
      "📈 Epoch 15/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1934, Mixup: False, Cutout: True, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.45it/s]\n",
      "Val Loss: 1.1919: 100%|██████████| 10/10 [00:01<00:00,  5.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 15 | Train Loss: 1.3763 | Train F1: 0.7760 | Val Loss: 1.2058 | Val F1: 0.8816 | LR: 4.09e-04\n",
      "\n",
      "📈 Epoch 16/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.7598, Mixup: True, Cutout: False, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.39it/s]\n",
      "Val Loss: 1.1895: 100%|██████████| 10/10 [00:01<00:00,  5.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 16 | Train Loss: 1.4502 | Train F1: 0.6776 | Val Loss: 1.1864 | Val F1: 0.9099 | LR: 3.97e-04\n",
      "🎉 새로운 최고 성능! F1: 0.9099\n",
      "\n",
      "📈 Epoch 17/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1348, Mixup: False, Cutout: True, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.40it/s]\n",
      "Val Loss: 1.2520: 100%|██████████| 10/10 [00:01<00:00,  6.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 17 | Train Loss: 1.3274 | Train F1: 0.8389 | Val Loss: 1.2224 | Val F1: 0.8931 | LR: 3.84e-04\n",
      "\n",
      "📈 Epoch 18/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.9785, Mixup: True, Cutout: False, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.51it/s]\n",
      "Val Loss: 1.2048: 100%|██████████| 10/10 [00:01<00:00,  5.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 18 | Train Loss: 1.3719 | Train F1: 0.8212 | Val Loss: 1.1901 | Val F1: 0.8985 | LR: 3.70e-04\n",
      "\n",
      "📈 Epoch 19/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2842, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:11<00:00,  3.39it/s]\n",
      "Val Loss: 1.1518: 100%|██████████| 10/10 [00:01<00:00,  5.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 19 | Train Loss: 1.3176 | Train F1: 0.7398 | Val Loss: 1.1886 | Val F1: 0.8868 | LR: 3.56e-04\n",
      "\n",
      "📈 Epoch 20/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.0918, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:11<00:00,  3.42it/s]\n",
      "Val Loss: 1.1585: 100%|██████████| 10/10 [00:01<00:00,  6.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 20 | Train Loss: 1.3726 | Train F1: 0.8114 | Val Loss: 1.1724 | Val F1: 0.9129 | LR: 3.42e-04\n",
      "🎉 새로운 최고 성능! F1: 0.9129\n",
      "\n",
      "📈 Epoch 21/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1113, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:11<00:00,  3.35it/s]\n",
      "Val Loss: 1.2178: 100%|██████████| 10/10 [00:01<00:00,  5.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 21 | Train Loss: 1.2536 | Train F1: 0.8151 | Val Loss: 1.1816 | Val F1: 0.9080 | LR: 3.27e-04\n",
      "\n",
      "📈 Epoch 22/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1611, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:12<00:00,  3.23it/s]\n",
      "Val Loss: 1.1300: 100%|██████████| 10/10 [00:01<00:00,  5.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 22 | Train Loss: 1.2417 | Train F1: 0.9141 | Val Loss: 1.1766 | Val F1: 0.9030 | LR: 3.12e-04\n",
      "\n",
      "📈 Epoch 23/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2197, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:11<00:00,  3.34it/s]\n",
      "Val Loss: 1.1440: 100%|██████████| 10/10 [00:01<00:00,  6.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 23 | Train Loss: 1.3416 | Train F1: 0.7600 | Val Loss: 1.1720 | Val F1: 0.9136 | LR: 2.97e-04\n",
      "🎉 새로운 최고 성능! F1: 0.9136\n",
      "\n",
      "📈 Epoch 24/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.8691, Mixup: True, Cutout: False, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.43it/s]\n",
      "Val Loss: 1.1511: 100%|██████████| 10/10 [00:01<00:00,  6.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 24 | Train Loss: 1.3341 | Train F1: 0.8095 | Val Loss: 1.1764 | Val F1: 0.9068 | LR: 2.81e-04\n",
      "\n",
      "📈 Epoch 25/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1543, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:11<00:00,  3.45it/s]\n",
      "Val Loss: 1.1747: 100%|██████████| 10/10 [00:01<00:00,  5.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 25 | Train Loss: 1.3416 | Train F1: 0.7703 | Val Loss: 1.1735 | Val F1: 0.8994 | LR: 2.66e-04\n",
      "\n",
      "📈 Epoch 26/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.8086, Mixup: True, Cutout: False, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.52it/s]\n",
      "Val Loss: 1.1886: 100%|██████████| 10/10 [00:01<00:00,  5.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 26 | Train Loss: 1.2959 | Train F1: 0.8043 | Val Loss: 1.1677 | Val F1: 0.9168 | LR: 2.50e-04\n",
      "🎉 새로운 최고 성능! F1: 0.9168\n",
      "\n",
      "📈 Epoch 27/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.0508, Mixup: False, Cutout: True, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.39it/s]\n",
      "Val Loss: 1.1333: 100%|██████████| 10/10 [00:01<00:00,  5.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 27 | Train Loss: 1.2736 | Train F1: 0.8329 | Val Loss: 1.1671 | Val F1: 0.9279 | LR: 2.34e-04\n",
      "🎉 새로운 최고 성능! F1: 0.9279\n",
      "\n",
      "📈 Epoch 28/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1328, Mixup: False, Cutout: True, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.39it/s]\n",
      "Val Loss: 1.1440: 100%|██████████| 10/10 [00:01<00:00,  5.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 28 | Train Loss: 1.3010 | Train F1: 0.7823 | Val Loss: 1.1631 | Val F1: 0.9204 | LR: 2.19e-04\n",
      "\n",
      "📈 Epoch 29/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1201, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:11<00:00,  3.48it/s]\n",
      "Val Loss: 1.1710: 100%|██████████| 10/10 [00:01<00:00,  6.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 29 | Train Loss: 1.3069 | Train F1: 0.8128 | Val Loss: 1.1637 | Val F1: 0.9115 | LR: 2.03e-04\n",
      "\n",
      "📈 Epoch 30/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2383, Mixup: False, Cutout: True, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.36it/s]\n",
      "Val Loss: 1.1294: 100%|██████████| 10/10 [00:01<00:00,  5.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 30 | Train Loss: 1.3378 | Train F1: 0.7996 | Val Loss: 1.1463 | Val F1: 0.9291 | LR: 1.88e-04\n",
      "🎉 새로운 최고 성능! F1: 0.9291\n",
      "\n",
      "📈 Epoch 31/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.8877, Mixup: True, Cutout: False, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.45it/s]\n",
      "Val Loss: 1.1387: 100%|██████████| 10/10 [00:01<00:00,  5.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 31 | Train Loss: 1.2434 | Train F1: 0.8706 | Val Loss: 1.1447 | Val F1: 0.9297 | LR: 1.73e-04\n",
      "🎉 새로운 최고 성능! F1: 0.9297\n",
      "\n",
      "📈 Epoch 32/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2598, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:11<00:00,  3.46it/s]\n",
      "Val Loss: 1.1190: 100%|██████████| 10/10 [00:01<00:00,  6.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 32 | Train Loss: 1.2548 | Train F1: 0.8861 | Val Loss: 1.1525 | Val F1: 0.9306 | LR: 1.58e-04\n",
      "🎉 새로운 최고 성능! F1: 0.9306\n",
      "\n",
      "📈 Epoch 33/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.0293, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:11<00:00,  3.43it/s]\n",
      "Val Loss: 1.1494: 100%|██████████| 10/10 [00:01<00:00,  5.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 33 | Train Loss: 1.2109 | Train F1: 0.9142 | Val Loss: 1.1471 | Val F1: 0.9211 | LR: 1.44e-04\n",
      "\n",
      "📈 Epoch 34/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1338, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:11<00:00,  3.37it/s]\n",
      "Val Loss: 1.1696: 100%|██████████| 10/10 [00:01<00:00,  6.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 34 | Train Loss: 1.3375 | Train F1: 0.8074 | Val Loss: 1.1533 | Val F1: 0.9299 | LR: 1.30e-04\n",
      "\n",
      "📈 Epoch 35/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1211, Mixup: False, Cutout: True, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.36it/s]\n",
      "Val Loss: 1.1442: 100%|██████████| 10/10 [00:01<00:00,  5.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 35 | Train Loss: 1.2594 | Train F1: 0.8288 | Val Loss: 1.1445 | Val F1: 0.9299 | LR: 1.16e-04\n",
      "\n",
      "📈 Epoch 36/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1094, Mixup: True, Cutout: False, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.39it/s]\n",
      "Val Loss: 1.1601: 100%|██████████| 10/10 [00:01<00:00,  5.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 36 | Train Loss: 1.3014 | Train F1: 0.7933 | Val Loss: 1.1483 | Val F1: 0.9353 | LR: 1.03e-04\n",
      "🎉 새로운 최고 성능! F1: 0.9353\n",
      "\n",
      "📈 Epoch 37/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.0439, Mixup: False, Cutout: True, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.40it/s]\n",
      "Val Loss: 1.1495: 100%|██████████| 10/10 [00:01<00:00,  5.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 37 | Train Loss: 1.2059 | Train F1: 0.8544 | Val Loss: 1.1460 | Val F1: 0.9411 | LR: 9.06e-05\n",
      "🎉 새로운 최고 성능! F1: 0.9411\n",
      "\n",
      "📈 Epoch 38/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1621, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:11<00:00,  3.41it/s]\n",
      "Val Loss: 1.1391: 100%|██████████| 10/10 [00:01<00:00,  5.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 38 | Train Loss: 1.2677 | Train F1: 0.8281 | Val Loss: 1.1512 | Val F1: 0.9267 | LR: 7.89e-05\n",
      "\n",
      "📈 Epoch 39/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1699, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:11<00:00,  3.45it/s]\n",
      "Val Loss: 1.1456: 100%|██████████| 10/10 [00:01<00:00,  6.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 39 | Train Loss: 1.2675 | Train F1: 0.7464 | Val Loss: 1.1475 | Val F1: 0.9310 | LR: 6.78e-05\n",
      "\n",
      "📈 Epoch 40/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.8945, Mixup: True, Cutout: False, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.48it/s]\n",
      "Val Loss: 1.1321: 100%|██████████| 10/10 [00:01<00:00,  5.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 40 | Train Loss: 1.2760 | Train F1: 0.8662 | Val Loss: 1.1466 | Val F1: 0.9344 | LR: 5.74e-05\n",
      "\n",
      "📈 Epoch 41/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.9482, Mixup: False, Cutout: True, RandomCrop: False: 100%|██████████| 40/40 [00:12<00:00,  3.33it/s]\n",
      "Val Loss: 1.1380: 100%|██████████| 10/10 [00:01<00:00,  6.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 41 | Train Loss: 1.2532 | Train F1: 0.8403 | Val Loss: 1.1404 | Val F1: 0.9412 | LR: 4.77e-05\n",
      "🎉 새로운 최고 성능! F1: 0.9412\n",
      "\n",
      "📈 Epoch 42/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.8887, Mixup: True, Cutout: False, RandomCrop: False: 100%|██████████| 40/40 [00:12<00:00,  3.23it/s]\n",
      "Val Loss: 1.1778: 100%|██████████| 10/10 [00:01<00:00,  6.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 42 | Train Loss: 1.2611 | Train F1: 0.8900 | Val Loss: 1.1563 | Val F1: 0.9317 | LR: 3.89e-05\n",
      "\n",
      "📈 Epoch 43/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1035, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:11<00:00,  3.40it/s]\n",
      "Val Loss: 1.1334: 100%|██████████| 10/10 [00:01<00:00,  6.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 43 | Train Loss: 1.1909 | Train F1: 0.8800 | Val Loss: 1.1464 | Val F1: 0.9302 | LR: 3.09e-05\n",
      "\n",
      "📈 Epoch 44/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.7578, Mixup: True, Cutout: False, RandomCrop: False: 100%|██████████| 40/40 [00:12<00:00,  3.31it/s]\n",
      "Val Loss: 1.1545: 100%|██████████| 10/10 [00:01<00:00,  6.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 44 | Train Loss: 1.2135 | Train F1: 0.8979 | Val Loss: 1.1519 | Val F1: 0.9329 | LR: 2.38e-05\n",
      "\n",
      "📈 Epoch 45/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.9961, Mixup: True, Cutout: False, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.51it/s]\n",
      "Val Loss: 1.1447: 100%|██████████| 10/10 [00:01<00:00,  5.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 45 | Train Loss: 1.2069 | Train F1: 0.8663 | Val Loss: 1.1511 | Val F1: 0.9411 | LR: 1.76e-05\n",
      "\n",
      "📈 Epoch 46/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3447, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:11<00:00,  3.36it/s]\n",
      "Val Loss: 1.1488: 100%|██████████| 10/10 [00:01<00:00,  5.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 46 | Train Loss: 1.2337 | Train F1: 0.8611 | Val Loss: 1.1528 | Val F1: 0.9409 | LR: 1.22e-05\n",
      "\n",
      "📈 Epoch 47/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2334, Mixup: False, Cutout: True, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.39it/s]\n",
      "Val Loss: 1.1423: 100%|██████████| 10/10 [00:01<00:00,  5.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 47 | Train Loss: 1.2268 | Train F1: 0.8626 | Val Loss: 1.1484 | Val F1: 0.9409 | LR: 7.85e-06\n",
      "\n",
      "📈 Epoch 48/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.5225, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:11<00:00,  3.43it/s]\n",
      "Val Loss: 1.1531: 100%|██████████| 10/10 [00:01<00:00,  5.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 48 | Train Loss: 1.2988 | Train F1: 0.7891 | Val Loss: 1.1527 | Val F1: 0.9409 | LR: 4.43e-06\n",
      "⏸️ Early stopping at epoch 48 (patience: 7)\n",
      "\n",
      " Fold 2 완료!\n",
      " 최고 Validation F1: 0.9412\n",
      " 학습된 에폭: 48/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>best_performance/epoch</td><td>▁▁▁▂▂▂▂▃▃▄▄▅▅▆▆▆▆▇▇█</td></tr><tr><td>best_performance/val_acc</td><td>▁▄▅▆▇▆▇▇▇▇▇▇▇███████</td></tr><tr><td>best_performance/val_f1</td><td>▁▄▅▆▆▆▇▇▇▇▇▇▇███████</td></tr><tr><td>best_performance/val_loss</td><td>█▅▄▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>early_stopping/epoch</td><td>▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>fold</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>fold_2/batch_step</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>fold_2/cutout_applied</td><td>▁██▁█▁▁▁▁▁▁▁█▁▁▁▁█▁▁█▁██▁▁█▁▁▁█▁▁██▁▁▁▁▁</td></tr><tr><td>fold_2/mixup_applied</td><td>█▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁█▁█▁█▁▁▁██▁▁▁</td></tr><tr><td>+22</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_performance/epoch</td><td>41</td></tr><tr><td>best_performance/val_acc</td><td>0.94586</td></tr><tr><td>best_performance/val_f1</td><td>0.94124</td></tr><tr><td>best_performance/val_loss</td><td>1.14038</td></tr><tr><td>early_stopping/epoch</td><td>48</td></tr><tr><td>epoch</td><td>48</td></tr><tr><td>fold</td><td>2</td></tr><tr><td>fold_2/batch_step</td><td>1880</td></tr><tr><td>fold_2/cutout_applied</td><td>0</td></tr><tr><td>fold_2/mixup_applied</td><td>0</td></tr><tr><td>+23</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fold-2-efficientnet_b3-1348</strong> at: <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/6ezm341t' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/6ezm341t</a><br> View project at: <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250904_134802-6ezm341t/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      " FOLD 3/5\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "creating run (0.1s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/ephemeral/home/computervisioncompetition-cv-1/wandb/wandb/run-20250904_135854-ailr3rai</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/ailr3rai' target=\"_blank\">fold-3-efficientnet_b3-1358</a></strong> to <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/ailr3rai' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/ailr3rai</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Fold 3 Dashboard: https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/ailr3rai\n",
      "Train samples: 1256, Validation samples: 314\n",
      " 모델 학습 시작 - Fold 3\n",
      "\n",
      "📈 Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.0195, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:12<00:00,  3.22it/s]\n",
      "Val Loss: 1.6158: 100%|██████████| 10/10 [00:01<00:00,  5.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  1 | Train Loss: 2.7335 | Train F1: 0.2469 | Val Loss: 1.7240 | Val F1: 0.6256 | LR: 5.00e-04\n",
      "🎉 새로운 최고 성능! F1: 0.6256\n",
      "\n",
      "📈 Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.9424, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:11<00:00,  3.43it/s]\n",
      "Val Loss: 1.4114: 100%|██████████| 10/10 [00:01<00:00,  6.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  2 | Train Loss: 2.0801 | Train F1: 0.4753 | Val Loss: 1.5084 | Val F1: 0.7141 | LR: 5.00e-04\n",
      "🎉 새로운 최고 성능! F1: 0.7141\n",
      "\n",
      "📈 Epoch 3/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.0898, Mixup: True, Cutout: False, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.38it/s]\n",
      "Val Loss: 1.3176: 100%|██████████| 10/10 [00:01<00:00,  5.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  3 | Train Loss: 1.8310 | Train F1: 0.6225 | Val Loss: 1.3955 | Val F1: 0.8199 | LR: 4.98e-04\n",
      "🎉 새로운 최고 성능! F1: 0.8199\n",
      "\n",
      "📈 Epoch 4/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.3984, Mixup: True, Cutout: False, RandomCrop: False: 100%|██████████| 40/40 [00:12<00:00,  3.32it/s]\n",
      "Val Loss: 1.3669: 100%|██████████| 10/10 [00:01<00:00,  6.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  4 | Train Loss: 1.7421 | Train F1: 0.6532 | Val Loss: 1.3824 | Val F1: 0.8150 | LR: 4.96e-04\n",
      "\n",
      "📈 Epoch 5/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.7676, Mixup: False, Cutout: True, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.41it/s]\n",
      "Val Loss: 1.3001: 100%|██████████| 10/10 [00:01<00:00,  5.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  5 | Train Loss: 1.6742 | Train F1: 0.6656 | Val Loss: 1.3280 | Val F1: 0.8546 | LR: 4.92e-04\n",
      "🎉 새로운 최고 성능! F1: 0.8546\n",
      "\n",
      "📈 Epoch 6/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3730, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:11<00:00,  3.41it/s]\n",
      "Val Loss: 1.2144: 100%|██████████| 10/10 [00:01<00:00,  5.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  6 | Train Loss: 1.6762 | Train F1: 0.5853 | Val Loss: 1.2911 | Val F1: 0.8739 | LR: 4.88e-04\n",
      "🎉 새로운 최고 성능! F1: 0.8739\n",
      "\n",
      "📈 Epoch 7/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.7373, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:11<00:00,  3.43it/s]\n",
      "Val Loss: 1.1905: 100%|██████████| 10/10 [00:01<00:00,  5.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  7 | Train Loss: 1.5459 | Train F1: 0.6935 | Val Loss: 1.2620 | Val F1: 0.8705 | LR: 4.82e-04\n",
      "\n",
      "📈 Epoch 8/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.4238, Mixup: False, Cutout: True, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.39it/s]\n",
      "Val Loss: 1.1545: 100%|██████████| 10/10 [00:01<00:00,  6.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  8 | Train Loss: 1.5054 | Train F1: 0.7209 | Val Loss: 1.2725 | Val F1: 0.8658 | LR: 4.76e-04\n",
      "\n",
      "📈 Epoch 9/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3438, Mixup: False, Cutout: True, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.34it/s]\n",
      "Val Loss: 1.1503: 100%|██████████| 10/10 [00:01<00:00,  5.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  9 | Train Loss: 1.5068 | Train F1: 0.7456 | Val Loss: 1.2382 | Val F1: 0.8726 | LR: 4.69e-04\n",
      "\n",
      "📈 Epoch 10/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.6963, Mixup: True, Cutout: False, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.48it/s]\n",
      "Val Loss: 1.1860: 100%|██████████| 10/10 [00:01<00:00,  5.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 10 | Train Loss: 1.4159 | Train F1: 0.7679 | Val Loss: 1.2363 | Val F1: 0.8595 | LR: 4.61e-04\n",
      "\n",
      "📈 Epoch 11/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.4912, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:11<00:00,  3.40it/s]\n",
      "Val Loss: 1.1411: 100%|██████████| 10/10 [00:01<00:00,  5.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 11 | Train Loss: 1.5120 | Train F1: 0.7667 | Val Loss: 1.2178 | Val F1: 0.8845 | LR: 4.52e-04\n",
      "🎉 새로운 최고 성능! F1: 0.8845\n",
      "\n",
      "📈 Epoch 12/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1562, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:11<00:00,  3.42it/s]\n",
      "Val Loss: 1.1331: 100%|██████████| 10/10 [00:01<00:00,  5.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 12 | Train Loss: 1.4401 | Train F1: 0.7768 | Val Loss: 1.2193 | Val F1: 0.8847 | LR: 4.43e-04\n",
      "🎉 새로운 최고 성능! F1: 0.8847\n",
      "\n",
      "📈 Epoch 13/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1533, Mixup: False, Cutout: True, RandomCrop: False: 100%|██████████| 40/40 [00:12<00:00,  3.31it/s]\n",
      "Val Loss: 1.2241: 100%|██████████| 10/10 [00:01<00:00,  6.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 13 | Train Loss: 1.4414 | Train F1: 0.7794 | Val Loss: 1.2362 | Val F1: 0.8665 | LR: 4.32e-04\n",
      "\n",
      "📈 Epoch 14/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.0957, Mixup: False, Cutout: True, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.40it/s]\n",
      "Val Loss: 1.2325: 100%|██████████| 10/10 [00:01<00:00,  5.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 14 | Train Loss: 1.4276 | Train F1: 0.7370 | Val Loss: 1.2252 | Val F1: 0.8580 | LR: 4.21e-04\n",
      "\n",
      "📈 Epoch 15/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3086, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:12<00:00,  3.31it/s]\n",
      "Val Loss: 1.1886: 100%|██████████| 10/10 [00:01<00:00,  5.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 15 | Train Loss: 1.4661 | Train F1: 0.7212 | Val Loss: 1.2027 | Val F1: 0.8873 | LR: 4.09e-04\n",
      "🎉 새로운 최고 성능! F1: 0.8873\n",
      "\n",
      "📈 Epoch 16/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1152, Mixup: False, Cutout: True, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.37it/s]\n",
      "Val Loss: 1.1960: 100%|██████████| 10/10 [00:01<00:00,  6.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 16 | Train Loss: 1.4054 | Train F1: 0.7872 | Val Loss: 1.2021 | Val F1: 0.8855 | LR: 3.97e-04\n",
      "\n",
      "📈 Epoch 17/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3242, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:11<00:00,  3.46it/s]\n",
      "Val Loss: 1.1524: 100%|██████████| 10/10 [00:01<00:00,  6.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 17 | Train Loss: 1.3555 | Train F1: 0.7900 | Val Loss: 1.1981 | Val F1: 0.8858 | LR: 3.84e-04\n",
      "\n",
      "📈 Epoch 18/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2158, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:11<00:00,  3.48it/s]\n",
      "Val Loss: 1.1305: 100%|██████████| 10/10 [00:01<00:00,  5.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 18 | Train Loss: 1.3076 | Train F1: 0.8421 | Val Loss: 1.1914 | Val F1: 0.8860 | LR: 3.70e-04\n",
      "\n",
      "📈 Epoch 19/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3643, Mixup: True, Cutout: False, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.37it/s]\n",
      "Val Loss: 1.1450: 100%|██████████| 10/10 [00:01<00:00,  6.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 19 | Train Loss: 1.3802 | Train F1: 0.7942 | Val Loss: 1.1984 | Val F1: 0.8869 | LR: 3.56e-04\n",
      "\n",
      "📈 Epoch 20/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.7148, Mixup: True, Cutout: False, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.40it/s]\n",
      "Val Loss: 1.2077: 100%|██████████| 10/10 [00:01<00:00,  5.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 20 | Train Loss: 1.4547 | Train F1: 0.7239 | Val Loss: 1.2104 | Val F1: 0.8830 | LR: 3.42e-04\n",
      "\n",
      "📈 Epoch 21/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.4395, Mixup: True, Cutout: False, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.43it/s]\n",
      "Val Loss: 1.0888: 100%|██████████| 10/10 [00:01<00:00,  5.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 21 | Train Loss: 1.3839 | Train F1: 0.8348 | Val Loss: 1.1666 | Val F1: 0.9231 | LR: 3.27e-04\n",
      "🎉 새로운 최고 성능! F1: 0.9231\n",
      "\n",
      "📈 Epoch 22/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1934, Mixup: False, Cutout: True, RandomCrop: False: 100%|██████████| 40/40 [00:12<00:00,  3.25it/s]\n",
      "Val Loss: 1.0886: 100%|██████████| 10/10 [00:01<00:00,  6.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 22 | Train Loss: 1.4253 | Train F1: 0.7684 | Val Loss: 1.1690 | Val F1: 0.9239 | LR: 3.12e-04\n",
      "🎉 새로운 최고 성능! F1: 0.9239\n",
      "\n",
      "📈 Epoch 23/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.4941, Mixup: True, Cutout: False, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.52it/s]\n",
      "Val Loss: 1.0868: 100%|██████████| 10/10 [00:01<00:00,  5.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 23 | Train Loss: 1.2829 | Train F1: 0.8522 | Val Loss: 1.1708 | Val F1: 0.9129 | LR: 2.97e-04\n",
      "\n",
      "📈 Epoch 24/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.4971, Mixup: True, Cutout: False, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.39it/s]\n",
      "Val Loss: 1.0769: 100%|██████████| 10/10 [00:01<00:00,  6.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 24 | Train Loss: 1.3591 | Train F1: 0.8317 | Val Loss: 1.1736 | Val F1: 0.9198 | LR: 2.81e-04\n",
      "\n",
      "📈 Epoch 25/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.0625, Mixup: True, Cutout: False, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.43it/s]\n",
      "Val Loss: 1.1236: 100%|██████████| 10/10 [00:01<00:00,  6.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 25 | Train Loss: 1.3041 | Train F1: 0.8332 | Val Loss: 1.1923 | Val F1: 0.8958 | LR: 2.66e-04\n",
      "\n",
      "📈 Epoch 26/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3125, Mixup: False, Cutout: True, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.34it/s]\n",
      "Val Loss: 1.1370: 100%|██████████| 10/10 [00:01<00:00,  5.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 26 | Train Loss: 1.2892 | Train F1: 0.8078 | Val Loss: 1.2187 | Val F1: 0.8843 | LR: 2.50e-04\n",
      "\n",
      "📈 Epoch 27/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1719, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:11<00:00,  3.48it/s]\n",
      "Val Loss: 1.0847: 100%|██████████| 10/10 [00:01<00:00,  5.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 27 | Train Loss: 1.3556 | Train F1: 0.7769 | Val Loss: 1.1579 | Val F1: 0.9322 | LR: 2.34e-04\n",
      "🎉 새로운 최고 성능! F1: 0.9322\n",
      "\n",
      "📈 Epoch 28/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.8916, Mixup: True, Cutout: False, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.33it/s]\n",
      "Val Loss: 1.1194: 100%|██████████| 10/10 [00:01<00:00,  5.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 28 | Train Loss: 1.3063 | Train F1: 0.8141 | Val Loss: 1.1709 | Val F1: 0.8969 | LR: 2.19e-04\n",
      "\n",
      "📈 Epoch 29/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1631, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:11<00:00,  3.40it/s]\n",
      "Val Loss: 1.1441: 100%|██████████| 10/10 [00:01<00:00,  5.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 29 | Train Loss: 1.2996 | Train F1: 0.8206 | Val Loss: 1.1778 | Val F1: 0.9135 | LR: 2.03e-04\n",
      "\n",
      "📈 Epoch 30/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2148, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:11<00:00,  3.42it/s]\n",
      "Val Loss: 1.1192: 100%|██████████| 10/10 [00:01<00:00,  5.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 30 | Train Loss: 1.2784 | Train F1: 0.8766 | Val Loss: 1.1757 | Val F1: 0.8834 | LR: 1.88e-04\n",
      "\n",
      "📈 Epoch 31/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1797, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:11<00:00,  3.45it/s]\n",
      "Val Loss: 1.1190: 100%|██████████| 10/10 [00:01<00:00,  5.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 31 | Train Loss: 1.2979 | Train F1: 0.8098 | Val Loss: 1.1735 | Val F1: 0.9044 | LR: 1.73e-04\n",
      "\n",
      "📈 Epoch 32/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1201, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:11<00:00,  3.37it/s]\n",
      "Val Loss: 1.1129: 100%|██████████| 10/10 [00:01<00:00,  5.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 32 | Train Loss: 1.3110 | Train F1: 0.7717 | Val Loss: 1.1739 | Val F1: 0.9192 | LR: 1.58e-04\n",
      "\n",
      "📈 Epoch 33/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1074, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:11<00:00,  3.40it/s]\n",
      "Val Loss: 1.1015: 100%|██████████| 10/10 [00:01<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 33 | Train Loss: 1.2138 | Train F1: 0.9255 | Val Loss: 1.1707 | Val F1: 0.9161 | LR: 1.44e-04\n",
      "\n",
      "📈 Epoch 34/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2246, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:11<00:00,  3.39it/s]\n",
      "Val Loss: 1.0987: 100%|██████████| 10/10 [00:01<00:00,  5.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 34 | Train Loss: 1.1834 | Train F1: 0.9057 | Val Loss: 1.1763 | Val F1: 0.9155 | LR: 1.30e-04\n",
      "⏸️ Early stopping at epoch 34 (patience: 7)\n",
      "\n",
      " Fold 3 완료!\n",
      " 최고 Validation F1: 0.9322\n",
      " 학습된 에폭: 34/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>best_performance/epoch</td><td>▁▁▂▂▂▄▄▅▆▇█</td></tr><tr><td>best_performance/val_acc</td><td>▁▄▅▇▇▇▇▇███</td></tr><tr><td>best_performance/val_f1</td><td>▁▃▅▆▇▇▇▇███</td></tr><tr><td>best_performance/val_loss</td><td>█▅▄▃▃▂▂▂▁▁▁</td></tr><tr><td>early_stopping/epoch</td><td>▁</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>fold</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>fold_3/batch_step</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>fold_3/cutout_applied</td><td>▁▁██▁▁██▁███▁▁▁▁▁▁█▁█▁▁█▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>fold_3/mixup_applied</td><td>▁▁▁▁█▁▁▁▁▁▁▁███▁▁▁▁█▁▁▁▁██▁▁█▁██▁▁</td></tr><tr><td>+22</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_performance/epoch</td><td>27</td></tr><tr><td>best_performance/val_acc</td><td>0.93631</td></tr><tr><td>best_performance/val_f1</td><td>0.93221</td></tr><tr><td>best_performance/val_loss</td><td>1.1579</td></tr><tr><td>early_stopping/epoch</td><td>34</td></tr><tr><td>epoch</td><td>34</td></tr><tr><td>fold</td><td>3</td></tr><tr><td>fold_3/batch_step</td><td>1320</td></tr><tr><td>fold_3/cutout_applied</td><td>0</td></tr><tr><td>fold_3/mixup_applied</td><td>0</td></tr><tr><td>+23</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fold-3-efficientnet_b3-1358</strong> at: <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/ailr3rai' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/ailr3rai</a><br> View project at: <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250904_135854-ailr3rai/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      " FOLD 4/5\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "creating run (0.1s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/ephemeral/home/computervisioncompetition-cv-1/wandb/wandb/run-20250904_140636-j75cyh6j</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/j75cyh6j' target=\"_blank\">fold-4-efficientnet_b3-1406</a></strong> to <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/j75cyh6j' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/j75cyh6j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Fold 4 Dashboard: https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/j75cyh6j\n",
      "Train samples: 1256, Validation samples: 314\n",
      " 모델 학습 시작 - Fold 4\n",
      "\n",
      "📈 Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.1738, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:12<00:00,  3.30it/s]\n",
      "Val Loss: 1.7969: 100%|██████████| 10/10 [00:01<00:00,  6.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  1 | Train Loss: 2.6602 | Train F1: 0.2756 | Val Loss: 1.8156 | Val F1: 0.6188 | LR: 5.00e-04\n",
      "🎉 새로운 최고 성능! F1: 0.6188\n",
      "\n",
      "📈 Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.9053, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:11<00:00,  3.39it/s]\n",
      "Val Loss: 1.5285: 100%|██████████| 10/10 [00:01<00:00,  6.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  2 | Train Loss: 2.0823 | Train F1: 0.4941 | Val Loss: 1.6167 | Val F1: 0.6888 | LR: 5.00e-04\n",
      "🎉 새로운 최고 성능! F1: 0.6888\n",
      "\n",
      "📈 Epoch 3/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.4668, Mixup: True, Cutout: False, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.43it/s]\n",
      "Val Loss: 1.4568: 100%|██████████| 10/10 [00:01<00:00,  5.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  3 | Train Loss: 1.8359 | Train F1: 0.5858 | Val Loss: 1.4577 | Val F1: 0.7760 | LR: 4.98e-04\n",
      "🎉 새로운 최고 성능! F1: 0.7760\n",
      "\n",
      "📈 Epoch 4/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.1855, Mixup: True, Cutout: False, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.42it/s]\n",
      "Val Loss: 1.3671: 100%|██████████| 10/10 [00:01<00:00,  6.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  4 | Train Loss: 1.7341 | Train F1: 0.6738 | Val Loss: 1.4228 | Val F1: 0.7978 | LR: 4.96e-04\n",
      "🎉 새로운 최고 성능! F1: 0.7978\n",
      "\n",
      "📈 Epoch 5/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.5645, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:11<00:00,  3.46it/s]\n",
      "Val Loss: 1.3733: 100%|██████████| 10/10 [00:01<00:00,  5.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  5 | Train Loss: 1.6048 | Train F1: 0.7126 | Val Loss: 1.3962 | Val F1: 0.8097 | LR: 4.92e-04\n",
      "🎉 새로운 최고 성능! F1: 0.8097\n",
      "\n",
      "📈 Epoch 6/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.9434, Mixup: True, Cutout: False, RandomCrop: False: 100%|██████████| 40/40 [00:12<00:00,  3.32it/s]\n",
      "Val Loss: 1.2597: 100%|██████████| 10/10 [00:01<00:00,  5.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  6 | Train Loss: 1.5595 | Train F1: 0.7029 | Val Loss: 1.2902 | Val F1: 0.8788 | LR: 4.88e-04\n",
      "🎉 새로운 최고 성능! F1: 0.8788\n",
      "\n",
      "📈 Epoch 7/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.7773, Mixup: True, Cutout: False, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.38it/s]\n",
      "Val Loss: 1.1641: 100%|██████████| 10/10 [00:01<00:00,  5.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  7 | Train Loss: 1.5495 | Train F1: 0.7114 | Val Loss: 1.2950 | Val F1: 0.8704 | LR: 4.82e-04\n",
      "\n",
      "📈 Epoch 8/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.4316, Mixup: True, Cutout: False, RandomCrop: False: 100%|██████████| 40/40 [00:12<00:00,  3.33it/s]\n",
      "Val Loss: 1.1469: 100%|██████████| 10/10 [00:01<00:00,  5.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  8 | Train Loss: 1.5168 | Train F1: 0.7492 | Val Loss: 1.2717 | Val F1: 0.8930 | LR: 4.76e-04\n",
      "🎉 새로운 최고 성능! F1: 0.8930\n",
      "\n",
      "📈 Epoch 9/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.8555, Mixup: True, Cutout: False, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.35it/s]\n",
      "Val Loss: 1.1919: 100%|██████████| 10/10 [00:01<00:00,  5.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  9 | Train Loss: 1.4769 | Train F1: 0.7197 | Val Loss: 1.2700 | Val F1: 0.8667 | LR: 4.69e-04\n",
      "\n",
      "📈 Epoch 10/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.4424, Mixup: False, Cutout: True, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.43it/s]\n",
      "Val Loss: 1.1624: 100%|██████████| 10/10 [00:01<00:00,  5.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 10 | Train Loss: 1.4061 | Train F1: 0.8062 | Val Loss: 1.2701 | Val F1: 0.8628 | LR: 4.61e-04\n",
      "\n",
      "📈 Epoch 11/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.2031, Mixup: True, Cutout: False, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.43it/s]\n",
      "Val Loss: 1.1593: 100%|██████████| 10/10 [00:01<00:00,  5.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 11 | Train Loss: 1.3684 | Train F1: 0.8197 | Val Loss: 1.2775 | Val F1: 0.8751 | LR: 4.52e-04\n",
      "\n",
      "📈 Epoch 12/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3945, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:12<00:00,  3.32it/s]\n",
      "Val Loss: 1.2008: 100%|██████████| 10/10 [00:01<00:00,  6.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 12 | Train Loss: 1.4177 | Train F1: 0.7813 | Val Loss: 1.2565 | Val F1: 0.8782 | LR: 4.43e-04\n",
      "\n",
      "📈 Epoch 13/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.2578, Mixup: True, Cutout: False, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.36it/s]\n",
      "Val Loss: 1.1980: 100%|██████████| 10/10 [00:01<00:00,  6.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 13 | Train Loss: 1.3983 | Train F1: 0.7757 | Val Loss: 1.2477 | Val F1: 0.8965 | LR: 4.32e-04\n",
      "🎉 새로운 최고 성능! F1: 0.8965\n",
      "\n",
      "📈 Epoch 14/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.9336, Mixup: True, Cutout: False, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.37it/s]\n",
      "Val Loss: 1.2150: 100%|██████████| 10/10 [00:01<00:00,  5.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 14 | Train Loss: 1.4695 | Train F1: 0.7742 | Val Loss: 1.2734 | Val F1: 0.8575 | LR: 4.21e-04\n",
      "\n",
      "📈 Epoch 15/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1240, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:11<00:00,  3.48it/s]\n",
      "Val Loss: 1.1742: 100%|██████████| 10/10 [00:01<00:00,  6.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 15 | Train Loss: 1.3552 | Train F1: 0.8280 | Val Loss: 1.2583 | Val F1: 0.8720 | LR: 4.09e-04\n",
      "\n",
      "📈 Epoch 16/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.5195, Mixup: True, Cutout: False, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.42it/s]\n",
      "Val Loss: 1.1152: 100%|██████████| 10/10 [00:01<00:00,  5.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 16 | Train Loss: 1.3580 | Train F1: 0.8432 | Val Loss: 1.2324 | Val F1: 0.8910 | LR: 3.97e-04\n",
      "\n",
      "📈 Epoch 17/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.0918, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:11<00:00,  3.39it/s]\n",
      "Val Loss: 1.1001: 100%|██████████| 10/10 [00:01<00:00,  6.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 17 | Train Loss: 1.4179 | Train F1: 0.7912 | Val Loss: 1.2253 | Val F1: 0.8996 | LR: 3.84e-04\n",
      "🎉 새로운 최고 성능! F1: 0.8996\n",
      "\n",
      "📈 Epoch 18/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2471, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:11<00:00,  3.46it/s]\n",
      "Val Loss: 1.1285: 100%|██████████| 10/10 [00:01<00:00,  6.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 18 | Train Loss: 1.3389 | Train F1: 0.8120 | Val Loss: 1.2211 | Val F1: 0.8898 | LR: 3.70e-04\n",
      "\n",
      "📈 Epoch 19/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.5547, Mixup: True, Cutout: False, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.43it/s]\n",
      "Val Loss: 1.0848: 100%|██████████| 10/10 [00:01<00:00,  5.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 19 | Train Loss: 1.3760 | Train F1: 0.7950 | Val Loss: 1.1977 | Val F1: 0.9180 | LR: 3.56e-04\n",
      "🎉 새로운 최고 성능! F1: 0.9180\n",
      "\n",
      "📈 Epoch 20/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.3457, Mixup: True, Cutout: False, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.46it/s]\n",
      "Val Loss: 1.0789: 100%|██████████| 10/10 [00:01<00:00,  5.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 20 | Train Loss: 1.3668 | Train F1: 0.8050 | Val Loss: 1.2020 | Val F1: 0.9186 | LR: 3.42e-04\n",
      "🎉 새로운 최고 성능! F1: 0.9186\n",
      "\n",
      "📈 Epoch 21/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.5039, Mixup: False, Cutout: True, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.45it/s]\n",
      "Val Loss: 1.1250: 100%|██████████| 10/10 [00:01<00:00,  6.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 21 | Train Loss: 1.2681 | Train F1: 0.8433 | Val Loss: 1.2022 | Val F1: 0.8832 | LR: 3.27e-04\n",
      "\n",
      "📈 Epoch 22/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3330, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:11<00:00,  3.33it/s]\n",
      "Val Loss: 1.1183: 100%|██████████| 10/10 [00:01<00:00,  5.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 22 | Train Loss: 1.4544 | Train F1: 0.7468 | Val Loss: 1.2104 | Val F1: 0.8921 | LR: 3.12e-04\n",
      "\n",
      "📈 Epoch 23/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.4307, Mixup: True, Cutout: False, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.42it/s]\n",
      "Val Loss: 1.1109: 100%|██████████| 10/10 [00:01<00:00,  6.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 23 | Train Loss: 1.3735 | Train F1: 0.7513 | Val Loss: 1.2019 | Val F1: 0.8948 | LR: 2.97e-04\n",
      "\n",
      "📈 Epoch 24/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2803, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:11<00:00,  3.34it/s]\n",
      "Val Loss: 1.1070: 100%|██████████| 10/10 [00:01<00:00,  5.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 24 | Train Loss: 1.2853 | Train F1: 0.8700 | Val Loss: 1.1978 | Val F1: 0.8894 | LR: 2.81e-04\n",
      "\n",
      "📈 Epoch 25/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1641, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:12<00:00,  3.31it/s]\n",
      "Val Loss: 1.1027: 100%|██████████| 10/10 [00:01<00:00,  5.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 25 | Train Loss: 1.2914 | Train F1: 0.8279 | Val Loss: 1.2148 | Val F1: 0.8887 | LR: 2.66e-04\n",
      "\n",
      "📈 Epoch 26/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1719, Mixup: False, Cutout: True, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.34it/s]\n",
      "Val Loss: 1.1122: 100%|██████████| 10/10 [00:01<00:00,  5.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 26 | Train Loss: 1.3821 | Train F1: 0.7635 | Val Loss: 1.2130 | Val F1: 0.8846 | LR: 2.50e-04\n",
      "\n",
      "📈 Epoch 27/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1914, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:11<00:00,  3.48it/s]\n",
      "Val Loss: 1.0910: 100%|██████████| 10/10 [00:01<00:00,  5.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 27 | Train Loss: 1.2598 | Train F1: 0.8366 | Val Loss: 1.2013 | Val F1: 0.8904 | LR: 2.34e-04\n",
      "⏸️ Early stopping at epoch 27 (patience: 7)\n",
      "\n",
      " Fold 4 완료!\n",
      " 최고 Validation F1: 0.9186\n",
      " 학습된 에폭: 27/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>best_performance/epoch</td><td>▁▁▂▂▂▃▄▅▇██</td></tr><tr><td>best_performance/val_acc</td><td>▁▃▅▆▆▇▇▇███</td></tr><tr><td>best_performance/val_f1</td><td>▁▃▅▅▅▇▇▇███</td></tr><tr><td>best_performance/val_loss</td><td>█▆▄▄▃▂▂▂▁▁▁</td></tr><tr><td>early_stopping/epoch</td><td>▁</td></tr><tr><td>epoch</td><td>▁▁▂▂▂▂▃▃▃▃▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇██</td></tr><tr><td>fold</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>fold_4/batch_step</td><td>▁▁▂▂▂▂▃▃▃▃▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇██</td></tr><tr><td>fold_4/cutout_applied</td><td>▁█▁▁▁▁▁▁█▁█▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>fold_4/mixup_applied</td><td>█▁▁█▁▁██▁▁▁▁▁▁██▁▁██▁▁█▁▁██</td></tr><tr><td>+22</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_performance/epoch</td><td>20</td></tr><tr><td>best_performance/val_acc</td><td>0.92675</td></tr><tr><td>best_performance/val_f1</td><td>0.91859</td></tr><tr><td>best_performance/val_loss</td><td>1.20204</td></tr><tr><td>early_stopping/epoch</td><td>27</td></tr><tr><td>epoch</td><td>27</td></tr><tr><td>fold</td><td>4</td></tr><tr><td>fold_4/batch_step</td><td>1040</td></tr><tr><td>fold_4/cutout_applied</td><td>0</td></tr><tr><td>fold_4/mixup_applied</td><td>1</td></tr><tr><td>+23</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fold-4-efficientnet_b3-1406</strong> at: <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/j75cyh6j' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/j75cyh6j</a><br> View project at: <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250904_140636-j75cyh6j/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      " FOLD 5/5\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "creating run (0.2s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/ephemeral/home/computervisioncompetition-cv-1/wandb/wandb/run-20250904_141244-bv3qvohp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/bv3qvohp' target=\"_blank\">fold-5-efficientnet_b3-1412</a></strong> to <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/bv3qvohp' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/bv3qvohp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Fold 5 Dashboard: https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/bv3qvohp\n",
      "Train samples: 1256, Validation samples: 314\n",
      " 모델 학습 시작 - Fold 5\n",
      "\n",
      "📈 Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.9355, Mixup: False, Cutout: True, RandomCrop: False: 100%|██████████| 40/40 [00:12<00:00,  3.30it/s]\n",
      "Val Loss: 1.6529: 100%|██████████| 10/10 [00:01<00:00,  6.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  1 | Train Loss: 2.7624 | Train F1: 0.2126 | Val Loss: 1.7412 | Val F1: 0.6563 | LR: 5.00e-04\n",
      "🎉 새로운 최고 성능! F1: 0.6563\n",
      "\n",
      "📈 Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.8926, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:12<00:00,  3.23it/s]\n",
      "Val Loss: 1.3612: 100%|██████████| 10/10 [00:01<00:00,  5.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  2 | Train Loss: 2.0261 | Train F1: 0.4909 | Val Loss: 1.5387 | Val F1: 0.7353 | LR: 5.00e-04\n",
      "🎉 새로운 최고 성능! F1: 0.7353\n",
      "\n",
      "📈 Epoch 3/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.2969, Mixup: True, Cutout: False, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.34it/s]\n",
      "Val Loss: 1.3089: 100%|██████████| 10/10 [00:01<00:00,  5.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  3 | Train Loss: 1.7352 | Train F1: 0.6192 | Val Loss: 1.3878 | Val F1: 0.8100 | LR: 4.98e-04\n",
      "🎉 새로운 최고 성능! F1: 0.8100\n",
      "\n",
      "📈 Epoch 4/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.5361, Mixup: False, Cutout: True, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.37it/s]\n",
      "Val Loss: 1.3109: 100%|██████████| 10/10 [00:01<00:00,  6.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  4 | Train Loss: 1.7112 | Train F1: 0.6303 | Val Loss: 1.3461 | Val F1: 0.8285 | LR: 4.96e-04\n",
      "🎉 새로운 최고 성능! F1: 0.8285\n",
      "\n",
      "📈 Epoch 5/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3574, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:11<00:00,  3.47it/s]\n",
      "Val Loss: 1.2812: 100%|██████████| 10/10 [00:01<00:00,  6.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  5 | Train Loss: 1.7267 | Train F1: 0.5866 | Val Loss: 1.3307 | Val F1: 0.8148 | LR: 4.92e-04\n",
      "\n",
      "📈 Epoch 6/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1572, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:11<00:00,  3.42it/s]\n",
      "Val Loss: 1.2379: 100%|██████████| 10/10 [00:01<00:00,  6.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  6 | Train Loss: 1.5679 | Train F1: 0.6875 | Val Loss: 1.2918 | Val F1: 0.8517 | LR: 4.88e-04\n",
      "🎉 새로운 최고 성능! F1: 0.8517\n",
      "\n",
      "📈 Epoch 7/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2529, Mixup: False, Cutout: True, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.37it/s]\n",
      "Val Loss: 1.2492: 100%|██████████| 10/10 [00:01<00:00,  5.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  7 | Train Loss: 1.4795 | Train F1: 0.7540 | Val Loss: 1.2708 | Val F1: 0.8522 | LR: 4.82e-04\n",
      "🎉 새로운 최고 성능! F1: 0.8522\n",
      "\n",
      "📈 Epoch 8/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.4697, Mixup: False, Cutout: True, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.39it/s]\n",
      "Val Loss: 1.1615: 100%|██████████| 10/10 [00:01<00:00,  6.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  8 | Train Loss: 1.4629 | Train F1: 0.7565 | Val Loss: 1.2640 | Val F1: 0.8596 | LR: 4.76e-04\n",
      "🎉 새로운 최고 성능! F1: 0.8596\n",
      "\n",
      "📈 Epoch 9/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2588, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:11<00:00,  3.35it/s]\n",
      "Val Loss: 1.1963: 100%|██████████| 10/10 [00:01<00:00,  5.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  9 | Train Loss: 1.5054 | Train F1: 0.7526 | Val Loss: 1.2469 | Val F1: 0.8741 | LR: 4.69e-04\n",
      "🎉 새로운 최고 성능! F1: 0.8741\n",
      "\n",
      "📈 Epoch 10/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.6211, Mixup: True, Cutout: False, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.40it/s]\n",
      "Val Loss: 1.1633: 100%|██████████| 10/10 [00:01<00:00,  5.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 10 | Train Loss: 1.4817 | Train F1: 0.7619 | Val Loss: 1.2535 | Val F1: 0.8869 | LR: 4.61e-04\n",
      "🎉 새로운 최고 성능! F1: 0.8869\n",
      "\n",
      "📈 Epoch 11/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3750, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:11<00:00,  3.35it/s]\n",
      "Val Loss: 1.3525: 100%|██████████| 10/10 [00:01<00:00,  6.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 11 | Train Loss: 1.3997 | Train F1: 0.7585 | Val Loss: 1.2848 | Val F1: 0.8614 | LR: 4.52e-04\n",
      "\n",
      "📈 Epoch 12/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2695, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:11<00:00,  3.46it/s]\n",
      "Val Loss: 1.1373: 100%|██████████| 10/10 [00:01<00:00,  5.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 12 | Train Loss: 1.4763 | Train F1: 0.7161 | Val Loss: 1.2270 | Val F1: 0.9088 | LR: 4.43e-04\n",
      "🎉 새로운 최고 성능! F1: 0.9088\n",
      "\n",
      "📈 Epoch 13/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2090, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:12<00:00,  3.32it/s]\n",
      "Val Loss: 1.1939: 100%|██████████| 10/10 [00:01<00:00,  6.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 13 | Train Loss: 1.3528 | Train F1: 0.7743 | Val Loss: 1.2157 | Val F1: 0.8764 | LR: 4.32e-04\n",
      "\n",
      "📈 Epoch 14/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3164, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:11<00:00,  3.43it/s]\n",
      "Val Loss: 1.1363: 100%|██████████| 10/10 [00:01<00:00,  5.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 14 | Train Loss: 1.4643 | Train F1: 0.7641 | Val Loss: 1.2076 | Val F1: 0.9108 | LR: 4.21e-04\n",
      "🎉 새로운 최고 성능! F1: 0.9108\n",
      "\n",
      "📈 Epoch 15/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2383, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:11<00:00,  3.38it/s]\n",
      "Val Loss: 1.1220: 100%|██████████| 10/10 [00:01<00:00,  5.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 15 | Train Loss: 1.3732 | Train F1: 0.7885 | Val Loss: 1.1908 | Val F1: 0.8974 | LR: 4.09e-04\n",
      "\n",
      "📈 Epoch 16/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.4346, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:11<00:00,  3.36it/s]\n",
      "Val Loss: 1.1410: 100%|██████████| 10/10 [00:01<00:00,  5.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 16 | Train Loss: 1.3068 | Train F1: 0.8598 | Val Loss: 1.1995 | Val F1: 0.8938 | LR: 3.97e-04\n",
      "\n",
      "📈 Epoch 17/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3174, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:11<00:00,  3.36it/s]\n",
      "Val Loss: 1.1914: 100%|██████████| 10/10 [00:01<00:00,  6.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 17 | Train Loss: 1.3110 | Train F1: 0.8232 | Val Loss: 1.2235 | Val F1: 0.8738 | LR: 3.84e-04\n",
      "\n",
      "📈 Epoch 18/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2949, Mixup: False, Cutout: True, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.45it/s]\n",
      "Val Loss: 1.2511: 100%|██████████| 10/10 [00:01<00:00,  5.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 18 | Train Loss: 1.3556 | Train F1: 0.7465 | Val Loss: 1.2125 | Val F1: 0.8836 | LR: 3.70e-04\n",
      "\n",
      "📈 Epoch 19/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.8818, Mixup: True, Cutout: False, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.51it/s]\n",
      "Val Loss: 1.0786: 100%|██████████| 10/10 [00:01<00:00,  6.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 19 | Train Loss: 1.2831 | Train F1: 0.8257 | Val Loss: 1.1860 | Val F1: 0.9187 | LR: 3.56e-04\n",
      "🎉 새로운 최고 성능! F1: 0.9187\n",
      "\n",
      "📈 Epoch 20/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.9238, Mixup: True, Cutout: False, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.40it/s]\n",
      "Val Loss: 1.1844: 100%|██████████| 10/10 [00:01<00:00,  5.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 20 | Train Loss: 1.3251 | Train F1: 0.8176 | Val Loss: 1.1817 | Val F1: 0.8994 | LR: 3.42e-04\n",
      "\n",
      "📈 Epoch 21/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1494, Mixup: False, Cutout: True, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.45it/s]\n",
      "Val Loss: 1.1569: 100%|██████████| 10/10 [00:01<00:00,  6.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 21 | Train Loss: 1.2949 | Train F1: 0.8863 | Val Loss: 1.2017 | Val F1: 0.8950 | LR: 3.27e-04\n",
      "\n",
      "📈 Epoch 22/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3594, Mixup: False, Cutout: True, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.40it/s]\n",
      "Val Loss: 1.1078: 100%|██████████| 10/10 [00:01<00:00,  5.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 22 | Train Loss: 1.2776 | Train F1: 0.8350 | Val Loss: 1.1853 | Val F1: 0.9085 | LR: 3.12e-04\n",
      "\n",
      "📈 Epoch 23/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3389, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:11<00:00,  3.42it/s]\n",
      "Val Loss: 1.1106: 100%|██████████| 10/10 [00:01<00:00,  5.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 23 | Train Loss: 1.2519 | Train F1: 0.8617 | Val Loss: 1.1949 | Val F1: 0.9064 | LR: 2.97e-04\n",
      "\n",
      "📈 Epoch 24/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.0781, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:12<00:00,  3.33it/s]\n",
      "Val Loss: 1.0949: 100%|██████████| 10/10 [00:01<00:00,  6.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 24 | Train Loss: 1.2630 | Train F1: 0.8128 | Val Loss: 1.1796 | Val F1: 0.9051 | LR: 2.81e-04\n",
      "\n",
      "📈 Epoch 25/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1357, Mixup: False, Cutout: True, RandomCrop: False: 100%|██████████| 40/40 [00:12<00:00,  3.32it/s]\n",
      "Val Loss: 1.2270: 100%|██████████| 10/10 [00:01<00:00,  5.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 25 | Train Loss: 1.3744 | Train F1: 0.7528 | Val Loss: 1.2108 | Val F1: 0.9086 | LR: 2.66e-04\n",
      "\n",
      "📈 Epoch 26/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.0850, Mixup: False, Cutout: True, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.39it/s]\n",
      "Val Loss: 1.0883: 100%|██████████| 10/10 [00:01<00:00,  5.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 26 | Train Loss: 1.2285 | Train F1: 0.8618 | Val Loss: 1.1746 | Val F1: 0.9107 | LR: 2.50e-04\n",
      "\n",
      "📈 Epoch 27/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1123, Mixup: False, Cutout: True, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.42it/s]\n",
      "Val Loss: 1.1326: 100%|██████████| 10/10 [00:01<00:00,  5.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 27 | Train Loss: 1.2462 | Train F1: 0.8905 | Val Loss: 1.1680 | Val F1: 0.9225 | LR: 2.34e-04\n",
      "🎉 새로운 최고 성능! F1: 0.9225\n",
      "\n",
      "📈 Epoch 28/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2061, Mixup: False, Cutout: True, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.48it/s]\n",
      "Val Loss: 1.1289: 100%|██████████| 10/10 [00:01<00:00,  5.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 28 | Train Loss: 1.3409 | Train F1: 0.8292 | Val Loss: 1.1839 | Val F1: 0.9176 | LR: 2.19e-04\n",
      "\n",
      "📈 Epoch 29/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.0215, Mixup: True, Cutout: False, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.48it/s]\n",
      "Val Loss: 1.1152: 100%|██████████| 10/10 [00:01<00:00,  5.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 29 | Train Loss: 1.2753 | Train F1: 0.8468 | Val Loss: 1.1763 | Val F1: 0.9197 | LR: 2.03e-04\n",
      "\n",
      "📈 Epoch 30/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2578, Mixup: False, Cutout: True, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.45it/s]\n",
      "Val Loss: 1.1309: 100%|██████████| 10/10 [00:01<00:00,  5.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 30 | Train Loss: 1.2594 | Train F1: 0.8682 | Val Loss: 1.1656 | Val F1: 0.9186 | LR: 1.88e-04\n",
      "\n",
      "📈 Epoch 31/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3359, Mixup: True, Cutout: False, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.40it/s]\n",
      "Val Loss: 1.0970: 100%|██████████| 10/10 [00:01<00:00,  5.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 31 | Train Loss: 1.2802 | Train F1: 0.8409 | Val Loss: 1.1863 | Val F1: 0.9024 | LR: 1.73e-04\n",
      "\n",
      "📈 Epoch 32/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2568, Mixup: False, Cutout: True, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.39it/s]\n",
      "Val Loss: 1.1469: 100%|██████████| 10/10 [00:01<00:00,  5.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 32 | Train Loss: 1.3748 | Train F1: 0.7990 | Val Loss: 1.1905 | Val F1: 0.9157 | LR: 1.58e-04\n",
      "\n",
      "📈 Epoch 33/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2646, Mixup: True, Cutout: False, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.42it/s]\n",
      "Val Loss: 1.1174: 100%|██████████| 10/10 [00:01<00:00,  5.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 33 | Train Loss: 1.2042 | Train F1: 0.9241 | Val Loss: 1.1716 | Val F1: 0.9141 | LR: 1.44e-04\n",
      "\n",
      "📈 Epoch 34/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2031, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:11<00:00,  3.42it/s]\n",
      "Val Loss: 1.1391: 100%|██████████| 10/10 [00:01<00:00,  6.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 34 | Train Loss: 1.2345 | Train F1: 0.8598 | Val Loss: 1.1756 | Val F1: 0.9033 | LR: 1.30e-04\n",
      "⏸️ Early stopping at epoch 34 (patience: 7)\n",
      "\n",
      " Fold 5 완료!\n",
      " 최고 Validation F1: 0.9225\n",
      " 학습된 에폭: 34/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>best_performance/epoch</td><td>▁▁▂▂▂▃▃▃▃▄▅▆█</td></tr><tr><td>best_performance/val_acc</td><td>▁▃▅▅▆▆▆▆▇▇▇██</td></tr><tr><td>best_performance/val_f1</td><td>▁▃▅▆▆▆▆▇▇████</td></tr><tr><td>best_performance/val_loss</td><td>█▆▄▃▃▂▂▂▂▂▁▁▁</td></tr><tr><td>early_stopping/epoch</td><td>▁</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>fold</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>fold_5/batch_step</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>fold_5/cutout_applied</td><td>█▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁█▁</td></tr><tr><td>fold_5/mixup_applied</td><td>▁▁▁▁▁█▁▁▁▁▁▁█▁█▁▁▁█▁▁▁▁▁█▁█▁▁▁▁▁▁▁</td></tr><tr><td>+22</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_performance/epoch</td><td>27</td></tr><tr><td>best_performance/val_acc</td><td>0.92994</td></tr><tr><td>best_performance/val_f1</td><td>0.92248</td></tr><tr><td>best_performance/val_loss</td><td>1.16797</td></tr><tr><td>early_stopping/epoch</td><td>34</td></tr><tr><td>epoch</td><td>34</td></tr><tr><td>fold</td><td>5</td></tr><tr><td>fold_5/batch_step</td><td>1320</td></tr><tr><td>fold_5/cutout_applied</td><td>0</td></tr><tr><td>fold_5/mixup_applied</td><td>0</td></tr><tr><td>+23</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fold-5-efficientnet_b3-1412</strong> at: <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/bv3qvohp' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/bv3qvohp</a><br> View project at: <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250904_141244-bv3qvohp/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# 10. K-Fold Cross Validation Loop with WandB\n",
    "# =============================================================================\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(train_df, train_df['target'])):\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\" FOLD {fold + 1}/{N_FOLDS}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    # 각 fold별 child run 생성\n",
    "    fold_run = wandb.init(\n",
    "        project=PROJECT_NAME,\n",
    "        entity=ENTITY,\n",
    "        name=f\"fold-{fold+1}-{model_name}-{datetime.now().strftime('%H%M')}\",\n",
    "        config=config,\n",
    "        tags=[\"fold\", f\"fold-{fold+1}\", model_name, \"child-run\"],\n",
    "        group=\"k-fold-experiment\",\n",
    "        job_type=f\"fold-{fold+1}\",\n",
    "        reinit=True  # 새로운 run 시작 허용\n",
    "    )\n",
    "    \n",
    "    print(f\"📊 Fold {fold+1} Dashboard: {fold_run.url}\")\n",
    "    \n",
    "    # 현재 fold의 train/validation 데이터 분할\n",
    "    train_fold_df = train_df.iloc[train_idx].reset_index(drop=True)\n",
    "    val_fold_df = train_df.iloc[val_idx].reset_index(drop=True)\n",
    "    \n",
    "    # 데이터 분할 정보 로깅\n",
    "    wandb.log({\n",
    "        \"fold_info/fold_number\": fold + 1,\n",
    "        \"fold_info/train_samples\": len(train_fold_df),\n",
    "        \"fold_info/val_samples\": len(val_fold_df),\n",
    "        \"fold_info/train_ratio\": len(train_fold_df) / len(train_df),\n",
    "        \"fold_info/val_ratio\": len(val_fold_df) / len(train_df)\n",
    "    })\n",
    "    \n",
    "    # 현재 fold의 Dataset 생성\n",
    "    trn_dataset = ImageDataset(\n",
    "        train_fold_df,\n",
    "        \"../data/train/\",\n",
    "        transform=trn_transform\n",
    "    )\n",
    "    \n",
    "    val_dataset = ImageDataset(\n",
    "        val_fold_df,\n",
    "        \"../data/train/\",\n",
    "        transform=tst_transform  # 검증에는 증강 적용 안함\n",
    "    )\n",
    "    \n",
    "    # 현재 fold의 DataLoader 생성\n",
    "    trn_loader = DataLoader(\n",
    "        trn_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=False\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    print(f\"Train samples: {len(trn_dataset)}, Validation samples: {len(val_dataset)}\")\n",
    "    \n",
    "    # 모델 초기화 (각 fold마다 새로운 모델)\n",
    "    model = timm.create_model(\n",
    "        model_name,\n",
    "        pretrained=True,\n",
    "        num_classes=17\n",
    "    ).to(device)\n",
    "    \n",
    "    loss_fn = nn.CrossEntropyLoss(label_smoothing=0.2)  # Label Smoothing 적용\n",
    "    optimizer = Adam(model.parameters(), lr=LR)\n",
    "    \n",
    "    # Learning Rate Scheduler 추가\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "    \n",
    "    # 현재 fold의 최고 성능 추적\n",
    "    best_val_f1 = 0.0\n",
    "    best_model = None\n",
    "    patience = 0\n",
    "    max_patience = 7\n",
    "    \n",
    "    print(f\" 모델 학습 시작 - Fold {fold+1}\")\n",
    "    \n",
    "    # =============================================================================\n",
    "    # 11. Training Loop for Current Fold\n",
    "    # =============================================================================\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        print(f\"\\n📈 Epoch {epoch+1}/{EPOCHS}\")\n",
    "        \n",
    "        # Training\n",
    "        train_ret = train_one_epoch(\n",
    "            trn_loader, model, optimizer, loss_fn, device, \n",
    "            epoch=epoch, fold=fold+1\n",
    "        )\n",
    "        \n",
    "        # Validation\n",
    "        val_ret = validate_one_epoch(\n",
    "            val_loader, model, loss_fn, device, \n",
    "            epoch=epoch, fold=fold+1,\n",
    "            log_confusion=(epoch == EPOCHS-1)  # 마지막 epoch에만 confusion matrix\n",
    "        )\n",
    "        \n",
    "        # Learning rate 로깅\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        \n",
    "        # WandB에 metrics 로깅\n",
    "        log_data = {\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"fold\": fold + 1,\n",
    "            \"train/loss\": train_ret['train_loss'],\n",
    "            \"train/accuracy\": train_ret['train_acc'], \n",
    "            \"train/f1\": train_ret['train_f1'],\n",
    "            \"val/loss\": val_ret['val_loss'],\n",
    "            \"val/accuracy\": val_ret['val_acc'],\n",
    "            \"val/f1\": val_ret['val_f1'],\n",
    "            \"learning_rate\": current_lr,\n",
    "            \"optimizer/lr\": current_lr\n",
    "        }\n",
    "        \n",
    "        # GPU 메모리 사용량 로깅\n",
    "        if torch.cuda.is_available():\n",
    "            gpu_memory_used = torch.cuda.memory_allocated(0) / 1e9\n",
    "            gpu_memory_total = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "            log_data.update({\n",
    "                \"system/gpu_memory_used_gb\": gpu_memory_used,\n",
    "                \"system/gpu_memory_total_gb\": gpu_memory_total,\n",
    "                \"system/gpu_utilization_pct\": (gpu_memory_used / gpu_memory_total) * 100\n",
    "            })\n",
    "        \n",
    "        wandb.log(log_data)\n",
    "        \n",
    "        # Scheduler step\n",
    "        scheduler.step()\n",
    "        \n",
    "        print(f\" Epoch {epoch+1:2d} | \"\n",
    "              f\"Train Loss: {train_ret['train_loss']:.4f} | \"\n",
    "              f\"Train F1: {train_ret['train_f1']:.4f} | \"\n",
    "              f\"Val Loss: {val_ret['val_loss']:.4f} | \"\n",
    "              f\"Val F1: {val_ret['val_f1']:.4f} | \"\n",
    "              f\"LR: {current_lr:.2e}\")\n",
    "        \n",
    "        # 최고 성능 모델 저장\n",
    "        if val_ret['val_f1'] > best_val_f1:\n",
    "            best_val_f1 = val_ret['val_f1']\n",
    "            best_model = copy.deepcopy(model.state_dict())\n",
    "            patience = 0\n",
    "            \n",
    "            # 최고 성능 모델 아티팩트로 저장\n",
    "            model_path = f'best_model_fold_{fold+1}.pth'\n",
    "            torch.save(best_model, model_path)\n",
    "            wandb.save(model_path, policy=\"now\")\n",
    "            \n",
    "            # 새로운 최고 성능 로깅\n",
    "            wandb.log({\n",
    "                f\"best_performance/epoch\": epoch + 1,\n",
    "                f\"best_performance/val_f1\": best_val_f1,\n",
    "                f\"best_performance/val_acc\": val_ret['val_acc'],\n",
    "                f\"best_performance/val_loss\": val_ret['val_loss'],\n",
    "            })\n",
    "            \n",
    "            print(f\"🎉 새로운 최고 성능! F1: {best_val_f1:.4f}\")\n",
    "        else:\n",
    "            patience += 1\n",
    "            \n",
    "        # Early stopping (선택적)\n",
    "        if patience >= max_patience and epoch > EPOCHS // 2:\n",
    "            print(f\"⏸️ Early stopping at epoch {epoch+1} (patience: {patience})\")\n",
    "            wandb.log({\"early_stopping/epoch\": epoch + 1})\n",
    "            break\n",
    "    \n",
    "    # =============================================================================\n",
    "    # 12. Fold Results Summary\n",
    "    # =============================================================================\n",
    "    \n",
    "    # 현재 fold 결과 저장\n",
    "    fold_result = {\n",
    "        'fold': fold + 1,\n",
    "        'best_val_f1': best_val_f1,\n",
    "        'final_train_f1': train_ret['train_f1'],\n",
    "        'train_samples': len(trn_dataset),\n",
    "        'val_samples': len(val_dataset),\n",
    "        'epochs_trained': epoch + 1,\n",
    "        'early_stopped': patience >= max_patience\n",
    "    }\n",
    "    \n",
    "    fold_results.append(fold_result)\n",
    "    fold_models.append(best_model)\n",
    "    \n",
    "    # Fold 최종 요약 로깅\n",
    "    wandb.log({\n",
    "        \"fold_summary/best_val_f1\": best_val_f1,\n",
    "        \"fold_summary/final_train_f1\": train_ret['train_f1'],\n",
    "        \"fold_summary/epochs_trained\": epoch + 1,\n",
    "        \"fold_summary/improvement\": best_val_f1 - val_ret['val_f1'],\n",
    "        \"fold_summary/early_stopped\": patience >= max_patience\n",
    "    })\n",
    "    \n",
    "    print(f\"\\n Fold {fold + 1} 완료!\")\n",
    "    print(f\" 최고 Validation F1: {best_val_f1:.4f}\")\n",
    "    print(f\" 학습된 에폭: {epoch + 1}/{EPOCHS}\")\n",
    "    \n",
    "    # Fold run 종료\n",
    "    wandb.finish()\n",
    "    \n",
    "    # 메모리 정리\n",
    "    del model, optimizer, scheduler, trn_loader, val_loader\n",
    "    torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5545246d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      " K-FOLD CROSS VALIDATION 최종 결과\n",
      "============================================================\n",
      " 활성화된 run이 없어 새로운 summary run을 생성합니다.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "creating run (0.1s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/ephemeral/home/computervisioncompetition-cv-1/wandb/wandb/run-20250904_142047-j2u6fpe8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/j2u6fpe8' target=\"_blank\">SUMMARY-efficientnet-b3-baseline-0904-1420</a></strong> to <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/j2u6fpe8' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/j2u6fpe8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " CV 결과 로깅 완료!\n",
      "Fold 1: 0.9271 (27 epochs)  Early Stopped\n",
      "Fold 2: 0.9412 (48 epochs)  Early Stopped\n",
      "Fold 3: 0.9322 (34 epochs)  Early Stopped\n",
      "Fold 4: 0.9186 (27 epochs)  Early Stopped\n",
      "Fold 5: 0.9225 (34 epochs)  Early Stopped\n",
      "\n",
      " 평균 CV F1: 0.9283 ± 0.0079\n",
      " 최고 Fold: 0.9412\n",
      " 최악 Fold: 0.9186\n",
      " 성능 범위: 0.0227\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 13. K-Fold Cross Validation Results Summary\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\" K-FOLD CROSS VALIDATION 최종 결과\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "val_f1_scores = [result['best_val_f1'] for result in fold_results]\n",
    "mean_f1 = np.mean(val_f1_scores)\n",
    "std_f1 = np.std(val_f1_scores)\n",
    "\n",
    "try:\n",
    "    # wandb.run이 현재 활성화된 run을 가리킴\n",
    "    if wandb.run is None:\n",
    "        print(\" 활성화된 run이 없어 새로운 summary run을 생성합니다.\")\n",
    "        active_run = wandb.init(\n",
    "            project=PROJECT_NAME,\n",
    "            name=f\"SUMMARY-{EXPERIMENT_NAME}-{datetime.now().strftime('%m%d-%H%M')}\",\n",
    "            config=config,\n",
    "            tags=[\"summary\", \"cv-results\", model_name],\n",
    "            group=\"k-fold-experiment\",\n",
    "            job_type=\"summary\",\n",
    "            reinit=True\n",
    "        )\n",
    "    else:\n",
    "        print(\" 기존 run을 사용합니다.\")\n",
    "        active_run = wandb.run\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\" Run 상태 확인 중 에러: {e}\")\n",
    "    # 새로운 run 생성\n",
    "    active_run = wandb.init(\n",
    "        project=PROJECT_NAME,\n",
    "        name=f\"SUMMARY-{EXPERIMENT_NAME}-{datetime.now().strftime('%m%d-%H%M')}\",\n",
    "        config=config,\n",
    "        tags=[\"summary\", \"cv-results\", model_name],\n",
    "        group=\"k-fold-experiment\",\n",
    "        job_type=\"summary\",\n",
    "        reinit=True\n",
    "    )\n",
    "\n",
    "# CV 요약 테이블 생성\n",
    "fold_table = wandb.Table(columns=[\n",
    "    \"Fold\", \"Best_Val_F1\", \"Final_Train_F1\", \"Train_Samples\", \n",
    "    \"Val_Samples\", \"Epochs_Trained\", \"Early_Stopped\"\n",
    "])\n",
    "\n",
    "for result in fold_results:\n",
    "    fold_table.add_data(\n",
    "        result['fold'], \n",
    "        result['best_val_f1'], \n",
    "        result['final_train_f1'],\n",
    "        result['train_samples'], \n",
    "        result['val_samples'],\n",
    "        result['epochs_trained'],\n",
    "        result['early_stopped']\n",
    "    )\n",
    "\n",
    "# 안전한 로깅\n",
    "try:\n",
    "    active_run.log({\n",
    "        \"cv_results/mean_f1\": mean_f1,\n",
    "        \"cv_results/std_f1\": std_f1,\n",
    "        \"cv_results/best_fold_f1\": max(val_f1_scores),\n",
    "        \"cv_results/worst_fold_f1\": min(val_f1_scores),\n",
    "        \"cv_results/f1_range\": max(val_f1_scores) - min(val_f1_scores),\n",
    "        \"cv_results/fold_results_table\": fold_table,\n",
    "        \"cv_results/n_folds\": N_FOLDS,\n",
    "        \"cv_results/total_epochs\": sum([r['epochs_trained'] for r in fold_results]),\n",
    "        \"cv_results/avg_epochs_per_fold\": np.mean([r['epochs_trained'] for r in fold_results]),\n",
    "        \"cv_results/early_stopped_folds\": sum([r['early_stopped'] for r in fold_results])\n",
    "    })\n",
    "    \n",
    "    # Fold별 성능 바차트 생성\n",
    "    fold_performance_data = [[f\"Fold {i+1}\", score] for i, score in enumerate(val_f1_scores)]\n",
    "    active_run.log({\n",
    "        \"cv_results/fold_performance_chart\": wandb.plot.bar(\n",
    "            wandb.Table(data=fold_performance_data, columns=[\"Fold\", \"F1_Score\"]),\n",
    "            \"Fold\", \"F1_Score\", \n",
    "            title=\"K-Fold Cross Validation Performance\"\n",
    "        )\n",
    "    })\n",
    "    \n",
    "    print(\" CV 결과 로깅 완료!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\" WandB 로깅 중 에러: {e}\")\n",
    "    print(\" 결과를 콘솔에 출력합니다:\")\n",
    "\n",
    "# 어떤 경우든 콘솔에는 결과 출력\n",
    "for result in fold_results:\n",
    "    status = \" Early Stopped\" if result['early_stopped'] else \" Completed\"\n",
    "    print(f\"Fold {result['fold']}: {result['best_val_f1']:.4f} \"\n",
    "          f\"({result['epochs_trained']} epochs) {status}\")\n",
    "\n",
    "print(f\"\\n 평균 CV F1: {mean_f1:.4f} ± {std_f1:.4f}\")\n",
    "print(f\" 최고 Fold: {max(val_f1_scores):.4f}\")\n",
    "print(f\" 최악 Fold: {min(val_f1_scores):.4f}\")\n",
    "print(f\" 성능 범위: {max(val_f1_scores) - min(val_f1_scores):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0c1ddb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔧 앙상블 모델 준비 중...\n",
      "Fold 1 모델 로드 완료\n",
      "Fold 2 모델 로드 완료\n",
      "Fold 3 모델 로드 완료\n",
      "Fold 4 모델 로드 완료\n",
      "Fold 5 모델 로드 완료\n",
      " 총 5개 모델로 앙상블 구성\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# 14. Ensemble Models Preparation\n",
    "# =============================================================================\n",
    "\n",
    "# 5-Fold 앙상블 모델 준비\n",
    "ensemble_models = []\n",
    "print(f\"\\n🔧 앙상블 모델 준비 중...\")\n",
    "\n",
    "for i, state_dict in enumerate(fold_models):\n",
    "    fold_model = timm.create_model(model_name, pretrained=True, num_classes=17).to(device)\n",
    "    fold_model.load_state_dict(state_dict)\n",
    "    fold_model.eval()\n",
    "    ensemble_models.append(fold_model)\n",
    "    print(f\"Fold {i+1} 모델 로드 완료\")\n",
    "\n",
    "print(f\" 총 {len(ensemble_models)}개 모델로 앙상블 구성\")\n",
    "\n",
    "try:\n",
    "    if wandb.run is not None:\n",
    "        wandb.run.log({\n",
    "            \"ensemble/num_models\": len(ensemble_models),\n",
    "            \"ensemble/model_architecture\": model_name,\n",
    "            \"ensemble/ensemble_type\": \"simple_average\"\n",
    "        })\n",
    "    else:\n",
    "        print(\"📊 앙상블 정보:\")\n",
    "        print(f\"  - 모델 개수: {len(ensemble_models)}\")\n",
    "        print(f\"  - 아키텍처: {model_name}\")\n",
    "        print(f\"  - 앙상블 타입: simple_average\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠️ 앙상블 정보 로깅 실패: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c98e388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " TTA (Test Time Augmentation) 설정...\n",
      "TTA 변환 5개 준비 완료\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# 15. TTA (Test Time Augmentation) Setup\n",
    "# =============================================================================\n",
    "\n",
    "# Temperature Scaling 클래스 정의\n",
    "class TemperatureScaling(nn.Module):\n",
    "    def __init__(self, temperature=1.5):\n",
    "        super().__init__()\n",
    "        self.temperature = nn.Parameter(torch.ones(1) * temperature)\n",
    "    \n",
    "    def forward(self, logits):\n",
    "        return logits / self.temperature\n",
    "\n",
    "print(f\"\\n TTA (Test Time Augmentation) 설정...\")\n",
    "\n",
    "# Essential TTA transforms\n",
    "essential_tta_transforms = [\n",
    "    # 원본\n",
    "    A.Compose([\n",
    "        A.LongestMaxSize(max_size=img_size),\n",
    "        A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "    # 90도 회전들\n",
    "    A.Compose([\n",
    "        A.LongestMaxSize(max_size=img_size),\n",
    "        A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "        A.Rotate(limit=[90, 90], p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "    A.Compose([\n",
    "        A.LongestMaxSize(max_size=img_size),\n",
    "        A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "        A.Rotate(limit=[180, 180], p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "    A.Compose([\n",
    "        A.LongestMaxSize(max_size=img_size),\n",
    "        A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "        A.Rotate(limit=[-90, -90], p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "    # 밝기 개선\n",
    "    A.Compose([\n",
    "        A.LongestMaxSize(max_size=img_size),\n",
    "        A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "        A.RandomBrightnessContrast(brightness_limit=[0.3, 0.3], contrast_limit=[0.3, 0.3], p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "]\n",
    "\n",
    "print(f\"TTA 변환 {len(essential_tta_transforms)}개 준비 완료\")\n",
    "\n",
    "try:\n",
    "    if wandb.run is not None:\n",
    "        wandb.run.log({\n",
    "            \"tta/num_transforms\": len(essential_tta_transforms),\n",
    "            \"tta/transforms_used\": [\"original\", \"rot_90\", \"rot_180\", \"rot_270\", \"brightness\"],\n",
    "            \"tta/batch_size\": 64  # TTA용 배치 크기\n",
    "        })\n",
    "    else:\n",
    "        print(\"📊 TTA 설정 정보:\")\n",
    "        print(f\"  - 변형 개수: {len(essential_tta_transforms)}\")\n",
    "        print(f\"  - 변형 종류: original, rot_90, rot_180, rot_270, brightness\")\n",
    "        print(f\"  - 배치 크기: 64\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠️ TTA 설정 로깅 실패: {e}\")\n",
    "    print(\"📊 TTA 설정 정보:\")\n",
    "    print(f\"  - 변형 개수: {len(essential_tta_transforms)}\")\n",
    "    print(f\"  - 배치 크기: 64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5f6fc07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " TTA Dataset: 3140개 테스트 샘플\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 16. TTA Dataset and DataLoader\n",
    "# =============================================================================\n",
    "\n",
    "class TTAImageDataset(Dataset):\n",
    "    def __init__(self, data, path, transforms):\n",
    "        if isinstance(data, str):\n",
    "            self.df = pd.read_csv(data).values\n",
    "        else:\n",
    "            self.df = data.values\n",
    "        self.path = path\n",
    "        self.transforms = transforms  # 여러 transform을 리스트로 받음\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        name, target = self.df[idx]\n",
    "        img = np.array(Image.open(os.path.join(self.path, name)))\n",
    "        \n",
    "        # 모든 transform을 적용한 결과를 리스트로 반환\n",
    "        augmented_images = []\n",
    "        for transform in self.transforms:\n",
    "            aug_img = transform(image=img)['image']\n",
    "            augmented_images.append(aug_img)\n",
    "        \n",
    "        return augmented_images, target\n",
    "\n",
    "# TTA Dataset 생성\n",
    "tta_dataset = TTAImageDataset(\n",
    "    \"../data/sample_submission.csv\",\n",
    "    \"../data/test/\",\n",
    "    essential_tta_transforms\n",
    ")\n",
    "\n",
    "# TTA DataLoader (배치 크기를 줄여서 메모리 절약)\n",
    "tta_loader = DataLoader(\n",
    "    tta_dataset,\n",
    "    batch_size=64,  # TTA는 메모리를 많이 사용하므로 배치 크기 줄임\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\" TTA Dataset: {len(tta_dataset)}개 테스트 샘플\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "45382398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      " 최종 추론 - 앙상블 + TTA\n",
      "============================================================\n",
      "앙상블 TTA 추론 시작...\n",
      "5개 모델 × 5개 TTA 변형 = 25개 예측 평균\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ensemble TTA: 100%|██████████| 50/50 [02:51<00:00,  3.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 앙상블 TTA 추론 완료!\n",
      "총 소요시간: 2.9분\n",
      " 평균 신뢰도: 0.4164 ± 0.0929\n",
      " 고신뢰도 샘플: 0/3140 (0.0%)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# 17. Ensemble + TTA Inference with WandB Logging\n",
    "# =============================================================================\n",
    "\n",
    "def ensemble_tta_inference_with_logging(models, loader, transforms, confidence_threshold=0.9):\n",
    "    \"\"\"5-Fold 모델 앙상블 + TTA 추론 with WandB 로깅\"\"\"\n",
    "    all_predictions = []\n",
    "    all_confidences = []\n",
    "    \n",
    "    # TTA 진행상황 로깅을 위한 테이블\n",
    "    tta_progress = wandb.Table(columns=[\"Batch\", \"Avg_Confidence\", \"Low_Conf_Count\", \"High_Conf_Count\"])\n",
    "    \n",
    "    # Temperature scaling 초기화\n",
    "    temp_scaling = TemperatureScaling().to(device)\n",
    "    \n",
    "    print(f\"앙상블 TTA 추론 시작...\")\n",
    "    print(f\"{len(models)}개 모델 × {len(transforms)}개 TTA 변형 = {len(models) * len(transforms)}개 예측 평균\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    for batch_idx, (images_list, _) in enumerate(tqdm(loader, desc=\"Ensemble TTA\")):\n",
    "        batch_size = images_list[0].size(0)\n",
    "        ensemble_probs = torch.zeros(batch_size, 17).to(device)\n",
    "        \n",
    "        # 각 fold 모델별 예측\n",
    "        for model_idx, model in enumerate(models):\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                # 각 TTA 변형별 예측\n",
    "                for tta_idx, images in enumerate(images_list):\n",
    "                    images = images.to(device)\n",
    "                    preds = model(images)\n",
    "                    \n",
    "                    # Temperature scaling 적용\n",
    "                    preds = temp_scaling(preds)\n",
    "                    probs = torch.softmax(preds, dim=1)\n",
    "                    \n",
    "                    # 앙상블 확률에 누적 (평균)\n",
    "                    ensemble_probs += probs / (len(models) * len(images_list))\n",
    "        \n",
    "        # 신뢰도 계산\n",
    "        max_probs = torch.max(ensemble_probs, dim=1)[0]\n",
    "        batch_confidences = max_probs.cpu().numpy()\n",
    "        all_confidences.extend(batch_confidences)\n",
    "        \n",
    "        final_preds = torch.argmax(ensemble_probs, dim=1)\n",
    "        all_predictions.extend(final_preds.cpu().numpy())\n",
    "        \n",
    "        # 배치별 신뢰도 분석\n",
    "        high_conf_count = np.sum(batch_confidences >= confidence_threshold)\n",
    "        low_conf_count = batch_size - high_conf_count\n",
    "        avg_confidence = np.mean(batch_confidences)\n",
    "        \n",
    "        # 진행상황 테이블에 추가\n",
    "        tta_progress.add_data(batch_idx, avg_confidence, low_conf_count, high_conf_count)\n",
    "        \n",
    "        # 배치별 상세 로깅 (20배치마다)\n",
    "        if batch_idx % 20 == 0:\n",
    "            elapsed_time = time.time() - start_time\n",
    "            estimated_total = elapsed_time * len(loader) / (batch_idx + 1)\n",
    "            remaining_time = estimated_total - elapsed_time\n",
    "            \n",
    "            wandb.log({\n",
    "                \"tta_progress/batch\": batch_idx,\n",
    "                \"tta_progress/avg_confidence\": avg_confidence,\n",
    "                \"tta_progress/high_confidence_ratio\": high_conf_count / batch_size,\n",
    "                \"tta_progress/low_confidence_count\": low_conf_count,\n",
    "                \"tta_progress/elapsed_time_min\": elapsed_time / 60,\n",
    "                \"tta_progress/estimated_remaining_min\": remaining_time / 60,\n",
    "                \"tta_progress/samples_processed\": (batch_idx + 1) * batch_size,\n",
    "            })\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    \n",
    "    # TTA 최종 결과 로깅\n",
    "    final_avg_confidence = np.mean(all_confidences)\n",
    "    confidence_std = np.std(all_confidences)\n",
    "    high_conf_samples = np.sum(np.array(all_confidences) >= confidence_threshold)\n",
    "    \n",
    "    wandb.log({\n",
    "        \"tta_results/total_time_min\": total_time / 60,\n",
    "        \"tta_results/samples_per_second\": len(all_predictions) / total_time,\n",
    "        \"tta_results/final_avg_confidence\": final_avg_confidence,\n",
    "        \"tta_results/confidence_std\": confidence_std,\n",
    "        \"tta_results/high_confidence_samples\": high_conf_samples,\n",
    "        \"tta_results/high_confidence_ratio\": high_conf_samples / len(all_predictions),\n",
    "        \"tta_results/total_predictions\": len(all_predictions),\n",
    "        \"tta_results/confidence_histogram\": wandb.Histogram(all_confidences),\n",
    "        \"tta_results/progress_table\": tta_progress\n",
    "    })\n",
    "    \n",
    "    print(f\"\\n 앙상블 TTA 추론 완료!\")\n",
    "    print(f\"총 소요시간: {total_time/60:.1f}분\")\n",
    "    print(f\" 평균 신뢰도: {final_avg_confidence:.4f} ± {confidence_std:.4f}\")\n",
    "    print(f\" 고신뢰도 샘플: {high_conf_samples}/{len(all_predictions)} ({high_conf_samples/len(all_predictions)*100:.1f}%)\")\n",
    "    \n",
    "    return all_predictions, all_confidences\n",
    "\n",
    "# 앙상블 TTA 실행\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\" 최종 추론 - 앙상블 + TTA\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "tta_predictions, confidences = ensemble_tta_inference_with_logging(\n",
    "    models=ensemble_models, \n",
    "    loader=tta_loader, \n",
    "    transforms=essential_tta_transforms,\n",
    "    confidence_threshold=0.9\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6e9072c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 최종 결과 정리 중...\n",
      "\n",
      "📊 예측 결과 분포:\n",
      "Class  0:  200 (  6.4%)\n",
      "Class  1:   91 (  2.9%)\n",
      "Class  2:  200 (  6.4%)\n",
      "Class  3:  258 (  8.2%)\n",
      "Class  4:  199 (  6.3%)\n",
      "Class  5:  200 (  6.4%)\n",
      "Class  6:  203 (  6.5%)\n",
      "Class  7:  142 (  4.5%)\n",
      "Class  8:  200 (  6.4%)\n",
      "Class  9:  200 (  6.4%)\n",
      "Class 10:  210 (  6.7%)\n",
      "Class 11:  191 (  6.1%)\n",
      "Class 12:  199 (  6.3%)\n",
      "Class 13:  158 (  5.0%)\n",
      "Class 14:   89 (  2.8%)\n",
      "Class 15:  200 (  6.4%)\n",
      "Class 16:  200 (  6.4%)\n",
      "최종 결과 WandB 로깅 완료!\n",
      "총 예측 수: 3140\n",
      "예측된 클래스 수: 17\n",
      "평균 신뢰도: 0.4164\n",
      "신뢰도 범위: 0.1129 ~ 0.6469\n",
      "예측 분포 차트 로깅 완료!\n",
      "실험 요약 로깅 완료!\n",
      "\n",
      " 최종 결과 저장 완료!\n",
      " 파일 위치: ../output/choice4.csv\n",
      " 총 예측 수: 3140\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 18. Final Results and Submission\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\n 최종 결과 정리 중...\")\n",
    "\n",
    "# TTA 결과로 submission 파일 생성\n",
    "tta_pred_df = pd.DataFrame(tta_dataset.df, columns=['ID', 'target'])\n",
    "tta_pred_df['target'] = tta_predictions\n",
    "\n",
    "# 기존 submission과 동일한 순서인지 확인\n",
    "sample_submission_df = pd.read_csv(\"../data/sample_submission.csv\")\n",
    "assert (sample_submission_df['ID'] == tta_pred_df['ID']).all(), \"ID 순서 불일치!\"\n",
    "\n",
    "# 예측 분포 분석\n",
    "pred_distribution = tta_pred_df['target'].value_counts().sort_index()\n",
    "pred_table = wandb.Table(columns=[\"Class\", \"Count\", \"Percentage\"])\n",
    "\n",
    "print(f\"\\n📊 예측 결과 분포:\")\n",
    "for class_id in range(17):\n",
    "    count = pred_distribution.get(class_id, 0)\n",
    "    percentage = count / len(tta_pred_df) * 100\n",
    "    pred_table.add_data(class_id, count, percentage)\n",
    "    print(f\"Class {class_id:2d}: {count:4d} ({percentage:5.1f}%)\")\n",
    "\n",
    "# 신뢰도 분석\n",
    "confidence_bins = [0.5, 0.7, 0.8, 0.9, 0.95, 1.0]\n",
    "confidence_analysis = {}\n",
    "for i, threshold in enumerate(confidence_bins):\n",
    "    if i == 0:\n",
    "        count = np.sum(np.array(confidences) >= threshold)\n",
    "    else:\n",
    "        prev_threshold = confidence_bins[i-1]\n",
    "        count = np.sum((np.array(confidences) >= prev_threshold) & (np.array(confidences) < threshold))\n",
    "    confidence_analysis[f\"conf_{threshold}\"] = count\n",
    "\n",
    "# 최종 결과 로깅\n",
    "try:\n",
    "    if wandb.run is not None:\n",
    "        wandb.run.log({\n",
    "            \"final_results/total_predictions\": len(tta_predictions),\n",
    "            \"final_results/unique_classes_predicted\": len(np.unique(tta_predictions)),\n",
    "            \"final_results/prediction_distribution_table\": pred_table,\n",
    "            \"final_results/avg_confidence\": np.mean(confidences),\n",
    "            \"final_results/median_confidence\": np.median(confidences),\n",
    "            \"final_results/min_confidence\": np.min(confidences),\n",
    "            \"final_results/max_confidence\": np.max(confidences),\n",
    "            \"final_results/confidence_distribution\": wandb.Histogram(confidences),\n",
    "            **confidence_analysis\n",
    "        })\n",
    "        print(\"최종 결과 WandB 로깅 완료!\")\n",
    "    else:\n",
    "        print(\"활성화된 run이 없어 로깅을 건너뜁니다.\")\n",
    "except Exception as e:\n",
    "    print(f\"WandB 로깅 중 에러: {e}\")\n",
    "\n",
    "# 콘솔 출력은 항상 실행\n",
    "print(f\"총 예측 수: {len(tta_predictions)}\")\n",
    "print(f\"예측된 클래스 수: {len(np.unique(tta_predictions))}\")\n",
    "print(f\"평균 신뢰도: {np.mean(confidences):.4f}\")\n",
    "print(f\"신뢰도 범위: {np.min(confidences):.4f} ~ {np.max(confidences):.4f}\")\n",
    "\n",
    "\n",
    "# 예측 분포 바차트\n",
    "try:\n",
    "    if wandb.run is not None:\n",
    "        pred_dist_data = [[f\"Class_{i}\", pred_distribution.get(i, 0)] for i in range(17)]\n",
    "        wandb.run.log({\n",
    "            \"final_results/prediction_distribution_chart\": wandb.plot.bar(\n",
    "                wandb.Table(data=pred_dist_data, columns=[\"Class\", \"Count\"]),\n",
    "                \"Class\", \"Count\", \n",
    "                title=\"Final Prediction Distribution\"\n",
    "            )\n",
    "        })\n",
    "        print(\"예측 분포 차트 로깅 완료!\")\n",
    "    else:\n",
    "        print(\"차트 로깅을 건너뜁니다.\")\n",
    "except Exception as e:\n",
    "    print(f\"차트 로깅 중 에러: {e}\")\n",
    "\n",
    "# 결과 저장\n",
    "output_path = \"../output/choice4.csv\"\n",
    "tta_pred_df.to_csv(output_path, index=False)\n",
    "\n",
    "# 결과 파일을 WandB 아티팩트로 저장\n",
    "artifact = wandb.Artifact(\n",
    "    name=\"final_predictions\",\n",
    "    type=\"predictions\",\n",
    "    description=f\"Final ensemble predictions with {N_FOLDS}-fold CV + TTA\"\n",
    ")\n",
    "artifact.add_file(output_path)\n",
    "\n",
    "try:\n",
    "    if wandb.run is not None:\n",
    "        wandb.run.log_artifact(artifact)\n",
    "        print(\"실험 요약 로깅 완료!\")\n",
    "    else:\n",
    "        print(\"활성화된 run이 없어 실험 요약 로깅을 건너뜁니다.\")\n",
    "except Exception as e:\n",
    "    print(f\"실험 요약 로깅 중 에러: {e}\")\n",
    "\n",
    "\n",
    "print(f\"\\n 최종 결과 저장 완료!\")\n",
    "print(f\" 파일 위치: {output_path}\")\n",
    "print(f\" 총 예측 수: {len(tta_predictions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "30990203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "실험 요약 로깅 완료!\n",
      "최종 상태 업데이트 완료!\n",
      "\n",
      "실험 완료 시간: 2025-09-04 14:24:08\n",
      "\n",
      "============================================================\n",
      "실험 완료!\n",
      "============================================================\n",
      " K-Fold CV 결과: 0.9283 ± 0.0079\n",
      " 최고 성능 Fold: 0.9412\n",
      " 앙상블 모델: 5개\n",
      " TTA 변형: 5개\n",
      " 평균 예측 신뢰도: 0.4164\n",
      " WandB 대시보드: https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/mdvqqydn\n",
      "\n",
      " 예측 결과 샘플:\n",
      "                     ID  target\n",
      "0  0008fdb22ddce0ce.jpg       2\n",
      "1  00091bffdffd83de.jpg      12\n",
      "2  00396fbc1f6cc21d.jpg       5\n",
      "3  00471f8038d9c4b6.jpg      12\n",
      "4  00901f504008d884.jpg       2\n",
      "5  009b22decbc7220c.jpg      15\n",
      "6  00b33e0ee6d59427.jpg       0\n",
      "7  00bbdcfbbdb3e131.jpg       8\n",
      "8  00c03047e0fbef40.jpg      15\n",
      "9  00c0dabb63ca7a16.jpg      11\n",
      "\n",
      " 모든 작업 완료!\n",
      " 결과 파일: ../output/choice4.csv\n",
      " WandB에서 전체 실험 결과를 확인하세요!\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 19. Experiment Summary and Cleanup\n",
    "# =============================================================================\n",
    "\n",
    "# 실험 요약 생성\n",
    "experiment_summary = {\n",
    "    \"experiment_name\": main_run.name,\n",
    "    \"model_architecture\": model_name,\n",
    "    \"image_size\": img_size,\n",
    "    \"cv_strategy\": f\"{N_FOLDS}-Fold StratifiedKFold\",\n",
    "    \"cv_mean_f1\": mean_f1,\n",
    "    \"cv_std_f1\": std_f1,\n",
    "    \"cv_best_fold\": max(val_f1_scores),\n",
    "    \"ensemble_models\": len(ensemble_models),\n",
    "    \"tta_transforms\": len(essential_tta_transforms),\n",
    "    \"total_training_time_min\": sum([r['epochs_trained'] for r in fold_results]) * 2,  # 추정치\n",
    "    \"avg_prediction_confidence\": np.mean(confidences),\n",
    "    \"high_confidence_predictions\": np.sum(np.array(confidences) >= 0.9),\n",
    "    \"experiment_tags\": [\"baseline\", \"efficientnet-b3\", \"k-fold-cv\", \"tta\", \"ensemble\"]\n",
    "}\n",
    "\n",
    "# 실험 요약\n",
    "try:\n",
    "    if wandb.run is not None:\n",
    "        wandb.run.log({\"experiment_summary\": experiment_summary})\n",
    "        print(\"실험 요약 로깅 완료!\")\n",
    "    else:\n",
    "        print(\"활성화된 run이 없어 실험 요약 로깅을 건너뜁니다.\")\n",
    "except Exception as e:\n",
    "    print(f\"실험 요약 로깅 중 에러: {e}\")\n",
    "\n",
    "\n",
    "# 마지막 상태 업데이트\n",
    "try:\n",
    "    if wandb.run is not None:\n",
    "        wandb.run.log({\n",
    "            \"status\": \"completed\",\n",
    "            \"completion_time\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "            \"total_runtime_hours\": 0  # start_time 속성 문제로 일단 0으로 설정\n",
    "        })\n",
    "        print(\"최종 상태 업데이트 완료!\")\n",
    "    else:\n",
    "        print(\"활성화된 run이 없어 상태 업데이트를 건너뜁니다.\")\n",
    "except Exception as e:\n",
    "    print(f\"상태 업데이트 중 에러: {e}\")\n",
    "\n",
    "print(f\"\\n실험 완료 시간: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"실험 완료!\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "print(f\" K-Fold CV 결과: {mean_f1:.4f} ± {std_f1:.4f}\")\n",
    "print(f\" 최고 성능 Fold: {max(val_f1_scores):.4f}\")\n",
    "print(f\" 앙상블 모델: {len(ensemble_models)}개\")\n",
    "print(f\" TTA 변형: {len(essential_tta_transforms)}개\")\n",
    "print(f\" 평균 예측 신뢰도: {np.mean(confidences):.4f}\")\n",
    "print(f\" WandB 대시보드: {main_run.url}\")\n",
    "\n",
    "# Sample predictions 출력\n",
    "print(f\"\\n 예측 결과 샘플:\")\n",
    "print(tta_pred_df.head(10))\n",
    "\n",
    "# 메인 run 종료\n",
    "main_run.finish()\n",
    "\n",
    "print(f\"\\n 모든 작업 완료!\")\n",
    "print(f\" 결과 파일: {output_path}\")\n",
    "print(f\" WandB에서 전체 실험 결과를 확인하세요!\")\n",
    "\n",
    "# 메모리 정리\n",
    "del ensemble_models\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b07f9c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
