ðŸ“‹ ì‹¤í—˜ëª…: fold-3-0909-1320-20250909_1320_swin_base_patch4_window12_384_in22k_ensemble_tta
ðŸ”— WandB URL: https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/ukud57hg
model.safetensors: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.22G/1.22G [00:09<00:00, 124MB/s]
2025-09-09 13:20:37 | [MULTI-MODEL] Fold 3 using model: vit_large_patch16_224
/home/ieyeppo/AI_Lab/computer-vision-competition-1SEN/src/training/train_highperf.py:421: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = GradScaler() if cfg["train"].get("mixed_precision", True) else None
2025-09-09 13:20:37 | [DATA] build highperf loaders | img_size=384 bs=16
2025-09-09 13:20:37 | [DATA] augmentation: baseline-advanced (normal + hard augmentation)
/home/ieyeppo/.pyenv/versions/cv_py3_11_9/lib/python3.11/site-packages/albumentations/augmentations/transforms.py:1692: UserWarning: Using default interpolation INTER_NEAREST, which is sub-optimal.Please specify interpolation mode for downscale and upscale explicitly.For additional information see this PR https://github.com/albumentations-team/albumentations/pull/584
  warnings.warn(
2025-09-09 13:20:37 | [HighPerfDataset] size=1256 img_size=384 epoch=0/3 p_hard=0.200 is_train=True
2025-09-09 13:20:37 | [HighPerfDataset] size=314 img_size=384 epoch=0/3 p_hard=0.000 is_train=False
2025-09-09 13:20:37 | [DATA] dataset sizes | train=1256 valid=314
2025-09-09 13:20:37 | [HighPerfDataset] updated epoch=1, p_hard=0.300
2025-09-09 13:20:37 | [EPOCH 1] >>> TRAIN start | steps=79 mixup=True
Train Epoch 1:   0%|                                                                                       | 0/79 [00:00<?, ?it/s]/home/ieyeppo/AI_Lab/computer-vision-competition-1SEN/src/training/train_highperf.py:84: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with autocast(enabled=scaler is not None):
Train Epoch 1:   0%|                                                                                       | 0/79 [00:00<?, ?it/s]
2025-09-09 13:20:37 | [ERROR] Training failed: Input height (384) doesn't match model (224).
2025-09-09 13:20:37 | [SHUTDOWN] Training pipeline ended
2025-09-09 13:20:37 | âŒ [PIPELINE] Failed: Input height (384) doesn't match model (224).
2025-09-09 13:20:37 | ðŸ [PIPELINE] Full pipeline ended
âŒ Optimization failed: Input height (384) doesn't match model (224).
