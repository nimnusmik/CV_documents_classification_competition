{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18bbe02e",
   "metadata": {},
   "source": [
    "# üìÑ Document type classification baseline code with WandB Integration\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92dc69ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# 0. Prepare Environments & Install Libraries\n",
    "# =============================================================================\n",
    "\n",
    "# ÌïÑÏöîÌïú ÎùºÏù¥Î∏åÎü¨Î¶¨Î•º ÏÑ§ÏπòÌï©ÎãàÎã§.\n",
    "#!pip install -r ../requirements.txt\n",
    "#!pip install transformers==4.44.0\n",
    "#!pip install easyocr\n",
    "#!pip install datasets\n",
    "#!pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a366485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Î©îÎ™®Î¶¨ Ï†ïÎ¶¨ ÏôÑÎ£å\n"
     ]
    }
   ],
   "source": [
    "# ÌòÑÏû¨ ÎÖ∏Ìä∏Î∂ÅÏóêÏÑú Î∞îÎ°ú Ïã§ÌñâÌïòÏÑ∏Ïöî\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "def quick_cleanup():\n",
    "    \"\"\"Ï¶âÏãú ÏÇ¨Ïö© Í∞ÄÎä•Ìïú Îπ†Î•∏ Î©îÎ™®Î¶¨ Ï†ïÎ¶¨\"\"\"\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.synchronize()\n",
    "    print(\"Î©îÎ™®Î¶¨ Ï†ïÎ¶¨ ÏôÑÎ£å\")\n",
    "\n",
    "# Î∞îÎ°ú Ïã§Ìñâ\n",
    "quick_cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cf3ee76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05a40f19952f4df790323004f4a42c1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers.utils import move_cache\n",
    "move_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "773408ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import copy\n",
    "import json\n",
    "\n",
    "import optuna, math\n",
    "import torch\n",
    "import albumentations as A\n",
    "import pandas as pd\n",
    "#import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.optim import Adam\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.cuda.amp import autocast, GradScaler  # Mixed PrecisionÏö©\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# WandB Í¥ÄÎ†® import Ï∂îÍ∞Ä\n",
    "import wandb\n",
    "from datetime import datetime\n",
    "\n",
    "# LayoutLMv3 Í¥ÄÎ†® import\n",
    "from transformers import LayoutLMv3Processor, LayoutLMv3ForSequenceClassification\n",
    "import easyocr\n",
    "from datasets import Dataset as HFDataset  # Hugging Face Dataset (ÏòµÏÖò)\n",
    "\n",
    "# OCR Ï¥àÍ∏∞Ìôî\n",
    "reader = easyocr.Reader(['en'], gpu=True)  # ÏòÅÏñ¥ Î¨∏ÏÑú Í∞ÄÏ†ï\n",
    "\n",
    "# OCR Ìï®Ïàò\n",
    "def extract_ocr(image_path, max_words=512):\n",
    "    \"\"\"Ïù¥ÎØ∏ÏßÄÏóêÏÑú ÌÖçÏä§Ìä∏ÏôÄ Î∞îÏö¥Îî© Î∞ïÏä§ Ï∂îÏ∂ú\"\"\"\n",
    "    try:\n",
    "        results = reader.readtext(image_path)\n",
    "        words = []\n",
    "        boxes = []\n",
    "        for (bbox, text, conf) in results:\n",
    "            if conf > 0.5:  # Ïã†Î¢∞ÎèÑ ÌïÑÌÑ∞\n",
    "                words.append(text.strip())\n",
    "                # Î∞îÏö¥Îî© Î∞ïÏä§: [x0, y0, x1, y1] ‚Üí LayoutLMv3 ÌòïÏãù (0-1000 Ïä§ÏºÄÏùº)\n",
    "                x0, y0 = bbox[0][0], bbox[0][1]\n",
    "                x1, y1 = bbox[2][0], bbox[2][1]\n",
    "                # Ïù¥ÎØ∏ÏßÄ ÌÅ¨Í∏∞ Í∏∞Ï§Ä Ï†ïÍ∑úÌôî (0-1000)\n",
    "                img = Image.open(image_path)\n",
    "                w, h = img.size\n",
    "                box = [int(1000 * (x0 / w)), int(1000 * (y0 / h)), \n",
    "                       int(1000 * (x1 / w)), int(1000 * (y1 / h))]\n",
    "                boxes.append(box)\n",
    "                if len(words) >= max_words:\n",
    "                    break\n",
    "        return words, boxes\n",
    "    except Exception as e:\n",
    "        print(f\"OCR error for {image_path}: {e}\")\n",
    "        return [], []\n",
    "\n",
    "# OCR Ï∫êÏã± (ÌõàÎ†® Ï†ÑÏóê Ïã§Ìñâ)\n",
    "def prepare_ocr_cache(df, img_path):\n",
    "    \"\"\"DataFrameÏóê OCR Í≤∞Í≥ºÎ•º Ï∂îÍ∞ÄÌïòÍ≥† Ï†ÄÏû•\"\"\"\n",
    "    ocr_cache = {}\n",
    "    for idx, row in df.iterrows():\n",
    "        image_id = row['ID']\n",
    "        img_full_path = os.path.join(img_path, image_id)\n",
    "        words, boxes = extract_ocr(img_full_path)\n",
    "        df.at[idx, 'words'] = json.dumps(words)\n",
    "        df.at[idx, 'boxes'] = json.dumps(boxes)\n",
    "        ocr_cache[image_id] = (words, boxes)\n",
    "    df.to_csv(os.path.join(img_path, 'with_ocr.csv'), index=False)\n",
    "    return ocr_cache\n",
    "\n",
    "# ÌîÑÎ°úÏÑ∏ÏÑú Î°úÎìú\n",
    "processor = LayoutLMv3Processor.from_pretrained(\"microsoft/layoutlmv3-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e142354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WandB Î°úÍ∑∏Ïù∏ ÏÉÅÌÉú: kimsunmin0227\n",
      "ÌîÑÎ°úÏ†ùÌä∏: document-classification-team-CV\n",
      "Ïã§ÌóòÎ™Ö: layoutlmv3-baseline\n"
     ]
    }
   ],
   "source": [
    " \n",
    "\"\"\"\n",
    "üöÄ ÌåÄÏõê ÏÇ¨Ïö© Í∞ÄÏù¥Îìú:\n",
    "\n",
    "1. WandB Í≥ÑÏ†ï ÏÉùÏÑ±: https://wandb.ai/signup\n",
    "2. Ïù¥ ÏÖÄ Ïã§Ìñâ Ïãú Î°úÍ∑∏Ïù∏ ÌîÑÎ°¨ÌîÑÌä∏Í∞Ä ÎÇòÌÉÄÎÇòÎ©¥ Í∞úÏù∏ API ÌÇ§ ÏûÖÎ†•\n",
    "3. EXPERIMENT_NAMEÏùÑ Îã§ÏùåÍ≥º Í∞ôÏù¥ Î≥ÄÍ≤Ω:\n",
    "   - \"member1-baseline\"\n",
    "   - \"member2-augmentation-test\"  \n",
    "   - \"member3-hyperparameter-tuning\"\n",
    "   Îì±Îì± Í∞ÅÏûê Îã§Î•∏ Ïù¥Î¶Ñ ÏÇ¨Ïö©\n",
    "\n",
    "4. ÌåÄ ÎåÄÏãúÎ≥¥Îìú URL: [Ïó¨Í∏∞Ïóê ÎãπÏã†Ïùò ÌîÑÎ°úÏ†ùÌä∏ URL Ï∂îÍ∞Ä]\n",
    "\n",
    "‚ö†Ô∏è Ï£ºÏùòÏÇ¨Ìï≠:\n",
    "- Ï†àÎåÄ API ÌÇ§Î•º ÏΩîÎìúÏóê ÌïòÎìúÏΩîÎî©ÌïòÏßÄ ÎßàÏÑ∏Ïöî\n",
    "- EXPERIMENT_NAMEÎßå Î≥ÄÍ≤ΩÌïòÍ≥† PROJECT_NAMEÏùÄ Í∑∏ÎåÄÎ°ú ÎëêÏÑ∏Ïöî\n",
    "- Í∞ÅÏûê Í∞úÏù∏ Í≥ÑÏ†ïÏúºÎ°ú Î°úÍ∑∏Ïù∏Ìï¥ÏÑú Ïã§ÌóòÏùÑ Ï∂îÍ∞ÄÌïòÏÑ∏Ïöî\n",
    "\"\"\"\n",
    "\n",
    "# WandB Î°úÍ∑∏Ïù∏ (Í∞ÅÏûê Ïã§Ìñâ)\n",
    "try:\n",
    "    if wandb.api.api_key is None:\n",
    "        print(\"WandBÏóê Î°úÍ∑∏Ïù∏Ïù¥ ÌïÑÏöîÌï©ÎãàÎã§.\")\n",
    "        wandb.login()\n",
    "    else:\n",
    "        print(f\"WandB Î°úÍ∑∏Ïù∏ ÏÉÅÌÉú: {wandb.api.viewer()['username']}\")\n",
    "except:\n",
    "    print(\"WandB Î°úÍ∑∏Ïù∏ÏùÑ ÏßÑÌñâÌï©ÎãàÎã§...\")\n",
    "    wandb.login()\n",
    "\n",
    "# ÌîÑÎ°úÏ†ùÌä∏ ÏÑ§Ï†ï (Í∞ÅÏûê ÏàòÏ†ïÌï† Î∂ÄÎ∂Ñ)\n",
    "PROJECT_NAME = \"document-classification-team-CV\"  # Î™®Îì† ÌåÄÏõê ÎèôÏùº\n",
    "ENTITY = None  # Í∞ÅÏûê Í∞úÏù∏ Í≥ÑÏ†ï ÏÇ¨Ïö©\n",
    "EXPERIMENT_NAME = \"layoutlmv3-baseline\"  # ÌåÄÏõêÎ≥ÑÎ°ú Î≥ÄÍ≤Ω (Ïòà: \"member1-hyperopt\", \"member2-augmentation\")\n",
    "\n",
    "print(f\"ÌîÑÎ°úÏ†ùÌä∏: {PROJECT_NAME}\")\n",
    "print(f\"Ïã§ÌóòÎ™Ö: {EXPERIMENT_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "448a2f52",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "# ÏãúÎìúÎ•º Í≥†Ï†ïÌï©ÎãàÎã§.\n",
    "SEED = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.benchmark = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f9d1a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LayoutLMv3ForSequenceClassification were not initialized from the model checkpoint at microsoft/layoutlmv3-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique labels: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]\n",
      "Number of unique labels: 17\n",
      "Dataset size: 1570\n",
      "Using device: cuda\n",
      "Starting training...\n",
      "Starting epoch 0\n",
      "Epoch 0, Batch 0, Loss: 2.9736\n",
      "Epoch 0, Batch 1, Loss: 2.7821\n",
      "Epoch 0, Batch 2, Loss: 2.4954\n",
      "Epoch 0, Batch 3, Loss: 2.5653\n",
      "Epoch 0, Batch 4, Loss: 3.0934\n",
      "Epoch 0 completed. Average loss: 2.7819\n",
      "Starting epoch 1\n",
      "Epoch 1, Batch 0, Loss: 2.2907\n",
      "Epoch 1, Batch 1, Loss: 2.4921\n",
      "Epoch 1, Batch 2, Loss: 2.2888\n",
      "Epoch 1, Batch 3, Loss: 2.4479\n",
      "Epoch 1, Batch 4, Loss: 2.3286\n",
      "Epoch 1 completed. Average loss: 2.3696\n",
      "Training completed successfully!\n",
      "\n",
      "Testing inference...\n",
      "Batch 0 predictions: [16, 16]\n",
      "Batch 0 actual labels: [16, 4]\n",
      "Batch 1 predictions: [16, 16]\n",
      "Batch 1 actual labels: [15, 14]\n",
      "Batch 2 predictions: [16, 16]\n",
      "Batch 2 actual labels: [10, 15]\n",
      "Inference test completed!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import LayoutLMv3Processor, LayoutLMv3ForSequenceClassification\n",
    "from PIL import Image\n",
    "\n",
    "# ÌôòÍ≤Ω Î≥ÄÏàò ÏÑ§Ï†ï (MKL/OpenMP Ï∂©Îèå Î∞©ÏßÄ)\n",
    "os.environ[\"MKL_SERVICE_FORCE_INTEL\"] = \"1\"\n",
    "os.environ[\"MKL_THREADING_LAYER\"] = \"GNU\"\n",
    "\n",
    "# Îç∞Ïù¥ÌÑ∞ Í≤ΩÎ°ú\n",
    "DATA_ROOT = \"/root/computervisioncompetition-cv-1/mywork/data\"\n",
    "\n",
    "# Îç∞Ïù¥ÌÑ∞ÏÖã ÌÅ¥ÎûòÏä§\n",
    "class LayoutLMv3Dataset(Dataset):\n",
    "    def __init__(self, df, img_path, processor, max_length=512):\n",
    "        self.df = df\n",
    "        self.img_path = img_path\n",
    "        self.processor = processor\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        image_path = os.path.join(self.img_path, row['ID'])\n",
    "        \n",
    "        try:\n",
    "            words = json.loads(row['words']) if isinstance(row['words'], str) else row['words']\n",
    "            boxes = json.loads(row['boxes']) if isinstance(row['boxes'], str) else row['boxes']\n",
    "        except:\n",
    "            words, boxes = [], []\n",
    "        \n",
    "        # Îπà Î¶¨Ïä§Ìä∏ Ï≤òÎ¶¨\n",
    "        if not words or not boxes:\n",
    "            words = [\"\"]\n",
    "            boxes = [[0, 0, 1, 1]]\n",
    "        \n",
    "        # Í∏∏Ïù¥ ÎßûÏ∂îÍ∏∞\n",
    "        if len(words) != len(boxes):\n",
    "            min_len = min(len(words), len(boxes))\n",
    "            words = words[:min_len]\n",
    "            boxes = boxes[:min_len]\n",
    "        \n",
    "        label = int(row['target'])\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        \n",
    "        # ProcessorÏóêÏÑú paddingÍ≥º truncation Î™ÖÏãúÏ†Å ÏÑ§Ï†ï\n",
    "        encoding = self.processor(\n",
    "            image, \n",
    "            text=words, \n",
    "            boxes=boxes, \n",
    "            return_tensors=\"pt\",\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=self.max_length\n",
    "        )\n",
    "        \n",
    "        # Î™®Îì† tensorÎ•º squeezeÌïòÏó¨ Î∞∞Ïπò Ï∞®Ïõê Ï†úÍ±∞\n",
    "        result = {}\n",
    "        for key, value in encoding.items():\n",
    "            if isinstance(value, torch.Tensor):\n",
    "                result[key] = value.squeeze(0)\n",
    "            else:\n",
    "                result[key] = value\n",
    "        \n",
    "        return result, label\n",
    "\n",
    "# Custom collate function\n",
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Custom collate function for LayoutLMv3\n",
    "    \"\"\"\n",
    "    inputs = {}\n",
    "    labels = []\n",
    "    \n",
    "    # Ï≤´ Î≤àÏß∏ ÏÉòÌîåÏóêÏÑú ÌÇ§ ÌôïÏù∏\n",
    "    sample_keys = batch[0][0].keys()\n",
    "    \n",
    "    for key in sample_keys:\n",
    "        inputs[key] = torch.stack([item[0][key] for item in batch])\n",
    "    \n",
    "    labels = torch.tensor([item[1] for item in batch], dtype=torch.long)\n",
    "    \n",
    "    return inputs, labels\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # ÌîÑÎ°úÏÑ∏ÏÑú Î∞è Î™®Îç∏\n",
    "    processor = LayoutLMv3Processor.from_pretrained(\"microsoft/layoutlmv3-base\", apply_ocr=False)\n",
    "    model = LayoutLMv3ForSequenceClassification.from_pretrained(\"microsoft/layoutlmv3-base\", num_labels=17)\n",
    "    \n",
    "    # Îç∞Ïù¥ÌÑ∞ÏÖã\n",
    "    train_df = pd.read_csv(os.path.join(DATA_ROOT, 'train/with_ocr.csv'))\n",
    "    print(\"Unique labels:\", sorted(train_df['target'].unique()))\n",
    "    print(\"Number of unique labels:\", len(train_df['target'].unique()))\n",
    "    print(\"Dataset size:\", len(train_df))\n",
    "    \n",
    "    # Î™á Í∞ú ÏÉòÌîåÎ°ú Î®ºÏ†Ä ÌÖåÏä§Ìä∏\n",
    "    test_df = train_df.head(10).copy()  # ÏûëÏùÄ ÏÉòÌîåÎ°ú ÌÖåÏä§Ìä∏\n",
    "    \n",
    "    train_dataset = LayoutLMv3Dataset(test_df, os.path.join(DATA_ROOT, 'train/'), processor)\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=2,  # ÏûëÏùÄ Î∞∞Ïπò ÌÅ¨Í∏∞Î°ú ÏãúÏûë\n",
    "        shuffle=True, \n",
    "        num_workers=0,  # ÎîîÎ≤ÑÍπÖÏùÑ ÏúÑÌï¥ 0ÏúºÎ°ú ÏÑ§Ï†ï\n",
    "        collate_fn=collate_fn  # Ïª§Ïä§ÌÖÄ collate function ÏÇ¨Ïö©\n",
    "    )\n",
    "    \n",
    "    # GPU ÏÑ§Ï†ï\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    model.to(device)\n",
    "    \n",
    "    # ÌïôÏäµ Î£®ÌîÑ\n",
    "    model.train()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
    "    \n",
    "    print(\"Starting training...\")\n",
    "    for epoch in range(2):  # ÌÖåÏä§Ìä∏Î•º ÏúÑÌï¥ 2 ÏóêÌè¨ÌÅ¨Îßå\n",
    "        print(f\"Starting epoch {epoch}\")\n",
    "        total_loss = 0\n",
    "        num_batches = 0\n",
    "        \n",
    "        for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
    "            try:\n",
    "                # ÏûÖÎ†•ÏùÑ GPUÎ°ú Ïù¥Îèô\n",
    "                inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                # Forward pass\n",
    "                outputs = model(**inputs, labels=labels)\n",
    "                loss = outputs.loss\n",
    "                \n",
    "                # Backward pass\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "                num_batches += 1\n",
    "                \n",
    "                print(f\"Epoch {epoch}, Batch {batch_idx}, Loss: {loss.item():.4f}\")\n",
    "                \n",
    "                # Î©îÎ™®Î¶¨ Ï†ïÎ¶¨\n",
    "                del inputs, labels, outputs, loss\n",
    "                torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error in batch {batch_idx}: {e}\")\n",
    "                print(\"Input shapes:\")\n",
    "                for k, v in inputs.items():\n",
    "                    print(f\"  {k}: {v.shape}\")\n",
    "                print(f\"Labels shape: {labels.shape}\")\n",
    "                break\n",
    "        \n",
    "        avg_loss = total_loss / num_batches if num_batches > 0 else 0\n",
    "        print(f\"Epoch {epoch} completed. Average loss: {avg_loss:.4f}\")\n",
    "    \n",
    "    print(\"Training completed successfully!\")\n",
    "    \n",
    "    # Í∞ÑÎã®Ìïú Ï∂îÎ°† ÌÖåÏä§Ìä∏\n",
    "    print(\"\\nTesting inference...\")\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
    "            inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "            outputs = model(**inputs)\n",
    "            predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "            print(f\"Batch {batch_idx} predictions: {predictions.cpu().tolist()}\")\n",
    "            print(f\"Batch {batch_idx} actual labels: {labels.tolist()}\")\n",
    "            if batch_idx >= 2:  # Î™á Í∞ú Î∞∞ÏπòÎßå ÌÖåÏä§Ìä∏\n",
    "                break\n",
    "    \n",
    "    print(\"Inference test completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "403c7204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cutout (Random Erasing) Ìï®Ïàò Ï†ïÏùò\n",
    "def random_erasing(image, p=0.5, scale=(0.02, 0.33), ratio=(0.3, 3.3)):\n",
    "    if random.random() > p:\n",
    "        return image\n",
    "    img_c, img_h, img_w = image.shape[1], image.shape[2], image.shape[3]\n",
    "    area = img_h * img_w\n",
    "    \n",
    "    target_area = torch.tensor(random.uniform(scale[0], scale[1]), dtype=torch.float32) * area\n",
    "    aspect_ratio = torch.tensor(random.uniform(ratio[0], ratio[1]), dtype=torch.float32)\n",
    "    h = int(round(math.sqrt(target_area * aspect_ratio)))\n",
    "    w = int(round(math.sqrt(target_area / aspect_ratio)))\n",
    "    \n",
    "    # h, wÍ∞Ä Ïù¥ÎØ∏ÏßÄ ÌÅ¨Í∏∞ ÎÇ¥Ïóê ÏûàÎäîÏßÄ ÌôïÏù∏\n",
    "    if w < img_w and h < img_h:\n",
    "        x = random.randint(0, img_w - w)\n",
    "        y = random.randint(0, img_h - h)\n",
    "        \n",
    "        # float32 ÎßàÏä§ÌÅ¨ ÏÉùÏÑ±\n",
    "        mask = torch.ones_like(image, dtype=torch.float32)\n",
    "        mask[:, y:y+h, x:x+w] = 0.0  # ÎòêÎäî ÎûúÎç§ Í∞í: torch.rand(3, h, w, dtype=torch.float32)\n",
    "        \n",
    "        # erasing Ï†ÅÏö©\n",
    "        erased = image * mask\n",
    "        return erased.float()  # float32 Ï∂úÎ†• Î≥¥Ïû•\n",
    "    return image.float()\n",
    "\n",
    "# RandomCrop Ìï®Ïàò Ï†ïÏùò\n",
    "def random_crop(image, crop_size=0.7):\n",
    "    img_c, img_h, img_w = image.shape[1], image.shape[2], image.shape[3]\n",
    "    crop_h = int(img_h * crop_size)\n",
    "    crop_w = int(img_w * crop_size)\n",
    "    \n",
    "    if crop_h >= img_h or crop_w >= img_w:\n",
    "        return image\n",
    "    \n",
    "    x = random.randint(0, img_w - crop_w)\n",
    "    y = random.randint(0, img_h - crop_h)\n",
    "    cropped_image = image[:, :, y:y+crop_h, x:x+crop_w]\n",
    "    \n",
    "    # Ìå®Îî©ÏúºÎ°ú ÏõêÎûò ÌÅ¨Í∏∞ Î≥µÏõê\n",
    "    padded_image = torch.zeros_like(image)\n",
    "    padded_image[:, :, y:y+crop_h, x:x+crop_w] = cropped_image\n",
    "    return padded_image\n",
    "\n",
    "# Mixup Ìï®Ïàò Ï†ïÏùò\n",
    "def mixup_data(x, y, alpha=1.0):\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "    batch_size = x.size()[0]\n",
    "    index = torch.randperm(batch_size).cuda()\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0a693a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ÌõàÎ†® Îç∞Ïù¥ÌÑ∞Ïóê OCR Ï∂îÍ∞Ä (Ìïú Î≤àÎßå Ïã§Ìñâ)\n",
    "#train_df = pd.read_csv('../data/train.csv')\n",
    "#train_ocr_cache = prepare_ocr_cache(train_df, '../data/train/')\n",
    "# Í≤ÄÏ¶ù/ÌÖåÏä§Ìä∏ÎèÑ ÎèôÏùºÌïòÍ≤å Ï≤òÎ¶¨\n",
    "#test_df = pd.read_csv('../data/sample_submission.csv')\n",
    "#test_ocr_cache = prepare_ocr_cache(test_df, '../data/test/')  # targetÏùÄ -1Î°ú ÏÑ§Ï†ï"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41682b9",
   "metadata": {},
   "source": [
    "Î≥ëÎ†¨Ï≤òÎ¶¨ Í∞ÄÎä•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39335a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiprocessing start method set to 'spawn'\n",
      "GPU memory cleared\n",
      "Starting script execution\n",
      "Loading existing cache from /root/computervisioncompetition-cv-1/mywork/data/train/with_ocr.csv\n",
      "Loaded 1570 cached OCR results\n",
      "Train cache loaded, skipping OCR processing\n",
      "Loading existing cache from /root/computervisioncompetition-cv-1/mywork/data/test/with_ocr.csv\n",
      "Loaded 3140 cached OCR results\n",
      "Test cache loaded, skipping OCR processing\n",
      "Script execution completed\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from tqdm.notebook import tqdm  # Jupyter/KaggleÏö© tqdm\n",
    "from PIL import Image\n",
    "import easyocr\n",
    "import multiprocessing as mp\n",
    "import torch\n",
    "\n",
    "# Îç∞Ïù¥ÌÑ∞ Í≤ΩÎ°ú ÏÑ§Ï†ï\n",
    "DATA_ROOT = \"/root/computervisioncompetition-cv-1/mywork/data\"  # Ïã§Ï†ú Í≤ΩÎ°ú ÌôïÏù∏\n",
    "\n",
    "# ÏãúÏûë Î∞©ÏãùÏùÑ 'spawn'ÏúºÎ°ú ÏÑ§Ï†ï\n",
    "try:\n",
    "    mp.set_start_method('spawn', force=True)\n",
    "    print(\"Multiprocessing start method set to 'spawn'\")\n",
    "except RuntimeError:\n",
    "    print(\"Multiprocessing start method already set\")\n",
    "\n",
    "# GPU Î©îÎ™®Î¶¨ Ï¥àÍ∏∞Ìôî\n",
    "torch.cuda.empty_cache()\n",
    "print(\"GPU memory cleared\")\n",
    "\n",
    "# EasyOCR Ï¥àÍ∏∞Ìôî\n",
    "def init_easyocr():\n",
    "    try:\n",
    "        reader = easyocr.Reader(['en'], gpu=True)\n",
    "        print(\"EasyOCR initialized with GPU\")\n",
    "        return reader\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to initialize EasyOCR with GPU: {e}. Falling back to CPU.\")\n",
    "        return easyocr.Reader(['en'], gpu=False)\n",
    "\n",
    "def extract_ocr(image_path, max_words=512):\n",
    "    try:\n",
    "        reader = init_easyocr()\n",
    "        results = reader.readtext(image_path)\n",
    "        words = []\n",
    "        boxes = []\n",
    "        for (bbox, text, conf) in results:\n",
    "            if conf > 0.5:\n",
    "                words.append(text.strip())\n",
    "                img = Image.open(image_path)\n",
    "                w, h = img.size\n",
    "                x0, y0 = bbox[0][0], bbox[0][1]\n",
    "                x1, y1 = bbox[2][0], bbox[2][1]\n",
    "                box = [int(1000 * (x0 / w)), int(1000 * (y0 / h)), \n",
    "                       int(1000 * (x1 / w)), int(1000 * (y1 / h))]\n",
    "                boxes.append(box)\n",
    "                if len(words) >= max_words:\n",
    "                    break\n",
    "        print(f\"OCR processed for {image_path}: {len(words)} words extracted\")\n",
    "        return words, boxes\n",
    "    except Exception as e:\n",
    "        print(f\"OCR error for {image_path}: {e}\")\n",
    "        return [], []\n",
    "    finally:\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "def process_image(args):\n",
    "    image_id, img_path = args\n",
    "    img_full_path = os.path.join(img_path, image_id)\n",
    "    words, boxes = extract_ocr(img_full_path)\n",
    "    return image_id, words, boxes\n",
    "\n",
    "def prepare_ocr_cache_parallel(df, img_path, num_workers=2):\n",
    "    print(f\"Starting OCR processing for {len(df)} images in {img_path}\")\n",
    "    ocr_cache = {}\n",
    "    df = df.copy()\n",
    "    \n",
    "    num_workers = min(num_workers, mp.cpu_count())\n",
    "    print(f\"Using {num_workers} workers for parallel processing\")\n",
    "    \n",
    "    with ProcessPoolExecutor(max_workers=num_workers) as executor:\n",
    "        futures = [executor.submit(process_image, (row['ID'], img_path)) for _, row in df.iterrows()]\n",
    "        for future in tqdm(futures, total=len(df), desc=\"OCR Processing\"):\n",
    "            try:\n",
    "                image_id, words, boxes = future.result()\n",
    "                ocr_cache[image_id] = (words, boxes)\n",
    "                df.loc[df['ID'] == image_id, 'words'] = json.dumps(words)\n",
    "                df.loc[df['ID'] == image_id, 'boxes'] = json.dumps(boxes)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing image {image_id if 'image_id' in locals() else 'unknown'}: {e}\")\n",
    "                continue\n",
    "    \n",
    "    output_path = os.path.join(img_path, 'with_ocr.csv')\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"OCR results saved to {output_path}\")\n",
    "    return ocr_cache\n",
    "\n",
    "def load_existing_cache(df, img_path):\n",
    "    cache_path = os.path.join(img_path, 'with_ocr.csv')\n",
    "    if os.path.exists(cache_path):\n",
    "        print(f\"Loading existing cache from {cache_path}\")\n",
    "        cached_df = pd.read_csv(cache_path)\n",
    "        ocr_cache = {row['ID']: (json.loads(row['words']), json.loads(row['boxes'])) \n",
    "                     for _, row in cached_df.iterrows()}\n",
    "        print(f\"Loaded {len(ocr_cache)} cached OCR results\")\n",
    "        return cached_df, ocr_cache\n",
    "    print(f\"No cache found at {cache_path}\")\n",
    "    return df, {}\n",
    "\n",
    "# Ïã§Ìñâ\n",
    "print(\"Starting script execution\")\n",
    "train_df, train_ocr_cache = load_existing_cache(\n",
    "    pd.read_csv(os.path.join(DATA_ROOT, 'train.csv')), \n",
    "    os.path.join(DATA_ROOT, 'train/')\n",
    ")\n",
    "if not train_ocr_cache:\n",
    "    print(\"No train cache found, running OCR processing\")\n",
    "    train_ocr_cache = prepare_ocr_cache_parallel(\n",
    "        train_df, os.path.join(DATA_ROOT, 'train/'), num_workers=2\n",
    "    )\n",
    "else:\n",
    "    print(\"Train cache loaded, skipping OCR processing\")\n",
    "\n",
    "test_df, test_ocr_cache = load_existing_cache(\n",
    "    pd.read_csv(os.path.join(DATA_ROOT, 'sample_submission.csv')), \n",
    "    os.path.join(DATA_ROOT, 'test/')\n",
    ")\n",
    "if not test_ocr_cache:\n",
    "    print(\"No test cache found, running OCR processing\")\n",
    "    test_ocr_cache = prepare_ocr_cache_parallel(\n",
    "        test_df, os.path.join(DATA_ROOT, 'test/'), num_workers=2\n",
    "    )\n",
    "else:\n",
    "    print(\"Test cache loaded, skipping OCR processing\")\n",
    "print(\"Script execution completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cacecd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Batch size: 4\n",
      "Gradient accumulation steps: 8\n",
      "Effective batch size: 32\n",
      "Max sequence length: 256\n",
      "Dataset size: 1570\n",
      "Unique labels: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]\n",
      "\n",
      "============================================================\n",
      "Fold 1/2\n",
      "============================================================\n",
      "Train samples: 785, Validation samples: 785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LayoutLMv3ForSequenceClassification were not initialized from the model checkpoint at microsoft/layoutlmv3-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to True."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>‚ñÅ‚ñÖ‚ñà</td></tr><tr><td>fold</td><td>‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>learning_rate</td><td>‚ñà‚ñÜ‚ñÅ</td></tr><tr><td>train/accuracy</td><td>‚ñÅ‚ñà‚ñÅ</td></tr><tr><td>train/f1</td><td>‚ñÇ‚ñà‚ñÅ</td></tr><tr><td>train/loss</td><td>‚ñà‚ñÉ‚ñÅ</td></tr><tr><td>val/accuracy</td><td>‚ñÅ‚ñÅ‚ñà</td></tr><tr><td>val/class_14_f1</td><td>‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>val/class_3_f1</td><td>‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>val/class_7_f1</td><td>‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>+3</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>3</td></tr><tr><td>fold</td><td>1</td></tr><tr><td>learning_rate</td><td>0.00025</td></tr><tr><td>train/accuracy</td><td>0.05711</td></tr><tr><td>train/f1</td><td>0.03199</td></tr><tr><td>train/loss</td><td>2.8499</td></tr><tr><td>val/accuracy</td><td>0.06599</td></tr><tr><td>val/class_14_f1</td><td>0</td></tr><tr><td>val/class_3_f1</td><td>0</td></tr><tr><td>val/class_7_f1</td><td>0</td></tr><tr><td>+3</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">layoutlmv3-baseline-fold-1</strong> at: <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV/runs/pa6sryof' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV/runs/pa6sryof</a><br> View project at: <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250909_041755-pa6sryof/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "creating run (0.1s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/root/computervisioncompetition-cv-1/mywork/experiments/wandb/run-20250909_042220-sjk38wnj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV/runs/sjk38wnj' target=\"_blank\">layoutlmv3-baseline-fold-1</a></strong> to <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV/runs/sjk38wnj' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV/runs/sjk38wnj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Î™®Îç∏ ÌïôÏäµ ÏãúÏûë - Fold 1\n",
      "\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 0 Train Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 197/197 [00:24<00:00,  8.19it/s, Loss=2.7988, F1=0.0000]\n",
      "Fold 0 Val Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 197/197 [00:22<00:00,  8.88it/s, Loss=2.6777, F1=0.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.8543 | Train F1: 0.0379\n",
      "Val Loss: 2.8177 | Val F1: 0.0277\n",
      "Problem Classes Avg F1: 0.0000\n",
      "New best! F1: 0.0277\n",
      "\n",
      "Epoch 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 0 Train Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 197/197 [00:24<00:00,  8.18it/s, Loss=2.7305, F1=0.0000]\n",
      "Fold 0 Val Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 197/197 [00:22<00:00,  8.69it/s, Loss=2.7246, F1=0.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.8272 | Train F1: 0.0322\n",
      "Val Loss: 2.8148 | Val F1: 0.0280\n",
      "Problem Classes Avg F1: 0.0000\n",
      "New best! F1: 0.0280\n",
      "\n",
      "Epoch 3/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 0 Train Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 197/197 [00:24<00:00,  8.19it/s, Loss=2.7656, F1=0.0000]\n",
      "Fold 0 Val Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 197/197 [00:22<00:00,  8.86it/s, Loss=2.7773, F1=0.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.8239 | Train F1: 0.0385\n",
      "Val Loss: 2.8136 | Val F1: 0.0267\n",
      "Problem Classes Avg F1: 0.3333\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>‚ñÅ‚ñÖ‚ñà</td></tr><tr><td>fold</td><td>‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>learning_rate</td><td>‚ñà‚ñÜ‚ñÅ</td></tr><tr><td>train/accuracy</td><td>‚ñà‚ñÅ‚ñá</td></tr><tr><td>train/f1</td><td>‚ñá‚ñÅ‚ñà</td></tr><tr><td>train/loss</td><td>‚ñà‚ñÇ‚ñÅ</td></tr><tr><td>val/accuracy</td><td>‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>val/class_14_f1</td><td>‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>val/class_3_f1</td><td>‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>val/class_7_f1</td><td>‚ñÅ‚ñÅ‚ñà</td></tr><tr><td>+3</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>3</td></tr><tr><td>fold</td><td>1</td></tr><tr><td>learning_rate</td><td>3e-05</td></tr><tr><td>train/accuracy</td><td>0.06472</td></tr><tr><td>train/f1</td><td>0.03847</td></tr><tr><td>train/loss</td><td>2.82386</td></tr><tr><td>val/accuracy</td><td>0.06345</td></tr><tr><td>val/class_14_f1</td><td>0</td></tr><tr><td>val/class_3_f1</td><td>0</td></tr><tr><td>val/class_7_f1</td><td>1</td></tr><tr><td>+3</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">layoutlmv3-baseline-fold-1</strong> at: <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV/runs/sjk38wnj' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV/runs/sjk38wnj</a><br> View project at: <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250909_042220-sjk38wnj/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 ÏôÑÎ£å!\n",
      "\n",
      "============================================================\n",
      "Fold 2/2\n",
      "============================================================\n",
      "Train samples: 785, Validation samples: 785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LayoutLMv3ForSequenceClassification were not initialized from the model checkpoint at microsoft/layoutlmv3-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "creating run (0.2s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/root/computervisioncompetition-cv-1/mywork/experiments/wandb/run-20250909_042445-v6ehrdcj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV/runs/v6ehrdcj' target=\"_blank\">layoutlmv3-baseline-fold-2</a></strong> to <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV/runs/v6ehrdcj' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV/runs/v6ehrdcj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Î™®Îç∏ ÌïôÏäµ ÏãúÏûë - Fold 2\n",
      "\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1 Train Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 197/197 [00:23<00:00,  8.21it/s, Loss=1.4160, F1=0.0000]\n",
      "Fold 1 Val Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 197/197 [00:22<00:00,  8.90it/s, Loss=0.7031, F1=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.4838 | Train F1: 0.1220\n",
      "Val Loss: 2.0999 | Val F1: 0.1704\n",
      "Problem Classes Avg F1: 0.1395\n",
      "New best! F1: 0.1704\n",
      "\n",
      "Epoch 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1 Train Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 197/197 [00:24<00:00,  8.12it/s, Loss=1.8320, F1=0.0000]\n",
      "Fold 1 Val Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 197/197 [00:22<00:00,  8.57it/s, Loss=0.0996, F1=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.8629 | Train F1: 0.3160\n",
      "Val Loss: 1.6000 | Val F1: 0.3760\n",
      "Problem Classes Avg F1: 0.0733\n",
      "New best! F1: 0.3760\n",
      "\n",
      "Epoch 3/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1 Train Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 197/197 [00:23<00:00,  8.22it/s, Loss=1.7852, F1=0.0000]\n",
      "Fold 1 Val Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 197/197 [00:22<00:00,  8.83it/s, Loss=0.0734, F1=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.4298 | Train F1: 0.4467\n",
      "Val Loss: 1.3589 | Val F1: 0.4462\n",
      "Problem Classes Avg F1: 0.0380\n",
      "New best! F1: 0.4462\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>‚ñÅ‚ñÖ‚ñà</td></tr><tr><td>fold</td><td>‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>learning_rate</td><td>‚ñà‚ñÜ‚ñÅ</td></tr><tr><td>train/accuracy</td><td>‚ñÅ‚ñÖ‚ñà</td></tr><tr><td>train/f1</td><td>‚ñÅ‚ñÖ‚ñà</td></tr><tr><td>train/loss</td><td>‚ñà‚ñÑ‚ñÅ</td></tr><tr><td>val/accuracy</td><td>‚ñÅ‚ñÜ‚ñà</td></tr><tr><td>val/class_14_f1</td><td>‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>val/class_3_f1</td><td>‚ñà‚ñÉ‚ñÅ</td></tr><tr><td>val/class_7_f1</td><td>‚ñÅ‚ñà‚ñà</td></tr><tr><td>+3</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>3</td></tr><tr><td>fold</td><td>2</td></tr><tr><td>learning_rate</td><td>3e-05</td></tr><tr><td>train/accuracy</td><td>0.56091</td></tr><tr><td>train/f1</td><td>0.44675</td></tr><tr><td>train/loss</td><td>1.42977</td></tr><tr><td>val/accuracy</td><td>0.5736</td></tr><tr><td>val/class_14_f1</td><td>0</td></tr><tr><td>val/class_3_f1</td><td>0.0307</td></tr><tr><td>val/class_7_f1</td><td>0.08333</td></tr><tr><td>+3</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">layoutlmv3-baseline-fold-2</strong> at: <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV/runs/v6ehrdcj' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV/runs/v6ehrdcj</a><br> View project at: <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250909_042445-v6ehrdcj/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 ÏôÑÎ£å!\n",
      "\n",
      "ÏïôÏÉÅÎ∏î Î™®Îç∏ Ï§ÄÎπÑ Ï§ë...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LayoutLMv3ForSequenceClassification were not initialized from the model checkpoint at microsoft/layoutlmv3-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Î™®Îç∏ Î°úÎìú ÏôÑÎ£å\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LayoutLMv3ForSequenceClassification were not initialized from the model checkpoint at microsoft/layoutlmv3-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 Î™®Îç∏ Î°úÎìú ÏôÑÎ£å\n",
      "Ï¥ù 2Í∞ú Î™®Îç∏Î°ú ÏïôÏÉÅÎ∏î Íµ¨ÏÑ±\n",
      "\n",
      "============================================================\n",
      " K-FOLD CROSS VALIDATION ÏµúÏ¢Ö Í≤∞Í≥º\n",
      "============================================================\n",
      "Fold 1: 0.0280 (3 epochs) Completed\n",
      "Fold 2: 0.4462 (3 epochs) Completed\n",
      "\n",
      "ÌèâÍ∑† CV F1: 0.2371 ¬± 0.2091\n",
      "ÏµúÍ≥† Fold: 0.4462\n",
      "ÏµúÏïÖ Fold: 0.0280\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import copy\n",
    "import time\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from transformers import LayoutLMv3Processor, LayoutLMv3ForSequenceClassification\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import wandb\n",
    "import torch.nn as nn\n",
    "\n",
    "# ÌôòÍ≤Ω Î≥ÄÏàò ÏÑ§Ï†ï\n",
    "os.environ[\"MKL_SERVICE_FORCE_INTEL\"] = \"1\"\n",
    "os.environ[\"MKL_THREADING_LAYER\"] = \"GNU\"\n",
    "\n",
    "# Dataset ÌÅ¥ÎûòÏä§Î•º Ï†ÑÏó≠ÏúºÎ°ú Ï†ïÏùò (multiprocessing ÏóêÎü¨ Î∞©ÏßÄ)\n",
    "class LayoutLMv3Dataset(Dataset):\n",
    "    def __init__(self, df, img_path, processor, max_length=256):\n",
    "        self.df = df\n",
    "        self.img_path = img_path\n",
    "        self.processor = processor\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        image_path = os.path.join(self.img_path, row['ID'])\n",
    "        \n",
    "        try:\n",
    "            words = json.loads(row['words']) if isinstance(row['words'], str) else row['words']\n",
    "            boxes = json.loads(row['boxes']) if isinstance(row['boxes'], str) else row['boxes']  # Ïò§ÌÉÄ ÏàòÏ†ï: boxe√•s -> boxes\n",
    "        except:\n",
    "            words, boxes = [], []\n",
    "        \n",
    "        # Îπà Î¶¨Ïä§Ìä∏ Ï≤òÎ¶¨\n",
    "        if not words or not boxes:\n",
    "            words = [\"\"]\n",
    "            boxes = [[0, 0, 1, 1]]\n",
    "        \n",
    "        # Í∏∏Ïù¥ ÎßûÏ∂îÍ∏∞\n",
    "        if len(words) != len(boxes):\n",
    "            min_len = min(len(words), len(boxes))\n",
    "            words = words[:min_len]\n",
    "            boxes = boxes[:min_len]\n",
    "        \n",
    "        label = int(row['target'])\n",
    "        \n",
    "        # Ïù¥ÎØ∏ÏßÄ ÌÅ¨Í∏∞ Ï∂ïÏÜå (Î©îÎ™®Î¶¨ Ï†àÏïΩ)\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        image = image.resize((224, 224))\n",
    "        \n",
    "        # ProcessorÏóêÏÑú paddingÍ≥º truncation Î™ÖÏãúÏ†Å ÏÑ§Ï†ï\n",
    "        encoding = self.processor(\n",
    "            image, \n",
    "            text=words, \n",
    "            boxes=boxes, \n",
    "            return_tensors=\"pt\",\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=self.max_length\n",
    "        )\n",
    "        \n",
    "        # Î™®Îì† tensorÎ•º squeezeÌïòÏó¨ Î∞∞Ïπò Ï∞®Ïõê Ï†úÍ±∞\n",
    "        result = {}\n",
    "        for key, value in encoding.items():\n",
    "            if isinstance(value, torch.Tensor):\n",
    "                result[key] = value.squeeze(0)\n",
    "            else:\n",
    "                result[key] = value\n",
    "        \n",
    "        return result, label\n",
    "\n",
    "# Collate functionÏùÑ Ï†ÑÏó≠ÏúºÎ°ú Ï†ïÏùò\n",
    "def collate_fn(batch):\n",
    "    \"\"\"Custom collate function for LayoutLMv3\"\"\"\n",
    "    inputs = {}\n",
    "    labels = []\n",
    "    \n",
    "    # Ï≤´ Î≤àÏß∏ ÏÉòÌîåÏóêÏÑú ÌÇ§ ÌôïÏù∏\n",
    "    sample_keys = batch[0][0].keys()\n",
    "    \n",
    "    for key in sample_keys:\n",
    "        inputs[key] = torch.stack([item[0][key] for item in batch])\n",
    "    \n",
    "    labels = torch.tensor([item[1] for item in batch], dtype=torch.long)\n",
    "    \n",
    "    return inputs, labels\n",
    "\n",
    "# Î©îÎ™®Î¶¨ Ï†ïÎ¶¨ Ìï®Ïàò\n",
    "def clear_memory():\n",
    "    torch.cuda.empty_cache()\n",
    "    import gc\n",
    "    gc.collect()\n",
    "\n",
    "def train_one_epoch_with_grad_accumulation(train_loader, model, optimizer, loss_fn, device, scaler, epoch, fold, gradient_accumulation_steps=1):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_acc = 0\n",
    "    total_f1 = 0\n",
    "    num_batches = len(train_loader)\n",
    "    \n",
    "    optimizer.zero_grad()  # ÏãúÏûë Ïãú gradient Ï¥àÍ∏∞Ìôî\n",
    "    \n",
    "    pbar = tqdm(train_loader, desc=f\"Fold {fold} Train Epoch {epoch+1}\")\n",
    "    for batch_idx, (inputs, targets) in enumerate(pbar):\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        with autocast():\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs.logits\n",
    "            loss = loss_fn(logits, targets)\n",
    "            # Gradient accumulationÏùÑ ÏúÑÌï¥ lossÎ•º ÎÇòÎàî\n",
    "            loss = loss / gradient_accumulation_steps\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "        \n",
    "        # Gradient accumulation\n",
    "        if (batch_idx + 1) % gradient_accumulation_steps == 0 or (batch_idx + 1) == len(train_loader):\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = accuracy_score(targets.cpu(), preds.cpu())\n",
    "        f1 = f1_score(targets.cpu(), preds.cpu(), average='macro')\n",
    "        \n",
    "        total_loss += loss.item() * gradient_accumulation_steps  # ÏõêÎûò lossÎ°ú Î≥µÏõê\n",
    "        total_acc += acc\n",
    "        total_f1 += f1\n",
    "        \n",
    "        pbar.set_postfix({'Loss': f\"{loss.item() * gradient_accumulation_steps:.4f}\", 'F1': f\"{f1:.4f}\"})\n",
    "        \n",
    "        # Î©îÎ™®Î¶¨ Ï†ïÎ¶¨\n",
    "        del inputs, targets, outputs, logits, loss\n",
    "        if batch_idx % 10 == 0:\n",
    "            clear_memory()\n",
    "    \n",
    "    return {\n",
    "        'train_loss': total_loss / num_batches,\n",
    "        'train_acc': total_acc / num_batches,\n",
    "        'train_f1': total_f1 / num_batches\n",
    "    }\n",
    "\n",
    "def validate_one_epoch(val_loader, model, loss_fn, device, epoch, fold, log_confusion=False):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_acc = 0\n",
    "    total_f1 = 0\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    num_batches = len(val_loader)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(val_loader, desc=f\"Fold {fold} Val Epoch {epoch+1}\")\n",
    "        for batch_idx, (inputs, targets) in enumerate(pbar):\n",
    "            inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            with autocast():\n",
    "                outputs = model(**inputs)\n",
    "                logits = outputs.logits\n",
    "                loss = loss_fn(logits, targets)\n",
    "            \n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            acc = accuracy_score(targets.cpu(), preds.cpu())\n",
    "            f1 = f1_score(targets.cpu(), preds.cpu(), average='macro')\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            total_acc += acc\n",
    "            total_f1 += f1\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_targets.extend(targets.cpu().numpy())\n",
    "            \n",
    "            pbar.set_postfix({'Loss': f\"{loss.item():.4f}\", 'F1': f\"{f1:.4f}\"})\n",
    "            \n",
    "            # Î©îÎ™®Î¶¨ Ï†ïÎ¶¨\n",
    "            del inputs, targets, outputs, logits, loss\n",
    "            if batch_idx % 5 == 0:\n",
    "                clear_memory()\n",
    "    \n",
    "    # Problem classes (3,7,14) F1 Í≥ÑÏÇ∞\n",
    "    problem_f1 = {}\n",
    "    for cls in [3,7,14]:\n",
    "        cls_mask = np.array(all_targets) == cls\n",
    "        if np.sum(cls_mask) > 0:\n",
    "            cls_preds = np.array(all_preds)[cls_mask]\n",
    "            cls_targets = np.array(all_targets)[cls_mask]\n",
    "            problem_f1[f'class_{cls}_f1'] = f1_score(cls_targets, cls_preds, average='macro')\n",
    "    \n",
    "    avg_problem_f1 = np.mean(list(problem_f1.values())) if problem_f1 else 0\n",
    "    \n",
    "    return {\n",
    "        'val_loss': total_loss / num_batches,\n",
    "        'val_acc': total_acc / num_batches,\n",
    "        'val_f1': total_f1 / num_batches,\n",
    "        'problem_class_f1': problem_f1,\n",
    "        'avg_problem_f1': avg_problem_f1\n",
    "    }\n",
    "\n",
    "def main():\n",
    "    # ÏÑ§Ï†ïÍ∞íÎì§\n",
    "    DATA_ROOT = \"/root/computervisioncompetition-cv-1/mywork/data\"\n",
    "    model_name = \"microsoft/layoutlmv3-base\"\n",
    "    num_classes = 17\n",
    "    EPOCHS = 3\n",
    "    BATCH_SIZE = 4  # Î©îÎ™®Î¶¨ Í≥†Î†§\n",
    "    GRADIENT_ACCUMULATION_STEPS = 8  # Ïã§ÏßàÏ†Å Î∞∞Ïπò ÌÅ¨Í∏∞ = 2 * 16 = 32\n",
    "    N_FOLDS = 2\n",
    "    LR = 0.0001\n",
    "    MAX_PATIENCE = 5\n",
    "    NUM_WORKERS = 0\n",
    "    SEED = 42\n",
    "    max_length = 256  # Î©îÎ™®Î¶¨ Ï†àÏïΩÏùÑ ÏúÑÌï¥ Ï§ÑÏûÑ\n",
    "    \n",
    "    # WandB ÏÑ§Ï†ï\n",
    "    PROJECT_NAME = \"document-classification-team-CV\"\n",
    "    EXPERIMENT_NAME = \"layoutlmv3-baseline\"\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    print(f\"Batch size: {BATCH_SIZE}\")\n",
    "    print(f\"Gradient accumulation steps: {GRADIENT_ACCUMULATION_STEPS}\")\n",
    "    print(f\"Effective batch size: {BATCH_SIZE * GRADIENT_ACCUMULATION_STEPS}\")\n",
    "    print(f\"Max sequence length: {max_length}\")\n",
    "    \n",
    "    # ÌîÑÎ°úÏÑ∏ÏÑú Î°úÎìú\n",
    "    processor = LayoutLMv3Processor.from_pretrained(model_name, apply_ocr=False)\n",
    "    \n",
    "    # Îç∞Ïù¥ÌÑ∞ Î°úÎìú\n",
    "    train_df = pd.read_csv(os.path.join(DATA_ROOT, 'train/with_ocr.csv'))\n",
    "    print(f\"Dataset size: {len(train_df)}\")\n",
    "    print(f\"Unique labels: {sorted(train_df['target'].unique())}\")\n",
    "    \n",
    "    # ÏûëÏùÄ ÏÉòÌîåÎ°ú ÌÖåÏä§Ìä∏\n",
    "    #train_df = train_df.head(200).copy()  \n",
    "    #print(f\"Using {len(train_df)} samples for testing\")\n",
    "    \n",
    "    fold_results = []\n",
    "    fold_models = []\n",
    "    \n",
    "    # K-Fold ÍµêÏ∞® Í≤ÄÏ¶ù\n",
    "    skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)\n",
    "    \n",
    "    for fold, (trn_idx, val_idx) in enumerate(skf.split(train_df['ID'], train_df['target'])):\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Fold {fold+1}/{N_FOLDS}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        # ÏãúÏûë Ï†Ñ Î©îÎ™®Î¶¨ Ï†ïÎ¶¨\n",
    "        clear_memory()\n",
    "        \n",
    "        # Îç∞Ïù¥ÌÑ∞ Î∂ÑÌï†\n",
    "        trn_df = train_df.iloc[trn_idx].reset_index(drop=True)\n",
    "        val_df = train_df.iloc[val_idx].reset_index(drop=True)\n",
    "        \n",
    "        print(f\"Train samples: {len(trn_df)}, Validation samples: {len(val_df)}\")\n",
    "        \n",
    "        # Îç∞Ïù¥ÌÑ∞ÏÖã ÏÉùÏÑ±\n",
    "        trn_dataset = LayoutLMv3Dataset(trn_df, os.path.join(DATA_ROOT, 'train/'), processor, max_length=max_length)\n",
    "        val_dataset = LayoutLMv3Dataset(val_df, os.path.join(DATA_ROOT, 'train/'), processor, max_length=max_length)\n",
    "        \n",
    "        # DataLoader ÏÉùÏÑ±\n",
    "        trn_loader = DataLoader(\n",
    "            trn_dataset, \n",
    "            batch_size=BATCH_SIZE, \n",
    "            shuffle=True, \n",
    "            collate_fn=collate_fn, \n",
    "            num_workers=NUM_WORKERS,\n",
    "            pin_memory=False\n",
    "        )\n",
    "        val_loader = DataLoader(\n",
    "            val_dataset, \n",
    "            batch_size=BATCH_SIZE, \n",
    "            shuffle=False, \n",
    "            collate_fn=collate_fn, \n",
    "            num_workers=NUM_WORKERS,\n",
    "            pin_memory=False\n",
    "        )\n",
    "        \n",
    "        # Î™®Îç∏ ÏÉùÏÑ±\n",
    "        model = LayoutLMv3ForSequenceClassification.from_pretrained(\n",
    "            model_name, num_labels=num_classes, ignore_mismatched_sizes=True\n",
    "        ).to(device)\n",
    "        \n",
    "        optimizer = Adam(model.parameters(), lr=LR)\n",
    "        scheduler = CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "        loss_fn = nn.CrossEntropyLoss()\n",
    "        scaler = GradScaler()\n",
    "        \n",
    "        best_val_f1 = 0\n",
    "        patience = 0\n",
    "        best_model = None\n",
    "        \n",
    "        # WandB Ï¥àÍ∏∞Ìôî\n",
    "        wandb.init(\n",
    "            project=PROJECT_NAME, \n",
    "            name=f\"{EXPERIMENT_NAME}-fold-{fold+1}\", \n",
    "            config={\n",
    "                'fold': fold+1,\n",
    "                'model_name': model_name,\n",
    "                'batch_size': BATCH_SIZE,\n",
    "                'gradient_accumulation_steps': GRADIENT_ACCUMULATION_STEPS,\n",
    "                'effective_batch_size': BATCH_SIZE * GRADIENT_ACCUMULATION_STEPS,\n",
    "                'learning_rate': LR,\n",
    "                'epochs': EPOCHS,\n",
    "                'max_length': max_length\n",
    "            },\n",
    "            reinit=True\n",
    "        )\n",
    "        \n",
    "        print(f\"Î™®Îç∏ ÌïôÏäµ ÏãúÏûë - Fold {fold+1}\")\n",
    "        \n",
    "        for epoch in range(EPOCHS):\n",
    "            print(f\"\\nEpoch {epoch+1}/{EPOCHS}\")\n",
    "            \n",
    "            # ÌõàÎ†® (gradient accumulation Ìè¨Ìï®)\n",
    "            train_ret = train_one_epoch_with_grad_accumulation(\n",
    "                trn_loader, model, optimizer, loss_fn, device, scaler, \n",
    "                epoch, fold, GRADIENT_ACCUMULATION_STEPS\n",
    "            )\n",
    "            \n",
    "            # Í≤ÄÏ¶ù\n",
    "            val_ret = validate_one_epoch(val_loader, model, loss_fn, device, epoch, fold)\n",
    "            \n",
    "            current_lr = optimizer.param_groups[0]['lr']\n",
    "            \n",
    "            # WandB Î°úÍπÖ\n",
    "            log_data = {\n",
    "                \"epoch\": epoch + 1,\n",
    "                \"fold\": fold + 1,\n",
    "                \"train/loss\": train_ret['train_loss'],\n",
    "                \"train/accuracy\": train_ret['train_acc'], \n",
    "                \"train/f1\": train_ret['train_f1'],\n",
    "                \"val/loss\": val_ret['val_loss'],\n",
    "                \"val/accuracy\": val_ret['val_acc'],\n",
    "                \"val/f1\": val_ret['val_f1'],\n",
    "                \"learning_rate\": current_lr,\n",
    "            }\n",
    "            \n",
    "            if 'avg_problem_f1' in val_ret:\n",
    "                log_data[\"val/problem_classes_avg_f1\"] = val_ret['avg_problem_f1']\n",
    "            \n",
    "            for cls in [3, 7, 14]:\n",
    "                if f\"class_{cls}_f1\" in val_ret['problem_class_f1']:\n",
    "                    log_data[f\"val/class_{cls}_f1\"] = val_ret['problem_class_f1'][f\"class_{cls}_f1\"]\n",
    "            \n",
    "            wandb.log(log_data)\n",
    "            \n",
    "            scheduler.step()\n",
    "            \n",
    "            # Ï∂úÎ†•\n",
    "            print(f\"Train Loss: {train_ret['train_loss']:.4f} | Train F1: {train_ret['train_f1']:.4f}\")\n",
    "            print(f\"Val Loss: {val_ret['val_loss']:.4f} | Val F1: {val_ret['val_f1']:.4f}\")\n",
    "            if 'avg_problem_f1' in val_ret:\n",
    "                print(f\"Problem Classes Avg F1: {val_ret['avg_problem_f1']:.4f}\")\n",
    "            \n",
    "            # ÏµúÍ≥† Î™®Îç∏ Ï†ÄÏû•\n",
    "            if val_ret['val_f1'] > best_val_f1:\n",
    "                best_val_f1 = val_ret['val_f1']\n",
    "                best_model = copy.deepcopy(model.state_dict())\n",
    "                patience = 0\n",
    "                model_path = f'best_model_fold_{fold+1}.pth'\n",
    "                torch.save(best_model, model_path)\n",
    "                print(f\"New best! F1: {best_val_f1:.4f}\")\n",
    "            else:\n",
    "                patience += 1\n",
    "            \n",
    "            if patience >= MAX_PATIENCE and epoch > EPOCHS // 2:\n",
    "                print(f\"Early stopping at epoch {epoch+1}\")\n",
    "                break\n",
    "            \n",
    "            # ÏóêÌè¨ÌÅ¨ ÎÅùÎÇ† ÎïåÎßàÎã§ Î©îÎ™®Î¶¨ Ï†ïÎ¶¨\n",
    "            clear_memory()\n",
    "        \n",
    "        fold_results.append({\n",
    "            'fold': fold+1, \n",
    "            'best_val_f1': best_val_f1, \n",
    "            'epochs_trained': epoch+1,\n",
    "            'early_stopped': patience >= MAX_PATIENCE,\n",
    "            'final_train_f1': train_ret['train_f1'],\n",
    "            'train_samples': len(trn_df),\n",
    "            'val_samples': len(val_df)\n",
    "        })\n",
    "        fold_models.append(best_model)\n",
    "        \n",
    "        wandb.finish()\n",
    "        \n",
    "        # Î©îÎ™®Î¶¨ Ï†ïÎ¶¨\n",
    "        del model, optimizer, scheduler, trn_loader, val_loader\n",
    "        clear_memory()\n",
    "        \n",
    "        print(f\"Fold {fold+1} ÏôÑÎ£å!\")\n",
    "    \n",
    "    # ÏïôÏÉÅÎ∏î Î™®Îç∏ Ï§ÄÎπÑ (Î™®Îì† foldÍ∞Ä ÎÅùÎÇú ÌõÑ)\n",
    "    print(f\"\\nÏïôÏÉÅÎ∏î Î™®Îç∏ Ï§ÄÎπÑ Ï§ë...\")\n",
    "    ensemble_models = []\n",
    "    \n",
    "    for i, state_dict in enumerate(fold_models):\n",
    "        fold_model = LayoutLMv3ForSequenceClassification.from_pretrained(\n",
    "            model_name, num_labels=num_classes, ignore_mismatched_sizes=True\n",
    "        ).to(device)\n",
    "        fold_model.load_state_dict(state_dict)\n",
    "        fold_model.eval()\n",
    "        ensemble_models.append(fold_model)\n",
    "        print(f\"Fold {i+1} Î™®Îç∏ Î°úÎìú ÏôÑÎ£å\")\n",
    "    \n",
    "    print(f\"Ï¥ù {len(ensemble_models)}Í∞ú Î™®Îç∏Î°ú ÏïôÏÉÅÎ∏î Íµ¨ÏÑ±\")\n",
    "    \n",
    "    # Í≤∞Í≥º ÏöîÏïΩ\n",
    "    val_f1_scores = [result['best_val_f1'] for result in fold_results]\n",
    "    mean_f1 = np.mean(val_f1_scores)\n",
    "    std_f1 = np.std(val_f1_scores)\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\" K-FOLD CROSS VALIDATION ÏµúÏ¢Ö Í≤∞Í≥º\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    for result in fold_results:\n",
    "        status = \" Early Stopped\" if result['early_stopped'] else \" Completed\"\n",
    "        print(f\"Fold {result['fold']}: {result['best_val_f1']:.4f} \"\n",
    "              f\"({result['epochs_trained']} epochs){status}\")\n",
    "    \n",
    "    print(f\"\\nÌèâÍ∑† CV F1: {mean_f1:.4f} ¬± {std_f1:.4f}\")\n",
    "    print(f\"ÏµúÍ≥† Fold: {max(val_f1_scores):.4f}\")\n",
    "    print(f\"ÏµúÏïÖ Fold: {min(val_f1_scores):.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f941711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Î©îÎ™®Î¶¨ Ï†ïÎ¶¨ ÏôÑÎ£å\n"
     ]
    }
   ],
   "source": [
    "# ÌòÑÏû¨ ÎÖ∏Ìä∏Î∂ÅÏóêÏÑú Î∞îÎ°ú Ïã§ÌñâÌïòÏÑ∏Ïöî\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "def quick_cleanup():\n",
    "    \"\"\"Ï¶âÏãú ÏÇ¨Ïö© Í∞ÄÎä•Ìïú Îπ†Î•∏ Î©îÎ™®Î¶¨ Ï†ïÎ¶¨\"\"\"\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.synchronize()\n",
    "    print(\"Î©îÎ™®Î¶¨ Ï†ïÎ¶¨ ÏôÑÎ£å\")\n",
    "\n",
    "# Î∞îÎ°ú Ïã§Ìñâ\n",
    "quick_cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f420558",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m `start_method` is deprecated and will be removed in a future version of wandb. This setting is currently non-functional and safely ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß WandB Ïó∞Í≤∞ Î¨∏Ï†ú Ìï¥Í≤∞ Ï§ë...\n",
      "WandB Ï¥àÍ∏∞Ìôî ÏãúÎèÑ 1/3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkimsunmin0227\u001b[0m (\u001b[33mkimsunmin0227-hufs\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "creating run (0.2s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/root/computervisioncompetition-cv-1/mywork/experiments/wandb/run-20250909_021839-g7stly7w</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV/runs/g7stly7w' target=\"_blank\">efficientnet-b3-baseline-0909-0218</a></strong> to <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV/runs/g7stly7w' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV/runs/g7stly7w</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ WandB Ï¥àÍ∏∞Ìôî ÏÑ±Í≥µ!\n",
      "\n",
      "üöÄ WandB Ïã§Ìóò ÏãúÏûë!\n",
      "üìä ÎåÄÏãúÎ≥¥Îìú: https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV/runs/g7stly7w\n",
      "üìã Ïã§ÌóòÎ™Ö: efficientnet-b3-baseline-0909-0218\n"
     ]
    }
   ],
   "source": [
    "# Essential TTA transforms (Ïù¥ÎØ∏ÏßÄ Î≥ÄÌòïÎßå)\n",
    "essential_tta_transforms = [\n",
    "    A.Compose([  # ÏõêÎ≥∏\n",
    "        A.LongestMaxSize(max_size=img_size),\n",
    "        A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "     \n",
    "    # 90ÎèÑ ÌöåÏ†ÑÎì§\n",
    "    A.Compose([\n",
    "        A.LongestMaxSize(max_size=img_size),\n",
    "        A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "        A.Rotate(limit=[90, 90], p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "    A.Compose([\n",
    "        A.LongestMaxSize(max_size=img_size),\n",
    "        A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "        A.Rotate(limit=[180, 180], p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "    A.Compose([\n",
    "        A.LongestMaxSize(max_size=img_size),\n",
    "        A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "        A.Rotate(limit=[-90, -90], p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "    # Î∞ùÍ∏∞ Í∞úÏÑ†\n",
    "    A.Compose([\n",
    "        A.LongestMaxSize(max_size=img_size),\n",
    "        A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "        A.RandomBrightnessContrast(brightness_limit=[0.3, 0.3], contrast_limit=[0.3, 0.3], p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "]\n",
    "\n",
    "print(f\"TTA Î≥ÄÌôò {len(essential_tta_transforms)}Í∞ú Ï§ÄÎπÑ ÏôÑÎ£å\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6514acaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÌïôÏäµ Îç∞Ïù¥ÌÑ∞: 1570Í∞ú ÏÉòÌîå\n",
      " ÌÅ¥ÎûòÏä§ Î∂ÑÌè¨: {0: 100, 1: 46, 2: 100, 3: 100, 4: 100, 5: 100, 6: 100, 7: 100, 8: 100, 9: 100, 10: 100, 11: 100, 12: 100, 13: 74, 14: 50, 15: 100, 16: 100}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to True."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">efficientnet-b3-baseline-0909-0218</strong> at: <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV/runs/g7stly7w' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV/runs/g7stly7w</a><br> View project at: <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250909_021839-g7stly7w/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "creating run (0.2s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/root/computervisioncompetition-cv-1/mywork/experiments/wandb/run-20250909_021840-qaeb6wly</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV/runs/qaeb6wly' target=\"_blank\">efficientnet-b3-baseline-0909-0218</a></strong> to <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV/runs/qaeb6wly' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV/runs/qaeb6wly</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ WandB Ïã§Ìóò ÏãúÏûë!\n",
      "üìä ÎåÄÏãúÎ≥¥Îìú: https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV/runs/qaeb6wly\n",
      "üìã Ïã§ÌóòÎ™Ö: efficientnet-b3-baseline-0909-0218\n"
     ]
    }
   ],
   "source": [
    "class TTALayoutLMv3Dataset(Dataset):\n",
    "    def __init__(self, df, img_path, ocr_cache, transforms):\n",
    "        super().__init__(df, img_path, ocr_cache, transform=None)  # Í∏∞Î≥∏ transform None\n",
    "        self.transforms = transforms  # TTAÏö©\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        image_id = row['ID']\n",
    "        target = row['target']\n",
    "        img_full_path = os.path.join(self.img_path, image_id)\n",
    "        \n",
    "        image = Image.open(img_full_path).convert(\"RGB\")\n",
    "        words, boxes = self.ocr_cache[image_id] if self.ocr_cache else ([], [])\n",
    "        \n",
    "        # TTA: Ïó¨Îü¨ Î≥ÄÌòïÎêú Ïù¥ÎØ∏ÏßÄ Î¶¨Ïä§Ìä∏ ÏÉùÏÑ± (OCR Í≥†Ï†ï)\n",
    "        augmented_images = []\n",
    "        for transform in self.transforms:\n",
    "            if transform is not None:  # ÏõêÎ≥∏ÏùÄ None ÏïÑÎãò\n",
    "                image_np = np.array(image)\n",
    "                aug_img_np = transform(image=image_np)['image']\n",
    "                aug_img = Image.fromarray(aug_img_np).convert(\"RGB\")\n",
    "            else:\n",
    "                aug_img = image\n",
    "            # Í∞Å aug_imgÏóê ÎèôÏùº OCR Ï†ÅÏö©Ìï¥ encoding ÏÉùÏÑ±\n",
    "            encoding = processor(images=aug_img, words=words, boxes=boxes, return_tensors=\"pt\", truncation=True, padding=\"max_length\")\n",
    "            inputs = {\n",
    "                'input_ids': encoding['input_ids'].squeeze(),\n",
    "                'attention_mask': encoding['attention_mask'].squeeze(),\n",
    "                'bbox': encoding['bbox'].squeeze() if 'bbox' in encoding else None,\n",
    "                'pixel_values': encoding['pixel_values'].squeeze(),\n",
    "            }\n",
    "            augmented_images.append(inputs)\n",
    "        \n",
    "        return augmented_images, target  # Î¶¨Ïä§Ìä∏ Î∞òÌôò\n",
    "\n",
    "# TTA Dataset\n",
    "tta_dataset = TTALayoutLMv3Dataset(test_df, '../data/test/', test_ocr_cache, essential_tta_transforms)\n",
    "tta_loader = DataLoader(tta_dataset, batch_size=4, shuffle=False, collate_fn=lambda b: collate_tta(b), num_workers=NUM_WORKERS)  # Î∞∞Ïπò ÌÅ¨Í∏∞ Ï§ÑÏûÑ\n",
    "\n",
    "def collate_tta(batch):\n",
    "    # TTA Î∞∞Ïπò Ï≤òÎ¶¨ (Í∞Å ÏÉòÌîåÏùò augmented_images Î¶¨Ïä§Ìä∏ Ïä§ÌÉù)\n",
    "    all_inputs = []\n",
    "    for sample in batch:\n",
    "        all_inputs.extend(sample[0])  # Flatten list of dicts\n",
    "    # Stack as usual\n",
    "    inputs = {}\n",
    "    for key in all_inputs[0].keys():\n",
    "        inputs[key] = torch.stack([inp[key] for inp in all_inputs])\n",
    "    targets = torch.tensor([s[1] for s in batch])\n",
    "    return inputs, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c320bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      " FOLD 1/5\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to True."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">efficientnet-b3-baseline-0909-0218</strong> at: <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV/runs/qaeb6wly' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV/runs/qaeb6wly</a><br> View project at: <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250909_021840-qaeb6wly/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "creating run (0.2s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/root/computervisioncompetition-cv-1/mywork/experiments/wandb/run-20250909_021842-kyfo47f4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV/runs/kyfo47f4' target=\"_blank\">fold-1-efficientnet_b3-0218</a></strong> to <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV/runs/kyfo47f4' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV/runs/kyfo47f4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Fold 1 Dashboard: https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV/runs/kyfo47f4\n",
      "Train samples: 1256, Validation samples: 314\n",
      " Î™®Îç∏ ÌïôÏäµ ÏãúÏûë - Fold 1\n",
      "\n",
      "üìà Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.9053, Mixup: True, Cutout: False, RandomCrop: False: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:35<00:00,  1.80s/it]\n",
      "Val Loss: 2.3544: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:02<00:00,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Class 3 F1: 0.1980\n",
      "  Class 7 F1: 0.2588\n",
      "  Class 14 F1: 0.2000\n",
      "  Problem Classes Avg F1: 0.2189\n",
      " Epoch  1 | Train Loss: 3.1569 | Train F1: 0.0707 | Val Loss: 2.2478 | Val F1: 0.2575 | LR: 2.00e-04\n",
      "         Problem Classes (3,7,14) Avg F1: 0.2189 | ‚úÖ Problem classes performing well\n",
      "üéâ ÏÉàÎ°úÏö¥ ÏµúÍ≥† ÏÑ±Îä•! F1: 0.2575 (Problem Classes: 0.2189)\n",
      "\n",
      "üìà Epoch 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.6389, Mixup: False, Cutout: False, RandomCrop: True: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:16<00:00,  1.22it/s]\n",
      "Val Loss: 2.0480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:02<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Class 3 F1: 0.2336\n",
      "  Class 7 F1: 0.3103\n",
      "  Class 14 F1: 0.1111\n",
      "  Problem Classes Avg F1: 0.2183\n",
      " Epoch  2 | Train Loss: 2.5265 | Train F1: 0.1662 | Val Loss: 1.9551 | Val F1: 0.4072 | LR: 1.81e-04\n",
      "         Problem Classes (3,7,14) Avg F1: 0.2183 | ‚ö†Ô∏è Problem classes need attention\n",
      "üéâ ÏÉàÎ°úÏö¥ ÏµúÍ≥† ÏÑ±Îä•! F1: 0.4072 (Problem Classes: 0.2183)\n",
      "\n",
      "üìà Epoch 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.3842, Mixup: False, Cutout: True, RandomCrop: False: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:16<00:00,  1.20it/s]\n",
      "Val Loss: 1.9502: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:01<00:00,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Class 3 F1: 0.2368\n",
      "  Class 7 F1: 0.0625\n",
      "  Class 14 F1: 0.0000\n",
      "  Problem Classes Avg F1: 0.0998\n",
      " Epoch  3 | Train Loss: 2.3387 | Train F1: 0.2710 | Val Loss: 1.8810 | Val F1: 0.4629 | LR: 1.31e-04\n",
      "         Problem Classes (3,7,14) Avg F1: 0.0998 | ‚ö†Ô∏è Problem classes need attention\n",
      "üéâ ÏÉàÎ°úÏö¥ ÏµúÍ≥† ÏÑ±Îä•! F1: 0.4629 (Problem Classes: 0.0998)\n",
      "\n",
      "üìà Epoch 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.3648, Mixup: False, Cutout: False, RandomCrop: True: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:17<00:00,  1.16it/s]\n",
      "Val Loss: 1.7044: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:01<00:00,  2.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Class 3 F1: 0.2727\n",
      "  Class 7 F1: 0.2500\n",
      "  Class 14 F1: 0.1176\n",
      "  Problem Classes Avg F1: 0.2135\n",
      " Epoch  4 | Train Loss: 2.2945 | Train F1: 0.2921 | Val Loss: 1.7210 | Val F1: 0.5273 | LR: 6.91e-05\n",
      "         Problem Classes (3,7,14) Avg F1: 0.2135 | ‚ö†Ô∏è Problem classes need attention\n",
      "üéâ ÏÉàÎ°úÏö¥ ÏµúÍ≥† ÏÑ±Îä•! F1: 0.5273 (Problem Classes: 0.2135)\n",
      "\n",
      "üìà Epoch 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "def ensemble_tta_inference_with_logging(models, loader, confidence_threshold=0.9):\n",
    "    all_predictions = []\n",
    "    all_confidences = []\n",
    "    \n",
    "    print(f\"ÏïôÏÉÅÎ∏î TTA Ï∂îÎ°† ÏãúÏûë...\")\n",
    "    print(f\"{len(models)}Í∞ú Î™®Îç∏ √ó {len(essential_tta_transforms)}Í∞ú TTA = {len(models)*len(essential_tta_transforms)} ÏòàÏ∏° ÌèâÍ∑†\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    for batch_idx, (aug_inputs_list, targets) in enumerate(tqdm(loader, desc=\"Ensemble TTA\")):\n",
    "        batch_size = len(targets)\n",
    "        ensemble_probs = torch.zeros(batch_size * len(aug_inputs_list[0]), num_classes).to(device)  # TTA ÌôïÏû•\n",
    "        \n",
    "        for model in models:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                for aug_idx, inputs in enumerate(aug_inputs_list):  # TTA Î£®ÌîÑ\n",
    "                    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "                    outputs = model(**inputs)\n",
    "                    probs = torch.softmax(outputs.logits, dim=1)\n",
    "                    ensemble_probs[aug_idx::len(aug_inputs_list)] += probs / len(models)\n",
    "        \n",
    "        # ÌèâÍ∑† ÌõÑ ÏõêÎ≥∏ Î∞∞Ïπò ÌÅ¨Í∏∞Î°ú reshape\n",
    "        ensemble_probs = ensemble_probs.view(batch_size, -1, num_classes).mean(dim=1)\n",
    "        \n",
    "        max_probs = torch.max(ensemble_probs, dim=1)[0]\n",
    "        batch_confidences = max_probs.cpu().numpy()\n",
    "        all_confidences.extend(batch_confidences)\n",
    "        \n",
    "        final_preds = torch.argmax(ensemble_probs, dim=1)\n",
    "        all_predictions.extend(final_preds.cpu().numpy())\n",
    "        \n",
    "        # Î°úÍπÖ (Í∏∞Ï°¥Í≥º ÎèôÏùº)\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"\\n ÏïôÏÉÅÎ∏î TTA Ï∂îÎ°† ÏôÑÎ£å! Ï¥ù ÏÜåÏöîÏãúÍ∞Ñ: {total_time/60:.1f}Î∂Ñ\")\n",
    "    return all_predictions, all_confidences\n",
    "\n",
    "tta_predictions, confidences = ensemble_tta_inference_with_logging(ensemble_models, tta_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1675898e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      " K-FOLD CROSS VALIDATION ÏµúÏ¢Ö Í≤∞Í≥º\n",
      "============================================================\n",
      " Í∏∞Ï°¥ runÏùÑ ÏÇ¨Ïö©Ìï©ÎãàÎã§.\n",
      " CV Í≤∞Í≥º Î°úÍπÖ ÏôÑÎ£å!\n",
      "Fold 1: 0.9390 (70 epochs)  Completed\n",
      "Fold 2: 0.9319 (70 epochs)  Completed\n",
      "Fold 3: 0.9420 (70 epochs)  Completed\n",
      "Fold 4: 0.9376 (70 epochs)  Completed\n",
      "Fold 5: 0.9402 (70 epochs)  Completed\n",
      "\n",
      " ÌèâÍ∑† CV F1: 0.9381 ¬± 0.0035\n",
      " ÏµúÍ≥† Fold: 0.9420\n",
      " ÏµúÏïÖ Fold: 0.9319\n",
      " ÏÑ±Îä• Î≤îÏúÑ: 0.0102\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 13. K-Fold Cross Validation Results Summary\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\" K-FOLD CROSS VALIDATION ÏµúÏ¢Ö Í≤∞Í≥º\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "val_f1_scores = [result['best_val_f1'] for result in fold_results]\n",
    "mean_f1 = np.mean(val_f1_scores)\n",
    "std_f1 = np.std(val_f1_scores)\n",
    "\n",
    "try:\n",
    "    # wandb.runÏù¥ ÌòÑÏû¨ ÌôúÏÑ±ÌôîÎêú runÏùÑ Í∞ÄÎ¶¨ÌÇ¥\n",
    "    if wandb.run is None:\n",
    "        print(\" ÌôúÏÑ±ÌôîÎêú runÏù¥ ÏóÜÏñ¥ ÏÉàÎ°úÏö¥ summary runÏùÑ ÏÉùÏÑ±Ìï©ÎãàÎã§.\")\n",
    "        active_run = wandb.init(\n",
    "            project=PROJECT_NAME,\n",
    "            name=f\"SUMMARY-{EXPERIMENT_NAME}-{datetime.now().strftime('%m%d-%H%M')}\",\n",
    "            config=config,\n",
    "            tags=[\"summary\", \"cv-results\", model_name],\n",
    "            group=\"k-fold-experiment\",\n",
    "            job_type=\"summary\",\n",
    "            reinit=True\n",
    "        )\n",
    "    else:\n",
    "        print(\" Í∏∞Ï°¥ runÏùÑ ÏÇ¨Ïö©Ìï©ÎãàÎã§.\")\n",
    "        active_run = wandb.run\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\" Run ÏÉÅÌÉú ÌôïÏù∏ Ï§ë ÏóêÎü¨: {e}\")\n",
    "    # ÏÉàÎ°úÏö¥ run ÏÉùÏÑ±\n",
    "    active_run = wandb.init(\n",
    "        project=PROJECT_NAME,\n",
    "        name=f\"SUMMARY-{EXPERIMENT_NAME}-{datetime.now().strftime('%m%d-%H%M')}\",\n",
    "        config=config,\n",
    "        tags=[\"summary\", \"cv-results\", model_name],\n",
    "        group=\"k-fold-experiment\",\n",
    "        job_type=\"summary\",\n",
    "        reinit=True\n",
    "    )\n",
    "\n",
    "# CV ÏöîÏïΩ ÌÖåÏù¥Î∏î ÏÉùÏÑ±\n",
    "fold_table = wandb.Table(columns=[\n",
    "    \"Fold\", \"Best_Val_F1\", \"Final_Train_F1\", \"Train_Samples\", \n",
    "    \"Val_Samples\", \"Epochs_Trained\", \"Early_Stopped\"\n",
    "])\n",
    "\n",
    "for result in fold_results:\n",
    "    fold_table.add_data(\n",
    "        result['fold'], \n",
    "        result['best_val_f1'], \n",
    "        result['final_train_f1'],\n",
    "        result['train_samples'], \n",
    "        result['val_samples'],\n",
    "        result['epochs_trained'],\n",
    "        result['early_stopped']\n",
    "    )\n",
    "\n",
    "# ÏïàÏ†ÑÌïú Î°úÍπÖ\n",
    "try:\n",
    "    active_run.log({\n",
    "        \"cv_results/mean_f1\": mean_f1,\n",
    "        \"cv_results/std_f1\": std_f1,\n",
    "        \"cv_results/best_fold_f1\": max(val_f1_scores),\n",
    "        \"cv_results/worst_fold_f1\": min(val_f1_scores),\n",
    "        \"cv_results/f1_range\": max(val_f1_scores) - min(val_f1_scores),\n",
    "        \"cv_results/fold_results_table\": fold_table,\n",
    "        \"cv_results/n_folds\": N_FOLDS,\n",
    "        \"cv_results/total_epochs\": sum([r['epochs_trained'] for r in fold_results]),\n",
    "        \"cv_results/avg_epochs_per_fold\": np.mean([r['epochs_trained'] for r in fold_results]),\n",
    "        \"cv_results/early_stopped_folds\": sum([r['early_stopped'] for r in fold_results])\n",
    "    })\n",
    "    \n",
    "    # FoldÎ≥Ñ ÏÑ±Îä• Î∞îÏ∞®Ìä∏ ÏÉùÏÑ±\n",
    "    fold_performance_data = [[f\"Fold {i+1}\", score] for i, score in enumerate(val_f1_scores)]\n",
    "    active_run.log({\n",
    "        \"cv_results/fold_performance_chart\": wandb.plot.bar(\n",
    "            wandb.Table(data=fold_performance_data, columns=[\"Fold\", \"F1_Score\"]),\n",
    "            \"Fold\", \"F1_Score\", \n",
    "            title=\"K-Fold Cross Validation Performance\"\n",
    "        )\n",
    "    })\n",
    "    \n",
    "    print(\" CV Í≤∞Í≥º Î°úÍπÖ ÏôÑÎ£å!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\" WandB Î°úÍπÖ Ï§ë ÏóêÎü¨: {e}\")\n",
    "    print(\" Í≤∞Í≥ºÎ•º ÏΩòÏÜîÏóê Ï∂úÎ†•Ìï©ÎãàÎã§:\")\n",
    "\n",
    "# Ïñ¥Îñ§ Í≤ΩÏö∞Îì† ÏΩòÏÜîÏóêÎäî Í≤∞Í≥º Ï∂úÎ†•\n",
    "for result in fold_results:\n",
    "    status = \" Early Stopped\" if result['early_stopped'] else \" Completed\"\n",
    "    print(f\"Fold {result['fold']}: {result['best_val_f1']:.4f} \"\n",
    "          f\"({result['epochs_trained']} epochs) {status}\")\n",
    "\n",
    "print(f\"\\n ÌèâÍ∑† CV F1: {mean_f1:.4f} ¬± {std_f1:.4f}\")\n",
    "print(f\" ÏµúÍ≥† Fold: {max(val_f1_scores):.4f}\")\n",
    "print(f\" ÏµúÏïÖ Fold: {min(val_f1_scores):.4f}\")\n",
    "print(f\" ÏÑ±Îä• Î≤îÏúÑ: {max(val_f1_scores) - min(val_f1_scores):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb258fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîß ÏïôÏÉÅÎ∏î Î™®Îç∏ Ï§ÄÎπÑ Ï§ë...\n",
      "Fold 1 Î™®Îç∏ Î°úÎìú ÏôÑÎ£å\n",
      "Fold 2 Î™®Îç∏ Î°úÎìú ÏôÑÎ£å\n",
      "Fold 3 Î™®Îç∏ Î°úÎìú ÏôÑÎ£å\n",
      "Fold 4 Î™®Îç∏ Î°úÎìú ÏôÑÎ£å\n",
      "Fold 5 Î™®Îç∏ Î°úÎìú ÏôÑÎ£å\n",
      " Ï¥ù 5Í∞ú Î™®Îç∏Î°ú ÏïôÏÉÅÎ∏î Íµ¨ÏÑ±\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# 14. Ensemble Models Preparation\n",
    "# =============================================================================\n",
    "\n",
    "# 5-Fold ÏïôÏÉÅÎ∏î Î™®Îç∏ Ï§ÄÎπÑ\n",
    "ensemble_models = []\n",
    "print(f\"\\nüîß ÏïôÏÉÅÎ∏î Î™®Îç∏ Ï§ÄÎπÑ Ï§ë...\")\n",
    "\n",
    "for i, state_dict in enumerate(fold_models):\n",
    "    fold_model = timm.create_model(model_name, pretrained=True, num_classes=17).to(device)\n",
    "    fold_model.load_state_dict(state_dict)\n",
    "    fold_model.eval()\n",
    "    ensemble_models.append(fold_model)\n",
    "    print(f\"Fold {i+1} Î™®Îç∏ Î°úÎìú ÏôÑÎ£å\")\n",
    "\n",
    "print(f\" Ï¥ù {len(ensemble_models)}Í∞ú Î™®Îç∏Î°ú ÏïôÏÉÅÎ∏î Íµ¨ÏÑ±\")\n",
    "\n",
    "try:\n",
    "    if wandb.run is not None:\n",
    "        wandb.run.log({\n",
    "            \"ensemble/num_models\": len(ensemble_models),\n",
    "            \"ensemble/model_architecture\": model_name,\n",
    "            \"ensemble/ensemble_type\": \"simple_average\"\n",
    "        })\n",
    "    else:\n",
    "        print(\"üìä ÏïôÏÉÅÎ∏î Ï†ïÎ≥¥:\")\n",
    "        print(f\"  - Î™®Îç∏ Í∞úÏàò: {len(ensemble_models)}\")\n",
    "        print(f\"  - ÏïÑÌÇ§ÌÖçÏ≤ò: {model_name}\")\n",
    "        print(f\"  - ÏïôÏÉÅÎ∏î ÌÉÄÏûÖ: simple_average\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è ÏïôÏÉÅÎ∏î Ï†ïÎ≥¥ Î°úÍπÖ Ïã§Ìå®: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bb2ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " TTA (Test Time Augmentation) ÏÑ§Ï†ï...\n",
      "TTA Î≥ÄÌôò 5Í∞ú Ï§ÄÎπÑ ÏôÑÎ£å\n"
     ]
    }
   ],
   "source": [
    "tta_pred_df = pd.DataFrame(test_df, columns=['ID', 'target'])\n",
    "tta_pred_df['target'] = tta_predictions\n",
    "tta_pred_df.to_csv('../data/output/layoutlmv3_ensemble.csv', index=False)\n",
    "\n",
    "# WandB ÏïÑÌã∞Ìå©Ìä∏ Îì± (Í∏∞Ï°¥)\n",
    "print(\"ÏµúÏ¢Ö Í≤∞Í≥º Ï†ÄÏû• ÏôÑÎ£å!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
