{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1b33696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ import\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import copy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import torchvision.transforms as transforms\n",
    "import timm\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# ì‹œë“œ ê³ ì •\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c278793",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, gc\n",
    "\n",
    "def free_cuda():\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.ipc_collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33cc277f",
   "metadata": {},
   "outputs": [],
   "source": [
    "free_cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58fcc030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target vulnerable classes: [3, 4, 7, 14]\n"
     ]
    }
   ],
   "source": [
    "# í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •\n",
    "model_name = 'convnext_base_384_in22ft1k'  # ê¸°ì¡´ê³¼ ë™ì¼í•œ ëª¨ë¸\n",
    "img_size = 512\n",
    "LR = 2e-4\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 10\n",
    "num_workers = 8\n",
    "\n",
    "# ì·¨ì•½ í´ë˜ìŠ¤ ì„¤ì •\n",
    "vulnerable_classes = [3, 4, 7, 14]\n",
    "print(f\"Target vulnerable classes: {vulnerable_classes}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcf816a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë°ì´í„°ì…‹ í´ë˜ìŠ¤ ì •ì˜ (ê¸°ì¡´ê³¼ ë™ì¼, __init__ë§Œ ìˆ˜ì •)\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, data, path, epoch=0, total_epochs=10, is_train=True):\n",
    "        if isinstance(data, str):\n",
    "            df_temp = pd.read_csv(data)\n",
    "        else:\n",
    "            df_temp = data\n",
    "        \n",
    "        # ìˆ˜ì •: í•­ìƒ ['ID', 'target'] ì»¬ëŸ¼ë§Œ ì„ íƒí•˜ì—¬ self.df ì´ˆê¸°í™”\n",
    "        self.df = df_temp[['ID', 'target']].values\n",
    "        self.path = path\n",
    "        self.epoch = epoch\n",
    "        self.total_epochs = total_epochs\n",
    "        self.is_train = is_train\n",
    "        \n",
    "        # Hard augmentation í™•ë¥  ê³„ì‚°\n",
    "        self.p_hard = 0.2 + 0.3 * (epoch / total_epochs) if is_train else 0\n",
    "        \n",
    "        # Normal augmentation\n",
    "        self.normal_aug = A.Compose([\n",
    "            A.LongestMaxSize(max_size=img_size),\n",
    "            A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "            A.OneOf([\n",
    "                A.Rotate(limit=[90, 90], p=1.0),\n",
    "                A.Rotate(limit=[180, 180], p=1.0),\n",
    "                A.Rotate(limit=[270, 270], p=1.0),\n",
    "            ], p=0.6),\n",
    "            A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=0.8),\n",
    "            A.GaussNoise(var_limit=(30.0, 100.0), p=0.7),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "        \n",
    "        # Hard augmentation\n",
    "        self.hard_aug = A.Compose([\n",
    "            A.LongestMaxSize(max_size=img_size),\n",
    "            A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "            A.OneOf([\n",
    "                A.Rotate(limit=[90, 90], p=1.0),\n",
    "                A.Rotate(limit=[180, 180], p=1.0),\n",
    "                A.Rotate(limit=[270, 270], p=1.0),\n",
    "                A.Rotate(limit=[-15, 15], p=1.0),\n",
    "            ], p=0.8),\n",
    "            A.OneOf([\n",
    "                A.MotionBlur(blur_limit=15, p=1.0),\n",
    "                A.GaussianBlur(blur_limit=15, p=1.0),\n",
    "            ], p=0.95),\n",
    "            A.RandomBrightnessContrast(brightness_limit=0.5, contrast_limit=0.5, p=0.9),\n",
    "            A.GaussNoise(var_limit=(50.0, 150.0), p=0.8),\n",
    "            A.JpegCompression(quality_lower=70, quality_upper=100, p=0.5),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        name, target = self.df[idx]\n",
    "        img = np.array(Image.open(os.path.join(self.path, name)).convert('RGB'))\n",
    "        \n",
    "        # ë°°ì¹˜ë³„ ì¦ê°• ì„ íƒ\n",
    "        if self.is_train and random.random() < self.p_hard:\n",
    "            img = self.hard_aug(image=img)['image']\n",
    "        else:\n",
    "            img = self.normal_aug(image=img)['image']\n",
    "        \n",
    "        return img, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83201539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mixup í•¨ìˆ˜ ì •ì˜\n",
    "def mixup_data(x, y, alpha=1.0):\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "    batch_size = x.size()[0]\n",
    "    index = torch.randperm(batch_size).cuda()\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "# í•™ìŠµ í•¨ìˆ˜\n",
    "def train_one_epoch(loader, model, optimizer, loss_fn, device):\n",
    "    scaler = GradScaler()\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    preds_list = []\n",
    "    targets_list = []\n",
    "\n",
    "    pbar = tqdm(loader)\n",
    "    for image, targets in pbar:\n",
    "        image = image.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        # Cutmix/Mixup ì ìš© (30% í™•ë¥ )\n",
    "        if random.random() < 0.3:\n",
    "            mixed_x, y_a, y_b, lam = mixup_data(image, targets, alpha=1.0)\n",
    "            with autocast(): \n",
    "                preds = model(mixed_x)\n",
    "            loss = lam * loss_fn(preds, y_a) + (1 - lam) * loss_fn(preds, y_b)\n",
    "        else:\n",
    "            with autocast(): \n",
    "                preds = model(image)\n",
    "            loss = loss_fn(preds, targets)\n",
    "\n",
    "        model.zero_grad(set_to_none=True)\n",
    "        scaler.scale(loss).backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
    "        targets_list.extend(targets.detach().cpu().numpy())\n",
    "\n",
    "        pbar.set_description(f\"Loss: {loss.item():.4f}\")\n",
    "\n",
    "    train_loss /= len(loader)\n",
    "    train_acc = accuracy_score(targets_list, preds_list)\n",
    "    train_f1 = f1_score(targets_list, preds_list, average='macro')\n",
    "\n",
    "    return {\n",
    "        \"train_loss\": train_loss,\n",
    "        \"train_acc\": train_acc,\n",
    "        \"train_f1\": train_f1,\n",
    "    }\n",
    "\n",
    "# ê²€ì¦ í•¨ìˆ˜\n",
    "def validate_one_epoch(loader, model, loss_fn, device):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    preds_list = []\n",
    "    targets_list = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(loader, desc=\"Validating\")\n",
    "        for image, targets in pbar:\n",
    "            image = image.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            preds = model(image)\n",
    "            loss = loss_fn(preds, targets)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
    "            targets_list.extend(targets.detach().cpu().numpy())\n",
    "            \n",
    "            pbar.set_description(f\"Val Loss: {loss.item():.4f}\")\n",
    "    \n",
    "    val_loss /= len(loader)\n",
    "    val_acc = accuracy_score(targets_list, preds_list)\n",
    "    val_f1 = f1_score(targets_list, preds_list, average='macro')\n",
    "    \n",
    "    return {\n",
    "        \"val_loss\": val_loss,\n",
    "        \"val_acc\": val_acc,\n",
    "        \"val_f1\": val_f1,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57d0d490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset size: 1570\n",
      "Filtered dataset size: 350\n",
      "\n",
      "Class distribution:\n",
      "Class 3: 100 samples\n",
      "Class 4: 100 samples\n",
      "Class 7: 100 samples\n",
      "Class 14: 50 samples\n",
      "\n",
      "Label mapping:\n",
      "Original class 3 -> New class 0\n",
      "Original class 4 -> New class 1\n",
      "Original class 7 -> New class 2\n",
      "Original class 14 -> New class 3\n",
      "\n",
      "New class distribution:\n",
      "New class 0: 100 samples\n",
      "New class 1: 100 samples\n",
      "New class 2: 100 samples\n",
      "New class 3: 50 samples\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# 1. ì·¨ì•½ í´ë˜ìŠ¤ ë°ì´í„° ì¤€ë¹„\n",
    "# ========================================\n",
    "\n",
    "# ì›ë³¸ ë°ì´í„° ë¡œë“œ\n",
    "train_df = pd.read_csv(\"../data/train.csv\")\n",
    "print(f\"Original dataset size: {len(train_df)}\")\n",
    "\n",
    "# ì·¨ì•½ í´ë˜ìŠ¤ë§Œ í•„í„°ë§\n",
    "filtered_df = train_df[train_df['target'].isin(vulnerable_classes)].copy()\n",
    "print(f\"Filtered dataset size: {len(filtered_df)}\")\n",
    "\n",
    "# í´ë˜ìŠ¤ë³„ ìƒ˜í”Œ ìˆ˜ í™•ì¸\n",
    "print(\"\\nClass distribution:\")\n",
    "for cls in vulnerable_classes:\n",
    "    count = len(filtered_df[filtered_df['target'] == cls])\n",
    "    print(f\"Class {cls}: {count} samples\")\n",
    "\n",
    "# ë¼ë²¨ ì¬ë§¤í•‘ (3->0, 4->1, 7->2, 14->3)\n",
    "label_mapping = {3: 0, 4: 1, 7: 2, 14: 3}\n",
    "filtered_df['original_target'] = filtered_df['target']  # ì›ë³¸ ë¼ë²¨ ë³´ì¡´\n",
    "filtered_df['target'] = filtered_df['target'].map(label_mapping)\n",
    "\n",
    "print(\"\\nLabel mapping:\")\n",
    "for orig, new in label_mapping.items():\n",
    "    print(f\"Original class {orig} -> New class {new}\")\n",
    "\n",
    "# í´ë˜ìŠ¤ ë¶ˆê· í˜• í™•ì¸\n",
    "print(\"\\nNew class distribution:\")\n",
    "for new_cls in range(4):\n",
    "    count = len(filtered_df[filtered_df['target'] == new_cls])\n",
    "    print(f\"New class {new_cls}: {count} samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba8a120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# 2. 3-Fold Cross Validationìœ¼ë¡œ ì„œë¸Œì…‹ ëª¨ë¸ í•™ìŠµ\n",
    "# ========================================\n",
    "\n",
    "# 3-Fold ì„¤ì •\n",
    "N_FOLDS = 5\n",
    "skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=42)\n",
    "\n",
    "# ê²°ê³¼ ì €ì¥ìš© ë¦¬ìŠ¤íŠ¸\n",
    "fold_results = []\n",
    "fold_models = []\n",
    "\n",
    "print(f\"Starting {N_FOLDS}-Fold Cross Validation for Subset Model...\")\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(filtered_df, filtered_df['target'])):\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"SUBSET FOLD {fold + 1}/{N_FOLDS}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    # í˜„ì¬ foldì˜ train/validation ë°ì´í„° ë¶„í• \n",
    "    train_fold_df = filtered_df.iloc[train_idx].reset_index(drop=True)\n",
    "    val_fold_df = filtered_df.iloc[val_idx].reset_index(drop=True)\n",
    "    \n",
    "    # í˜„ì¬ foldì˜ Dataset ìƒì„±\n",
    "    trn_dataset = ImageDataset(\n",
    "        train_fold_df,\n",
    "        \"../data/train/\",\n",
    "        epoch=0,\n",
    "        total_epochs=EPOCHS,\n",
    "        is_train=True\n",
    "    )\n",
    "    \n",
    "    val_dataset = ImageDataset(\n",
    "        val_fold_df,\n",
    "        \"../data/train/\",\n",
    "        epoch=0,\n",
    "        total_epochs=EPOCHS,\n",
    "        is_train=False\n",
    "    )\n",
    "    \n",
    "    # í˜„ì¬ foldì˜ DataLoader ìƒì„±\n",
    "    trn_loader = DataLoader(\n",
    "        trn_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=False\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    print(f\"Train samples: {len(trn_dataset)}, Validation samples: {len(val_dataset)}\")\n",
    "    \n",
    "    # ëª¨ë¸ ì´ˆê¸°í™” (4ê°œ í´ë˜ìŠ¤)\n",
    "    model = timm.create_model(\n",
    "        model_name,\n",
    "        pretrained=True,\n",
    "        num_classes=4  # ì·¨ì•½ í´ë˜ìŠ¤ 4ê°œ\n",
    "    ).to(device)\n",
    "    \n",
    "    loss_fn = nn.CrossEntropyLoss(label_smoothing=0.05)\n",
    "    optimizer = Adam(model.parameters(), lr=LR)\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "    \n",
    "    # í˜„ì¬ foldì˜ ìµœê³  ì„±ëŠ¥ ì¶”ì \n",
    "    best_val_f1 = 0.0\n",
    "    best_model = None\n",
    "    \n",
    "    # í˜„ì¬ fold í•™ìŠµ\n",
    "    for epoch in range(EPOCHS):\n",
    "        # Training\n",
    "        train_ret = train_one_epoch(trn_loader, model, optimizer, loss_fn, device)\n",
    "        \n",
    "        # Validation\n",
    "        val_ret = validate_one_epoch(val_loader, model, loss_fn, device)\n",
    "        \n",
    "        # Scheduler step\n",
    "        scheduler.step()\n",
    "        \n",
    "        print(f\"Epoch {epoch+1:2d} | \"\n",
    "              f\"Train Loss: {train_ret['train_loss']:.4f} | \"\n",
    "              f\"Train F1: {train_ret['train_f1']:.4f} | \"\n",
    "              f\"Val Loss: {val_ret['val_loss']:.4f} | \"\n",
    "              f\"Val F1: {val_ret['val_f1']:.4f}\")\n",
    "        \n",
    "        # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥\n",
    "        if val_ret['val_f1'] > best_val_f1:\n",
    "            best_val_f1 = val_ret['val_f1']\n",
    "            best_model = copy.deepcopy(model.state_dict())\n",
    "    \n",
    "    # í˜„ì¬ fold ê²°ê³¼ ì €ì¥\n",
    "    fold_results.append({\n",
    "        'fold': fold + 1,\n",
    "        'best_val_f1': best_val_f1,\n",
    "        'train_samples': len(trn_dataset),\n",
    "        'val_samples': len(val_dataset)\n",
    "    })\n",
    "    \n",
    "    fold_models.append(best_model)\n",
    "    \n",
    "    print(f\"Subset Fold {fold + 1} Best Validation F1: {best_val_f1:.4f}\")\n",
    "\n",
    "# ê²°ê³¼ ìš”ì•½\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"SUBSET MODEL CROSS VALIDATION RESULTS\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "val_f1_scores = [result['best_val_f1'] for result in fold_results]\n",
    "mean_f1 = np.mean(val_f1_scores)\n",
    "std_f1 = np.std(val_f1_scores)\n",
    "\n",
    "for result in fold_results:\n",
    "    print(f\"Fold {result['fold']}: {result['best_val_f1']:.4f}\")\n",
    "\n",
    "print(f\"\\nMean CV F1: {mean_f1:.4f} Â± {std_f1:.4f}\")\n",
    "print(f\"Best single fold: {max(val_f1_scores):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d030b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# 3. ì„œë¸Œì…‹ ëª¨ë¸ ì €ì¥\n",
    "# ========================================\n",
    "\n",
    "# ì„œë¸Œì…‹ ëª¨ë¸ë“¤ ì €ì¥\n",
    "save_dir = \"subset_models\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "print(f\"\\nSaving subset models to {save_dir}/\")\n",
    "for fold, state_dict in enumerate(fold_models):\n",
    "    model_path = f\"{save_dir}/subset_fold_{fold}_model.pth\"\n",
    "    torch.save({\n",
    "        'model_state_dict': state_dict,\n",
    "        'fold': fold,\n",
    "        'classes': vulnerable_classes,\n",
    "        'label_mapping': label_mapping,\n",
    "        'model_name': model_name,\n",
    "        'img_size': img_size,\n",
    "        'num_classes': 4,\n",
    "        'best_f1': fold_results[fold]['best_val_f1']\n",
    "    }, model_path)\n",
    "    print(f\"âœ… Fold {fold} model saved: {model_path}\")\n",
    "\n",
    "print(\"\\nğŸ‰ 4-Class subset training completed!\")\n",
    "print(f\"ğŸ“Š Final Results Summary:\")\n",
    "print(f\"   - Target classes: {vulnerable_classes}\")\n",
    "print(f\"   - Training samples: {len(filtered_df)}\")\n",
    "print(f\"   - Mean CV F1: {mean_f1:.4f} Â± {std_f1:.4f}\")\n",
    "print(f\"   - Models saved in: {save_dir}/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f64e3c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# ë…¸íŠ¸ë¶ ì…€ 4 ìˆ˜ì •: ê¸°ì¡´ CascadeClassifierì— TTAë§Œ ì¶”ê°€\n",
    "# ========================================\n",
    "\n",
    "\n",
    "class CascadeClassifier:\n",
    "    \"\"\"\n",
    "    TTAê°€ ì¶”ê°€ëœ 2ë‹¨ê³„ ìºìŠ¤ì¼€ì´ë“œ ë¶„ë¥˜ ì‹œìŠ¤í…œ\n",
    "    \n",
    "    1ë‹¨ê³„: ë¶„ë¥˜ê¸° A (17ê°œ í´ë˜ìŠ¤ ì „ì²´ ë¶„ë¥˜) â†’ TTA + K-fold ì•™ìƒë¸”\n",
    "    2ë‹¨ê³„: ë¶„ë¥˜ê¸° B (ì·¨ì•½ í´ë˜ìŠ¤ 3,4,7,14ë§Œ ë¶„ë¥˜) â†’ TTA + K-fold ì•™ìƒë¸”\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, main_models, subset_models, vulnerable_classes=[3,4,7,14], \n",
    "                 confidence_threshold=0.7):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            main_models: ë¶„ë¥˜ê¸° Aì˜ ì•™ìƒë¸” ëª¨ë¸ë“¤ (17ê°œ í´ë˜ìŠ¤)\n",
    "            subset_models: ë¶„ë¥˜ê¸° Bì˜ ì•™ìƒë¸” ëª¨ë¸ë“¤ (4ê°œ í´ë˜ìŠ¤)\n",
    "            vulnerable_classes: ì·¨ì•½ í´ë˜ìŠ¤ ë¦¬ìŠ¤íŠ¸\n",
    "            confidence_threshold: 2ë‹¨ê³„ ë¶„ë¥˜ê¸°ë¡œ ë„˜ì–´ê°ˆ ì‹ ë¢°ë„ ì„ê³„ê°’\n",
    "        \"\"\"\n",
    "        self.main_models = main_models\n",
    "        self.subset_models = subset_models\n",
    "        self.vulnerable_classes = vulnerable_classes\n",
    "        self.confidence_threshold = confidence_threshold\n",
    "        \n",
    "        # ì·¨ì•½ í´ë˜ìŠ¤ ë§¤í•‘ (ì›ë³¸ í´ë˜ìŠ¤ -> ì„œë¸Œì…‹ í´ë˜ìŠ¤)\n",
    "        self.class_mapping = {cls: idx for idx, cls in enumerate(vulnerable_classes)}\n",
    "        \n",
    "        # ê¸°ì¡´ ì‚¬ìš©ìì˜ TTA ë³€í™˜ë“¤ ì„¤ì •\n",
    "        self.essential_tta_transforms = self._setup_tta_transforms()\n",
    "        \n",
    "        print(f\"TTA ìºìŠ¤ì¼€ì´ë“œ ë¶„ë¥˜ê¸° ì´ˆê¸°í™” ì™„ë£Œ\")\n",
    "        print(f\"- ì·¨ì•½ í´ë˜ìŠ¤: {vulnerable_classes}\")\n",
    "        print(f\"- ì‹ ë¢°ë„ ì„ê³„ê°’: {confidence_threshold}\")\n",
    "        print(f\"- ë©”ì¸ ëª¨ë¸ ìˆ˜: {len(main_models)}\")\n",
    "        print(f\"- ì„œë¸Œì…‹ ëª¨ë¸ ìˆ˜: {len(subset_models)}\")\n",
    "        print(f\"- TTA ë³€í™˜ ìˆ˜: {len(self.essential_tta_transforms)}\")\n",
    "    \n",
    "    def _setup_tta_transforms(self):\n",
    "        \"\"\"ì‚¬ìš©ìì˜ ê¸°ì¡´ TTA ë³€í™˜ë“¤ ì„¤ì •\"\"\"\n",
    "        img_size = 384  # ë…¸íŠ¸ë¶ì˜ img_size ë³€ìˆ˜ ì‚¬ìš©\n",
    "        \n",
    "        return [\n",
    "            # ì›ë³¸\n",
    "            A.Compose([\n",
    "                A.LongestMaxSize(max_size=img_size),\n",
    "                A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "                A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "                ToTensorV2(),\n",
    "            ]),\n",
    "            # 90ë„ íšŒì „\n",
    "            A.Compose([\n",
    "                A.LongestMaxSize(max_size=img_size),\n",
    "                A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "                A.Rotate(limit=[90, 90], p=1.0),\n",
    "                A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "                ToTensorV2(),\n",
    "            ]),\n",
    "            # 180ë„ íšŒì „\n",
    "            A.Compose([\n",
    "                A.LongestMaxSize(max_size=img_size),\n",
    "                A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "                A.Rotate(limit=[180, 180], p=1.0),\n",
    "                A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "                ToTensorV2(),\n",
    "            ]),\n",
    "            # -90ë„ íšŒì „ (270ë„)\n",
    "            A.Compose([\n",
    "                A.LongestMaxSize(max_size=img_size),\n",
    "                A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "                A.Rotate(limit=[-90, -90], p=1.0),\n",
    "                A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "                ToTensorV2(),\n",
    "            ]),\n",
    "            # ë°ê¸° ê°œì„ \n",
    "            A.Compose([\n",
    "                A.LongestMaxSize(max_size=img_size),\n",
    "                A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "                A.RandomBrightnessContrast(brightness_limit=[0.3, 0.3], contrast_limit=[0.3, 0.3], p=1.0),\n",
    "                A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "                ToTensorV2(),\n",
    "            ]),\n",
    "        ]\n",
    "    \n",
    "    def _apply_tta_to_image(self, image_array):\n",
    "        \"\"\"numpy ì´ë¯¸ì§€ ë°°ì—´ì— ëª¨ë“  TTA ë³€í™˜ ì ìš©\"\"\"\n",
    "        tta_tensors = []\n",
    "        for transform in self.essential_tta_transforms:\n",
    "            transformed = transform(image=image_array)['image']\n",
    "            tta_tensors.append(transformed)\n",
    "        return tta_tensors\n",
    "    \n",
    "    def predict_single(self, image, device):\n",
    "        \"\"\"\n",
    "        ë‹¨ì¼ ì´ë¯¸ì§€ì— ëŒ€í•œ ìºìŠ¤ì¼€ì´ë“œ ì˜ˆì¸¡\n",
    "        \n",
    "        Args:\n",
    "            image: ì „ì²˜ë¦¬ëœ ì´ë¯¸ì§€ í…ì„œ [C, H, W] ë˜ëŠ” numpy ë°°ì—´\n",
    "            device: GPU/CPU ë””ë°”ì´ìŠ¤\n",
    "            \n",
    "        Returns:\n",
    "            final_prediction: ìµœì¢… ì˜ˆì¸¡ í´ë˜ìŠ¤\n",
    "            confidence: ì˜ˆì¸¡ ì‹ ë¢°ë„\n",
    "            used_cascade: ì‚¬ìš©ëœ ë¶„ë¥˜ê¸° ('main' ë˜ëŠ” 'cascade')\n",
    "        \"\"\"\n",
    "        # ì…ë ¥ì´ í…ì„œì¸ ê²½ìš° numpyë¡œ ë³€í™˜ (TTAë¥¼ ìœ„í•´)\n",
    "        if isinstance(image, torch.Tensor):\n",
    "            # í…ì„œë¥¼ ë‹¤ì‹œ PIL -> numpyë¡œ ë³€í™˜í•´ì•¼ í•¨ (ë¹„íš¨ìœ¨ì ì´ì§€ë§Œ TTA ì ìš©ì„ ìœ„í•´)\n",
    "            # ì‹¤ì œë¡œëŠ” ì›ë³¸ ì´ë¯¸ì§€ íŒŒì¼ì—ì„œ ì§ì ‘ ë¡œë“œí•˜ëŠ” ê²ƒì´ ì¢‹ìŒ\n",
    "            # ì—¬ê¸°ì„œëŠ” ê¸°ì¡´ ì¸í„°í˜ì´ìŠ¤ ìœ ì§€ë¥¼ ìœ„í•œ ì„ì‹œ ì²˜ë¦¬\n",
    "            image_np = image.permute(1, 2, 0).cpu().numpy()\n",
    "            # ì •ê·œí™” ì—­ë³€í™˜ (ëŒ€ëµì )\n",
    "            image_np = image_np * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
    "            image_np = (image_np * 255).astype(np.uint8)\n",
    "        else:\n",
    "            image_np = image\n",
    "        \n",
    "        # 1ë‹¨ê³„: ë©”ì¸ ë¶„ë¥˜ê¸°ë¡œ TTA + K-fold ì•™ìƒë¸” ì˜ˆì¸¡\n",
    "        main_probs = self._predict_main_ensemble(image_np, device)\n",
    "        main_pred = torch.argmax(main_probs).item()\n",
    "        main_confidence = torch.max(main_probs).item()\n",
    "        \n",
    "        # 1ë‹¨ê³„ ì˜ˆì¸¡ì´ ì·¨ì•½ í´ë˜ìŠ¤ì´ê³  ì‹ ë¢°ë„ê°€ ë‚®ìœ¼ë©´ 2ë‹¨ê³„ë¡œ\n",
    "        if (main_pred in self.vulnerable_classes and \n",
    "            main_confidence < self.confidence_threshold):\n",
    "            \n",
    "            # 2ë‹¨ê³„: ì„œë¸Œì…‹ ë¶„ë¥˜ê¸°ë¡œ TTA + K-fold ì•™ìƒë¸” ì˜ˆì¸¡\n",
    "            subset_probs = self._predict_subset_ensemble(image_np, device)\n",
    "            subset_pred_idx = torch.argmax(subset_probs).item()\n",
    "            subset_confidence = torch.max(subset_probs).item()\n",
    "            \n",
    "            # ì„œë¸Œì…‹ ì˜ˆì¸¡ì„ ì›ë³¸ í´ë˜ìŠ¤ë¡œ ë³€í™˜\n",
    "            final_prediction = self.vulnerable_classes[subset_pred_idx]\n",
    "            final_confidence = subset_confidence\n",
    "            used_cascade = 'cascade'\n",
    "            \n",
    "            print(f\"ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: {main_pred}({main_confidence:.3f}) -> {final_prediction}({subset_confidence:.3f})\")\n",
    "            \n",
    "        else:\n",
    "            # 1ë‹¨ê³„ ì˜ˆì¸¡ ê·¸ëŒ€ë¡œ ì‚¬ìš©\n",
    "            final_prediction = main_pred\n",
    "            final_confidence = main_confidence\n",
    "            used_cascade = 'main'\n",
    "        \n",
    "        return final_prediction, final_confidence, used_cascade\n",
    "    \n",
    "    def _predict_main_ensemble(self, image_array, device):\n",
    "        \"\"\"ë©”ì¸ ë¶„ë¥˜ê¸° TTA + K-fold ì•™ìƒë¸” ì˜ˆì¸¡\"\"\"\n",
    "        # TTA ì ìš©\n",
    "        tta_tensors = self._apply_tta_to_image(image_array)\n",
    "        all_predictions = []\n",
    "        \n",
    "        # ê° TTA ë³€í™˜ì— ëŒ€í•´ K-fold ì•™ìƒë¸”\n",
    "        for tta_tensor in tta_tensors:\n",
    "            tta_tensor = tta_tensor.unsqueeze(0).to(device)  # ë°°ì¹˜ ì°¨ì› ì¶”ê°€\n",
    "            \n",
    "            # K-fold ì•™ìƒë¸”\n",
    "            fold_predictions = []\n",
    "            with torch.no_grad():\n",
    "                for model in self.main_models:\n",
    "                    model.eval()\n",
    "                    preds = model(tta_tensor)\n",
    "                    probs = torch.softmax(preds, dim=1)\n",
    "                    fold_predictions.append(probs)\n",
    "            \n",
    "            # K-fold í‰ê· \n",
    "            fold_ensemble = torch.mean(torch.stack(fold_predictions), dim=0)\n",
    "            all_predictions.append(fold_ensemble)\n",
    "        \n",
    "        # TTA í‰ê· \n",
    "        final_prediction = torch.mean(torch.stack(all_predictions), dim=0).squeeze()\n",
    "        return final_prediction\n",
    "    \n",
    "    def _predict_subset_ensemble(self, image_array, device):\n",
    "        \"\"\"ì„œë¸Œì…‹ ë¶„ë¥˜ê¸° TTA + K-fold ì•™ìƒë¸” ì˜ˆì¸¡\"\"\"\n",
    "        # TTA ì ìš©\n",
    "        tta_tensors = self._apply_tta_to_image(image_array)\n",
    "        all_predictions = []\n",
    "        \n",
    "        # ê° TTA ë³€í™˜ì— ëŒ€í•´ K-fold ì•™ìƒë¸”\n",
    "        for tta_tensor in tta_tensors:\n",
    "            tta_tensor = tta_tensor.unsqueeze(0).to(device)  # ë°°ì¹˜ ì°¨ì› ì¶”ê°€\n",
    "            \n",
    "            # K-fold ì•™ìƒë¸”\n",
    "            fold_predictions = []\n",
    "            with torch.no_grad():\n",
    "                for model in self.subset_models:\n",
    "                    model.eval()\n",
    "                    preds = model(tta_tensor)\n",
    "                    probs = torch.softmax(preds, dim=1)\n",
    "                    fold_predictions.append(probs)\n",
    "            \n",
    "            # K-fold í‰ê· \n",
    "            fold_ensemble = torch.mean(torch.stack(fold_predictions), dim=0)\n",
    "            all_predictions.append(fold_ensemble)\n",
    "        \n",
    "        # TTA í‰ê· \n",
    "        final_prediction = torch.mean(torch.stack(all_predictions), dim=0).squeeze()\n",
    "        return final_prediction\n",
    "    \n",
    "    def predict_batch(self, dataloader, device):\n",
    "        \"\"\"\n",
    "        ë°°ì¹˜ ë°ì´í„°ì— ëŒ€í•œ ìºìŠ¤ì¼€ì´ë“œ ì˜ˆì¸¡\n",
    "        \n",
    "        Args:\n",
    "            dataloader: í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œë”\n",
    "            device: GPU/CPU ë””ë°”ì´ìŠ¤\n",
    "            \n",
    "        Returns:\n",
    "            predictions: ìµœì¢… ì˜ˆì¸¡ ë¦¬ìŠ¤íŠ¸\n",
    "            confidences: ì˜ˆì¸¡ ì‹ ë¢°ë„ ë¦¬ìŠ¤íŠ¸\n",
    "            cascade_usage: ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš© í†µê³„\n",
    "        \"\"\"\n",
    "        all_predictions = []\n",
    "        all_confidences = []\n",
    "        cascade_usage = {'main': 0, 'cascade': 0}\n",
    "        \n",
    "        for images, _ in tqdm(dataloader, desc=\"TTA Cascade Prediction\"):\n",
    "            batch_predictions = []\n",
    "            batch_confidences = []\n",
    "            \n",
    "            for i in range(images.size(0)):\n",
    "                single_image = images[i]\n",
    "                pred, conf, used = self.predict_single(single_image, device)\n",
    "                \n",
    "                batch_predictions.append(pred)\n",
    "                batch_confidences.append(conf)\n",
    "                cascade_usage[used] += 1\n",
    "            \n",
    "            all_predictions.extend(batch_predictions)\n",
    "            all_confidences.extend(batch_confidences)\n",
    "        \n",
    "        return all_predictions, all_confidences, cascade_usage\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5057054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë©”ì¸ ëª¨ë¸ë“¤ ë¡œë“œ ì¤‘...\n",
      "âœ… ë©”ì¸ ëª¨ë¸ 1 ë¡œë“œ ì™„ë£Œ\n",
      "âœ… ë©”ì¸ ëª¨ë¸ 2 ë¡œë“œ ì™„ë£Œ\n",
      "âœ… ë©”ì¸ ëª¨ë¸ 3 ë¡œë“œ ì™„ë£Œ\n",
      "âœ… ë©”ì¸ ëª¨ë¸ 4 ë¡œë“œ ì™„ë£Œ\n",
      "âœ… ë©”ì¸ ëª¨ë¸ 5 ë¡œë“œ ì™„ë£Œ\n",
      "ì´ 5ê°œì˜ ë©”ì¸ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ\n",
      "\n",
      "ì„œë¸Œì…‹ ëª¨ë¸ë“¤ ë¡œë“œ ì¤‘...\n",
      "âœ… ì„œë¸Œì…‹ ëª¨ë¸ 0 ë¡œë“œ ì™„ë£Œ (F1: 0.8820)\n",
      "âœ… ì„œë¸Œì…‹ ëª¨ë¸ 1 ë¡œë“œ ì™„ë£Œ (F1: 0.9059)\n",
      "âœ… ì„œë¸Œì…‹ ëª¨ë¸ 2 ë¡œë“œ ì™„ë£Œ (F1: 0.8886)\n",
      "âœ… ì„œë¸Œì…‹ ëª¨ë¸ 3 ë¡œë“œ ì™„ë£Œ (F1: 0.9750)\n",
      "âœ… ì„œë¸Œì…‹ ëª¨ë¸ 4 ë¡œë“œ ì™„ë£Œ (F1: 0.8390)\n",
      "ì´ 5ê°œì˜ ì„œë¸Œì…‹ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# 5. ë©”ì¸ ëª¨ë¸ê³¼ ì„œë¸Œì…‹ ëª¨ë¸ ë¡œë“œ\n",
    "# ========================================\n",
    "\n",
    "# ë©”ì¸ ëª¨ë¸ë“¤ ë¡œë“œ (17ê°œ í´ë˜ìŠ¤)\n",
    "print(\"ë©”ì¸ ëª¨ë¸ë“¤ ë¡œë“œ ì¤‘...\")\n",
    "main_models = []\n",
    "for fold in range(5):\n",
    "\n",
    "    #model_path = f\"best_model_fold_{fold+1}.pth\"\n",
    "    model_path = f\"fold_{fold+1}_best.pth\"\n",
    "    \n",
    "    if os.path.exists(model_path):\n",
    "        # ë©”ì¸ ëª¨ë¸ ìƒì„± (17ê°œ í´ë˜ìŠ¤)\n",
    "        main_model = timm.create_model(model_name, pretrained=True, num_classes=17).to(device)\n",
    "        main_model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "        main_model.eval()\n",
    "        \n",
    "        main_models.append(main_model)\n",
    "        print(f\"âœ… ë©”ì¸ ëª¨ë¸ {fold+1} ë¡œë“œ ì™„ë£Œ\")\n",
    "    else:\n",
    "        print(f\"âŒ ë©”ì¸ ëª¨ë¸ {fold+1} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path}\")\n",
    "\n",
    "print(f\"ì´ {len(main_models)}ê°œì˜ ë©”ì¸ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ\")\n",
    "\n",
    "save_dir = 'subset_models'\n",
    "\n",
    "# ì„œë¸Œì…‹ ëª¨ë¸ë“¤ ë¡œë“œ (4ê°œ í´ë˜ìŠ¤)\n",
    "print(\"\\nì„œë¸Œì…‹ ëª¨ë¸ë“¤ ë¡œë“œ ì¤‘...\")\n",
    "subset_models = []\n",
    "for fold in range(5):\n",
    "    model_path = f\"{save_dir}/subset_fold_{fold}_model.pth\"\n",
    "    \n",
    "    if os.path.exists(model_path):\n",
    "        # ì„œë¸Œì…‹ ëª¨ë¸ ìƒì„± (4ê°œ í´ë˜ìŠ¤)\n",
    "        subset_model = timm.create_model(model_name, pretrained=True, num_classes=4).to(device)\n",
    "        checkpoint = torch.load(model_path, map_location=device)\n",
    "        subset_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        subset_model.eval()\n",
    "        \n",
    "        subset_models.append(subset_model)\n",
    "        print(f\"âœ… ì„œë¸Œì…‹ ëª¨ë¸ {fold} ë¡œë“œ ì™„ë£Œ (F1: {checkpoint['best_f1']:.4f})\")\n",
    "    else:\n",
    "        print(f\"âŒ ì„œë¸Œì…‹ ëª¨ë¸ {fold} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path}\")\n",
    "\n",
    "print(f\"ì´ {len(subset_models)}ê°œì˜ ì„œë¸Œì…‹ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ea6b713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TTA ìºìŠ¤ì¼€ì´ë“œ ë¶„ë¥˜ê¸° ì´ˆê¸°í™” ì™„ë£Œ\n",
      "- ì·¨ì•½ í´ë˜ìŠ¤: [3, 4, 7, 14]\n",
      "- ì‹ ë¢°ë„ ì„ê³„ê°’: 0.7\n",
      "- ë©”ì¸ ëª¨ë¸ ìˆ˜: 5\n",
      "- ì„œë¸Œì…‹ ëª¨ë¸ ìˆ˜: 5\n",
      "- TTA ë³€í™˜ ìˆ˜: 5\n",
      "í…ŒìŠ¤íŠ¸ ë°ì´í„° í¬ê¸°: 3140\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‹œìŠ¤í…œìœ¼ë¡œ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡ ì‹œì‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:   0%|          | 0/99 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 3(0.611) -> 3(0.631)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 4(0.358) -> 4(0.476)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 7(0.541) -> 7(0.438)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:   1%|          | 1/99 [00:11<18:16, 11.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 14(0.428) -> 7(0.579)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 3(0.616) -> 3(0.822)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 3(0.396) -> 3(0.484)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:   2%|â–         | 2/99 [00:19<15:34,  9.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 7(0.544) -> 7(0.579)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 14(0.554) -> 14(0.452)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 4(0.413) -> 4(0.544)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 7(0.510) -> 7(0.666)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:   4%|â–         | 4/99 [00:36<13:43,  8.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 3(0.397) -> 3(0.430)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 4(0.646) -> 4(0.621)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 3(0.614) -> 3(0.670)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:   5%|â–Œ         | 5/99 [00:44<13:30,  8.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 7(0.520) -> 3(0.575)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 7(0.417) -> 4(0.449)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:   6%|â–Œ         | 6/99 [00:53<13:11,  8.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 4(0.379) -> 7(0.350)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 14(0.430) -> 14(0.475)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 3(0.564) -> 3(0.627)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 7(0.679) -> 7(0.550)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:   7%|â–‹         | 7/99 [01:02<13:20,  8.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 3(0.600) -> 3(0.461)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 7(0.658) -> 7(0.343)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 7(0.590) -> 7(0.522)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 7(0.440) -> 3(0.559)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 14(0.646) -> 14(0.729)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:   8%|â–Š         | 8/99 [01:11<13:16,  8.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 4(0.692) -> 4(0.518)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 7(0.467) -> 4(0.350)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 7(0.596) -> 4(0.487)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:   9%|â–‰         | 9/99 [01:19<13:06,  8.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 3(0.406) -> 7(0.487)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 7(0.400) -> 7(0.488)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 3(0.313) -> 3(0.452)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:  10%|â–ˆ         | 10/99 [01:28<12:54,  8.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 3(0.322) -> 3(0.349)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:  11%|â–ˆ         | 11/99 [01:36<12:31,  8.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 3(0.540) -> 3(0.521)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 3(0.509) -> 3(0.756)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 4(0.693) -> 4(0.475)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 7(0.565) -> 3(0.440)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:  12%|â–ˆâ–        | 12/99 [01:45<12:39,  8.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 7(0.494) -> 4(0.367)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 7(0.269) -> 4(0.420)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:  13%|â–ˆâ–        | 13/99 [01:53<12:16,  8.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 3(0.281) -> 3(0.447)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 7(0.595) -> 7(0.709)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 4(0.639) -> 4(0.569)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 3(0.597) -> 7(0.476)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:  14%|â–ˆâ–        | 14/99 [02:02<12:17,  8.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 4(0.653) -> 4(0.550)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 7(0.681) -> 7(0.577)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 7(0.680) -> 3(0.512)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 4(0.531) -> 4(0.695)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:  15%|â–ˆâ–Œ        | 15/99 [02:11<12:17,  8.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 3(0.572) -> 3(0.598)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 7(0.537) -> 3(0.499)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:  16%|â–ˆâ–Œ        | 16/99 [02:20<12:00,  8.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 4(0.543) -> 4(0.517)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 4(0.437) -> 4(0.498)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 4(0.693) -> 4(0.626)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 3(0.574) -> 3(0.667)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:  17%|â–ˆâ–‹        | 17/99 [02:29<12:00,  8.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 7(0.639) -> 7(0.385)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 14(0.359) -> 7(0.273)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:  18%|â–ˆâ–Š        | 18/99 [02:37<11:44,  8.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 3(0.613) -> 3(0.821)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 7(0.494) -> 7(0.511)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 14(0.271) -> 4(0.295)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:  19%|â–ˆâ–‰        | 19/99 [02:46<11:35,  8.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 3(0.428) -> 3(0.682)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 7(0.515) -> 7(0.477)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 3(0.353) -> 3(0.570)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 4(0.552) -> 4(0.424)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:  20%|â–ˆâ–ˆ        | 20/99 [02:55<11:33,  8.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 4(0.491) -> 4(0.469)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 4(0.571) -> 4(0.462)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:  21%|â–ˆâ–ˆ        | 21/99 [03:04<11:18,  8.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 3(0.581) -> 3(0.577)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 4(0.310) -> 3(0.496)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 3(0.504) -> 3(0.501)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 3(0.401) -> 3(0.585)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 7(0.431) -> 3(0.655)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:  22%|â–ˆâ–ˆâ–       | 22/99 [03:13<11:21,  8.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 4(0.639) -> 4(0.445)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 14(0.513) -> 14(0.446)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 7(0.529) -> 7(0.400)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:  23%|â–ˆâ–ˆâ–       | 23/99 [03:22<11:10,  8.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 3(0.360) -> 7(0.379)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 7(0.672) -> 7(0.417)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 7(0.570) -> 7(0.462)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 3(0.502) -> 3(0.441)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:  24%|â–ˆâ–ˆâ–       | 24/99 [03:31<11:06,  8.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 4(0.622) -> 4(0.617)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 7(0.445) -> 3(0.450)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 7(0.303) -> 7(0.503)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 14(0.457) -> 7(0.431)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:  25%|â–ˆâ–ˆâ–Œ       | 25/99 [03:40<10:59,  8.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 4(0.639) -> 4(0.758)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 7(0.679) -> 7(0.413)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 3(0.512) -> 3(0.485)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:  26%|â–ˆâ–ˆâ–‹       | 26/99 [03:48<10:47,  8.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 7(0.427) -> 3(0.402)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 7(0.525) -> 3(0.515)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 14(0.562) -> 14(0.634)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:  27%|â–ˆâ–ˆâ–‹       | 27/99 [03:57<10:36,  8.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 7(0.445) -> 3(0.664)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:  28%|â–ˆâ–ˆâ–Š       | 28/99 [04:06<10:20,  8.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 7(0.476) -> 7(0.464)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:  29%|â–ˆâ–ˆâ–‰       | 29/99 [04:14<09:56,  8.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 4(0.613) -> 7(0.433)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 3(0.613) -> 3(0.661)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 3(0.618) -> 3(0.600)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 14(0.587) -> 4(0.486)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:  30%|â–ˆâ–ˆâ–ˆ       | 30/99 [04:23<09:59,  8.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 14(0.563) -> 14(0.397)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:  31%|â–ˆâ–ˆâ–ˆâ–      | 31/99 [04:31<09:43,  8.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 4(0.301) -> 4(0.391)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 4(0.583) -> 4(0.491)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 7(0.673) -> 7(0.719)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:  32%|â–ˆâ–ˆâ–ˆâ–      | 32/99 [04:40<09:40,  8.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 7(0.639) -> 7(0.411)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 7(0.675) -> 7(0.515)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 7(0.549) -> 7(0.501)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 14(0.675) -> 14(0.701)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:  33%|â–ˆâ–ˆâ–ˆâ–      | 33/99 [04:49<09:41,  8.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 7(0.469) -> 3(0.485)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 7(0.593) -> 7(0.482)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 4(0.384) -> 3(0.311)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:  34%|â–ˆâ–ˆâ–ˆâ–      | 34/99 [04:58<09:35,  8.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 7(0.688) -> 7(0.782)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 7(0.434) -> 3(0.457)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 35/99 [05:07<09:23,  8.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 7(0.671) -> 3(0.651)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 3(0.476) -> 3(0.609)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 7(0.658) -> 7(0.481)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 37/99 [05:24<08:57,  8.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 7(0.472) -> 3(0.564)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 38/99 [05:32<08:45,  8.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 3(0.654) -> 3(0.585)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 14(0.389) -> 14(0.401)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 39/99 [05:41<08:40,  8.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 7(0.594) -> 7(0.646)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 4(0.475) -> 14(0.481)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 14(0.352) -> 3(0.354)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 40/99 [05:50<08:37,  8.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 7(0.550) -> 3(0.462)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 41/99 [05:59<08:23,  8.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 7(0.593) -> 3(0.539)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 3(0.428) -> 3(0.473)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 14(0.597) -> 14(0.626)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 3(0.643) -> 3(0.705)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/99 [06:08<08:24,  8.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 7(0.597) -> 7(0.551)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 7(0.692) -> 3(0.462)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 3(0.454) -> 3(0.525)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 3(0.607) -> 3(0.513)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/99 [06:17<08:25,  9.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 7(0.481) -> 7(0.407)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 14(0.677) -> 14(0.615)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 44/99 [06:26<08:12,  8.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 3(0.455) -> 3(0.619)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 3(0.450) -> 3(0.372)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 3(0.450) -> 3(0.361)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 14(0.326) -> 7(0.574)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 46/99 [06:44<07:45,  8.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 7(0.581) -> 7(0.583)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 47/99 [06:52<07:31,  8.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 4(0.429) -> 3(0.400)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 48/99 [07:01<07:21,  8.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 14(0.475) -> 4(0.445)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 7(0.566) -> 4(0.462)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 7(0.489) -> 3(0.566)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 49/99 [07:10<07:17,  8.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 3(0.509) -> 3(0.576)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 3(0.338) -> 3(0.412)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 3(0.553) -> 3(0.758)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 14(0.514) -> 7(0.465)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 50/99 [07:19<07:16,  8.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 4(0.457) -> 4(0.419)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 7(0.659) -> 7(0.534)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 7(0.511) -> 7(0.627)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 14(0.504) -> 4(0.372)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 3(0.512) -> 3(0.480)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 51/99 [07:28<07:16,  9.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 7(0.389) -> 3(0.327)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 4(0.395) -> 7(0.485)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 3(0.527) -> 3(0.591)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 4(0.488) -> 4(0.548)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/99 [07:38<07:11,  9.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 7(0.686) -> 7(0.524)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 3(0.699) -> 3(0.801)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 4(0.435) -> 4(0.469)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 7(0.384) -> 7(0.349)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 3(0.359) -> 3(0.538)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 14(0.662) -> 14(0.640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 53/99 [07:48<07:10,  9.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 4(0.513) -> 4(0.405)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 14(0.509) -> 14(0.295)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 14(0.343) -> 3(0.361)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 54/99 [07:57<06:57,  9.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 7(0.645) -> 3(0.672)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 55/99 [08:05<06:37,  9.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 7(0.563) -> 7(0.527)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 7(0.597) -> 7(0.664)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 3(0.666) -> 3(0.731)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 14(0.321) -> 3(0.399)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 56/99 [08:14<06:31,  9.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 7(0.553) -> 7(0.634)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 7(0.690) -> 7(0.711)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 57/99 [08:23<06:18,  9.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 7(0.620) -> 3(0.379)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 4(0.646) -> 4(0.497)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 58/99 [08:32<06:06,  8.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 4(0.352) -> 7(0.394)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 14(0.653) -> 14(0.693)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 3(0.412) -> 7(0.503)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 59/99 [08:41<06:02,  9.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 3(0.404) -> 3(0.435)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 3(0.445) -> 7(0.526)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 7(0.513) -> 3(0.427)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 7(0.463) -> 7(0.394)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 60/99 [08:50<05:52,  9.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 7(0.696) -> 7(0.738)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 4(0.333) -> 4(0.332)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 7(0.363) -> 7(0.469)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 61/99 [09:00<05:46,  9.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 4(0.660) -> 4(0.385)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 14(0.291) -> 7(0.386)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 14(0.585) -> 14(0.496)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 7(0.538) -> 3(0.594)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 3(0.505) -> 3(0.522)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/99 [09:09<05:39,  9.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 14(0.651) -> 14(0.570)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 7(0.643) -> 7(0.441)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 63/99 [09:18<05:25,  9.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 3(0.625) -> 3(0.567)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 4(0.660) -> 4(0.502)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 4(0.554) -> 4(0.482)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 65/99 [09:35<04:58,  8.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 3(0.489) -> 7(0.506)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 7(0.656) -> 7(0.509)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 66/99 [09:44<04:51,  8.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 7(0.390) -> 3(0.435)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 3(0.467) -> 3(0.649)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 4(0.465) -> 4(0.365)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 3(0.585) -> 3(0.705)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 68/99 [10:01<04:29,  8.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 7(0.678) -> 7(0.631)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 4(0.428) -> 4(0.435)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 69/99 [10:10<04:20,  8.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 7(0.529) -> 7(0.658)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 3(0.515) -> 3(0.561)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 7(0.246) -> 7(0.367)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 70/99 [10:19<04:14,  8.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 3(0.393) -> 7(0.400)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 4(0.541) -> 7(0.607)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/99 [10:27<04:05,  8.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 14(0.404) -> 7(0.455)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 72/99 [10:36<03:53,  8.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 7(0.568) -> 7(0.516)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 7(0.601) -> 3(0.498)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 3(0.434) -> 3(0.632)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 14(0.514) -> 14(0.497)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 4(0.626) -> 4(0.592)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 73/99 [10:45<03:53,  8.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 7(0.506) -> 7(0.596)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 4(0.625) -> 14(0.590)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 74/99 [10:54<03:40,  8.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 7(0.692) -> 7(0.678)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 3(0.506) -> 3(0.545)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 14(0.630) -> 14(0.427)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 75/99 [11:03<03:33,  8.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 7(0.325) -> 7(0.515)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 7(0.384) -> 3(0.394)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 76/99 [11:12<03:23,  8.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 4(0.265) -> 3(0.369)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 3(0.431) -> 3(0.642)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 14(0.614) -> 14(0.442)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 77/99 [11:21<03:15,  8.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 7(0.493) -> 3(0.500)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 4(0.657) -> 4(0.526)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 7(0.204) -> 7(0.406)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 3(0.448) -> 3(0.619)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 3(0.672) -> 3(0.779)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 78/99 [11:30<03:10,  9.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 7(0.425) -> 7(0.321)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 3(0.642) -> 3(0.710)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 7(0.661) -> 7(0.758)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 4(0.260) -> 4(0.370)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 7(0.515) -> 3(0.547)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 79/99 [11:40<03:03,  9.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 3(0.557) -> 3(0.446)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 4(0.457) -> 7(0.415)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 80/99 [11:48<02:51,  9.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 4(0.549) -> 4(0.398)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 7(0.520) -> 3(0.546)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 7(0.498) -> 7(0.496)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 3(0.495) -> 3(0.680)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/99 [11:58<02:43,  9.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 4(0.585) -> 4(0.408)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 82/99 [12:06<02:31,  8.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 7(0.296) -> 7(0.413)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 83/99 [12:14<02:20,  8.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 7(0.317) -> 3(0.433)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 3(0.432) -> 7(0.462)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 84/99 [12:23<02:11,  8.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 4(0.367) -> 3(0.565)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 14(0.698) -> 14(0.798)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 86/99 [12:40<01:51,  8.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 3(0.433) -> 3(0.429)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 3(0.627) -> 3(0.523)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 7(0.489) -> 3(0.418)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 7(0.445) -> 7(0.407)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 7(0.258) -> 7(0.442)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 87/99 [12:50<01:46,  8.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 4(0.430) -> 4(0.402)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 4(0.520) -> 14(0.435)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 4(0.424) -> 4(0.347)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 88/99 [12:59<01:37,  8.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 4(0.349) -> 4(0.317)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 4(0.682) -> 4(0.414)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 14(0.356) -> 3(0.363)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 3(0.647) -> 3(0.787)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 89/99 [13:08<01:30,  9.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 4(0.510) -> 4(0.455)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 14(0.686) -> 14(0.690)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 7(0.309) -> 4(0.410)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 90/99 [13:17<01:21,  9.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 3(0.538) -> 7(0.481)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 7(0.643) -> 7(0.432)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 4(0.696) -> 14(0.477)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/99 [13:26<01:11,  9.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 14(0.205) -> 3(0.306)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 92/99 [13:34<01:01,  8.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 3(0.693) -> 3(0.608)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 3(0.510) -> 3(0.560)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 14(0.543) -> 7(0.664)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 3(0.503) -> 3(0.529)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 14(0.525) -> 4(0.383)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 93/99 [13:44<00:54,  9.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 3(0.355) -> 3(0.405)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 3(0.571) -> 3(0.467)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 94/99 [13:52<00:44,  8.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 7(0.426) -> 4(0.360)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 96/99 [14:09<00:25,  8.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 3(0.363) -> 3(0.436)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 7(0.644) -> 7(0.790)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 7(0.450) -> 4(0.397)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 7(0.611) -> 7(0.459)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 3(0.663) -> 3(0.622)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 7(0.307) -> 3(0.422)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 7(0.514) -> 7(0.491)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 3(0.591) -> 3(0.584)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 4(0.334) -> 3(0.441)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 3(0.275) -> 3(0.668)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 97/99 [14:20<00:18,  9.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 14(0.638) -> 14(0.519)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 4(0.331) -> 7(0.360)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 7(0.406) -> 7(0.531)\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 3(0.416) -> 7(0.456)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 99/99 [14:30<00:00,  8.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš© í†µê³„:\n",
      "- ë©”ì¸ ë¶„ë¥˜ê¸°ë§Œ ì‚¬ìš©: 2865ê°œ (91.2%)\n",
      "- ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: 275ê°œ (8.8%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# 6. ìºìŠ¤ì¼€ì´ë“œ ë¶„ë¥˜ê¸° ì´ˆê¸°í™” ë° í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡\n",
    "# ========================================\n",
    "\n",
    "# ìºìŠ¤ì¼€ì´ë“œ ë¶„ë¥˜ê¸° ì¸ìŠ¤í„´ìŠ¤ ìƒì„±\n",
    "cascade_classifier = CascadeClassifier(\n",
    "    main_models=main_models,      # ë¶„ë¥˜ê¸° A (17ê°œ í´ë˜ìŠ¤)\n",
    "    subset_models=subset_models,  # ë¶„ë¥˜ê¸° B (4ê°œ í´ë˜ìŠ¤)\n",
    "    vulnerable_classes=vulnerable_classes, # [3, 4, 7, 14]\n",
    "    confidence_threshold=0.7      # ì‹ ë¢°ë„ ì„ê³„ê°’\n",
    ")\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ\n",
    "test_df = pd.read_csv(\"../data/sample_submission.csv\")\n",
    "print(f\"í…ŒìŠ¤íŠ¸ ë°ì´í„° í¬ê¸°: {len(test_df)}\")\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ìƒì„±\n",
    "test_dataset = ImageDataset(\n",
    "    test_df,\n",
    "    \"../data/test/\",\n",
    "    epoch=0,\n",
    "    total_epochs=EPOCHS,\n",
    "    is_train=False  # í…ŒìŠ¤íŠ¸ì´ë¯€ë¡œ ì¦ê°• ì—†ìŒ\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=32,  # ë°°ì¹˜ í¬ê¸° ì¤„ì„\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(\"ìºìŠ¤ì¼€ì´ë“œ ì‹œìŠ¤í…œìœ¼ë¡œ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡ ì‹œì‘...\")\n",
    "\n",
    "# ì˜¬ë°”ë¥¸ ì½”ë“œ - ì¸ìŠ¤í„´ìŠ¤ì—ì„œ ë©”ì„œë“œ í˜¸ì¶œ\n",
    "test_predictions, test_confidences, cascade_usage = cascade_classifier.predict_batch(\n",
    "    test_loader, device\n",
    ")\n",
    "\n",
    "print(f\"\\nìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš© í†µê³„:\")\n",
    "print(f\"- ë©”ì¸ ë¶„ë¥˜ê¸°ë§Œ ì‚¬ìš©: {cascade_usage['main']}ê°œ ({cascade_usage['main']/len(test_predictions)*100:.1f}%)\")\n",
    "print(f\"- ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: {cascade_usage['cascade']}ê°œ ({cascade_usage['cascade']/len(test_predictions)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a602d517",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ê²°ê³¼ ì €ì¥\n",
    "result_df = test_df.copy()\n",
    "result_df['target'] = test_predictions\n",
    "result_df['confidence'] = test_confidences\n",
    "\n",
    "# submission íŒŒì¼ ì €ì¥\n",
    "output_path = \"../data/output/cascade_submission3.csv\"\n",
    "print(f\"ğŸ“ ê²°ê³¼ ì €ì¥: {output_path}\")\n",
    "result_df[['ID', 'target']].to_csv(output_path, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
