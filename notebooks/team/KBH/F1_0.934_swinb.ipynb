{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "OliaDaX_lwou"
   },
   "source": [
    "# **ğŸ“„ Document type classification baseline code**\n",
    "> ë¬¸ì„œ íƒ€ì… ë¶„ë¥˜ ëŒ€íšŒì— ì˜¤ì‹  ì—¬ëŸ¬ë¶„ í™˜ì˜í•©ë‹ˆë‹¤! ğŸ‰     \n",
    "> ì•„ë˜ baselineì—ì„œëŠ” ResNet ëª¨ë¸ì„ ë¡œë“œí•˜ì—¬, ëª¨ë¸ì„ í•™ìŠµ ë° ì˜ˆì¸¡ íŒŒì¼ ìƒì„±í•˜ëŠ” í”„ë¡œì„¸ìŠ¤ì— ëŒ€í•´ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤.\n",
    "\n",
    "## Contents\n",
    "- Prepare Environments\n",
    "- Import Library & Define Functions\n",
    "- Hyper-parameters\n",
    "- Load Data\n",
    "- Train Model\n",
    "- Inference & Save File\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "zkH9T_86lDSS"
   },
   "source": [
    "## 1. Prepare Environments\n",
    "\n",
    "* ë°ì´í„° ë¡œë“œë¥¼ ìœ„í•œ êµ¬ê¸€ ë“œë¼ì´ë¸Œë¥¼ ë§ˆìš´íŠ¸í•©ë‹ˆë‹¤.\n",
    "* í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8489,
     "status": "ok",
     "timestamp": 1700314558888,
     "user": {
      "displayName": "Ynot(ì†¡ì›í˜¸)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "NC8V-D393wY4",
    "outputId": "e9927325-26c4-4b89-9c51-c1d6541388d6"
   },
   "outputs": [],
   "source": [
    "# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤.\n",
    "# !pip install timm\n",
    "# !pip install matplotlib\n",
    "# !pip install seaborn\n",
    "# !pip install optuna"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "PXa_FPM73R9f"
   },
   "source": [
    "## 2. Import Library & Define Functions\n",
    "* í•™ìŠµ ë° ì¶”ë¡ ì— í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.\n",
    "* í•™ìŠµ ë° ì¶”ë¡ ì— í•„ìš”í•œ í•¨ìˆ˜ì™€ í´ë˜ìŠ¤ë¥¼ ì •ì˜í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 9396,
     "status": "ok",
     "timestamp": 1700314592802,
     "user": {
      "displayName": "Ynot(ì†¡ì›í˜¸)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "3BaoIkv5Xwa0"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import copy\n",
    "\n",
    "import optuna, math\n",
    "import timm\n",
    "import torch\n",
    "import albumentations as A\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.optim import Adam\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.cuda.amp import autocast, GradScaler  # Mixed Precisionìš©\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "\n",
    "def mixup_data(x, y, alpha=1.0):\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "    batch_size = x.size()[0]\n",
    "    index = torch.randperm(batch_size).cuda()\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# í•œê¸€ í°íŠ¸ ì„¤ì • (ì‹œê°í™”ìš©)\n",
    "plt.rcParams['font.family'] = ['DejaVu Sans']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ ë…¸íŠ¸ë¶ ì‘ì—… ì‹œì‘: F1_0_934_swinb\n",
      "ğŸ“ ë¡œê·¸ ë””ë ‰í† ë¦¬: /home/ieyeppo/AI_Lab/computer-vision-competition-1SEN/notebooks/team/KBH/F1_0_934_swinb/20250908_095705\n",
      "âœ… ë…¸íŠ¸ë¶ ë¡œê±° ì„¤ì • ì™„ë£Œ!\n",
      "ğŸ“ ë¡œê·¸ ê²½ë¡œ: /home/ieyeppo/AI_Lab/computer-vision-competition-1SEN/notebooks/team/KBH/F1_0_934_swinb/20250908_095705/logs\n"
     ]
    }
   ],
   "source": [
    "# [ì¶”ê°€] ë…¸íŠ¸ë¶ ë¡œê±° ì„¤ì •\n",
    "# ê²°ê³¼ ì €ì¥ì„ ìœ„í•œ ë¡œê±° ì´ˆê¸°í™”\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('../../../')  # í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¡œ ê²½ë¡œ ì¶”ê°€\n",
    "\n",
    "from src.logging.notebook_logger import create_notebook_logger\n",
    "\n",
    "# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ ì°¾ê¸°\n",
    "current_dir = os.getcwd()\n",
    "if 'notebooks/team/KBH' in current_dir:\n",
    "    project_root = current_dir.replace('/notebooks/team/KBH', '')\n",
    "else:\n",
    "    project_root = os.path.abspath('../../../')\n",
    "\n",
    "# ì ˆëŒ€ ê²½ë¡œë¡œ íŒ€ ë…¸íŠ¸ë¶ ë¡œê±° ì´ˆê¸°í™”\n",
    "base_log_path = os.path.join(project_root, \"notebooks/team\")\n",
    "logger = create_notebook_logger(\n",
    "    base_log_dir=base_log_path,\n",
    "    folder_name=\"KBH\", \n",
    "    file_name=\"F1_0_934_swinb\"\n",
    ")\n",
    "\n",
    "print(\"âœ… ë…¸íŠ¸ë¶ ë¡œê±° ì„¤ì • ì™„ë£Œ!\")\n",
    "print(f\"ğŸ“ ë¡œê·¸ ê²½ë¡œ: {logger.log_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì‹¤ì œ ê¸°ë³¸ ë””ë ‰í† ë¦¬: notebooks/team/KBH/F1_0_934_swinb/20250908_095307\n",
      "ë¡œê·¸ ë””ë ‰í† ë¦¬: notebooks/team/KBH/F1_0_934_swinb/20250908_095307/logs\n",
      "í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬: /home/ieyeppo/AI_Lab/computer-vision-competition-1SEN/notebooks/team/KBH\n",
      "âœ… ë¡œê·¸ ë””ë ‰í† ë¦¬ ì¡´ì¬í•¨: notebooks/team/KBH/F1_0_934_swinb/20250908_095307/logs\n"
     ]
    }
   ],
   "source": [
    "# ë¡œê±° ê²½ë¡œ í™•ì¸\n",
    "print(f\"ì‹¤ì œ ê¸°ë³¸ ë””ë ‰í† ë¦¬: {logger.base_dir}\")\n",
    "print(f\"ë¡œê·¸ ë””ë ‰í† ë¦¬: {logger.log_dir}\")\n",
    "import os\n",
    "print(f\"í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬: {os.getcwd()}\")\n",
    "\n",
    "# ë””ë ‰í† ë¦¬ ì¡´ì¬ í™•ì¸\n",
    "if logger.log_dir.exists():\n",
    "    print(f\"âœ… ë¡œê·¸ ë””ë ‰í† ë¦¬ ì¡´ì¬í•¨: {logger.log_dir}\")\n",
    "else:\n",
    "    print(f\"âŒ ë¡œê·¸ ë””ë ‰í† ë¦¬ ì—†ìŒ: {logger.log_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‹œë“œë¥¼ ê³ ì •í•©ë‹ˆë‹¤.\n",
    "SEED = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 241,
     "status": "ok",
     "timestamp": 1700314772722,
     "user": {
      "displayName": "Ynot(ì†¡ì›í˜¸)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "Hyl8oAy6TZAu"
   },
   "outputs": [],
   "source": [
    "# ë°ì´í„°ì…‹ í´ë˜ìŠ¤ë¥¼ ì •ì˜í•©ë‹ˆë‹¤. (Hard Augmentation í¬í•¨)\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, data, path, epoch=0, total_epochs=10, is_train=True):\n",
    "        if isinstance(data, str):\n",
    "            self.df = pd.read_csv(data).values\n",
    "        else:\n",
    "            self.df = data.values\n",
    "        self.path = path\n",
    "        self.epoch = epoch\n",
    "        self.total_epochs = total_epochs\n",
    "        self.is_train = is_train\n",
    "        \n",
    "        # Hard augmentation í™•ë¥  ê³„ì‚°\n",
    "        self.p_hard = 0.2 + 0.3 * (epoch / total_epochs) if is_train else 0\n",
    "        \n",
    "        # Normal augmentation\n",
    "        self.normal_aug = A.Compose([\n",
    "            A.LongestMaxSize(max_size=img_size),\n",
    "            A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "            A.OneOf([\n",
    "                A.Rotate(limit=[90,90], p=1.0),\n",
    "                A.Rotate(limit=[180,180], p=1.0),\n",
    "                A.Rotate(limit=[270,270], p=1.0),\n",
    "            ], p=0.6),\n",
    "            A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=0.8),\n",
    "            A.GaussNoise(var_limit=(30.0, 100.0), p=0.7),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "        \n",
    "        # Hard augmentation\n",
    "        self.hard_aug = A.Compose([\n",
    "            A.LongestMaxSize(max_size=img_size),\n",
    "            A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "            A.OneOf([\n",
    "                A.Rotate(limit=[90,90], p=1.0),\n",
    "                A.Rotate(limit=[180,180], p=1.0),\n",
    "                A.Rotate(limit=[270,270], p=1.0),\n",
    "                A.Rotate(limit=[-15,15], p=1.0),\n",
    "            ], p=0.8),\n",
    "            A.OneOf([\n",
    "                A.MotionBlur(blur_limit=15, p=1.0),\n",
    "                A.GaussianBlur(blur_limit=15, p=1.0),\n",
    "            ], p=0.95),\n",
    "            A.RandomBrightnessContrast(brightness_limit=0.5, contrast_limit=0.5, p=0.9),\n",
    "            A.GaussNoise(var_limit=(50.0, 150.0), p=0.8),\n",
    "            A.JpegCompression(quality_lower=70, quality_upper=100, p=0.5),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        name, target = self.df[idx]\n",
    "        img = np.array(Image.open(os.path.join(self.path, name)))\n",
    "        \n",
    "        # ë°°ì¹˜ë³„ ì¦ê°• ì„ íƒ\n",
    "        if self.is_train and random.random() < self.p_hard:\n",
    "            img = self.hard_aug(image=img)['image']\n",
    "        else:\n",
    "            img = self.normal_aug(image=img)['image']\n",
    "        \n",
    "        return img, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 255,
     "status": "ok",
     "timestamp": 1700315066028,
     "user": {
      "displayName": "Ynot(ì†¡ì›í˜¸)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "kTECBJfVTbdl"
   },
   "outputs": [],
   "source": [
    "# one epoch í•™ìŠµì„ ìœ„í•œ í•¨ìˆ˜ì…ë‹ˆë‹¤.\n",
    "def train_one_epoch(loader, model, optimizer, loss_fn, device):\n",
    "    scaler = GradScaler()  # Mixed Precisionìš©\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    preds_list = []\n",
    "    targets_list = []\n",
    "\n",
    "    pbar = tqdm(loader)\n",
    "    for image, targets in pbar:\n",
    "        image = image.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        # Cutmix/Mixup ì ìš© (30% í™•ë¥ )\n",
    "        if random.random() < 0.3:\n",
    "            mixed_x, y_a, y_b, lam = mixup_data(image, targets, alpha=1.0)\n",
    "            with autocast(): preds = model(mixed_x)\n",
    "            loss = lam * loss_fn(preds, y_a) + (1 - lam) * loss_fn(preds, y_b)\n",
    "        else:\n",
    "            with autocast(): preds = model(image)\n",
    "            loss = loss_fn(preds, targets)\n",
    "\n",
    "        model.zero_grad(set_to_none=True)\n",
    "\n",
    "        scaler.scale(loss).backward()  # Mixed Precisionìš©\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        scaler.step(optimizer); scaler.update()  # Mixed Precisionìš©\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
    "        targets_list.extend(targets.detach().cpu().numpy())\n",
    "\n",
    "        pbar.set_description(f\"Loss: {loss.item():.4f}\")\n",
    "\n",
    "    train_loss /= len(loader)\n",
    "    train_acc = accuracy_score(targets_list, preds_list)\n",
    "    train_f1 = f1_score(targets_list, preds_list, average='macro')\n",
    "\n",
    "    ret = {\n",
    "        \"train_loss\": train_loss,\n",
    "        \"train_acc\": train_acc,\n",
    "        \"train_f1\": train_f1,\n",
    "    }\n",
    "\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [ì¶”ê°€] í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì • ì €ì¥\n",
    "# í˜„ì¬ ì‹¤í—˜ ì„¤ì •ì„ ì €ì¥\n",
    "hyperparams = {\n",
    "    'model_name': model_name,\n",
    "    'img_size': img_size,\n",
    "    'lr': LR,\n",
    "    'epochs': EPOCHS,\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'num_workers': num_workers,\n",
    "    'n_folds': N_FOLDS,\n",
    "    'use_optuna': USE_OPTUNA,\n",
    "    'seed': SEED\n",
    "}\n",
    "\n",
    "# í•˜ì´í¼íŒŒë¼ë¯¸í„° ì €ì¥\n",
    "logger.save_json(hyperparams, 'hyperparameters', 'ì‹¤í—˜ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •')\n",
    "\n",
    "print(\"âœ… í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì • ì €ì¥ ì™„ë£Œ!\")\n",
    "print(f\"ğŸ“Š ëª¨ë¸: {model_name}, ì´ë¯¸ì§€ í¬ê¸°: {img_size}, ë°°ì¹˜ í¬ê¸°: {BATCH_SIZE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validationì„ ìœ„í•œ í•¨ìˆ˜ ì¶”ê°€\n",
    "def validate_one_epoch(loader, model, loss_fn, device):\n",
    "    \"\"\"\n",
    "    í•œ ì—í­ ê²€ì¦ì„ ìˆ˜í–‰í•˜ëŠ” í•¨ìˆ˜\n",
    "    - model.eval()ë¡œ ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ ì „í™˜\n",
    "    - torch.no_grad()ë¡œ gradient ê³„ì‚° ë¹„í™œì„±í™”í•˜ì—¬ ë©”ëª¨ë¦¬ ì ˆì•½\n",
    "    - ê²€ì¦ ë°ì´í„°ì— ëŒ€í•œ loss, accuracy, f1 score ê³„ì‚°\n",
    "    \"\"\"\n",
    "    model.eval()  # ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ ì „í™˜ (dropout, batchnorm ë¹„í™œì„±í™”)\n",
    "    val_loss = 0\n",
    "    preds_list = []\n",
    "    targets_list = []\n",
    "    \n",
    "    with torch.no_grad():  # gradient ê³„ì‚° ë¹„í™œì„±í™”ë¡œ ë©”ëª¨ë¦¬ ì ˆì•½\n",
    "        pbar = tqdm(loader, desc=\"Validating\")\n",
    "        for image, targets in pbar:\n",
    "            image = image.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            preds = model(image)  # ëª¨ë¸ ì˜ˆì¸¡\n",
    "            loss = loss_fn(preds, targets)  # ì†ì‹¤ ê³„ì‚°\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())  # ì˜ˆì¸¡ í´ë˜ìŠ¤ ì €ì¥\n",
    "            targets_list.extend(targets.detach().cpu().numpy())  # ì‹¤ì œ í´ë˜ìŠ¤ ì €ì¥\n",
    "            \n",
    "            pbar.set_description(f\"Val Loss: {loss.item():.4f}\")\n",
    "    \n",
    "    val_loss /= len(loader)  # í‰ê·  ì†ì‹¤ ê³„ì‚°\n",
    "    val_acc = accuracy_score(targets_list, preds_list)  # ì •í™•ë„ ê³„ì‚°\n",
    "    val_f1 = f1_score(targets_list, preds_list, average='macro')  # Macro F1 ê³„ì‚° (ëŒ€íšŒ í‰ê°€ì§€í‘œ)\n",
    "    \n",
    "    ret = {\n",
    "        \"val_loss\": val_loss,\n",
    "        \"val_acc\": val_acc,\n",
    "        \"val_f1\": val_f1,\n",
    "    }\n",
    "    \n",
    "    return ret"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Wjom43UvoXcx"
   },
   "source": [
    "## 3. Hyper-parameters\n",
    "* í•™ìŠµ ë° ì¶”ë¡ ì— í•„ìš”í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë“¤ì„ ì •ì˜í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 436,
     "status": "ok",
     "timestamp": 1700315112439,
     "user": {
      "displayName": "Ynot(ì†¡ì›í˜¸)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "KByfAeRmXwYk"
   },
   "outputs": [],
   "source": [
    "# device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# data config\n",
    "data_path = '../data/'\n",
    "\n",
    "# model config\n",
    "# model_name = 'tf_efficientnetv2_b3' # 'resnet50' 'efficientnet-b0', ...\n",
    "model_name = 'swin_base_patch4_window12_384_in22k'\n",
    "\n",
    "# training config\n",
    "img_size = 384\n",
    "LR = 5e-4\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 32\n",
    "num_workers = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optunaë¥¼ ì‚¬ìš©í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ (ì„ íƒì  ì‹¤í–‰)\n",
    "USE_OPTUNA = False  # Trueë¡œ ë°”ê¾¸ë©´ íŠœë‹ ì‹¤í–‰\n",
    "\n",
    "if USE_OPTUNA:\n",
    "    def objective(trial):\n",
    "        lr = trial.suggest_loguniform('lr', 1e-5, 1e-2)\n",
    "        batch_size = trial.suggest_categorical('batch_size', [32, 64, 128])\n",
    "        \n",
    "        # ê°„ë‹¨í•œ 3-fold CVë¡œ ë¹ ë¥¸ í‰ê°€\n",
    "        skf_simple = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "        fold_scores = []\n",
    "        \n",
    "        for fold, (train_idx, val_idx) in enumerate(skf_simple.split(train_df, train_df['target'])):\n",
    "            # ëª¨ë¸ ìƒì„±\n",
    "            model = timm.create_model(model_name, pretrained=True, num_classes=17).to(device)\n",
    "            optimizer = Adam(model.parameters(), lr=lr)\n",
    "            loss_fn = nn.CrossEntropyLoss()\n",
    "            \n",
    "            # ê°„ë‹¨í•œ 2 epoch í•™ìŠµ\n",
    "            for epoch in range(2):\n",
    "                train_ret = train_one_epoch(trn_loader, model, optimizer, loss_fn, device)\n",
    "            \n",
    "            val_ret = validate_one_epoch(val_loader, model, loss_fn, device)\n",
    "            fold_scores.append(val_ret['val_f1'])\n",
    "        \n",
    "        return np.mean(fold_scores)\n",
    "    \n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=10)\n",
    "    \n",
    "    # ìµœì  íŒŒë¼ë¯¸í„° ì ìš©\n",
    "    LR = study.best_params['lr']\n",
    "    BATCH_SIZE = study.best_params['batch_size']\n",
    "    print(f\"Best params: {study.best_params}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "amum-FlIojc6"
   },
   "source": [
    "## 4. Load Data\n",
    "* í•™ìŠµ, í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ê³¼ ë¡œë”ë¥¼ ì •ì˜í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1700315112439,
     "user": {
      "displayName": "Ynot(ì†¡ì›í˜¸)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "llh5C7ZKoq2S"
   },
   "outputs": [],
   "source": [
    "# # augmentationì„ ìœ„í•œ transform ì½”ë“œ\n",
    "# trn_transform = A.Compose([\n",
    "#     # ë¹„ìœ¨ ë³´ì¡´ ë¦¬ì‚¬ì´ì§• (í•µì‹¬ ê°œì„ )\n",
    "#     A.LongestMaxSize(max_size=img_size),\n",
    "#     A.PadIfNeeded(min_height=img_size, min_width=img_size, \n",
    "#                   border_mode=0, value=0),\n",
    "    \n",
    "#     # ë¬¸ì„œ íŠ¹í™” íšŒì „ (ì •í™•í•œ 90ë„ ë°°ìˆ˜)\n",
    "#     A.OneOf([\n",
    "#         A.Rotate(limit=[90,90], p=1.0),\n",
    "#         A.Rotate(limit=[180,180], p=1.0),\n",
    "#         A.Rotate(limit=[270,270], p=1.0),\n",
    "#     ], p=0.6),\n",
    "    \n",
    "#     # í…ŒìŠ¤íŠ¸ íŠ¹í™” ê°•í™” ì¦ê°•\n",
    "#     A.OneOf([\n",
    "#         A.MotionBlur(blur_limit=7, p=1.0),\n",
    "#         A.GaussianBlur(blur_limit=7, p=1.0),\n",
    "#     ], p=0.9),\n",
    "    \n",
    "#     A.RandomBrightnessContrast(\n",
    "#         brightness_limit=0.3, \n",
    "#         contrast_limit=0.3, \n",
    "#         p=0.8\n",
    "#     ),\n",
    "#     A.GaussNoise(var_limit=(30.0, 100.0), p=0.7),\n",
    "#     A.HorizontalFlip(p=0.5),\n",
    "    \n",
    "#     A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "#     ToTensorV2(),\n",
    "# ])\n",
    "\n",
    "# # test image ë³€í™˜ì„ ìœ„í•œ transform ì½”ë“œ\n",
    "# tst_transform = A.Compose([\n",
    "#     A.LongestMaxSize(max_size=img_size),\n",
    "#     A.PadIfNeeded(min_height=img_size, min_width=img_size, \n",
    "#                   border_mode=0, value=0),\n",
    "#     A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "#     ToTensorV2(),\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optuna íŠœë‹ (ì„ íƒì  ì‹¤í–‰)\n",
    "USE_OPTUNA = False  # Trueë¡œ ë°”ê¾¸ë©´ íŠœë‹ ì‹¤í–‰\n",
    "\n",
    "if USE_OPTUNA:\n",
    "    # ìœ„ì˜ objective í•¨ìˆ˜ì™€ study ì½”ë“œ\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Fold ì ìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 5-Fold Cross Validation...\n",
      "\n",
      "==================================================\n",
      "FOLD 1/5\n",
      "==================================================\n",
      "Train samples: 1256, Validation samples: 314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2568: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:29<00:00,  1.36it/s]\n",
      "Val Loss: 1.2543: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1 | Train Loss: 2.0037 | Train F1: 0.3924 | Val Loss: 1.2250 | Val F1: 0.7012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 1.4023: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:24<00:00,  1.65it/s]\n",
      "Val Loss: 0.9299: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  2 | Train Loss: 1.3647 | Train F1: 0.5950 | Val Loss: 0.8975 | Val F1: 0.8432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 1.6816: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:23<00:00,  1.69it/s]\n",
      "Val Loss: 0.9034: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  3 | Train Loss: 1.1569 | Train F1: 0.7036 | Val Loss: 0.8661 | Val F1: 0.8768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.9531: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:23<00:00,  1.69it/s]\n",
      "Val Loss: 0.8864: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  4 | Train Loss: 1.0904 | Train F1: 0.7165 | Val Loss: 0.8224 | Val F1: 0.8987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.9990: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:23<00:00,  1.70it/s]\n",
      "Val Loss: 1.0481: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  5 | Train Loss: 1.0137 | Train F1: 0.7544 | Val Loss: 0.8708 | Val F1: 0.8378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.6543: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:24<00:00,  1.64it/s]\n",
      "Val Loss: 0.7578: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  6 | Train Loss: 1.0291 | Train F1: 0.7583 | Val Loss: 0.7916 | Val F1: 0.8884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.7822: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:22<00:00,  1.75it/s]\n",
      "Val Loss: 0.9114: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  7 | Train Loss: 0.9923 | Train F1: 0.7648 | Val Loss: 0.8177 | Val F1: 0.8995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.7070: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:23<00:00,  1.69it/s]\n",
      "Val Loss: 0.7943: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  8 | Train Loss: 0.9125 | Train F1: 0.7671 | Val Loss: 0.7620 | Val F1: 0.8981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.7827: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:24<00:00,  1.61it/s]\n",
      "Val Loss: 0.8543: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  9 | Train Loss: 0.8655 | Train F1: 0.7567 | Val Loss: 0.7964 | Val F1: 0.9095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.7524: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:24<00:00,  1.61it/s]\n",
      "Val Loss: 0.7355: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Train Loss: 0.8238 | Train F1: 0.8546 | Val Loss: 0.7477 | Val F1: 0.9193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.5879: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:23<00:00,  1.72it/s]\n",
      "Val Loss: 0.7626: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | Train Loss: 0.9413 | Train F1: 0.8249 | Val Loss: 0.7343 | Val F1: 0.9279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.6064: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:23<00:00,  1.71it/s]\n",
      "Val Loss: 0.8751: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | Train Loss: 0.8555 | Train F1: 0.8327 | Val Loss: 0.8045 | Val F1: 0.9153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.6162: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:23<00:00,  1.68it/s]\n",
      "Val Loss: 0.7245: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 | Train Loss: 0.8915 | Train F1: 0.7444 | Val Loss: 0.7215 | Val F1: 0.9475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.7129: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:24<00:00,  1.66it/s]\n",
      "Val Loss: 0.6447: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | Train Loss: 0.8637 | Train F1: 0.8191 | Val Loss: 0.7284 | Val F1: 0.9212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.5796: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:23<00:00,  1.73it/s]\n",
      "Val Loss: 0.6929: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 | Train Loss: 0.7969 | Train F1: 0.8266 | Val Loss: 0.7409 | Val F1: 0.9402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2227: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:23<00:00,  1.72it/s]\n",
      "Val Loss: 0.6763: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 | Train Loss: 0.9091 | Train F1: 0.7118 | Val Loss: 0.7330 | Val F1: 0.9329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3184: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:24<00:00,  1.65it/s]\n",
      "Val Loss: 0.7365: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 | Train Loss: 0.7641 | Train F1: 0.8623 | Val Loss: 0.7466 | Val F1: 0.9279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.5371: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:23<00:00,  1.73it/s]\n",
      "Val Loss: 0.6369: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 | Train Loss: 0.8158 | Train F1: 0.8095 | Val Loss: 0.7099 | Val F1: 0.9399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.5967: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:23<00:00,  1.69it/s]\n",
      "Val Loss: 0.6988: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 | Train Loss: 0.7236 | Train F1: 0.8890 | Val Loss: 0.7261 | Val F1: 0.9356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.8105: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:23<00:00,  1.71it/s]\n",
      "Val Loss: 0.6069: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 | Train Loss: 0.7599 | Train F1: 0.8715 | Val Loss: 0.7207 | Val F1: 0.9388\n",
      "Fold 1 Best Validation F1: 0.9475\n",
      "\n",
      "==================================================\n",
      "FOLD 2/5\n",
      "==================================================\n",
      "Train samples: 1256, Validation samples: 314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3867: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:23<00:00,  1.68it/s]\n",
      "Val Loss: 1.1320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1 | Train Loss: 1.8723 | Train F1: 0.4408 | Val Loss: 1.2795 | Val F1: 0.6270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.7754: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:23<00:00,  1.67it/s]\n",
      "Val Loss: 0.9377: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  2 | Train Loss: 1.2796 | Train F1: 0.6634 | Val Loss: 0.9480 | Val F1: 0.7922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 1.1191: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:23<00:00,  1.68it/s]\n",
      "Val Loss: 0.7414: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  3 | Train Loss: 1.1091 | Train F1: 0.7127 | Val Loss: 0.8365 | Val F1: 0.8370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.9658: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:23<00:00,  1.68it/s]\n",
      "Val Loss: 0.7499: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  4 | Train Loss: 1.0358 | Train F1: 0.8223 | Val Loss: 0.9291 | Val F1: 0.8351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.0254: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:23<00:00,  1.69it/s]\n",
      "Val Loss: 0.7028: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  5 | Train Loss: 1.0384 | Train F1: 0.7689 | Val Loss: 0.7793 | Val F1: 0.9023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 1.7578: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:23<00:00,  1.67it/s]\n",
      "Val Loss: 0.7572: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  6 | Train Loss: 1.0532 | Train F1: 0.7079 | Val Loss: 0.8718 | Val F1: 0.8347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.9277: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:23<00:00,  1.70it/s]\n",
      "Val Loss: 0.6496: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  7 | Train Loss: 0.9429 | Train F1: 0.7989 | Val Loss: 0.7742 | Val F1: 0.9001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.7754: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:23<00:00,  1.68it/s]\n",
      "Val Loss: 0.6797: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  8 | Train Loss: 0.9068 | Train F1: 0.7879 | Val Loss: 0.7555 | Val F1: 0.9157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 1.5996: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:23<00:00,  1.70it/s]\n",
      "Val Loss: 0.6526: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  9 | Train Loss: 0.9972 | Train F1: 0.7560 | Val Loss: 0.7549 | Val F1: 0.9010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.9365: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:23<00:00,  1.69it/s]\n",
      "Val Loss: 0.8229: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Train Loss: 0.9521 | Train F1: 0.7708 | Val Loss: 0.7730 | Val F1: 0.9050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.3516: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:24<00:00,  1.64it/s]\n",
      "Val Loss: 0.6619: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | Train Loss: 0.8708 | Train F1: 0.8149 | Val Loss: 0.7321 | Val F1: 0.9187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.7197: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:24<00:00,  1.65it/s]\n",
      "Val Loss: 0.6774: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | Train Loss: 0.8471 | Train F1: 0.8444 | Val Loss: 0.7228 | Val F1: 0.9278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.9629: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:23<00:00,  1.70it/s]\n",
      "Val Loss: 0.6331: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 | Train Loss: 0.8403 | Train F1: 0.8449 | Val Loss: 0.7168 | Val F1: 0.9275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.5977: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:24<00:00,  1.61it/s]\n",
      "Val Loss: 0.6389: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | Train Loss: 0.8177 | Train F1: 0.8825 | Val Loss: 0.7152 | Val F1: 0.9404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 1.2969: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:23<00:00,  1.67it/s]\n",
      "Val Loss: 0.6907: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 | Train Loss: 0.8936 | Train F1: 0.7050 | Val Loss: 0.7269 | Val F1: 0.9111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.6250: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:23<00:00,  1.69it/s]\n",
      "Val Loss: 0.6946: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 | Train Loss: 0.8032 | Train F1: 0.8051 | Val Loss: 0.7123 | Val F1: 0.9298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.6196: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:24<00:00,  1.65it/s]\n",
      "Val Loss: 0.6082: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 | Train Loss: 0.8000 | Train F1: 0.8980 | Val Loss: 0.7232 | Val F1: 0.9352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.5947: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:24<00:00,  1.63it/s]\n",
      "Val Loss: 0.6345: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 | Train Loss: 0.7160 | Train F1: 0.8874 | Val Loss: 0.7166 | Val F1: 0.9278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.5830: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:23<00:00,  1.70it/s]\n",
      "Val Loss: 0.6330: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:06<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 | Train Loss: 0.7860 | Train F1: 0.8209 | Val Loss: 0.7165 | Val F1: 0.9372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2129: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:23<00:00,  1.70it/s]\n",
      "Val Loss: 0.6289: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 | Train Loss: 0.7766 | Train F1: 0.8506 | Val Loss: 0.7085 | Val F1: 0.9431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 Best Validation F1: 0.9431\n",
      "\n",
      "==================================================\n",
      "FOLD 3/5\n",
      "==================================================\n",
      "Train samples: 1256, Validation samples: 314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.5186: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:23<00:00,  1.72it/s]\n",
      "Val Loss: 1.0456: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1 | Train Loss: 1.8147 | Train F1: 0.4777 | Val Loss: 1.1760 | Val F1: 0.7030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 1.1631: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:23<00:00,  1.70it/s]\n",
      "Val Loss: 0.9350: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  2 | Train Loss: 1.2947 | Train F1: 0.6759 | Val Loss: 0.9679 | Val F1: 0.7878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 1.0303: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:23<00:00,  1.67it/s]\n",
      "Val Loss: 0.9992: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  3 | Train Loss: 1.1376 | Train F1: 0.7261 | Val Loss: 0.9563 | Val F1: 0.7924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.6279: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:23<00:00,  1.68it/s]\n",
      "Val Loss: 0.8027: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  4 | Train Loss: 1.0885 | Train F1: 0.7199 | Val Loss: 0.8462 | Val F1: 0.8351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.7861: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:23<00:00,  1.67it/s]\n",
      "Val Loss: 0.8538: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:06<00:00,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  5 | Train Loss: 1.0883 | Train F1: 0.6872 | Val Loss: 0.8204 | Val F1: 0.8724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.6353: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:23<00:00,  1.69it/s]\n",
      "Val Loss: 0.8100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  6 | Train Loss: 0.9547 | Train F1: 0.7956 | Val Loss: 0.7998 | Val F1: 0.8865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.7261: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:24<00:00,  1.65it/s]\n",
      "Val Loss: 0.7827: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  7 | Train Loss: 1.0264 | Train F1: 0.7157 | Val Loss: 0.7843 | Val F1: 0.8787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.7568: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:23<00:00,  1.70it/s]\n",
      "Val Loss: 0.7992: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  8 | Train Loss: 0.9723 | Train F1: 0.7736 | Val Loss: 0.7970 | Val F1: 0.8758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.9316: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:23<00:00,  1.67it/s]\n",
      "Val Loss: 0.6488: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  9 | Train Loss: 0.8684 | Train F1: 0.8723 | Val Loss: 0.7548 | Val F1: 0.9140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.6123: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:24<00:00,  1.65it/s]\n",
      "Val Loss: 0.7635: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:06<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Train Loss: 0.9524 | Train F1: 0.7846 | Val Loss: 0.7655 | Val F1: 0.8961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.0283: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:23<00:00,  1.71it/s]\n",
      "Val Loss: 0.7395: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | Train Loss: 0.8667 | Train F1: 0.8416 | Val Loss: 0.7528 | Val F1: 0.9068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.6304: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:24<00:00,  1.67it/s]\n",
      "Val Loss: 0.7113: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | Train Loss: 0.8336 | Train F1: 0.9071 | Val Loss: 0.7195 | Val F1: 0.9043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.6133: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:24<00:00,  1.66it/s]\n",
      "Val Loss: 0.7336: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 | Train Loss: 0.8368 | Train F1: 0.8881 | Val Loss: 0.7168 | Val F1: 0.9196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.6279: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:24<00:00,  1.66it/s]\n",
      "Val Loss: 0.7820: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | Train Loss: 0.8450 | Train F1: 0.8187 | Val Loss: 0.7148 | Val F1: 0.9318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.5859: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:24<00:00,  1.65it/s]\n",
      "Val Loss: 0.7340: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 | Train Loss: 0.8355 | Train F1: 0.8150 | Val Loss: 0.7399 | Val F1: 0.9100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.0137: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:23<00:00,  1.67it/s]\n",
      "Val Loss: 0.6280: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 | Train Loss: 0.8300 | Train F1: 0.7953 | Val Loss: 0.7175 | Val F1: 0.9284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.5898: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:23<00:00,  1.69it/s]\n",
      "Val Loss: 0.7235: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:06<00:00,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 | Train Loss: 0.7810 | Train F1: 0.8202 | Val Loss: 0.7005 | Val F1: 0.9349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.6191: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:24<00:00,  1.63it/s]\n",
      "Val Loss: 0.7021: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 | Train Loss: 0.6822 | Train F1: 0.9109 | Val Loss: 0.7050 | Val F1: 0.9391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.6465: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:23<00:00,  1.70it/s]\n",
      "Val Loss: 0.7327: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:06<00:00,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 | Train Loss: 0.7382 | Train F1: 0.8600 | Val Loss: 0.7189 | Val F1: 0.9391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.6543: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:24<00:00,  1.63it/s]\n",
      "Val Loss: 0.7030: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 | Train Loss: 0.8063 | Train F1: 0.8631 | Val Loss: 0.7278 | Val F1: 0.9233\n",
      "Fold 3 Best Validation F1: 0.9391\n",
      "\n",
      "==================================================\n",
      "FOLD 4/5\n",
      "==================================================\n",
      "Train samples: 1256, Validation samples: 314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.7090: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:24<00:00,  1.66it/s]\n",
      "Val Loss: 1.1130: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:06<00:00,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1 | Train Loss: 1.8308 | Train F1: 0.4703 | Val Loss: 1.2078 | Val F1: 0.6995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 1.2227: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:23<00:00,  1.68it/s]\n",
      "Val Loss: 0.9368: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:06<00:00,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  2 | Train Loss: 1.3497 | Train F1: 0.6906 | Val Loss: 1.0112 | Val F1: 0.8522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 1.0586: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:24<00:00,  1.63it/s]\n",
      "Val Loss: 0.7853: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  3 | Train Loss: 1.0823 | Train F1: 0.7373 | Val Loss: 0.8750 | Val F1: 0.8709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.9102: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:24<00:00,  1.67it/s]\n",
      "Val Loss: 0.9011: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  4 | Train Loss: 1.0612 | Train F1: 0.7394 | Val Loss: 0.8875 | Val F1: 0.8309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.9404: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:24<00:00,  1.63it/s]\n",
      "Val Loss: 0.7499: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  5 | Train Loss: 1.0847 | Train F1: 0.7241 | Val Loss: 0.7957 | Val F1: 0.8881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.9790: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:24<00:00,  1.62it/s]\n",
      "Val Loss: 0.9357: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:06<00:00,  1.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  6 | Train Loss: 0.9515 | Train F1: 0.7942 | Val Loss: 0.8869 | Val F1: 0.8196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.6123: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:24<00:00,  1.64it/s]\n",
      "Val Loss: 0.6633: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  7 | Train Loss: 0.9102 | Train F1: 0.8148 | Val Loss: 0.8379 | Val F1: 0.8850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.6753: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:24<00:00,  1.66it/s]\n",
      "Val Loss: 0.6766: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:06<00:00,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  8 | Train Loss: 0.9810 | Train F1: 0.7801 | Val Loss: 0.7504 | Val F1: 0.9118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.9092: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:24<00:00,  1.65it/s]\n",
      "Val Loss: 0.6143: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  9 | Train Loss: 0.9682 | Train F1: 0.7845 | Val Loss: 0.7463 | Val F1: 0.9205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 1.5547: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:24<00:00,  1.66it/s]\n",
      "Val Loss: 0.7421: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:06<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Train Loss: 0.9661 | Train F1: 0.8566 | Val Loss: 0.7415 | Val F1: 0.8995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.7710: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:24<00:00,  1.61it/s]\n",
      "Val Loss: 0.6489: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | Train Loss: 0.9103 | Train F1: 0.8059 | Val Loss: 0.7230 | Val F1: 0.9227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.7539: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:23<00:00,  1.70it/s]\n",
      "Val Loss: 0.6880: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:06<00:00,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | Train Loss: 0.8898 | Train F1: 0.7453 | Val Loss: 0.7698 | Val F1: 0.9107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.6309: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:23<00:00,  1.69it/s]\n",
      "Val Loss: 0.6290: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 | Train Loss: 0.8137 | Train F1: 0.8462 | Val Loss: 0.7271 | Val F1: 0.9312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.7441: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:23<00:00,  1.72it/s]\n",
      "Val Loss: 0.7021: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | Train Loss: 0.8119 | Train F1: 0.8230 | Val Loss: 0.7021 | Val F1: 0.9461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 1.0088: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:23<00:00,  1.67it/s]\n",
      "Val Loss: 0.6733: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 | Train Loss: 0.8761 | Train F1: 0.7796 | Val Loss: 0.7647 | Val F1: 0.9143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.0527: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:24<00:00,  1.65it/s]\n",
      "Val Loss: 0.6236: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 | Train Loss: 0.9042 | Train F1: 0.7415 | Val Loss: 0.7062 | Val F1: 0.9288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.9551: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:23<00:00,  1.68it/s]\n",
      "Val Loss: 0.6260: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 | Train Loss: 0.8373 | Train F1: 0.8714 | Val Loss: 0.7270 | Val F1: 0.9352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.5840: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:23<00:00,  1.67it/s]\n",
      "Val Loss: 0.6241: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:06<00:00,  1.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 | Train Loss: 0.7310 | Train F1: 0.9306 | Val Loss: 0.6948 | Val F1: 0.9288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.5918: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:25<00:00,  1.60it/s]\n",
      "Val Loss: 0.6432: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:06<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 | Train Loss: 0.8061 | Train F1: 0.7990 | Val Loss: 0.7122 | Val F1: 0.9416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.6279: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:23<00:00,  1.67it/s]\n",
      "Val Loss: 0.6711: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:06<00:00,  1.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 | Train Loss: 0.7783 | Train F1: 0.8558 | Val Loss: 0.7201 | Val F1: 0.9206\n",
      "Fold 4 Best Validation F1: 0.9461\n",
      "\n",
      "==================================================\n",
      "FOLD 5/5\n",
      "==================================================\n",
      "Train samples: 1256, Validation samples: 314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2051: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:24<00:00,  1.67it/s]\n",
      "Val Loss: 1.2663: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1 | Train Loss: 1.9576 | Train F1: 0.4370 | Val Loss: 1.2684 | Val F1: 0.6660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 1.8535: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:24<00:00,  1.66it/s]\n",
      "Val Loss: 0.9549: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  2 | Train Loss: 1.4155 | Train F1: 0.6182 | Val Loss: 0.9896 | Val F1: 0.7892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.8340: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:24<00:00,  1.61it/s]\n",
      "Val Loss: 0.9622: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  3 | Train Loss: 1.1728 | Train F1: 0.6713 | Val Loss: 0.9774 | Val F1: 0.7631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2705: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:23<00:00,  1.69it/s]\n",
      "Val Loss: 0.9632: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  4 | Train Loss: 1.1576 | Train F1: 0.6804 | Val Loss: 0.8876 | Val F1: 0.8301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.7378: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:23<00:00,  1.67it/s]\n",
      "Val Loss: 0.8874: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:06<00:00,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  5 | Train Loss: 1.1542 | Train F1: 0.7554 | Val Loss: 0.8427 | Val F1: 0.8607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.9775: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:23<00:00,  1.70it/s]\n",
      "Val Loss: 0.7080: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  6 | Train Loss: 1.0956 | Train F1: 0.7371 | Val Loss: 0.7748 | Val F1: 0.9174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.8384: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:23<00:00,  1.67it/s]\n",
      "Val Loss: 0.6804: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:06<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  7 | Train Loss: 0.9416 | Train F1: 0.8094 | Val Loss: 0.7566 | Val F1: 0.9036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.7310: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:24<00:00,  1.63it/s]\n",
      "Val Loss: 0.7092: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  8 | Train Loss: 0.9970 | Train F1: 0.7450 | Val Loss: 0.7475 | Val F1: 0.8941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.6040: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:23<00:00,  1.70it/s]\n",
      "Val Loss: 0.7576: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  9 | Train Loss: 0.9321 | Train F1: 0.7721 | Val Loss: 0.7698 | Val F1: 0.9162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.9707: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:24<00:00,  1.62it/s]\n",
      "Val Loss: 0.6855: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:06<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Train Loss: 0.8651 | Train F1: 0.8189 | Val Loss: 0.7474 | Val F1: 0.9088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.6157: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:23<00:00,  1.67it/s]\n",
      "Val Loss: 0.7787: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | Train Loss: 0.8908 | Train F1: 0.8400 | Val Loss: 0.7699 | Val F1: 0.8855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.6631: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:24<00:00,  1.65it/s]\n",
      "Val Loss: 0.6866: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | Train Loss: 0.8589 | Train F1: 0.7863 | Val Loss: 0.7229 | Val F1: 0.9140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.5874: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:24<00:00,  1.66it/s]\n",
      "Val Loss: 0.7007: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 | Train Loss: 0.8791 | Train F1: 0.8066 | Val Loss: 0.7196 | Val F1: 0.9178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.6772: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:24<00:00,  1.64it/s]\n",
      "Val Loss: 0.7352: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | Train Loss: 0.8542 | Train F1: 0.8290 | Val Loss: 0.7334 | Val F1: 0.9324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.6387: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:23<00:00,  1.69it/s]\n",
      "Val Loss: 0.6491: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 | Train Loss: 0.8094 | Train F1: 0.8696 | Val Loss: 0.7284 | Val F1: 0.9221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.6040: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:23<00:00,  1.68it/s]\n",
      "Val Loss: 0.6037: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 | Train Loss: 0.7686 | Train F1: 0.8344 | Val Loss: 0.7007 | Val F1: 0.9615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.6152: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:23<00:00,  1.69it/s]\n",
      "Val Loss: 0.6080: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:06<00:00,  1.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 | Train Loss: 0.7907 | Train F1: 0.8664 | Val Loss: 0.7233 | Val F1: 0.9349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.0293: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:24<00:00,  1.64it/s]\n",
      "Val Loss: 0.6117: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 | Train Loss: 0.8034 | Train F1: 0.8847 | Val Loss: 0.7034 | Val F1: 0.9404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.5913: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:23<00:00,  1.72it/s]\n",
      "Val Loss: 0.5993: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 | Train Loss: 0.8408 | Train F1: 0.7995 | Val Loss: 0.6976 | Val F1: 0.9403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.5952: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:24<00:00,  1.65it/s]\n",
      "Val Loss: 0.6066: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:06<00:00,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 | Train Loss: 0.8620 | Train F1: 0.8840 | Val Loss: 0.6874 | Val F1: 0.9508\n",
      "Fold 5 Best Validation F1: 0.9615\n",
      "\n",
      "============================================================\n",
      "K-FOLD CROSS VALIDATION RESULTS\n",
      "============================================================\n",
      "Fold 1: 0.9475\n",
      "Fold 2: 0.9431\n",
      "Fold 3: 0.9391\n",
      "Fold 4: 0.9461\n",
      "Fold 5: 0.9615\n",
      "\n",
      "Mean CV F1: 0.9475 Â± 0.0076\n",
      "Best single fold: 0.9615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# K-Fold ì„¤ì •\n",
    "N_FOLDS = 5  # 5-foldë¡œ ì„¤ì • (ë°ì´í„°ê°€ ì ìœ¼ë¯€ë¡œ)\n",
    "skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=42)\n",
    "\n",
    "# í´ë˜ìŠ¤ë³„ ìµœì†Œ ìƒ˜í”Œ ë³´ì¥ í™•ì¸\n",
    "# for fold, (train_idx, val_idx) in enumerate(skf.split(train_df, train_df['target'])):\n",
    "#     assert len(np.unique(train_df.iloc[val_idx]['target'])) == 17\n",
    "\n",
    "# ì „ì²´ í•™ìŠµ ë°ì´í„° ë¡œë“œ\n",
    "train_df = pd.read_csv(\"../data/train.csv\")\n",
    "\n",
    "# K-Fold ê²°ê³¼ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸\n",
    "fold_results = []\n",
    "fold_models = []  # ê° foldì˜ ìµœê³  ì„±ëŠ¥ ëª¨ë¸ì„ ì €ì¥\n",
    "fold_class_accuracies = [] # ê° foldì˜ í´ë˜ìŠ¤ë³„ ì •í™•ë„ ì €ì¥\n",
    "\n",
    "print(f\"Starting {N_FOLDS}-Fold Cross Validation...\")\n",
    "\n",
    "# LR = best_params['lr']\n",
    "# BATCH_SIZE = best_params['batch_size']\n",
    "\n",
    "# K-Fold Cross Validation ì‹œì‘\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(train_df, train_df['target'])):\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"FOLD {fold + 1}/{N_FOLDS}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    current_model = model_name\n",
    "    \n",
    "    # í˜„ì¬ foldì˜ train/validation ë°ì´í„° ë¶„í• \n",
    "    train_fold_df = train_df.iloc[train_idx].reset_index(drop=True)\n",
    "    val_fold_df = train_df.iloc[val_idx].reset_index(drop=True)\n",
    "    \n",
    "    # í˜„ì¬ foldì˜ Dataset ìƒì„±\n",
    "    trn_dataset = ImageDataset(\n",
    "        train_fold_df,\n",
    "        \"../data/train/\",\n",
    "        # transform=trn_transform\n",
    "        epoch=0,  # í˜„ì¬ epoch ì „ë‹¬\n",
    "        total_epochs=EPOCHS,\n",
    "        is_train=True\n",
    "    )\n",
    "    \n",
    "    val_dataset = ImageDataset(\n",
    "        val_fold_df,\n",
    "        \"../data/train/\",\n",
    "        # transform=tst_transform  # ê²€ì¦ì—ëŠ” ì¦ê°• ì ìš© ì•ˆí•¨\n",
    "        epoch=0,  # validationì€ epoch ê´€ê³„ì—†ìŒ\n",
    "        total_epochs=EPOCHS,\n",
    "        is_train=False  # validationì´ë¯€ë¡œ hard augmentation ë¹„í™œì„±í™”\n",
    "    )\n",
    "    \n",
    "    # í˜„ì¬ foldì˜ DataLoader ìƒì„±\n",
    "    trn_loader = DataLoader(\n",
    "        trn_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=False\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    print(f\"Train samples: {len(trn_dataset)}, Validation samples: {len(val_dataset)}\")\n",
    "    \n",
    "    # ëª¨ë¸ ì´ˆê¸°í™” (ê° foldë§ˆë‹¤ ìƒˆë¡œìš´ ëª¨ë¸)\n",
    "    model = timm.create_model(\n",
    "        current_model,\n",
    "        pretrained=True,\n",
    "        num_classes=17\n",
    "    ).to(device)\n",
    "    \n",
    "    loss_fn = nn.CrossEntropyLoss(label_smoothing=0.1)  # Label Smoothing ì ìš©\n",
    "    optimizer = Adam(model.parameters(), lr=LR)\n",
    "    \n",
    "    # Learning Rate Scheduler ì¶”ê°€\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "    \n",
    "    # í˜„ì¬ foldì˜ ìµœê³  ì„±ëŠ¥ ì¶”ì \n",
    "    best_val_f1 = 0.0\n",
    "    best_model = None\n",
    "    \n",
    "    # í˜„ì¬ fold í•™ìŠµ\n",
    "    for epoch in range(EPOCHS):\n",
    "        # Training\n",
    "        train_ret = train_one_epoch(trn_loader, model, optimizer, loss_fn, device)\n",
    "        \n",
    "        # Validation\n",
    "        val_ret = validate_one_epoch(val_loader, model, loss_fn, device)\n",
    "        \n",
    "        # Scheduler step ì¶”ê°€\n",
    "        scheduler.step()\n",
    "        \n",
    "        print(f\"Epoch {epoch+1:2d} | \"\n",
    "              f\"Train Loss: {train_ret['train_loss']:.4f} | \"\n",
    "              f\"Train F1: {train_ret['train_f1']:.4f} | \"\n",
    "              f\"Val Loss: {val_ret['val_loss']:.4f} | \"\n",
    "              f\"Val F1: {val_ret['val_f1']:.4f}\")\n",
    "        \n",
    "        # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥\n",
    "        if val_ret['val_f1'] > best_val_f1:\n",
    "            best_val_f1 = val_ret['val_f1']\n",
    "            best_model = copy.deepcopy(model.state_dict())\n",
    "            \n",
    "            # Best ëª¨ë¸ ë¶„ì„\n",
    "            model.eval()\n",
    "            val_preds, val_targets = [], []\n",
    "            with torch.no_grad():\n",
    "                for image, targets in val_loader:\n",
    "                    preds = model(image.to(device)).argmax(dim=1)\n",
    "                    val_preds.extend(preds.cpu().numpy())\n",
    "                    val_targets.extend(targets.numpy())\n",
    "            \n",
    "            # í´ë˜ìŠ¤ë³„ ì •í™•ë„\n",
    "            fold_class_acc = {}\n",
    "            for c in range(17):\n",
    "                mask = np.array(val_targets) == c\n",
    "                if mask.sum() > 0:\n",
    "                    fold_class_acc[c] = (np.array(val_preds)[mask] == c).mean()\n",
    "    \n",
    "    # í˜„ì¬ fold ê²°ê³¼ ì €ì¥\n",
    "    fold_results.append({\n",
    "        'fold': fold + 1,\n",
    "        'best_val_f1': best_val_f1,\n",
    "        'train_samples': len(trn_dataset),\n",
    "        'val_samples': len(val_dataset)\n",
    "    })\n",
    "    \n",
    "    fold_models.append(best_model)\n",
    "    \n",
    "    print(f\"Fold {fold + 1} Best Validation F1: {best_val_f1:.4f}\")\n",
    "    \n",
    "    fold_class_accuracies.append(fold_class_acc) # ê° foldì˜ í´ë˜ìŠ¤ë³„ ì •í™•ë„ ì €ì¥\n",
    "\n",
    "# K-Fold ê²°ê³¼ ìš”ì•½\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"K-FOLD CROSS VALIDATION RESULTS\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "val_f1_scores = [result['best_val_f1'] for result in fold_results]\n",
    "mean_f1 = np.mean(val_f1_scores)\n",
    "std_f1 = np.std(val_f1_scores)\n",
    "\n",
    "for result in fold_results:\n",
    "    print(f\"Fold {result['fold']}: {result['best_val_f1']:.4f}\")\n",
    "\n",
    "print(f\"\\nMean CV F1: {mean_f1:.4f} Â± {std_f1:.4f}\")\n",
    "print(f\"Best single fold: {max(val_f1_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worst 3 classes:\n",
      "Class 7: 72.0%\n",
      "Class 3: 74.0%\n",
      "Class 14: 76.0%\n"
     ]
    }
   ],
   "source": [
    "# í´ë˜ìŠ¤ë³„ ì„±ëŠ¥ ì‹œê°í™”\n",
    "meta_df = pd.read_csv(\"../data/meta.csv\")\n",
    "avg_acc = {c: np.mean([f.get(c,0) for f in fold_class_accuracies]) for c in range(17)}\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "classes = list(avg_acc.keys())\n",
    "accs = [avg_acc[c] * 100 for c in classes]\n",
    "names = [f\"C{c}\" for c in classes]\n",
    "\n",
    "plt.bar(range(17), accs)\n",
    "plt.xticks(range(17), names)\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Class-wise Prediction Accuracy')\n",
    "for i, acc in enumerate(accs):\n",
    "    plt.text(i, acc + 1, f'{acc:.1f}%', ha='center', fontsize=8)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Worst 3 classes:\")\n",
    "worst = sorted(avg_acc.items(), key=lambda x: x[1])[:3]\n",
    "for c, acc in worst:\n",
    "    print(f\"Class {c}: {acc*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using ensemble of all 5 fold models for inference\n"
     ]
    }
   ],
   "source": [
    "# 5-Fold ì•™ìƒë¸” ëª¨ë¸ ì¤€ë¹„\n",
    "ensemble_models = []\n",
    "for i, state_dict in enumerate(fold_models):\n",
    "    fold_model = timm.create_model(model_name, pretrained=True, num_classes=17).to(device)\n",
    "    fold_model.load_state_dict(state_dict)\n",
    "    fold_model.eval()\n",
    "    ensemble_models.append(fold_model)\n",
    "print(f\"Using ensemble of all {len(ensemble_models)} fold models for inference\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Nmm5h3J-pXNV"
   },
   "source": [
    "## 5. Train Model\n",
    "* ëª¨ë¸ì„ ë¡œë“œí•˜ê³ , í•™ìŠµì„ ì§„í–‰í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 870,
     "status": "ok",
     "timestamp": 1700315114067,
     "user": {
      "displayName": "Ynot(ì†¡ì›í˜¸)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "FbBgFPsLT-CO"
   },
   "outputs": [],
   "source": [
    "# # load model\n",
    "# model = timm.create_model(\n",
    "#     model_name,\n",
    "#     pretrained=True,\n",
    "#     num_classes=17\n",
    "# ).to(device)\n",
    "# loss_fn = nn.CrossEntropyLoss()\n",
    "# optimizer = Adam(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8778,
     "status": "ok",
     "timestamp": 1700315122843,
     "user": {
      "displayName": "Ynot(ì†¡ì›í˜¸)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "OvIVcSRgUPtS",
    "outputId": "88230bf2-976f-45f6-b3b7-1a2d0ad00548"
   },
   "outputs": [],
   "source": [
    "# for epoch in range(EPOCHS):\n",
    "#     ret = train_one_epoch(trn_loader, model, optimizer, loss_fn, device=device)\n",
    "#     ret['epoch'] = epoch\n",
    "\n",
    "#     log = \"\"\n",
    "#     for k, v in ret.items():\n",
    "#       log += f\"{k}: {v:.4f}\\n\"\n",
    "#     print(log)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "lkwxRXoBpbaX"
   },
   "source": [
    "# 6. Inference & Save File\n",
    "* í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ì— ëŒ€í•œ ì¶”ë¡ ì„ ì§„í–‰í•˜ê³ , ê²°ê³¼ íŒŒì¼ì„ ì €ì¥í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12776,
     "status": "ok",
     "timestamp": 1700315185336,
     "user": {
      "displayName": "Ynot(ì†¡ì›í˜¸)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "uRYe6jlPU_Om",
    "outputId": "2a08690c-9ffe-418d-8679-eb9280147110"
   },
   "outputs": [],
   "source": [
    "# preds_list = []\n",
    "\n",
    "# model.eval()\n",
    "# for image, _ in tqdm(tst_loader):\n",
    "#     image = image.to(device)\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         preds = model(image)\n",
    "#     preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 282,
     "status": "ok",
     "timestamp": 1700315216829,
     "user": {
      "displayName": "Ynot(ì†¡ì›í˜¸)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "aClN7Qi7VZoh"
   },
   "outputs": [],
   "source": [
    "# pred_df = pd.DataFrame(tst_dataset.df, columns=['ID', 'target'])\n",
    "# pred_df['target'] = preds_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1700315238836,
     "user": {
      "displayName": "Ynot(ì†¡ì›í˜¸)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "VDBXQqAzVvLY"
   },
   "outputs": [],
   "source": [
    "# sample_submission_df = pd.read_csv(\"../data/sample_submission.csv\")\n",
    "# assert (sample_submission_df['ID'] == pred_df['ID']).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 317,
     "status": "ok",
     "timestamp": 1700315244710,
     "user": {
      "displayName": "Ynot(ì†¡ì›í˜¸)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "ePx2vCELVnuS"
   },
   "outputs": [],
   "source": [
    "# pred_df.to_csv(\"pred.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temperature Scaling í´ë˜ìŠ¤ ì •ì˜\n",
    "class TemperatureScaling(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.temperature = nn.Parameter(torch.ones(1) * 1.5)\n",
    "    \n",
    "    def forward(self, logits):\n",
    "        return logits / self.temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "essential_tta_transforms = [\n",
    "    # ì›ë³¸\n",
    "    A.Compose([\n",
    "        A.LongestMaxSize(max_size=img_size),\n",
    "        A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "    # 90ë„ íšŒì „ë“¤\n",
    "    A.Compose([\n",
    "        A.LongestMaxSize(max_size=img_size),\n",
    "        A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "        A.Rotate(limit=[90, 90], p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "    A.Compose([\n",
    "        A.LongestMaxSize(max_size=img_size),\n",
    "        A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "        A.Rotate(limit=[180, 180], p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "    A.Compose([\n",
    "        A.LongestMaxSize(max_size=img_size),\n",
    "        A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "        A.Rotate(limit=[-90, -90], p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "    # ë°ê¸° ê°œì„ \n",
    "    A.Compose([\n",
    "        A.LongestMaxSize(max_size=img_size),\n",
    "        A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "        A.RandomBrightnessContrast(brightness_limit=[0.3, 0.3], contrast_limit=[0.3, 0.3], p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TTA ì¶”ë¡ ì„ ìœ„í•œ Dataset í´ë˜ìŠ¤\n",
    "class TTAImageDataset(Dataset):\n",
    "    def __init__(self, data, path, transforms):\n",
    "        if isinstance(data, str):\n",
    "            self.df = pd.read_csv(data).values\n",
    "        else:\n",
    "            self.df = data.values\n",
    "        self.path = path\n",
    "        self.transforms = transforms  # ì—¬ëŸ¬ transformì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë°›ìŒ\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        name, target = self.df[idx]\n",
    "        img = np.array(Image.open(os.path.join(self.path, name)))\n",
    "        \n",
    "        # ëª¨ë“  transformì„ ì ìš©í•œ ê²°ê³¼ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜\n",
    "        augmented_images = []\n",
    "        for transform in self.transforms:\n",
    "            aug_img = transform(image=img)['image']\n",
    "            augmented_images.append(aug_img)\n",
    "        \n",
    "        return augmented_images, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TTA Dataset size: 3140\n"
     ]
    }
   ],
   "source": [
    "# TTA Dataset ìƒì„±\n",
    "tta_dataset = TTAImageDataset(\n",
    "    \"../data/sample_submission.csv\",\n",
    "    \"../data/test/\",\n",
    "    essential_tta_transforms\n",
    ")\n",
    "\n",
    "# TTA DataLoader (ë°°ì¹˜ í¬ê¸°ë¥¼ ì¤„ì—¬ì„œ ë©”ëª¨ë¦¬ ì ˆì•½)\n",
    "tta_loader = DataLoader(\n",
    "    tta_dataset,\n",
    "    batch_size=64,  # TTAëŠ” ë©”ëª¨ë¦¬ë¥¼ ë§ì´ ì‚¬ìš©í•˜ë¯€ë¡œ ë°°ì¹˜ í¬ê¸° ì¤„ì„\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"TTA Dataset size: {len(tta_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_tta_inference(models, loader, transforms, confidence_threshold=0.9):\n",
    "    \"\"\"5-Fold ëª¨ë¸ ì•™ìƒë¸” + TTA ì¶”ë¡ \"\"\"\n",
    "    all_predictions = []\n",
    "    \n",
    "    for batch_idx, (images_list, _) in enumerate(tqdm(loader, desc=\"Ensemble TTA\")):\n",
    "        batch_size = images_list[0].size(0)\n",
    "        ensemble_probs = torch.zeros(batch_size, 17).to(device)\n",
    "        \n",
    "        # ê° fold ëª¨ë¸ë³„ ì˜ˆì¸¡\n",
    "        for model in models:\n",
    "            with torch.no_grad():\n",
    "                # ê° TTA ë³€í˜•ë³„ ì˜ˆì¸¡\n",
    "                for images in images_list:\n",
    "                    images = images.to(device)\n",
    "                    preds = model(images)\n",
    "                    probs = torch.softmax(preds, dim=1)\n",
    "                    ensemble_probs += probs / (len(models) * len(images_list))\n",
    "        \n",
    "        final_preds = torch.argmax(ensemble_probs, dim=1)\n",
    "        all_predictions.extend(final_preds.cpu().numpy())\n",
    "    \n",
    "    return all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Ensemble TTA inference...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ensemble TTA: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [13:15<00:00, 15.90s/it]\n"
     ]
    }
   ],
   "source": [
    "# ì•™ìƒë¸” TTA ì‹¤í–‰\n",
    "print(\"Starting Ensemble TTA inference...\")\n",
    "tta_predictions = ensemble_tta_inference(\n",
    "    models=ensemble_models, \n",
    "    loader=tta_loader, \n",
    "    transforms=essential_tta_transforms,\n",
    "    confidence_threshold=0.9\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TTA ê²°ê³¼ë¡œ submission íŒŒì¼ ìƒì„±\n",
    "tta_pred_df = pd.DataFrame(tta_dataset.df, columns=['ID', 'target'])\n",
    "tta_pred_df['target'] = tta_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê¸°ì¡´ submissionê³¼ ë™ì¼í•œ ìˆœì„œì¸ì§€ í™•ì¸\n",
    "sample_submission_df = pd.read_csv(\"../data/sample_submission.csv\")\n",
    "assert (sample_submission_df['ID'] == tta_pred_df['ID']).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TTA predictions saved\n",
      "TTA Prediction sample:\n"
     ]
    }
   ],
   "source": [
    "# TTA ê²°ê³¼ ì €ì¥\n",
    "tta_pred_df.to_csv(\"../submission/choice.csv\", index=False)\n",
    "print(\"TTA predictions saved\")\n",
    "\n",
    "print(\"TTA Prediction sample:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [ì¶”ê°€] ìµœì¢… ì‹¤í—˜ ê²°ê³¼ ì €ì¥\n",
    "# K-Fold êµì°¨ê²€ì¦ ê²°ê³¼ ì €ì¥\n",
    "try:\n",
    "    # K-Fold ê²°ê³¼ ìš”ì•½\n",
    "    kfold_summary = {\n",
    "        'n_folds': N_FOLDS,\n",
    "        'avg_val_f1': np.mean([result['best_val_f1'] for result in fold_results]),\n",
    "        'std_val_f1': np.std([result['best_val_f1'] for result in fold_results]),\n",
    "        'fold_results': fold_results\n",
    "    }\n",
    "    \n",
    "    # K-Fold ê²°ê³¼ ì €ì¥\n",
    "    logger.save_json(kfold_summary, 'kfold_results', 'K-Fold êµì°¨ê²€ì¦ ê²°ê³¼')\n",
    "    \n",
    "    # TTA ì˜ˆì¸¡ ê²°ê³¼ ë°ì´í„°í”„ë ˆì„ ì €ì¥\n",
    "    logger.save_dataframe(tta_pred_df, 'tta_predictions', 'TTA ì•™ìƒë¸” ì˜ˆì¸¡ ê²°ê³¼')\n",
    "    \n",
    "    # ìµœì¢… ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì €ì¥\n",
    "    final_metrics = {\n",
    "        'model_name': model_name,\n",
    "        'final_cv_f1': np.mean([result['best_val_f1'] for result in fold_results]),\n",
    "        'total_folds': N_FOLDS,\n",
    "        'submission_file': 'choice.csv',\n",
    "        'tta_enabled': True,\n",
    "        'timestamp': pd.Timestamp.now().isoformat()\n",
    "    }\n",
    "    \n",
    "    logger.save_json(final_metrics, 'final_performance', 'ìµœì¢… ì„±ëŠ¥ ë©”íŠ¸ë¦­')\n",
    "    \n",
    "    print(\"âœ… ëª¨ë“  ì‹¤í—˜ ê²°ê³¼ ì €ì¥ ì™„ë£Œ!\")\n",
    "    print(f\"ğŸ“Š í‰ê·  CV F1: {final_metrics['final_cv_f1']:.4f}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ ê²°ê³¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}\")\n",
    "    print(\"ë³€ìˆ˜ë“¤ì´ ì •ì˜ë˜ì§€ ì•Šì•˜ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì „ì²´ ë…¸íŠ¸ë¶ì„ ì‹¤í–‰í•œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 353,
     "status": "ok",
     "timestamp": 1700315247734,
     "user": {
      "displayName": "Ynot(ì†¡ì›í˜¸)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "9yMO8s6GqAwZ",
    "outputId": "9a30616f-f0ea-439f-a906-dd806737ce00"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0008fdb22ddce0ce.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00091bffdffd83de.jpg</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00396fbc1f6cc21d.jpg</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00471f8038d9c4b6.jpg</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00901f504008d884.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     ID  target\n",
       "0  0008fdb22ddce0ce.jpg       2\n",
       "1  00091bffdffd83de.jpg      12\n",
       "2  00396fbc1f6cc21d.jpg       5\n",
       "3  00471f8038d9c4b6.jpg      12\n",
       "4  00901f504008d884.jpg       2"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tta_pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [ì¶”ê°€] ë…¸íŠ¸ë¶ ì‘ì—… ì™„ë£Œ ë° ìš”ì•½\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ KBH F1_0.934 Swin-B ë…¸íŠ¸ë¶ ì‘ì—… ì™„ë£Œ!\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ë¡œê±° ì •ë³´ ì¶œë ¥\n",
    "logger.print_summary()\n",
    "\n",
    "print(\"\\nğŸ“„ ìƒì„±ëœ ì£¼ìš” ê²°ê³¼:\")\n",
    "print(\"   âœ… K-Fold êµì°¨ê²€ì¦ ê²°ê³¼\")\n",
    "print(\"   âœ… TTA ì•™ìƒë¸” ì˜ˆì¸¡ ê²°ê³¼\") \n",
    "print(\"   âœ… í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •\")\n",
    "print(\"   âœ… ìµœì¢… ì„±ëŠ¥ ë©”íŠ¸ë¦­\")\n",
    "print(\"   âœ… ì œì¶œìš© CSV íŒŒì¼: choice.csv\")\n",
    "\n",
    "print(f\"\\nğŸ’¾ ëª¨ë“  ê²°ê³¼ëŠ” ë‹¤ìŒ ë””ë ‰í† ë¦¬ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤:\")\n",
    "print(f\"   ğŸ“ {logger.log_dir}\")\n",
    "\n",
    "print(\"\\nğŸ¯ ì´ ë…¸íŠ¸ë¶ì€ íŒ€ ë…¸íŠ¸ë¶ í†µí•© ëª¨ë“ˆí™” í”„ë¡œì íŠ¸ì˜ ì¼í™˜ìœ¼ë¡œ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤.\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "cv_py3_11_9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
