{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "OliaDaX_lwou"
   },
   "source": [
    "# **ğŸ“„ Document type classification baseline code**\n",
    "> ë¬¸ì„œ íƒ€ì… ë¶„ë¥˜ ëŒ€íšŒì— ì˜¤ì‹  ì—¬ëŸ¬ë¶„ í™˜ì˜í•©ë‹ˆë‹¤! ğŸ‰     \n",
    "> ì•„ë˜ baselineì—ì„œëŠ” ResNet ëª¨ë¸ì„ ë¡œë“œí•˜ì—¬, ëª¨ë¸ì„ í•™ìŠµ ë° ì˜ˆì¸¡ íŒŒì¼ ìƒì„±í•˜ëŠ” í”„ë¡œì„¸ìŠ¤ì— ëŒ€í•´ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤.\n",
    "\n",
    "## Contents\n",
    "- Prepare Environments\n",
    "- Import Library & Define Functions\n",
    "- Hyper-parameters\n",
    "- Load Data\n",
    "- Train Model\n",
    "- Inference & Save File\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "zkH9T_86lDSS"
   },
   "source": [
    "## 1. Prepare Environments\n",
    "\n",
    "* ë°ì´í„° ë¡œë“œë¥¼ ìœ„í•œ êµ¬ê¸€ ë“œë¼ì´ë¸Œë¥¼ ë§ˆìš´íŠ¸í•©ë‹ˆë‹¤.\n",
    "* í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8489,
     "status": "ok",
     "timestamp": 1700314558888,
     "user": {
      "displayName": "Ynot(ì†¡ì›í˜¸)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "NC8V-D393wY4",
    "outputId": "e9927325-26c4-4b89-9c51-c1d6541388d6"
   },
   "outputs": [],
   "source": [
    "# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤.\n",
    "# !pip install timm\n",
    "# !pip install matplotlib\n",
    "# !pip install seaborn\n",
    "# !pip install optuna"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "PXa_FPM73R9f"
   },
   "source": [
    "## 2. Import Library & Define Functions\n",
    "* í•™ìŠµ ë° ì¶”ë¡ ì— í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.\n",
    "* í•™ìŠµ ë° ì¶”ë¡ ì— í•„ìš”í•œ í•¨ìˆ˜ì™€ í´ë˜ìŠ¤ë¥¼ ì •ì˜í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 9396,
     "status": "ok",
     "timestamp": 1700314592802,
     "user": {
      "displayName": "Ynot(ì†¡ì›í˜¸)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "3BaoIkv5Xwa0"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import copy\n",
    "\n",
    "import optuna, math\n",
    "import timm\n",
    "import torch\n",
    "import albumentations as A\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.optim import Adam\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.cuda.amp import autocast, GradScaler  # Mixed Precisionìš©\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "\n",
    "def mixup_data(x, y, alpha=1.0):\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "    batch_size = x.size()[0]\n",
    "    index = torch.randperm(batch_size).cuda()\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# í•œê¸€ í°íŠ¸ ì„¤ì • (ì‹œê°í™”ìš©)\n",
    "plt.rcParams['font.family'] = ['DejaVu Sans']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‹œë“œë¥¼ ê³ ì •í•©ë‹ˆë‹¤.\n",
    "SEED = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 241,
     "status": "ok",
     "timestamp": 1700314772722,
     "user": {
      "displayName": "Ynot(ì†¡ì›í˜¸)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "Hyl8oAy6TZAu"
   },
   "outputs": [],
   "source": [
    "# ë°ì´í„°ì…‹ í´ë˜ìŠ¤ë¥¼ ì •ì˜í•©ë‹ˆë‹¤. (Hard Augmentation í¬í•¨)\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, data, path, epoch=0, total_epochs=10, is_train=True):\n",
    "        if isinstance(data, str):\n",
    "            self.df = pd.read_csv(data).values\n",
    "        else:\n",
    "            self.df = data.values\n",
    "        self.path = path\n",
    "        self.epoch = epoch\n",
    "        self.total_epochs = total_epochs\n",
    "        self.is_train = is_train\n",
    "        \n",
    "        # Hard augmentation í™•ë¥  ê³„ì‚°\n",
    "        self.p_hard = 0.2 + 0.3 * (epoch / total_epochs) if is_train else 0\n",
    "        \n",
    "        # Normal augmentation\n",
    "        self.normal_aug = A.Compose([\n",
    "            A.LongestMaxSize(max_size=img_size),\n",
    "            A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "            A.OneOf([\n",
    "                A.Rotate(limit=[90,90], p=1.0),\n",
    "                A.Rotate(limit=[180,180], p=1.0),\n",
    "                A.Rotate(limit=[270,270], p=1.0),\n",
    "            ], p=0.6),\n",
    "            A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=0.8),\n",
    "            A.GaussNoise(var_limit=(30.0, 100.0), p=0.7),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "        \n",
    "        # Hard augmentation\n",
    "        self.hard_aug = A.Compose([\n",
    "            A.LongestMaxSize(max_size=img_size),\n",
    "            A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "            A.OneOf([\n",
    "                A.Rotate(limit=[90,90], p=1.0),\n",
    "                A.Rotate(limit=[180,180], p=1.0),\n",
    "                A.Rotate(limit=[270,270], p=1.0),\n",
    "                A.Rotate(limit=[-15,15], p=1.0),\n",
    "            ], p=0.8),\n",
    "            A.OneOf([\n",
    "                A.MotionBlur(blur_limit=15, p=1.0),\n",
    "                A.GaussianBlur(blur_limit=15, p=1.0),\n",
    "            ], p=0.95),\n",
    "            A.RandomBrightnessContrast(brightness_limit=0.5, contrast_limit=0.5, p=0.9),\n",
    "            A.GaussNoise(var_limit=(50.0, 150.0), p=0.8),\n",
    "            A.JpegCompression(quality_lower=70, quality_upper=100, p=0.5),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        name, target = self.df[idx]\n",
    "        img = np.array(Image.open(os.path.join(self.path, name)))\n",
    "        \n",
    "        # ë°°ì¹˜ë³„ ì¦ê°• ì„ íƒ\n",
    "        if self.is_train and random.random() < self.p_hard:\n",
    "            img = self.hard_aug(image=img)['image']\n",
    "        else:\n",
    "            img = self.normal_aug(image=img)['image']\n",
    "        \n",
    "        return img, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 255,
     "status": "ok",
     "timestamp": 1700315066028,
     "user": {
      "displayName": "Ynot(ì†¡ì›í˜¸)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "kTECBJfVTbdl"
   },
   "outputs": [],
   "source": [
    "# one epoch í•™ìŠµì„ ìœ„í•œ í•¨ìˆ˜ì…ë‹ˆë‹¤.\n",
    "def train_one_epoch(loader, model, optimizer, loss_fn, device):\n",
    "    scaler = GradScaler()  # Mixed Precisionìš©\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    preds_list = []\n",
    "    targets_list = []\n",
    "\n",
    "    pbar = tqdm(loader)\n",
    "    for image, targets in pbar:\n",
    "        image = image.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        # Cutmix/Mixup ì ìš© (30% í™•ë¥ )\n",
    "        if random.random() < 0.3:\n",
    "            mixed_x, y_a, y_b, lam = mixup_data(image, targets, alpha=1.0)\n",
    "            with autocast(): preds = model(mixed_x)\n",
    "            loss = lam * loss_fn(preds, y_a) + (1 - lam) * loss_fn(preds, y_b)\n",
    "        else:\n",
    "            with autocast(): preds = model(image)\n",
    "            loss = loss_fn(preds, targets)\n",
    "\n",
    "        model.zero_grad(set_to_none=True)\n",
    "\n",
    "        scaler.scale(loss).backward()  # Mixed Precisionìš©\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        scaler.step(optimizer); scaler.update()  # Mixed Precisionìš©\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
    "        targets_list.extend(targets.detach().cpu().numpy())\n",
    "\n",
    "        pbar.set_description(f\"Loss: {loss.item():.4f}\")\n",
    "\n",
    "    train_loss /= len(loader)\n",
    "    train_acc = accuracy_score(targets_list, preds_list)\n",
    "    train_f1 = f1_score(targets_list, preds_list, average='macro')\n",
    "\n",
    "    ret = {\n",
    "        \"train_loss\": train_loss,\n",
    "        \"train_acc\": train_acc,\n",
    "        \"train_f1\": train_f1,\n",
    "    }\n",
    "\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validationì„ ìœ„í•œ í•¨ìˆ˜ ì¶”ê°€\n",
    "def validate_one_epoch(loader, model, loss_fn, device):\n",
    "    \"\"\"\n",
    "    í•œ ì—í­ ê²€ì¦ì„ ìˆ˜í–‰í•˜ëŠ” í•¨ìˆ˜\n",
    "    - model.eval()ë¡œ ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ ì „í™˜\n",
    "    - torch.no_grad()ë¡œ gradient ê³„ì‚° ë¹„í™œì„±í™”í•˜ì—¬ ë©”ëª¨ë¦¬ ì ˆì•½\n",
    "    - ê²€ì¦ ë°ì´í„°ì— ëŒ€í•œ loss, accuracy, f1 score ê³„ì‚°\n",
    "    \"\"\"\n",
    "    model.eval()  # ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ ì „í™˜ (dropout, batchnorm ë¹„í™œì„±í™”)\n",
    "    val_loss = 0\n",
    "    preds_list = []\n",
    "    targets_list = []\n",
    "    \n",
    "    with torch.no_grad():  # gradient ê³„ì‚° ë¹„í™œì„±í™”ë¡œ ë©”ëª¨ë¦¬ ì ˆì•½\n",
    "        pbar = tqdm(loader, desc=\"Validating\")\n",
    "        for image, targets in pbar:\n",
    "            image = image.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            preds = model(image)  # ëª¨ë¸ ì˜ˆì¸¡\n",
    "            loss = loss_fn(preds, targets)  # ì†ì‹¤ ê³„ì‚°\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())  # ì˜ˆì¸¡ í´ë˜ìŠ¤ ì €ì¥\n",
    "            targets_list.extend(targets.detach().cpu().numpy())  # ì‹¤ì œ í´ë˜ìŠ¤ ì €ì¥\n",
    "            \n",
    "            pbar.set_description(f\"Val Loss: {loss.item():.4f}\")\n",
    "    \n",
    "    val_loss /= len(loader)  # í‰ê·  ì†ì‹¤ ê³„ì‚°\n",
    "    val_acc = accuracy_score(targets_list, preds_list)  # ì •í™•ë„ ê³„ì‚°\n",
    "    val_f1 = f1_score(targets_list, preds_list, average='macro')  # Macro F1 ê³„ì‚° (ëŒ€íšŒ í‰ê°€ì§€í‘œ)\n",
    "    \n",
    "    ret = {\n",
    "        \"val_loss\": val_loss,\n",
    "        \"val_acc\": val_acc,\n",
    "        \"val_f1\": val_f1,\n",
    "    }\n",
    "    \n",
    "    return ret"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Wjom43UvoXcx"
   },
   "source": [
    "## 3. Hyper-parameters\n",
    "* í•™ìŠµ ë° ì¶”ë¡ ì— í•„ìš”í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë“¤ì„ ì •ì˜í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 436,
     "status": "ok",
     "timestamp": 1700315112439,
     "user": {
      "displayName": "Ynot(ì†¡ì›í˜¸)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "KByfAeRmXwYk"
   },
   "outputs": [],
   "source": [
    "# device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# data config\n",
    "data_path = '../data/'\n",
    "\n",
    "# model config\n",
    "# model_name = 'tf_efficientnetv2_b3' # 'resnet50' 'efficientnet-b0', ...\n",
    "# model_name = 'swin_base_patch4_window12_384_in22k'\n",
    "model_name = 'convnext_base_384_in22ft1k'\n",
    "\n",
    "# training config\n",
    "img_size = 384\n",
    "LR = 2e-4\n",
    "EPOCHS = 30\n",
    "BATCH_SIZE = 32\n",
    "num_workers = 16\n",
    "EMA = True  # Exponential Moving Average ì‚¬ìš© ì—¬ë¶€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optunaë¥¼ ì‚¬ìš©í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ (ì„ íƒì  ì‹¤í–‰)\n",
    "USE_OPTUNA = False  # Trueë¡œ ë°”ê¾¸ë©´ íŠœë‹ ì‹¤í–‰\n",
    "\n",
    "if USE_OPTUNA:\n",
    "    def objective(trial):\n",
    "        lr = trial.suggest_loguniform('lr', 1e-5, 1e-2)\n",
    "        batch_size = trial.suggest_categorical('batch_size', [32, 64, 128])\n",
    "        \n",
    "        # ê°„ë‹¨í•œ 3-fold CVë¡œ ë¹ ë¥¸ í‰ê°€\n",
    "        skf_simple = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "        fold_scores = []\n",
    "        \n",
    "        for fold, (train_idx, val_idx) in enumerate(skf_simple.split(train_df, train_df['target'])):\n",
    "            # ëª¨ë¸ ìƒì„±\n",
    "            model = timm.create_model(model_name, pretrained=True, num_classes=17).to(device)\n",
    "            optimizer = Adam(model.parameters(), lr=lr)\n",
    "            loss_fn = nn.CrossEntropyLoss()\n",
    "            \n",
    "            # ê°„ë‹¨í•œ 2 epoch í•™ìŠµ\n",
    "            for epoch in range(2):\n",
    "                train_ret = train_one_epoch(trn_loader, model, optimizer, loss_fn, device)\n",
    "            \n",
    "            val_ret = validate_one_epoch(val_loader, model, loss_fn, device)\n",
    "            fold_scores.append(val_ret['val_f1'])\n",
    "        \n",
    "        return np.mean(fold_scores)\n",
    "    \n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=10)\n",
    "    \n",
    "    # ìµœì  íŒŒë¼ë¯¸í„° ì ìš©\n",
    "    LR = study.best_params['lr']\n",
    "    BATCH_SIZE = study.best_params['batch_size']\n",
    "    print(f\"Best params: {study.best_params}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "amum-FlIojc6"
   },
   "source": [
    "## 4. Load Data\n",
    "* í•™ìŠµ, í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ê³¼ ë¡œë”ë¥¼ ì •ì˜í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1700315112439,
     "user": {
      "displayName": "Ynot(ì†¡ì›í˜¸)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "llh5C7ZKoq2S"
   },
   "outputs": [],
   "source": [
    "# # augmentationì„ ìœ„í•œ transform ì½”ë“œ\n",
    "# trn_transform = A.Compose([\n",
    "#     # ë¹„ìœ¨ ë³´ì¡´ ë¦¬ì‚¬ì´ì§• (í•µì‹¬ ê°œì„ )\n",
    "#     A.LongestMaxSize(max_size=img_size),\n",
    "#     A.PadIfNeeded(min_height=img_size, min_width=img_size, \n",
    "#                   border_mode=0, value=0),\n",
    "    \n",
    "#     # ë¬¸ì„œ íŠ¹í™” íšŒì „ (ì •í™•í•œ 90ë„ ë°°ìˆ˜)\n",
    "#     A.OneOf([\n",
    "#         A.Rotate(limit=[90,90], p=1.0),\n",
    "#         A.Rotate(limit=[180,180], p=1.0),\n",
    "#         A.Rotate(limit=[270,270], p=1.0),\n",
    "#     ], p=0.6),\n",
    "    \n",
    "#     # í…ŒìŠ¤íŠ¸ íŠ¹í™” ê°•í™” ì¦ê°•\n",
    "#     A.OneOf([\n",
    "#         A.MotionBlur(blur_limit=7, p=1.0),\n",
    "#         A.GaussianBlur(blur_limit=7, p=1.0),\n",
    "#     ], p=0.9),\n",
    "    \n",
    "#     A.RandomBrightnessContrast(\n",
    "#         brightness_limit=0.3, \n",
    "#         contrast_limit=0.3, \n",
    "#         p=0.8\n",
    "#     ),\n",
    "#     A.GaussNoise(var_limit=(30.0, 100.0), p=0.7),\n",
    "#     A.HorizontalFlip(p=0.5),\n",
    "    \n",
    "#     A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "#     ToTensorV2(),\n",
    "# ])\n",
    "\n",
    "# # test image ë³€í™˜ì„ ìœ„í•œ transform ì½”ë“œ\n",
    "# tst_transform = A.Compose([\n",
    "#     A.LongestMaxSize(max_size=img_size),\n",
    "#     A.PadIfNeeded(min_height=img_size, min_width=img_size, \n",
    "#                   border_mode=0, value=0),\n",
    "#     A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "#     ToTensorV2(),\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optuna íŠœë‹ (ì„ íƒì  ì‹¤í–‰)\n",
    "USE_OPTUNA = False  # Trueë¡œ ë°”ê¾¸ë©´ íŠœë‹ ì‹¤í–‰\n",
    "\n",
    "if USE_OPTUNA:\n",
    "    # ìœ„ì˜ objective í•¨ìˆ˜ì™€ study ì½”ë“œ\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Fold ì ìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 5-Fold Cross Validation...\n",
      "\n",
      "==================================================\n",
      "FOLD 1/5\n",
      "==================================================\n",
      "Train samples: 1256, Validation samples: 314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.5889: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:26<00:00,  1.52it/s]\n",
      "Val Loss: 1.2131: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:06<00:00,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1 | Train Loss: 2.1222 | Train F1: 0.3604 | Val Loss: 1.1315 | Val F1: 0.6378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 1.7207: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.56it/s]\n",
      "Val Loss: 0.8370: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  2 | Train Loss: 1.3145 | Train F1: 0.5567 | Val Loss: 0.8507 | Val F1: 0.7467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 1.4141: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.65it/s]\n",
      "Val Loss: 0.7507: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  3 | Train Loss: 1.0300 | Train F1: 0.7014 | Val Loss: 0.6767 | Val F1: 0.8413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 1.5527: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:14<00:00,  2.70it/s]\n",
      "Val Loss: 0.5964: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  4 | Train Loss: 0.9215 | Train F1: 0.7145 | Val Loss: 0.5938 | Val F1: 0.8631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.4795: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.66it/s]\n",
      "Val Loss: 0.6264: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  5 | Train Loss: 0.8464 | Train F1: 0.7367 | Val Loss: 0.6244 | Val F1: 0.8582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.7461: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.57it/s]\n",
      "Val Loss: 0.6269: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  6 | Train Loss: 0.8625 | Train F1: 0.7561 | Val Loss: 0.5791 | Val F1: 0.9016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.4380: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.64it/s]\n",
      "Val Loss: 0.4908: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  7 | Train Loss: 0.8323 | Train F1: 0.7693 | Val Loss: 0.5340 | Val F1: 0.8904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.5010: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:14<00:00,  2.71it/s]\n",
      "Val Loss: 0.5005: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  8 | Train Loss: 0.7179 | Train F1: 0.7733 | Val Loss: 0.5222 | Val F1: 0.9214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.5210: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:14<00:00,  2.69it/s]\n",
      "Val Loss: 0.4956: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  9 | Train Loss: 0.6840 | Train F1: 0.7458 | Val Loss: 0.5345 | Val F1: 0.9211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.5303: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.63it/s]\n",
      "Val Loss: 0.5532: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Train Loss: 0.6323 | Train F1: 0.8445 | Val Loss: 0.5501 | Val F1: 0.9013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.7842: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.52it/s]\n",
      "Val Loss: 0.5895: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | Train Loss: 0.7974 | Train F1: 0.8080 | Val Loss: 0.5974 | Val F1: 0.8904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.4404: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.67it/s]\n",
      "Val Loss: 0.5101: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | Train Loss: 0.7003 | Train F1: 0.8297 | Val Loss: 0.5120 | Val F1: 0.9334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.3735: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.58it/s]\n",
      "Val Loss: 0.6565: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 | Train Loss: 0.7516 | Train F1: 0.7275 | Val Loss: 0.5932 | Val F1: 0.9100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.5039: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.64it/s]\n",
      "Val Loss: 0.4293: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | Train Loss: 0.7193 | Train F1: 0.8008 | Val Loss: 0.4941 | Val F1: 0.9233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.4800: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.60it/s]\n",
      "Val Loss: 0.5424: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 | Train Loss: 0.6333 | Train F1: 0.8112 | Val Loss: 0.5241 | Val F1: 0.9230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2773: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.58it/s]\n",
      "Val Loss: 0.4878: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 | Train Loss: 0.7512 | Train F1: 0.7263 | Val Loss: 0.5035 | Val F1: 0.9207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.5059: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.61it/s]\n",
      "Val Loss: 0.5427: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 | Train Loss: 0.5892 | Train F1: 0.8602 | Val Loss: 0.5150 | Val F1: 0.9186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.8018: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.62it/s]\n",
      "Val Loss: 0.4833: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 | Train Loss: 0.6521 | Train F1: 0.7944 | Val Loss: 0.5076 | Val F1: 0.9304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.5347: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.60it/s]\n",
      "Val Loss: 0.4372: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 | Train Loss: 0.5297 | Train F1: 0.8842 | Val Loss: 0.4829 | Val F1: 0.9509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.3330: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.60it/s]\n",
      "Val Loss: 0.4251: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 | Train Loss: 0.5730 | Train F1: 0.8780 | Val Loss: 0.4910 | Val F1: 0.9396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3354: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.63it/s]\n",
      "Val Loss: 0.4601: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 | Train Loss: 0.5178 | Train F1: 0.8683 | Val Loss: 0.4630 | Val F1: 0.9464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3901: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.61it/s]\n",
      "Val Loss: 0.4354: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 | Train Loss: 0.5802 | Train F1: 0.8462 | Val Loss: 0.4608 | Val F1: 0.9451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3740: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.65it/s]\n",
      "Val Loss: 0.4312: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 | Train Loss: 0.5446 | Train F1: 0.8452 | Val Loss: 0.4709 | Val F1: 0.9499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3262: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.65it/s]\n",
      "Val Loss: 0.5053: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 | Train Loss: 0.5346 | Train F1: 0.9266 | Val Loss: 0.4827 | Val F1: 0.9468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3293: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.65it/s]\n",
      "Val Loss: 0.4170: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 | Train Loss: 0.5952 | Train F1: 0.8640 | Val Loss: 0.4729 | Val F1: 0.9385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.8193: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.56it/s]\n",
      "Val Loss: 0.4470: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 | Train Loss: 0.6515 | Train F1: 0.7680 | Val Loss: 0.4667 | Val F1: 0.9515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.5288: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.52it/s]\n",
      "Val Loss: 0.4330: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 | Train Loss: 0.5365 | Train F1: 0.8713 | Val Loss: 0.4675 | Val F1: 0.9382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3625: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.60it/s]\n",
      "Val Loss: 0.4502: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 | Train Loss: 0.5288 | Train F1: 0.8490 | Val Loss: 0.5048 | Val F1: 0.9308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1152: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.58it/s]\n",
      "Val Loss: 0.4725: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 | Train Loss: 0.6562 | Train F1: 0.8184 | Val Loss: 0.4780 | Val F1: 0.9417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3425: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.55it/s]\n",
      "Val Loss: 0.4339: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 | Train Loss: 0.6321 | Train F1: 0.8212 | Val Loss: 0.4666 | Val F1: 0.9412\n",
      "Fold 1 Best Validation F1: 0.9515\n",
      "\n",
      "==================================================\n",
      "FOLD 2/5\n",
      "==================================================\n",
      "Train samples: 1256, Validation samples: 314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.6719: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.65it/s]\n",
      "Val Loss: 0.9755: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1 | Train Loss: 2.1000 | Train F1: 0.3638 | Val Loss: 1.1857 | Val F1: 0.6554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 1.1279: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.58it/s]\n",
      "Val Loss: 0.6954: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  2 | Train Loss: 1.2281 | Train F1: 0.6402 | Val Loss: 0.7539 | Val F1: 0.8432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.9805: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.65it/s]\n",
      "Val Loss: 0.5882: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  3 | Train Loss: 1.0709 | Train F1: 0.7015 | Val Loss: 0.7193 | Val F1: 0.8231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.6396: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.58it/s]\n",
      "Val Loss: 0.5576: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  4 | Train Loss: 0.9358 | Train F1: 0.7576 | Val Loss: 0.6561 | Val F1: 0.8214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.5146: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.63it/s]\n",
      "Val Loss: 0.5384: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  5 | Train Loss: 0.9958 | Train F1: 0.6263 | Val Loss: 0.5791 | Val F1: 0.8940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.6641: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.63it/s]\n",
      "Val Loss: 0.6195: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  6 | Train Loss: 0.8352 | Train F1: 0.7350 | Val Loss: 0.5587 | Val F1: 0.9025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.5098: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.60it/s]\n",
      "Val Loss: 0.4760: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  7 | Train Loss: 0.7971 | Train F1: 0.8219 | Val Loss: 0.5455 | Val F1: 0.8908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.4429: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.58it/s]\n",
      "Val Loss: 0.6026: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  8 | Train Loss: 0.6542 | Train F1: 0.8378 | Val Loss: 0.5621 | Val F1: 0.8754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.6455: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.63it/s]\n",
      "Val Loss: 0.4103: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  9 | Train Loss: 0.7629 | Train F1: 0.7732 | Val Loss: 0.5002 | Val F1: 0.9171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 1.4492: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.56it/s]\n",
      "Val Loss: 0.3922: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Train Loss: 0.7284 | Train F1: 0.8009 | Val Loss: 0.4767 | Val F1: 0.9345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.9731: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:14<00:00,  2.67it/s]\n",
      "Val Loss: 0.4550: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | Train Loss: 0.6406 | Train F1: 0.8603 | Val Loss: 0.4856 | Val F1: 0.9330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.8174: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.63it/s]\n",
      "Val Loss: 0.3944: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | Train Loss: 0.6910 | Train F1: 0.8346 | Val Loss: 0.5128 | Val F1: 0.9213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.9053: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.58it/s]\n",
      "Val Loss: 0.4513: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 | Train Loss: 0.6431 | Train F1: 0.8597 | Val Loss: 0.5071 | Val F1: 0.9169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.9380: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.53it/s]\n",
      "Val Loss: 0.4390: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | Train Loss: 0.7086 | Train F1: 0.7971 | Val Loss: 0.4744 | Val F1: 0.9378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.4429: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.62it/s]\n",
      "Val Loss: 0.3986: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 | Train Loss: 0.7174 | Train F1: 0.7525 | Val Loss: 0.4634 | Val F1: 0.9418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.3459: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.61it/s]\n",
      "Val Loss: 0.3797: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 | Train Loss: 0.5942 | Train F1: 0.8420 | Val Loss: 0.4690 | Val F1: 0.9437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.4565: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.53it/s]\n",
      "Val Loss: 0.3924: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 | Train Loss: 0.7228 | Train F1: 0.7607 | Val Loss: 0.4635 | Val F1: 0.9394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3450: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.55it/s]\n",
      "Val Loss: 0.3796: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 | Train Loss: 0.6657 | Train F1: 0.8094 | Val Loss: 0.4810 | Val F1: 0.9430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3540: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.50it/s]\n",
      "Val Loss: 0.3820: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 | Train Loss: 0.5378 | Train F1: 0.9119 | Val Loss: 0.4474 | Val F1: 0.9592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.4834: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.56it/s]\n",
      "Val Loss: 0.4209: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 | Train Loss: 0.6867 | Train F1: 0.8133 | Val Loss: 0.4771 | Val F1: 0.9443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.4148: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.52it/s]\n",
      "Val Loss: 0.4165: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  2.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 | Train Loss: 0.5784 | Train F1: 0.8676 | Val Loss: 0.4521 | Val F1: 0.9554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3401: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.50it/s]\n",
      "Val Loss: 0.4405: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 | Train Loss: 0.5692 | Train F1: 0.9201 | Val Loss: 0.4846 | Val F1: 0.9426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3872: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.52it/s]\n",
      "Val Loss: 0.4505: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 | Train Loss: 0.5760 | Train F1: 0.9051 | Val Loss: 0.4588 | Val F1: 0.9533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.4971: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:16<00:00,  2.46it/s]\n",
      "Val Loss: 0.3873: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 | Train Loss: 0.6424 | Train F1: 0.8357 | Val Loss: 0.4463 | Val F1: 0.9591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.5586: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:14<00:00,  2.67it/s]\n",
      "Val Loss: 0.3992: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 | Train Loss: 0.6150 | Train F1: 0.8320 | Val Loss: 0.4446 | Val F1: 0.9582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3372: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.62it/s]\n",
      "Val Loss: 0.4167: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 | Train Loss: 0.6087 | Train F1: 0.8027 | Val Loss: 0.4680 | Val F1: 0.9465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3311: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.62it/s]\n",
      "Val Loss: 0.4203: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 | Train Loss: 0.5848 | Train F1: 0.8258 | Val Loss: 0.4518 | Val F1: 0.9630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.3535: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.63it/s]\n",
      "Val Loss: 0.4205: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 | Train Loss: 0.4589 | Train F1: 0.9147 | Val Loss: 0.4663 | Val F1: 0.9519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.5488: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.53it/s]\n",
      "Val Loss: 0.4366: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 | Train Loss: 0.5232 | Train F1: 0.8660 | Val Loss: 0.4558 | Val F1: 0.9495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3975: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.57it/s]\n",
      "Val Loss: 0.3955: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 | Train Loss: 0.6448 | Train F1: 0.8606 | Val Loss: 0.4495 | Val F1: 0.9565\n",
      "Fold 2 Best Validation F1: 0.9630\n",
      "\n",
      "==================================================\n",
      "FOLD 3/5\n",
      "==================================================\n",
      "Train samples: 1256, Validation samples: 314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.4238: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:16<00:00,  2.50it/s]\n",
      "Val Loss: 1.0881: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1 | Train Loss: 2.0113 | Train F1: 0.3974 | Val Loss: 1.1451 | Val F1: 0.6809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 1.3125: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.63it/s]\n",
      "Val Loss: 0.7825: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  2 | Train Loss: 1.3754 | Train F1: 0.6279 | Val Loss: 0.9639 | Val F1: 0.6784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.4983: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.57it/s]\n",
      "Val Loss: 0.5699: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  3 | Train Loss: 0.9593 | Train F1: 0.7245 | Val Loss: 0.6882 | Val F1: 0.8247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.6201: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.60it/s]\n",
      "Val Loss: 0.5388: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  4 | Train Loss: 0.9441 | Train F1: 0.7072 | Val Loss: 0.6238 | Val F1: 0.8606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.5850: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.60it/s]\n",
      "Val Loss: 0.4997: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  5 | Train Loss: 0.9213 | Train F1: 0.7188 | Val Loss: 0.5909 | Val F1: 0.8678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.9253: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.56it/s]\n",
      "Val Loss: 0.5193: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  6 | Train Loss: 0.7880 | Train F1: 0.7941 | Val Loss: 0.5785 | Val F1: 0.8857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.7080: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.56it/s]\n",
      "Val Loss: 0.4198: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  7 | Train Loss: 0.7237 | Train F1: 0.8154 | Val Loss: 0.5225 | Val F1: 0.8993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.4712: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.60it/s]\n",
      "Val Loss: 0.4260: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  8 | Train Loss: 0.8013 | Train F1: 0.7703 | Val Loss: 0.5259 | Val F1: 0.8979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1211: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.52it/s]\n",
      "Val Loss: 0.3919: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  9 | Train Loss: 0.8017 | Train F1: 0.7794 | Val Loss: 0.5044 | Val F1: 0.9245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.8174: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.51it/s]\n",
      "Val Loss: 0.4118: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Train Loss: 0.7883 | Train F1: 0.8557 | Val Loss: 0.5217 | Val F1: 0.8793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.4268: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.56it/s]\n",
      "Val Loss: 0.3677: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | Train Loss: 0.7699 | Train F1: 0.8005 | Val Loss: 0.4713 | Val F1: 0.9360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.4048: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.53it/s]\n",
      "Val Loss: 0.3953: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | Train Loss: 0.7423 | Train F1: 0.7381 | Val Loss: 0.4931 | Val F1: 0.9161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.8047: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.60it/s]\n",
      "Val Loss: 0.4393: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 | Train Loss: 0.6414 | Train F1: 0.8435 | Val Loss: 0.4884 | Val F1: 0.9122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3489: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.58it/s]\n",
      "Val Loss: 0.3776: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | Train Loss: 0.6497 | Train F1: 0.7973 | Val Loss: 0.4651 | Val F1: 0.9456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.4326: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.56it/s]\n",
      "Val Loss: 0.3688: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 | Train Loss: 0.7244 | Train F1: 0.7776 | Val Loss: 0.4635 | Val F1: 0.9295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1631: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.60it/s]\n",
      "Val Loss: 0.3968: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 | Train Loss: 0.7746 | Train F1: 0.7131 | Val Loss: 0.4741 | Val F1: 0.9189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1504: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.58it/s]\n",
      "Val Loss: 0.3749: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 | Train Loss: 0.6982 | Train F1: 0.8337 | Val Loss: 0.4738 | Val F1: 0.9310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3730: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.62it/s]\n",
      "Val Loss: 0.3988: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 | Train Loss: 0.5247 | Train F1: 0.9233 | Val Loss: 0.4833 | Val F1: 0.9054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.7529: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.62it/s]\n",
      "Val Loss: 0.4571: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 | Train Loss: 0.6614 | Train F1: 0.7983 | Val Loss: 0.4809 | Val F1: 0.9139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.4121: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.62it/s]\n",
      "Val Loss: 0.4290: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 | Train Loss: 0.6291 | Train F1: 0.8450 | Val Loss: 0.4549 | Val F1: 0.9324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.6221: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:16<00:00,  2.49it/s]\n",
      "Val Loss: 0.3684: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 | Train Loss: 0.6080 | Train F1: 0.8795 | Val Loss: 0.4594 | Val F1: 0.9341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.8799: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.59it/s]\n",
      "Val Loss: 0.3933: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 | Train Loss: 0.6251 | Train F1: 0.8326 | Val Loss: 0.4588 | Val F1: 0.9351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3423: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.55it/s]\n",
      "Val Loss: 0.3763: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 | Train Loss: 0.5509 | Train F1: 0.8238 | Val Loss: 0.4500 | Val F1: 0.9315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.6255: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.60it/s]\n",
      "Val Loss: 0.3834: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 | Train Loss: 0.5923 | Train F1: 0.8088 | Val Loss: 0.4675 | Val F1: 0.9342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.4958: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.58it/s]\n",
      "Val Loss: 0.4141: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 | Train Loss: 0.7184 | Train F1: 0.8433 | Val Loss: 0.4649 | Val F1: 0.9337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3315: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.58it/s]\n",
      "Val Loss: 0.3832: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 | Train Loss: 0.6816 | Train F1: 0.8363 | Val Loss: 0.4769 | Val F1: 0.9239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3372: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.53it/s]\n",
      "Val Loss: 0.3907: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 | Train Loss: 0.5388 | Train F1: 0.8992 | Val Loss: 0.4735 | Val F1: 0.9384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3394: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.58it/s]\n",
      "Val Loss: 0.4022: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 | Train Loss: 0.6278 | Train F1: 0.8211 | Val Loss: 0.4633 | Val F1: 0.9302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3293: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.53it/s]\n",
      "Val Loss: 0.3712: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 | Train Loss: 0.5981 | Train F1: 0.8275 | Val Loss: 0.4732 | Val F1: 0.9322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3406: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.61it/s]\n",
      "Val Loss: 0.3921: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 | Train Loss: 0.5066 | Train F1: 0.8639 | Val Loss: 0.4649 | Val F1: 0.9316\n",
      "Fold 3 Best Validation F1: 0.9456\n",
      "\n",
      "==================================================\n",
      "FOLD 4/5\n",
      "==================================================\n",
      "Train samples: 1256, Validation samples: 314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.4248: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.57it/s]\n",
      "Val Loss: 1.0450: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1 | Train Loss: 2.0197 | Train F1: 0.3938 | Val Loss: 1.1190 | Val F1: 0.7066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.5776: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:16<00:00,  2.47it/s]\n",
      "Val Loss: 0.6606: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  2 | Train Loss: 1.1350 | Train F1: 0.6385 | Val Loss: 0.7277 | Val F1: 0.8268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.9253: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.56it/s]\n",
      "Val Loss: 0.5794: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  3 | Train Loss: 1.0115 | Train F1: 0.6954 | Val Loss: 0.6474 | Val F1: 0.8365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.5635: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.60it/s]\n",
      "Val Loss: 0.5682: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  4 | Train Loss: 0.8711 | Train F1: 0.7488 | Val Loss: 0.6149 | Val F1: 0.8531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.5859: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.55it/s]\n",
      "Val Loss: 0.6759: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  5 | Train Loss: 0.7753 | Train F1: 0.8134 | Val Loss: 0.6421 | Val F1: 0.8349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.7100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.60it/s]\n",
      "Val Loss: 0.4606: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  6 | Train Loss: 0.7972 | Train F1: 0.7564 | Val Loss: 0.5577 | Val F1: 0.8650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.3396: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.61it/s]\n",
      "Val Loss: 0.4906: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  7 | Train Loss: 0.7588 | Train F1: 0.8004 | Val Loss: 0.5739 | Val F1: 0.8727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.7935: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.62it/s]\n",
      "Val Loss: 0.4921: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  8 | Train Loss: 0.7706 | Train F1: 0.7963 | Val Loss: 0.5339 | Val F1: 0.8719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3506: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.58it/s]\n",
      "Val Loss: 0.4170: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  9 | Train Loss: 0.8128 | Train F1: 0.7464 | Val Loss: 0.5265 | Val F1: 0.8940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.3396: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.56it/s]\n",
      "Val Loss: 0.5767: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Train Loss: 0.7873 | Train F1: 0.8378 | Val Loss: 0.5721 | Val F1: 0.8756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.6958: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.58it/s]\n",
      "Val Loss: 0.3949: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | Train Loss: 0.6899 | Train F1: 0.7970 | Val Loss: 0.5192 | Val F1: 0.9117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 1.1309: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.53it/s]\n",
      "Val Loss: 0.5022: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | Train Loss: 0.7290 | Train F1: 0.7895 | Val Loss: 0.5332 | Val F1: 0.8777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.5527: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.55it/s]\n",
      "Val Loss: 0.4201: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 | Train Loss: 0.7271 | Train F1: 0.8248 | Val Loss: 0.5044 | Val F1: 0.9019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.4146: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.50it/s]\n",
      "Val Loss: 0.4619: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | Train Loss: 0.6469 | Train F1: 0.8240 | Val Loss: 0.5038 | Val F1: 0.9181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.3784: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.56it/s]\n",
      "Val Loss: 0.3849: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 | Train Loss: 0.6768 | Train F1: 0.8419 | Val Loss: 0.4976 | Val F1: 0.9156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.5117: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.61it/s]\n",
      "Val Loss: 0.4498: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 | Train Loss: 0.7080 | Train F1: 0.7386 | Val Loss: 0.5253 | Val F1: 0.9121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.4790: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.52it/s]\n",
      "Val Loss: 0.3906: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 | Train Loss: 0.5932 | Train F1: 0.9002 | Val Loss: 0.5155 | Val F1: 0.9065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.5947: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.53it/s]\n",
      "Val Loss: 0.3811: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 | Train Loss: 0.7186 | Train F1: 0.8216 | Val Loss: 0.4950 | Val F1: 0.9249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 1.6514: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.63it/s]\n",
      "Val Loss: 0.3636: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 | Train Loss: 0.5824 | Train F1: 0.9338 | Val Loss: 0.4799 | Val F1: 0.9354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 1.1230: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.63it/s]\n",
      "Val Loss: 0.3532: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 | Train Loss: 0.6967 | Train F1: 0.7964 | Val Loss: 0.4923 | Val F1: 0.9230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3501: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.63it/s]\n",
      "Val Loss: 0.4651: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 | Train Loss: 0.5658 | Train F1: 0.8681 | Val Loss: 0.4900 | Val F1: 0.9222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3359: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.62it/s]\n",
      "Val Loss: 0.3706: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 | Train Loss: 0.7026 | Train F1: 0.7887 | Val Loss: 0.4786 | Val F1: 0.9274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.8301: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.55it/s]\n",
      "Val Loss: 0.3866: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 | Train Loss: 0.6692 | Train F1: 0.8183 | Val Loss: 0.4843 | Val F1: 0.9304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1816: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.64it/s]\n",
      "Val Loss: 0.3576: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 | Train Loss: 0.6229 | Train F1: 0.8512 | Val Loss: 0.4830 | Val F1: 0.9480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.4709: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.67it/s]\n",
      "Val Loss: 0.4082: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 | Train Loss: 0.4867 | Train F1: 0.8893 | Val Loss: 0.4840 | Val F1: 0.9379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.0137: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:16<00:00,  2.49it/s]\n",
      "Val Loss: 0.4132: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 | Train Loss: 0.6055 | Train F1: 0.8428 | Val Loss: 0.4797 | Val F1: 0.9425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.4556: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.53it/s]\n",
      "Val Loss: 0.4015: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 | Train Loss: 0.6574 | Train F1: 0.8486 | Val Loss: 0.4785 | Val F1: 0.9323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3374: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.60it/s]\n",
      "Val Loss: 0.3893: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 | Train Loss: 0.6233 | Train F1: 0.7943 | Val Loss: 0.4662 | Val F1: 0.9462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.0078: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.60it/s]\n",
      "Val Loss: 0.3723: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 | Train Loss: 0.6482 | Train F1: 0.8371 | Val Loss: 0.4753 | Val F1: 0.9394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3298: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.58it/s]\n",
      "Val Loss: 0.3942: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 | Train Loss: 0.5949 | Train F1: 0.8437 | Val Loss: 0.4722 | Val F1: 0.9360\n",
      "Fold 4 Best Validation F1: 0.9480\n",
      "\n",
      "==================================================\n",
      "FOLD 5/5\n",
      "==================================================\n",
      "Train samples: 1256, Validation samples: 314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.9805: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.60it/s]\n",
      "Val Loss: 1.0417: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1 | Train Loss: 2.0938 | Train F1: 0.3232 | Val Loss: 1.1865 | Val F1: 0.6426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 1.3057: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.54it/s]\n",
      "Val Loss: 0.7066: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  2 | Train Loss: 1.1075 | Train F1: 0.7003 | Val Loss: 0.7402 | Val F1: 0.8205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.5698: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:16<00:00,  2.47it/s]\n",
      "Val Loss: 0.7403: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  3 | Train Loss: 0.9408 | Train F1: 0.7359 | Val Loss: 0.6616 | Val F1: 0.8253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 1.1611: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.63it/s]\n",
      "Val Loss: 0.6507: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  4 | Train Loss: 1.0356 | Train F1: 0.6673 | Val Loss: 0.6245 | Val F1: 0.8664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.3560: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.58it/s]\n",
      "Val Loss: 0.5862: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  5 | Train Loss: 0.8319 | Train F1: 0.7338 | Val Loss: 0.6139 | Val F1: 0.8834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.3892: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.52it/s]\n",
      "Val Loss: 0.4912: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  6 | Train Loss: 0.7630 | Train F1: 0.7542 | Val Loss: 0.5509 | Val F1: 0.9065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 1.2305: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.53it/s]\n",
      "Val Loss: 0.5479: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  7 | Train Loss: 0.6941 | Train F1: 0.8620 | Val Loss: 0.5762 | Val F1: 0.8870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3442: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:16<00:00,  2.47it/s]\n",
      "Val Loss: 0.5521: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  8 | Train Loss: 0.7510 | Train F1: 0.8228 | Val Loss: 0.5474 | Val F1: 0.9027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.5557: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.50it/s]\n",
      "Val Loss: 0.4184: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  9 | Train Loss: 0.8133 | Train F1: 0.7543 | Val Loss: 0.5161 | Val F1: 0.9151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.0020: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.61it/s]\n",
      "Val Loss: 0.5671: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Train Loss: 0.6370 | Train F1: 0.8752 | Val Loss: 0.5954 | Val F1: 0.8727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3445: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.55it/s]\n",
      "Val Loss: 0.4121: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | Train Loss: 0.6874 | Train F1: 0.8309 | Val Loss: 0.5579 | Val F1: 0.9020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.4185: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.59it/s]\n",
      "Val Loss: 0.4189: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | Train Loss: 0.6775 | Train F1: 0.7983 | Val Loss: 0.5205 | Val F1: 0.9027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.4888: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.58it/s]\n",
      "Val Loss: 0.3995: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 | Train Loss: 0.6476 | Train F1: 0.8739 | Val Loss: 0.5404 | Val F1: 0.9166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 1.5391: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.58it/s]\n",
      "Val Loss: 0.4351: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | Train Loss: 0.7728 | Train F1: 0.7561 | Val Loss: 0.5469 | Val F1: 0.9072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3992: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:16<00:00,  2.45it/s]\n",
      "Val Loss: 0.4121: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 | Train Loss: 0.6134 | Train F1: 0.8474 | Val Loss: 0.4986 | Val F1: 0.9302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.8179: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:14<00:00,  2.67it/s]\n",
      "Val Loss: 0.3683: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 | Train Loss: 0.6563 | Train F1: 0.7711 | Val Loss: 0.4970 | Val F1: 0.9187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2676: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.55it/s]\n",
      "Val Loss: 0.3996: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 | Train Loss: 0.6449 | Train F1: 0.8088 | Val Loss: 0.5088 | Val F1: 0.9235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.0576: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.59it/s]\n",
      "Val Loss: 0.4337: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 | Train Loss: 0.5251 | Train F1: 0.9184 | Val Loss: 0.5239 | Val F1: 0.9125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1367: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.57it/s]\n",
      "Val Loss: 0.4075: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 | Train Loss: 0.5828 | Train F1: 0.8707 | Val Loss: 0.5068 | Val F1: 0.9304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.3289: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.56it/s]\n",
      "Val Loss: 0.4286: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 | Train Loss: 0.5767 | Train F1: 0.8424 | Val Loss: 0.4922 | Val F1: 0.9315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3779: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.63it/s]\n",
      "Val Loss: 0.3656: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 | Train Loss: 0.6583 | Train F1: 0.7744 | Val Loss: 0.5121 | Val F1: 0.9233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3701: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.60it/s]\n",
      "Val Loss: 0.3889: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 | Train Loss: 0.6178 | Train F1: 0.8354 | Val Loss: 0.4779 | Val F1: 0.9372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.3481: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.56it/s]\n",
      "Val Loss: 0.3783: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 | Train Loss: 0.6073 | Train F1: 0.8623 | Val Loss: 0.4904 | Val F1: 0.9347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3833: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.58it/s]\n",
      "Val Loss: 0.3849: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 | Train Loss: 0.5473 | Train F1: 0.9024 | Val Loss: 0.5005 | Val F1: 0.9353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.4541: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.52it/s]\n",
      "Val Loss: 0.3581: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 | Train Loss: 0.6797 | Train F1: 0.7854 | Val Loss: 0.5134 | Val F1: 0.9187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.4038: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.63it/s]\n",
      "Val Loss: 0.3747: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 | Train Loss: 0.5656 | Train F1: 0.8734 | Val Loss: 0.5091 | Val F1: 0.9330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.6099: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.60it/s]\n",
      "Val Loss: 0.3938: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 | Train Loss: 0.6821 | Train F1: 0.8313 | Val Loss: 0.5040 | Val F1: 0.9302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.5107: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.52it/s]\n",
      "Val Loss: 0.3558: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 | Train Loss: 0.5302 | Train F1: 0.9290 | Val Loss: 0.4913 | Val F1: 0.9356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3818: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.60it/s]\n",
      "Val Loss: 0.3581: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 | Train Loss: 0.5851 | Train F1: 0.8588 | Val Loss: 0.5017 | Val F1: 0.9379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.5444: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:15<00:00,  2.65it/s]\n",
      "Val Loss: 0.3575: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 | Train Loss: 0.6042 | Train F1: 0.8892 | Val Loss: 0.4947 | Val F1: 0.9446\n",
      "Fold 5 Best Validation F1: 0.9446\n",
      "\n",
      "============================================================\n",
      "K-FOLD CROSS VALIDATION RESULTS\n",
      "============================================================\n",
      "Fold 1: 0.9515\n",
      "Fold 2: 0.9630\n",
      "Fold 3: 0.9456\n",
      "Fold 4: 0.9480\n",
      "Fold 5: 0.9446\n",
      "\n",
      "Mean CV F1: 0.9506 Â± 0.0067\n",
      "Best single fold: 0.9630\n"
     ]
    }
   ],
   "source": [
    "# K-Fold ì„¤ì •\n",
    "N_FOLDS = 5  # 5-foldë¡œ ì„¤ì • (ë°ì´í„°ê°€ ì ìœ¼ë¯€ë¡œ)\n",
    "skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=42)\n",
    "\n",
    "# í´ë˜ìŠ¤ë³„ ìµœì†Œ ìƒ˜í”Œ ë³´ì¥ í™•ì¸\n",
    "# for fold, (train_idx, val_idx) in enumerate(skf.split(train_df, train_df['target'])):\n",
    "#     assert len(np.unique(train_df.iloc[val_idx]['target'])) == 17\n",
    "\n",
    "# ì „ì²´ í•™ìŠµ ë°ì´í„° ë¡œë“œ\n",
    "train_df = pd.read_csv(\"../data/train.csv\")\n",
    "\n",
    "# K-Fold ê²°ê³¼ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸\n",
    "fold_results = []\n",
    "fold_models = []  # ê° foldì˜ ìµœê³  ì„±ëŠ¥ ëª¨ë¸ì„ ì €ì¥\n",
    "fold_class_accuracies = [] # ê° foldì˜ í´ë˜ìŠ¤ë³„ ì •í™•ë„ ì €ì¥\n",
    "\n",
    "print(f\"Starting {N_FOLDS}-Fold Cross Validation...\")\n",
    "\n",
    "# LR = best_params['lr']\n",
    "# BATCH_SIZE = best_params['batch_size']\n",
    "\n",
    "# K-Fold Cross Validation ì‹œì‘\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(train_df, train_df['target'])):\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"FOLD {fold + 1}/{N_FOLDS}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    current_model = model_name\n",
    "    \n",
    "    # í˜„ì¬ foldì˜ train/validation ë°ì´í„° ë¶„í• \n",
    "    train_fold_df = train_df.iloc[train_idx].reset_index(drop=True)\n",
    "    val_fold_df = train_df.iloc[val_idx].reset_index(drop=True)\n",
    "    \n",
    "    # í˜„ì¬ foldì˜ Dataset ìƒì„±\n",
    "    trn_dataset = ImageDataset(\n",
    "        train_fold_df,\n",
    "        \"../data/train/\",\n",
    "        # transform=trn_transform\n",
    "        epoch=0,  # í˜„ì¬ epoch ì „ë‹¬\n",
    "        total_epochs=EPOCHS,\n",
    "        is_train=True\n",
    "    )\n",
    "    \n",
    "    val_dataset = ImageDataset(\n",
    "        val_fold_df,\n",
    "        \"../data/train/\",\n",
    "        # transform=tst_transform  # ê²€ì¦ì—ëŠ” ì¦ê°• ì ìš© ì•ˆí•¨\n",
    "        epoch=0,  # validationì€ epoch ê´€ê³„ì—†ìŒ\n",
    "        total_epochs=EPOCHS,\n",
    "        is_train=False  # validationì´ë¯€ë¡œ hard augmentation ë¹„í™œì„±í™”\n",
    "    )\n",
    "    \n",
    "    # í˜„ì¬ foldì˜ DataLoader ìƒì„±\n",
    "    trn_loader = DataLoader(\n",
    "        trn_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=False\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    print(f\"Train samples: {len(trn_dataset)}, Validation samples: {len(val_dataset)}\")\n",
    "    \n",
    "    # ëª¨ë¸ ì´ˆê¸°í™” (ê° foldë§ˆë‹¤ ìƒˆë¡œìš´ ëª¨ë¸)\n",
    "    model = timm.create_model(\n",
    "        current_model,\n",
    "        pretrained=True,\n",
    "        num_classes=17\n",
    "    ).to(device)\n",
    "    \n",
    "    loss_fn = nn.CrossEntropyLoss(label_smoothing=0.05)  # Label Smoothing ì ìš©\n",
    "    optimizer = Adam(model.parameters(), lr=LR)\n",
    "    \n",
    "    # Learning Rate Scheduler ì¶”ê°€\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "    \n",
    "    # í˜„ì¬ foldì˜ ìµœê³  ì„±ëŠ¥ ì¶”ì \n",
    "    best_val_f1 = 0.0\n",
    "    best_model = None\n",
    "    \n",
    "    # í˜„ì¬ fold í•™ìŠµ\n",
    "    for epoch in range(EPOCHS):\n",
    "        # Training\n",
    "        train_ret = train_one_epoch(trn_loader, model, optimizer, loss_fn, device)\n",
    "        \n",
    "        # Validation\n",
    "        val_ret = validate_one_epoch(val_loader, model, loss_fn, device)\n",
    "        \n",
    "        # Scheduler step ì¶”ê°€\n",
    "        scheduler.step()\n",
    "        \n",
    "        print(f\"Epoch {epoch+1:2d} | \"\n",
    "              f\"Train Loss: {train_ret['train_loss']:.4f} | \"\n",
    "              f\"Train F1: {train_ret['train_f1']:.4f} | \"\n",
    "              f\"Val Loss: {val_ret['val_loss']:.4f} | \"\n",
    "              f\"Val F1: {val_ret['val_f1']:.4f}\")\n",
    "        \n",
    "        # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥\n",
    "        if val_ret['val_f1'] > best_val_f1:\n",
    "            best_val_f1 = val_ret['val_f1']\n",
    "            best_model = copy.deepcopy(model.state_dict())\n",
    "            \n",
    "            # Best ëª¨ë¸ ë¶„ì„\n",
    "            model.eval()\n",
    "            val_preds, val_targets = [], []\n",
    "            with torch.no_grad():\n",
    "                for image, targets in val_loader:\n",
    "                    preds = model(image.to(device)).argmax(dim=1)\n",
    "                    val_preds.extend(preds.cpu().numpy())\n",
    "                    val_targets.extend(targets.numpy())\n",
    "            \n",
    "            # í´ë˜ìŠ¤ë³„ ì •í™•ë„\n",
    "            fold_class_acc = {}\n",
    "            for c in range(17):\n",
    "                mask = np.array(val_targets) == c\n",
    "                if mask.sum() > 0:\n",
    "                    fold_class_acc[c] = (np.array(val_preds)[mask] == c).mean()\n",
    "    \n",
    "    # í˜„ì¬ fold ê²°ê³¼ ì €ì¥\n",
    "    fold_results.append({\n",
    "        'fold': fold + 1,\n",
    "        'best_val_f1': best_val_f1,\n",
    "        'train_samples': len(trn_dataset),\n",
    "        'val_samples': len(val_dataset)\n",
    "    })\n",
    "    \n",
    "    fold_models.append(best_model)\n",
    "    \n",
    "    print(f\"Fold {fold + 1} Best Validation F1: {best_val_f1:.4f}\")\n",
    "    \n",
    "    fold_class_accuracies.append(fold_class_acc) # ê° foldì˜ í´ë˜ìŠ¤ë³„ ì •í™•ë„ ì €ì¥\n",
    "\n",
    "# K-Fold ê²°ê³¼ ìš”ì•½\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"K-FOLD CROSS VALIDATION RESULTS\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "val_f1_scores = [result['best_val_f1'] for result in fold_results]\n",
    "mean_f1 = np.mean(val_f1_scores)\n",
    "std_f1 = np.std(val_f1_scores)\n",
    "\n",
    "for result in fold_results:\n",
    "    print(f\"Fold {result['fold']}: {result['best_val_f1']:.4f}\")\n",
    "\n",
    "print(f\"\\nMean CV F1: {mean_f1:.4f} Â± {std_f1:.4f}\")\n",
    "print(f\"Best single fold: {max(val_f1_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worst 3 classes:\n",
      "Class 7: 69.0%\n",
      "Class 14: 74.0%\n",
      "Class 3: 78.0%\n"
     ]
    }
   ],
   "source": [
    "# í´ë˜ìŠ¤ë³„ ì„±ëŠ¥ ì‹œê°í™”\n",
    "meta_df = pd.read_csv(\"../data/meta.csv\")\n",
    "avg_acc = {c: np.mean([f.get(c,0) for f in fold_class_accuracies]) for c in range(17)}\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "classes = list(avg_acc.keys())\n",
    "accs = [avg_acc[c] * 100 for c in classes]\n",
    "names = [f\"C{c}\" for c in classes]\n",
    "\n",
    "plt.bar(range(17), accs)\n",
    "plt.xticks(range(17), names)\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Class-wise Prediction Accuracy')\n",
    "for i, acc in enumerate(accs):\n",
    "    plt.text(i, acc + 1, f'{acc:.1f}%', ha='center', fontsize=8)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Worst 3 classes:\")\n",
    "worst = sorted(avg_acc.items(), key=lambda x: x[1])[:3]\n",
    "for c, acc in worst:\n",
    "    print(f\"Class {c}: {acc*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using ensemble of all 5 fold models for inference\n"
     ]
    }
   ],
   "source": [
    "# 5-Fold ì•™ìƒë¸” ëª¨ë¸ ì¤€ë¹„\n",
    "ensemble_models = []\n",
    "for i, state_dict in enumerate(fold_models):\n",
    "    fold_model = timm.create_model(model_name, pretrained=True, num_classes=17).to(device)\n",
    "    fold_model.load_state_dict(state_dict)\n",
    "    fold_model.eval()\n",
    "    ensemble_models.append(fold_model)\n",
    "print(f\"Using ensemble of all {len(ensemble_models)} fold models for inference\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Nmm5h3J-pXNV"
   },
   "source": [
    "## 5. Train Model\n",
    "* ëª¨ë¸ì„ ë¡œë“œí•˜ê³ , í•™ìŠµì„ ì§„í–‰í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 870,
     "status": "ok",
     "timestamp": 1700315114067,
     "user": {
      "displayName": "Ynot(ì†¡ì›í˜¸)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "FbBgFPsLT-CO"
   },
   "outputs": [],
   "source": [
    "# # load model\n",
    "# model = timm.create_model(\n",
    "#     model_name,\n",
    "#     pretrained=True,\n",
    "#     num_classes=17\n",
    "# ).to(device)\n",
    "# loss_fn = nn.CrossEntropyLoss()\n",
    "# optimizer = Adam(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8778,
     "status": "ok",
     "timestamp": 1700315122843,
     "user": {
      "displayName": "Ynot(ì†¡ì›í˜¸)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "OvIVcSRgUPtS",
    "outputId": "88230bf2-976f-45f6-b3b7-1a2d0ad00548"
   },
   "outputs": [],
   "source": [
    "# for epoch in range(EPOCHS):\n",
    "#     ret = train_one_epoch(trn_loader, model, optimizer, loss_fn, device=device)\n",
    "#     ret['epoch'] = epoch\n",
    "\n",
    "#     log = \"\"\n",
    "#     for k, v in ret.items():\n",
    "#       log += f\"{k}: {v:.4f}\\n\"\n",
    "#     print(log)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "lkwxRXoBpbaX"
   },
   "source": [
    "# 6. Inference & Save File\n",
    "* í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ì— ëŒ€í•œ ì¶”ë¡ ì„ ì§„í–‰í•˜ê³ , ê²°ê³¼ íŒŒì¼ì„ ì €ì¥í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12776,
     "status": "ok",
     "timestamp": 1700315185336,
     "user": {
      "displayName": "Ynot(ì†¡ì›í˜¸)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "uRYe6jlPU_Om",
    "outputId": "2a08690c-9ffe-418d-8679-eb9280147110"
   },
   "outputs": [],
   "source": [
    "# preds_list = []\n",
    "\n",
    "# model.eval()\n",
    "# for image, _ in tqdm(tst_loader):\n",
    "#     image = image.to(device)\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         preds = model(image)\n",
    "#     preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 282,
     "status": "ok",
     "timestamp": 1700315216829,
     "user": {
      "displayName": "Ynot(ì†¡ì›í˜¸)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "aClN7Qi7VZoh"
   },
   "outputs": [],
   "source": [
    "# pred_df = pd.DataFrame(tst_dataset.df, columns=['ID', 'target'])\n",
    "# pred_df['target'] = preds_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1700315238836,
     "user": {
      "displayName": "Ynot(ì†¡ì›í˜¸)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "VDBXQqAzVvLY"
   },
   "outputs": [],
   "source": [
    "# sample_submission_df = pd.read_csv(\"../data/sample_submission.csv\")\n",
    "# assert (sample_submission_df['ID'] == pred_df['ID']).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 317,
     "status": "ok",
     "timestamp": 1700315244710,
     "user": {
      "displayName": "Ynot(ì†¡ì›í˜¸)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "ePx2vCELVnuS"
   },
   "outputs": [],
   "source": [
    "# pred_df.to_csv(\"pred.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temperature Scaling í´ë˜ìŠ¤ ì •ì˜\n",
    "class TemperatureScaling(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.temperature = nn.Parameter(torch.ones(1) * 1.5)\n",
    "    \n",
    "    def forward(self, logits):\n",
    "        return logits / self.temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "essential_tta_transforms = [\n",
    "    # ì›ë³¸\n",
    "    A.Compose([\n",
    "        A.LongestMaxSize(max_size=img_size),\n",
    "        A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "    # 90ë„ íšŒì „ë“¤\n",
    "    A.Compose([\n",
    "        A.LongestMaxSize(max_size=img_size),\n",
    "        A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "        A.Rotate(limit=[90, 90], p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "    A.Compose([\n",
    "        A.LongestMaxSize(max_size=img_size),\n",
    "        A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "        A.Rotate(limit=[180, 180], p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "    A.Compose([\n",
    "        A.LongestMaxSize(max_size=img_size),\n",
    "        A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "        A.Rotate(limit=[-90, -90], p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "    # ë°ê¸° ê°œì„ \n",
    "    A.Compose([\n",
    "        A.LongestMaxSize(max_size=img_size),\n",
    "        A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "        A.RandomBrightnessContrast(brightness_limit=[0.3, 0.3], contrast_limit=[0.3, 0.3], p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TTA ì¶”ë¡ ì„ ìœ„í•œ Dataset í´ë˜ìŠ¤\n",
    "class TTAImageDataset(Dataset):\n",
    "    def __init__(self, data, path, transforms):\n",
    "        if isinstance(data, str):\n",
    "            self.df = pd.read_csv(data).values\n",
    "        else:\n",
    "            self.df = data.values\n",
    "        self.path = path\n",
    "        self.transforms = transforms  # ì—¬ëŸ¬ transformì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë°›ìŒ\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        name, target = self.df[idx]\n",
    "        img = np.array(Image.open(os.path.join(self.path, name)))\n",
    "        \n",
    "        # ëª¨ë“  transformì„ ì ìš©í•œ ê²°ê³¼ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜\n",
    "        augmented_images = []\n",
    "        for transform in self.transforms:\n",
    "            aug_img = transform(image=img)['image']\n",
    "            augmented_images.append(aug_img)\n",
    "        \n",
    "        return augmented_images, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TTA Dataset size: 3140\n"
     ]
    }
   ],
   "source": [
    "# TTA Dataset ìƒì„±\n",
    "tta_dataset = TTAImageDataset(\n",
    "    \"../data/sample_submission.csv\",\n",
    "    \"../data/test/\",\n",
    "    essential_tta_transforms\n",
    ")\n",
    "\n",
    "# TTA DataLoader (ë°°ì¹˜ í¬ê¸°ë¥¼ ì¤„ì—¬ì„œ ë©”ëª¨ë¦¬ ì ˆì•½)\n",
    "tta_loader = DataLoader(\n",
    "    tta_dataset,\n",
    "    batch_size=64,  # TTAëŠ” ë©”ëª¨ë¦¬ë¥¼ ë§ì´ ì‚¬ìš©í•˜ë¯€ë¡œ ë°°ì¹˜ í¬ê¸° ì¤„ì„\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"TTA Dataset size: {len(tta_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_tta_inference(models, loader, transforms, confidence_threshold=0.9):\n",
    "    \"\"\"5-Fold ëª¨ë¸ ì•™ìƒë¸” + TTA ì¶”ë¡ \"\"\"\n",
    "    all_predictions = []\n",
    "    \n",
    "    for batch_idx, (images_list, _) in enumerate(tqdm(loader, desc=\"Ensemble TTA\")):\n",
    "        batch_size = images_list[0].size(0)\n",
    "        ensemble_probs = torch.zeros(batch_size, 17).to(device)\n",
    "        \n",
    "        # ê° fold ëª¨ë¸ë³„ ì˜ˆì¸¡\n",
    "        for model in models:\n",
    "            with torch.no_grad():\n",
    "                # ê° TTA ë³€í˜•ë³„ ì˜ˆì¸¡\n",
    "                for images in images_list:\n",
    "                    images = images.to(device)\n",
    "                    preds = model(images)\n",
    "                    probs = torch.softmax(preds, dim=1)\n",
    "                    ensemble_probs += probs / (len(models) * len(images_list))\n",
    "        \n",
    "        final_preds = torch.argmax(ensemble_probs, dim=1)\n",
    "        all_predictions.extend(final_preds.cpu().numpy())\n",
    "    \n",
    "    return all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Ensemble TTA inference...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ensemble TTA:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ensemble TTA: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [09:33<00:00, 11.47s/it]\n"
     ]
    }
   ],
   "source": [
    "# ì•™ìƒë¸” TTA ì‹¤í–‰\n",
    "print(\"Starting Ensemble TTA inference...\")\n",
    "tta_predictions = ensemble_tta_inference(\n",
    "    models=ensemble_models, \n",
    "    loader=tta_loader, \n",
    "    transforms=essential_tta_transforms,\n",
    "    confidence_threshold=0.9\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TTA ê²°ê³¼ë¡œ submission íŒŒì¼ ìƒì„±\n",
    "tta_pred_df = pd.DataFrame(tta_dataset.df, columns=['ID', 'target'])\n",
    "tta_pred_df['target'] = tta_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê¸°ì¡´ submissionê³¼ ë™ì¼í•œ ìˆœì„œì¸ì§€ í™•ì¸\n",
    "sample_submission_df = pd.read_csv(\"../data/sample_submission.csv\")\n",
    "assert (sample_submission_df['ID'] == tta_pred_df['ID']).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TTA predictions saved\n",
      "TTA Prediction sample:\n"
     ]
    }
   ],
   "source": [
    "# TTA ê²°ê³¼ ì €ì¥\n",
    "tta_pred_df.to_csv(\"../submission/choice.csv\", index=False)\n",
    "print(\"TTA predictions saved\")\n",
    "\n",
    "print(\"TTA Prediction sample:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 353,
     "status": "ok",
     "timestamp": 1700315247734,
     "user": {
      "displayName": "Ynot(ì†¡ì›í˜¸)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "9yMO8s6GqAwZ",
    "outputId": "9a30616f-f0ea-439f-a906-dd806737ce00"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0008fdb22ddce0ce.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00091bffdffd83de.jpg</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00396fbc1f6cc21d.jpg</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00471f8038d9c4b6.jpg</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00901f504008d884.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     ID  target\n",
       "0  0008fdb22ddce0ce.jpg       2\n",
       "1  00091bffdffd83de.jpg      12\n",
       "2  00396fbc1f6cc21d.jpg       5\n",
       "3  00471f8038d9c4b6.jpg      12\n",
       "4  00901f504008d884.jpg       2"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tta_pred_df.head()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
