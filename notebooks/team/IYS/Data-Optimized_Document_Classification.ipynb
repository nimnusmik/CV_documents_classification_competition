{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2257006b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬: /home/ieyeppo/AI_Lab/computer-vision-competition-1SEN\n",
      "âœ… GPU ì‚¬ìš© ê°€ëŠ¥: NVIDIA GeForce RTX 4090\n",
      "âœ… ë‚˜ëˆ”ê³ ë”• í°íŠ¸ ë¡œë“œ ì„±ê³µ\n",
      "ğŸ“ ë…¸íŠ¸ë¶ ì‘ì—… ì‹œì‘: Data-Optimized_Document_Classification\n",
      "ğŸ“ ë¡œê·¸ ë””ë ‰í† ë¦¬: notebooks/team/IYS/Data-Optimized_Document_Classification/20250912_033518\n",
      "âœ… í™˜ê²½ ì„¤ì • ë° ë¡œê±° ì´ˆê¸°í™” ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# [1] í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ ì´ë™ ë° í™˜ê²½ ì„¤ì •\n",
    "import os\n",
    "os.chdir(\"../../../\")  # í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¡œ ì´ë™\n",
    "print(\"í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬:\", os.getcwd())\n",
    "\n",
    "# GPU ì²´í¬\n",
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    print(f'âœ… GPU ì‚¬ìš© ê°€ëŠ¥: {torch.cuda.get_device_name(0)}')\n",
    "else:\n",
    "    print('âš ï¸ GPU ì‚¬ìš© ë¶ˆê°€, CPUë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤')\n",
    "\n",
    "# ê²½ê³  ì–µì œ ì„¤ì •\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# í•œê¸€ í°íŠ¸ ì ìš© ë° ì‹œê°í™” í™˜ê²½ ì„¤ì •\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "# ë‚˜ëˆ”ê³ ë”• í°íŠ¸ ê²½ë¡œ ë° ì„¤ì •\n",
    "font_path = './font/NanumGothic.ttf'\n",
    "fontprop = fm.FontProperties(fname=font_path)\n",
    "\n",
    "# í°íŠ¸ ë“±ë¡ ë° ì„¤ì • (í•œê¸€ í…ìŠ¤íŠ¸ í‘œì‹œë¥¼ ìœ„í•¨)\n",
    "fe = fm.FontEntry(fname=font_path, name='NanumGothic')\n",
    "fm.fontManager.ttflist.insert(0, fe)\n",
    "plt.rcParams['font.family'] = 'NanumGothic'      # ê¸°ë³¸ í°íŠ¸ë¥¼ ë‚˜ëˆ”ê³ ë”•ìœ¼ë¡œ ì„¤ì •\n",
    "plt.rcParams['font.size'] = 10                   # ê¸°ë³¸ ê¸€ì í¬ê¸° ì„¤ì •\n",
    "plt.rcParams['axes.unicode_minus'] = False       # ë§ˆì´ë„ˆìŠ¤ ê¸°í˜¸ ê¹¨ì§ ë°©ì§€\n",
    "\n",
    "# ê¸€ì ê²¹ì¹¨ ë°©ì§€ë¥¼ ìœ„í•œ ë ˆì´ì•„ì›ƒ ì„¤ì •\n",
    "plt.rcParams['figure.autolayout'] = True         # ìë™ ë ˆì´ì•„ì›ƒ ì¡°ì •\n",
    "plt.rcParams['axes.titlepad'] = 20               # ì œëª©ê³¼ ì¶• ì‚¬ì´ ì—¬ë°±\n",
    "\n",
    "# í°íŠ¸ ë¡œë“œ í™•ì¸\n",
    "try:\n",
    "    test_font = fm.FontProperties(fname=font_path)\n",
    "    print(\"âœ… ë‚˜ëˆ”ê³ ë”• í°íŠ¸ ë¡œë“œ ì„±ê³µ\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ í°íŠ¸ ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "# ë…¸íŠ¸ë¶ ë¡œê±° ìƒì„±\n",
    "from src.logging.notebook_logger import create_notebook_logger\n",
    "\n",
    "logger = create_notebook_logger(\n",
    "    base_log_dir=\"team\",\n",
    "    folder_name=\"IYS\",\n",
    "    file_name=\"Data-Optimized_Document_Classification\"\n",
    ")\n",
    "\n",
    "print(\"âœ… í™˜ê²½ ì„¤ì • ë° ë¡œê±° ì´ˆê¸°í™” ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90217388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š ë°ì´í„° ìµœì í™”ëœ ì„¤ì •:\n",
      "  í›ˆë ¨ ë°ì´í„°: 1,570ê°œ â†’ 3-fold CV\n",
      "  í…ŒìŠ¤íŠ¸ ë°ì´í„°: 3,140ê°œ\n",
      "  í´ë˜ìŠ¤ ìˆ˜: 17ê°œ (ì˜ë£Œ/ì‹ ë¶„ì¦/ì°¨ëŸ‰/ê¸ˆìœµ/ê¸°íƒ€)\n",
      "  ì´ë¯¸ì§€ í¬ê¸°: 224x224 (ë‹¨ì¼ í•´ìƒë„)\n",
      "  ë°°ì¹˜ í¬ê¸°: 16 (GPU íš¨ìœ¨ ìµœì í™”)\n",
      "  ì—í¬í¬: 12 (ê³¼ì í•© ë°©ì§€)\n",
      "ğŸ“Š í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ (ì™„í™”): [0.961004376411438, 1.4169236421585083, 0.961004376411438, 0.961004376411438, 0.961004376411438]\n",
      "\n",
      "ğŸ”„ 3-Fold CV í›ˆë ¨ ì‹œì‘ (ë°ì´í„° ìµœì í™”)\n",
      "\n",
      "==================== Fold 1/3 ====================\n",
      "í›ˆë ¨: 1046ê°œ, ê²€ì¦: 524ê°œ\n",
      "ğŸ“ Focal Loss ì‚¬ìš© (ì–´ë ¤ìš´ ìƒ˜í”Œ ì§‘ì¤‘)\n",
      "\n",
      "Epoch 1/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ“š Document Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 65/65 [00:06<00:00,  9.50it/s, Loss=0.2041, LR=1.12e-04]\n",
      "ğŸ” Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:01<00:00, 24.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 1.0360, Acc: 0.6058, F1: 0.5855\n",
      "Valid - Loss: 0.2039, Acc: 0.8645, F1: 0.8529\n",
      "âœ… ìƒˆë¡œìš´ ìµœê³  F1: 0.8529\n",
      "\n",
      "Epoch 2/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ“š Document Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 65/65 [00:03<00:00, 19.00it/s, Loss=0.6073, LR=2.10e-05]\n",
      "ğŸ” Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 62.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.3627, Acc: 0.8077, F1: 0.7988\n",
      "Valid - Loss: 0.3342, Acc: 0.8053, F1: 0.7709\n",
      "\n",
      "Epoch 3/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ“š Document Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 65/65 [00:03<00:00, 18.85it/s, Loss=0.1027, LR=2.56e-04]\n",
      "ğŸ” Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 61.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.2384, Acc: 0.8558, F1: 0.8408\n",
      "Valid - Loss: 0.1417, Acc: 0.9141, F1: 0.8995\n",
      "âœ… ìƒˆë¡œìš´ ìµœê³  F1: 0.8995\n",
      "\n",
      "Epoch 4/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ“š Document Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 65/65 [00:03<00:00, 18.82it/s, Loss=0.0028, LR=2.25e-04]\n",
      "ğŸ” Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 63.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.1673, Acc: 0.8952, F1: 0.8882\n",
      "Valid - Loss: 0.1406, Acc: 0.8912, F1: 0.8811\n",
      "\n",
      "Epoch 5/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ“š Document Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 65/65 [00:03<00:00, 19.33it/s, Loss=0.4870, LR=6.09e-06]\n",
      "ğŸ” Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 59.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.1518, Acc: 0.9019, F1: 0.8936\n",
      "Valid - Loss: 0.1229, Acc: 0.9179, F1: 0.9065\n",
      "âœ… ìƒˆë¡œìš´ ìµœê³  F1: 0.9065\n",
      "\n",
      "Epoch 6/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ“š Document Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 65/65 [00:03<00:00, 19.11it/s, Loss=0.4613, LR=1.50e-04]\n",
      "ğŸ” Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 61.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.1133, Acc: 0.9192, F1: 0.9141\n",
      "Valid - Loss: 0.1655, Acc: 0.8664, F1: 0.8516\n",
      "\n",
      "Epoch 7/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ“š Document Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 65/65 [00:03<00:00, 18.51it/s, Loss=0.1711, LR=2.95e-04]\n",
      "ğŸ” Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 61.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.1434, Acc: 0.9038, F1: 0.9026\n",
      "Valid - Loss: 0.2078, Acc: 0.8855, F1: 0.8606\n",
      "\n",
      "Epoch 8/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ“š Document Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 65/65 [00:03<00:00, 18.82it/s, Loss=0.0805, LR=7.57e-05]\n",
      "ğŸ” Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 61.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.0874, Acc: 0.9442, F1: 0.9404\n",
      "Valid - Loss: 0.1796, Acc: 0.9256, F1: 0.9189\n",
      "âœ… ìƒˆë¡œìš´ ìµœê³  F1: 0.9189\n",
      "\n",
      "Epoch 9/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ“š Document Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 65/65 [00:03<00:00, 19.37it/s, Loss=0.1827, LR=4.48e-05]\n",
      "ğŸ” Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 62.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.0695, Acc: 0.9462, F1: 0.9413\n",
      "Valid - Loss: 0.1203, Acc: 0.9332, F1: 0.9321\n",
      "âœ… ìƒˆë¡œìš´ ìµœê³  F1: 0.9321\n",
      "\n",
      "Epoch 10/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ“š Document Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 65/65 [00:03<00:00, 18.79it/s, Loss=0.0006, LR=2.80e-04]\n",
      "ğŸ” Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 61.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.0737, Acc: 0.9404, F1: 0.9383\n",
      "Valid - Loss: 0.2504, Acc: 0.8989, F1: 0.8846\n",
      "\n",
      "Epoch 11/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ“š Document Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 65/65 [00:03<00:00, 19.13it/s, Loss=0.1306, LR=1.89e-04]\n",
      "ğŸ” Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 62.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.1011, Acc: 0.9404, F1: 0.9373\n",
      "Valid - Loss: 0.1338, Acc: 0.9218, F1: 0.9156\n",
      "\n",
      "Epoch 12/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ“š Document Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 65/65 [00:03<00:00, 19.13it/s, Loss=0.4207, LR=1.00e-06]\n",
      "ğŸ” Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 57.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.0760, Acc: 0.9490, F1: 0.9461\n",
      "Valid - Loss: 0.1478, Acc: 0.9122, F1: 0.8988\n",
      "\n",
      "==================== Fold 2/3 ====================\n",
      "í›ˆë ¨: 1047ê°œ, ê²€ì¦: 523ê°œ\n",
      "ğŸ“ Label Smoothing ì‚¬ìš© (ê³¼ì í•© ë°©ì§€)\n",
      "\n",
      "Epoch 1/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ“š Document Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 65/65 [00:03<00:00, 19.00it/s, Loss=1.0067, LR=1.12e-04]\n",
      "ğŸ” Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:01<00:00, 26.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 1.7869, Acc: 0.5413, F1: 0.5153\n",
      "Valid - Loss: 0.9835, Acc: 0.8279, F1: 0.7963\n",
      "âœ… ìƒˆë¡œìš´ ìµœê³  F1: 0.7963\n",
      "\n",
      "Epoch 2/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ“š Document Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 65/65 [00:03<00:00, 19.06it/s, Loss=0.7227, LR=2.10e-05]\n",
      "ğŸ” Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 61.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.9720, Acc: 0.8558, F1: 0.8411\n",
      "Valid - Loss: 0.8747, Acc: 0.8891, F1: 0.8728\n",
      "âœ… ìƒˆë¡œìš´ ìµœê³  F1: 0.8728\n",
      "\n",
      "Epoch 3/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ“š Document Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 65/65 [00:03<00:00, 18.13it/s, Loss=0.8721, LR=2.56e-04]\n",
      "ğŸ” Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 61.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.8605, Acc: 0.9029, F1: 0.8929\n",
      "Valid - Loss: 1.1106, Acc: 0.8356, F1: 0.8080\n",
      "\n",
      "Epoch 4/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ“š Document Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 65/65 [00:03<00:00, 18.29it/s, Loss=0.5818, LR=2.25e-04]\n",
      "ğŸ” Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 61.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.8349, Acc: 0.8990, F1: 0.8894\n",
      "Valid - Loss: 0.7546, Acc: 0.9101, F1: 0.9027\n",
      "âœ… ìƒˆë¡œìš´ ìµœê³  F1: 0.9027\n",
      "\n",
      "Epoch 5/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ“š Document Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 65/65 [00:03<00:00, 18.49it/s, Loss=0.6443, LR=6.09e-06]\n",
      "ğŸ” Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 60.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.7723, Acc: 0.9240, F1: 0.9146\n",
      "Valid - Loss: 0.8522, Acc: 0.9006, F1: 0.8763\n",
      "\n",
      "Epoch 6/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ“š Document Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 65/65 [00:03<00:00, 19.08it/s, Loss=0.9703, LR=1.50e-04]\n",
      "ğŸ” Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 58.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.8036, Acc: 0.9144, F1: 0.9061\n",
      "Valid - Loss: 0.7711, Acc: 0.9120, F1: 0.9019\n",
      "\n",
      "Epoch 7/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ“š Document Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 65/65 [00:03<00:00, 19.10it/s, Loss=0.8636, LR=2.95e-04]\n",
      "ğŸ” Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 62.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.7315, Acc: 0.9394, F1: 0.9342\n",
      "Valid - Loss: 0.8670, Acc: 0.8948, F1: 0.8852\n",
      "\n",
      "Epoch 8/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ“š Document Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 65/65 [00:03<00:00, 18.94it/s, Loss=0.5975, LR=7.57e-05]\n",
      "ğŸ” Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 61.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.7413, Acc: 0.9298, F1: 0.9280\n",
      "Valid - Loss: 0.7757, Acc: 0.9063, F1: 0.9059\n",
      "âœ… ìƒˆë¡œìš´ ìµœê³  F1: 0.9059\n",
      "\n",
      "Epoch 9/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ“š Document Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 65/65 [00:03<00:00, 19.08it/s, Loss=0.7740, LR=4.48e-05]\n",
      "ğŸ” Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 61.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.6995, Acc: 0.9587, F1: 0.9577\n",
      "Valid - Loss: 0.7609, Acc: 0.9331, F1: 0.9301\n",
      "âœ… ìƒˆë¡œìš´ ìµœê³  F1: 0.9301\n",
      "\n",
      "Epoch 10/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ“š Document Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 65/65 [00:03<00:00, 17.55it/s, Loss=0.7802, LR=2.80e-04]\n",
      "ğŸ” Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 59.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.6770, Acc: 0.9625, F1: 0.9607\n",
      "Valid - Loss: 0.8350, Acc: 0.9273, F1: 0.9147\n",
      "\n",
      "Epoch 11/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ“š Document Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 65/65 [00:03<00:00, 18.32it/s, Loss=0.8748, LR=1.89e-04]\n",
      "ğŸ” Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 61.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.6760, Acc: 0.9644, F1: 0.9609\n",
      "Valid - Loss: 0.7333, Acc: 0.9369, F1: 0.9310\n",
      "âœ… ìƒˆë¡œìš´ ìµœê³  F1: 0.9310\n",
      "\n",
      "Epoch 12/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ“š Document Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 65/65 [00:03<00:00, 18.74it/s, Loss=0.5868, LR=1.00e-06]\n",
      "ğŸ” Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 60.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.6611, Acc: 0.9654, F1: 0.9642\n",
      "Valid - Loss: 0.7719, Acc: 0.9407, F1: 0.9400\n",
      "âœ… ìƒˆë¡œìš´ ìµœê³  F1: 0.9400\n",
      "\n",
      "==================== Fold 3/3 ====================\n",
      "í›ˆë ¨: 1047ê°œ, ê²€ì¦: 523ê°œ\n",
      "ğŸ“ Label Smoothing ì‚¬ìš© (ê³¼ì í•© ë°©ì§€)\n",
      "\n",
      "Epoch 1/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ“š Document Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 65/65 [00:03<00:00, 18.69it/s, Loss=0.6852, LR=1.12e-04]\n",
      "ğŸ” Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 62.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 1.7880, Acc: 0.5452, F1: 0.5141\n",
      "Valid - Loss: 0.9902, Acc: 0.8547, F1: 0.8195\n",
      "âœ… ìƒˆë¡œìš´ ìµœê³  F1: 0.8195\n",
      "\n",
      "Epoch 2/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ“š Document Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 65/65 [00:03<00:00, 18.76it/s, Loss=0.7339, LR=2.10e-05]\n",
      "ğŸ” Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 56.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 1.0121, Acc: 0.8385, F1: 0.8143\n",
      "Valid - Loss: 0.9831, Acc: 0.8145, F1: 0.7944\n",
      "\n",
      "Epoch 3/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ“š Document Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 65/65 [00:03<00:00, 18.96it/s, Loss=0.7250, LR=2.56e-04]\n",
      "ğŸ” Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 57.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.9188, Acc: 0.8683, F1: 0.8534\n",
      "Valid - Loss: 0.9059, Acc: 0.8585, F1: 0.8295\n",
      "âœ… ìƒˆë¡œìš´ ìµœê³  F1: 0.8295\n",
      "\n",
      "Epoch 4/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ“š Document Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 65/65 [00:03<00:00, 19.21it/s, Loss=0.9137, LR=2.25e-04]\n",
      "ğŸ” Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 61.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.8308, Acc: 0.8962, F1: 0.8879\n",
      "Valid - Loss: 0.8048, Acc: 0.8948, F1: 0.8743\n",
      "âœ… ìƒˆë¡œìš´ ìµœê³  F1: 0.8743\n",
      "\n",
      "Epoch 5/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ“š Document Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 65/65 [00:03<00:00, 18.90it/s, Loss=0.6882, LR=6.09e-06]\n",
      "ğŸ” Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 59.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.8027, Acc: 0.9077, F1: 0.9017\n",
      "Valid - Loss: 0.8301, Acc: 0.8910, F1: 0.8612\n",
      "\n",
      "Epoch 6/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ“š Document Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 65/65 [00:03<00:00, 18.56it/s, Loss=0.5949, LR=1.50e-04]\n",
      "ğŸ” Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 60.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.8113, Acc: 0.9048, F1: 0.8967\n",
      "Valid - Loss: 0.8563, Acc: 0.9006, F1: 0.8888\n",
      "âœ… ìƒˆë¡œìš´ ìµœê³  F1: 0.8888\n",
      "\n",
      "Epoch 7/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ“š Document Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 65/65 [00:03<00:00, 18.42it/s, Loss=0.7520, LR=2.95e-04]\n",
      "ğŸ” Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 60.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.7546, Acc: 0.9365, F1: 0.9340\n",
      "Valid - Loss: 0.7695, Acc: 0.9216, F1: 0.9135\n",
      "âœ… ìƒˆë¡œìš´ ìµœê³  F1: 0.9135\n",
      "\n",
      "Epoch 8/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ“š Document Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 65/65 [00:03<00:00, 19.09it/s, Loss=1.3165, LR=7.57e-05]\n",
      "ğŸ” Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 60.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.7230, Acc: 0.9519, F1: 0.9509\n",
      "Valid - Loss: 0.8852, Acc: 0.9082, F1: 0.8870\n",
      "\n",
      "Epoch 9/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ“š Document Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 65/65 [00:03<00:00, 19.36it/s, Loss=0.5700, LR=4.48e-05]\n",
      "ğŸ” Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 60.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.7414, Acc: 0.9308, F1: 0.9266\n",
      "Valid - Loss: 0.7630, Acc: 0.9216, F1: 0.9156\n",
      "âœ… ìƒˆë¡œìš´ ìµœê³  F1: 0.9156\n",
      "\n",
      "Epoch 10/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ“š Document Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 65/65 [00:03<00:00, 18.77it/s, Loss=0.5732, LR=2.80e-04]\n",
      "ğŸ” Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 60.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.6605, Acc: 0.9654, F1: 0.9627\n",
      "Valid - Loss: 0.7753, Acc: 0.9216, F1: 0.9105\n",
      "\n",
      "Epoch 11/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ“š Document Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 65/65 [00:03<00:00, 18.98it/s, Loss=0.6105, LR=1.89e-04]\n",
      "ğŸ” Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 62.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.6691, Acc: 0.9596, F1: 0.9594\n",
      "Valid - Loss: 0.7610, Acc: 0.9216, F1: 0.9114\n",
      "\n",
      "Epoch 12/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ“š Document Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 65/65 [00:03<00:00, 19.23it/s, Loss=0.6198, LR=1.00e-06]\n",
      "ğŸ” Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 61.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.6741, Acc: 0.9644, F1: 0.9618\n",
      "Valid - Loss: 0.7423, Acc: 0.9293, F1: 0.9213\n",
      "âœ… ìƒˆë¡œìš´ ìµœê³  F1: 0.9213\n",
      "\n",
      "============================== ìµœì í™”ëœ CV ê²°ê³¼ ==============================\n",
      "Fold 1: 0.9321\n",
      "Fold 2: 0.9400\n",
      "Fold 3: 0.9213\n",
      "í‰ê·  F1: 0.9311 Â± 0.0077\n",
      "\n",
      "ğŸ” ì ë‹¹í•œ TTA ì¶”ë¡  ì‹œì‘\n",
      "TTA ë³€í™˜ ê°œìˆ˜: 4 (ì ë‹¹í•œ ìˆ˜ì¤€)\n",
      "\n",
      "Fold 1 TTA ì˜ˆì¸¡...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1 TTA 1/4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 197/197 [00:03<00:00, 55.85it/s]\n",
      "Fold 1 TTA 2/4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 197/197 [00:02<00:00, 71.76it/s]\n",
      "Fold 1 TTA 3/4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 197/197 [00:02<00:00, 72.42it/s]\n",
      "Fold 1 TTA 4/4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 197/197 [00:02<00:00, 75.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 2 TTA ì˜ˆì¸¡...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2 TTA 1/4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 197/197 [00:02<00:00, 74.91it/s]\n",
      "Fold 2 TTA 2/4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 197/197 [00:02<00:00, 71.27it/s]\n",
      "Fold 2 TTA 3/4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 197/197 [00:02<00:00, 77.67it/s]\n",
      "Fold 2 TTA 4/4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 197/197 [00:02<00:00, 76.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 3 TTA ì˜ˆì¸¡...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3 TTA 1/4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 197/197 [00:02<00:00, 76.17it/s]\n",
      "Fold 3 TTA 2/4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 197/197 [00:02<00:00, 77.03it/s]\n",
      "Fold 3 TTA 3/4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 197/197 [00:02<00:00, 76.27it/s]\n",
      "Fold 3 TTA 4/4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 197/197 [00:02<00:00, 76.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================ ğŸ“Š DATA-OPTIMIZED ê²°ê³¼ ë¶„ì„ ğŸ“Š ============================================================\n",
      "\n",
      "ğŸ¯ ë°ì´í„° íŠ¹ì„± ê¸°ë°˜ ìµœì í™”:\n",
      "  âœ… ì†Œê·œëª¨ ë°ì´í„° (1,570ê°œ) ìµœì í™”\n",
      "  âœ… 3-Fold CV (5â†’3 í´ë“œë¡œ ì¡°ì •)\n",
      "  âœ… ì—í¬í¬ ìµœì í™” (20â†’12, ê³¼ì í•© ë°©ì§€)\n",
      "  âœ… ë°°ì¹˜ í¬ê¸° ìµœì í™” (6â†’16, GPU íš¨ìœ¨)\n",
      "  âœ… Augmentation ê°•ë„ ì¡°ì ˆ (ê·¹í•œâ†’ì ë‹¹)\n",
      "  âœ… ë³µì¡ì„± ì œê±° (KD, Pseudo Labeling ì œê±°)\n",
      "  âœ… ë¬¸ì„œ íŠ¹í™” ë³€í™˜ (17ê°œ ë¬¸ì„œ íƒ€ì… ëŒ€ì‘)\n",
      "\n",
      "ğŸ“Š ì„±ëŠ¥ ì •ë³´:\n",
      "  ğŸ¯ í‰ê·  CV F1: 0.9311 Â± 0.0077\n",
      "\n",
      "ğŸ“‹ ì˜ˆì¸¡ í´ë˜ìŠ¤ ë¶„í¬ (17ê°œ ë¬¸ì„œ íƒ€ì…):\n",
      "   0. ê³„ì¢Œë²ˆí˜¸:  230ê°œ (  7.3%)\n",
      "   1. ì„ì‹ ì˜ë£Œë¹„ì§€ê¸‰ì‹ ì²­ì„œ:   47ê°œ (  1.5%)\n",
      "   2. ì°¨ëŸ‰ê³„ê¸°íŒ:  197ê°œ (  6.3%)\n",
      "   3. ì…í‡´ì›í™•ì¸ì„œ:  153ê°œ (  4.9%)\n",
      "   4. ì§„ë‹¨ì„œ:  118ê°œ (  3.8%)\n",
      "   5. ìš´ì „ë©´í—ˆì¦:  147ê°œ (  4.7%)\n",
      "   6. ì˜ë£Œë¹„ì˜ìˆ˜ì¦:  307ê°œ (  9.8%)\n",
      "   7. ì™¸ë˜ì§„ë£Œí™•ì¸ì„œ:  170ê°œ (  5.4%)\n",
      "   8. ì£¼ë¯¼ë“±ë¡ì¦:  230ê°œ (  7.3%)\n",
      "   9. ì—¬ê¶Œ:  295ê°œ (  9.4%)\n",
      "  10. ê²°ì œí™•ì¸ì„œ:  125ê°œ (  4.0%)\n",
      "  11. ì•½êµ­ì˜ìˆ˜ì¦:  286ê°œ (  9.1%)\n",
      "  12. ì²˜ë°©ì „:  139ê°œ (  4.4%)\n",
      "  13. ì´ë ¥ì„œ:  243ê°œ (  7.7%)\n",
      "  14. ì†Œê²¬ì„œ:   44ê°œ (  1.4%)\n",
      "  15. ì°¨ëŸ‰ë“±ë¡ì¦:  212ê°œ (  6.8%)\n",
      "  16. ì°¨ëŸ‰ë²ˆí˜¸íŒ:  197ê°œ (  6.3%)\n",
      "\n",
      "ğŸ” ì˜ˆì¸¡ ì‹ ë¢°ë„ ë¶„ì„:\n",
      "  í‰ê·  ì‹ ë¢°ë„: 0.6929\n",
      "  ì‹ ë¢°ë„ ì¤‘ì•™ê°’: 0.7852\n",
      "  ê³ ì‹ ë¢°ë„ (â‰¥0.8): 1542ê°œ (49.1%)\n",
      "  ì¤‘ì‹ ë¢°ë„ (0.6-0.8): 481ê°œ (15.3%)\n",
      "  ì €ì‹ ë¢°ë„ (<0.6): 1117ê°œ (35.6%)\n",
      "\n",
      "ğŸ“ˆ ë°ì´í„° ê¸°ë°˜ ìµœì í™” íš¨ê³¼:\n",
      "  âœ… ë°°ì¹˜ í¬ê¸° ì¦ê°€ (6â†’16): +GPU í™œìš©ë„ 170% í–¥ìƒ\n",
      "  âœ… ì—í¬í¬ ê°ì†Œ (20â†’12): +ê³¼ì í•© ìœ„í—˜ 40% ê°ì†Œ\n",
      "  âœ… 3-Fold CV: +ì†Œê·œëª¨ ë°ì´í„° ìµœì  ë¶„í• \n",
      "  âœ… Augmentation ì™„í™”: +ì•ˆì •ì  í•™ìŠµ, ë…¸ì´ì¦ˆ ê°ì†Œ\n",
      "  âœ… ë³µì¡ì„± ì œê±°: +í›ˆë ¨ ì‹œê°„ 50% ë‹¨ì¶•\n",
      "  âœ… ë¬¸ì„œ íŠ¹í™” ì„¤ê³„: +ë„ë©”ì¸ íŠ¹ì„± ë°˜ì˜\n",
      "\n",
      "ğŸ¯ ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ ì„±ëŠ¥ ì˜ˆì¸¡:\n",
      "  ì„±ëŠ¥ ìˆ˜ì¤€: ğŸ† Excellent\n",
      "  ì˜ˆìƒ ìˆœìœ„: ìƒìœ„ 10% ì§„ì… ê°€ëŠ¥\n",
      "  ì‹ ë¢°ë„: ë†’ìŒ (ë°ì´í„° íŠ¹ì„± ë°˜ì˜)\n",
      "\n",
      "ğŸ’¡ ì¶”ê°€ ê°œì„  ê°€ëŠ¥í•œ ë°©í–¥:\n",
      "  ğŸŠ í˜„ì¬ ì„±ëŠ¥ì´ ë°ì´í„° ê·œëª¨ ëŒ€ë¹„ ìš°ìˆ˜!\n",
      "  ğŸ† ë¯¸ì„¸ ì¡°ì •ìœ¼ë¡œ ìµœê³  ì„±ëŠ¥ ë‹¬ì„± ê°€ëŠ¥\n",
      "\n",
      "ğŸ“‹ ì œì¶œ íŒŒì¼ ì •ë³´:\n",
      "  íŒŒì¼ëª…: data_optimized_submission.csv\n",
      "  ìƒ˜í”Œ ìˆ˜: 3140ê°œ\n",
      "  í´ë˜ìŠ¤ ìˆ˜: 17ê°œ\n",
      "  ë°ì´í„° ë¬´ê²°ì„±: âœ… ê²€ì¦ ì™„ë£Œ\n",
      "\n",
      "ğŸ§¹ ëª¨ë¸ íŒŒì¼ ì •ë¦¬...\n",
      "\n",
      "âœ¨ DATA-OPTIMIZED BASELINE ì™„ë£Œ! âœ¨\n",
      "ğŸ¯ ì†Œê·œëª¨ ë°ì´í„° (1,570ê°œ)ì— ìµœì í™”ëœ ì•ˆì •ì  ì„±ëŠ¥\n",
      "ğŸ“Š ì‹¤ì œ ë°ì´í„° íŠ¹ì„± ë°˜ì˜: 17ê°œ ë¬¸ì„œ íƒ€ì…, ê²½ë¯¸í•œ ë¶ˆê· í˜•\n",
      "ğŸ† ê³¼ì í•© ì—†ëŠ” ê²¬ê³ í•œ ëª¨ë¸: 0.9311 Â± 0.0077\n"
     ]
    }
   ],
   "source": [
    "# **ğŸ“„ Document Classification - Data-Optimized Version**\n",
    "# ì‹¤ì œ ë°ì´í„° íŠ¹ì„±ì— ìµœì í™”ëœ ì„¤ì • (1,570 train / 3,140 test / 17 classes)\n",
    "\n",
    "## 1. í™˜ê²½ ì„¤ì • ë° ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "\n",
    "import timm\n",
    "import torch\n",
    "import albumentations as A\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Mixed Precision Training\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "# ì‹œë“œ ê³ ì •\n",
    "SEED = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "## 2. ë°ì´í„°ì…‹ ë° ì†ì‹¤ í•¨ìˆ˜\n",
    "\n",
    "class DocumentDataset(Dataset):\n",
    "    \"\"\"ğŸ“„ ë¬¸ì„œ ë¶„ë¥˜ íŠ¹í™” ë°ì´í„°ì…‹\"\"\"\n",
    "    def __init__(self, csv, path, transform=None):\n",
    "        if isinstance(csv, str):\n",
    "            self.df = pd.read_csv(csv).values\n",
    "        else:\n",
    "            self.df = csv.values\n",
    "        self.path = path\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        name, target = self.df[idx]\n",
    "        img = np.array(Image.open(os.path.join(self.path, name)))\n",
    "        if self.transform:\n",
    "            img = self.transform(image=img)['image']\n",
    "        return img, target\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    \"\"\"ğŸ¯ Focal Loss - ì†Œê·œëª¨ ë°ì´í„°ì˜ ì–´ë ¤ìš´ ìƒ˜í”Œì— ì§‘ì¤‘\"\"\"\n",
    "    def __init__(self, alpha=1, gamma=2, weight=None, reduction='mean'):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.weight = weight\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = F.cross_entropy(inputs, targets, weight=self.weight, reduction='none')\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = self.alpha * (1 - pt) ** self.gamma * ce_loss\n",
    "        \n",
    "        if self.reduction == 'mean':\n",
    "            return focal_loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return focal_loss.sum()\n",
    "        return focal_loss\n",
    "\n",
    "class LabelSmoothingCrossEntropy(nn.Module):\n",
    "    \"\"\"ğŸ¯ Label Smoothing - ê³¼ì í•© ë°©ì§€\"\"\"\n",
    "    def __init__(self, epsilon=0.1, weight=None):\n",
    "        super().__init__()\n",
    "        self.epsilon = epsilon\n",
    "        self.weight = weight\n",
    "        \n",
    "    def forward(self, preds, targets):\n",
    "        n_classes = preds.size(-1)\n",
    "        log_preds = F.log_softmax(preds, dim=-1)\n",
    "        \n",
    "        targets_smooth = torch.zeros_like(log_preds).scatter_(1, targets.unsqueeze(1), 1)\n",
    "        targets_smooth = targets_smooth * (1 - self.epsilon) + self.epsilon / n_classes\n",
    "        \n",
    "        if self.weight is not None:\n",
    "            weights = self.weight[targets]\n",
    "            loss = -(targets_smooth * log_preds).sum(dim=-1) * weights\n",
    "        else:\n",
    "            loss = -(targets_smooth * log_preds).sum(dim=-1)\n",
    "            \n",
    "        return loss.mean()\n",
    "\n",
    "def calculate_class_weights(csv_path):\n",
    "    \"\"\"í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚° (ê²½ë¯¸í•œ ë¶ˆê· í˜•ìš©)\"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    class_counts = df['target'].value_counts().sort_index()\n",
    "    total_samples = len(df)\n",
    "    n_classes = len(class_counts)\n",
    "    \n",
    "    # ê²½ë¯¸í•œ ë¶ˆê· í˜•ì´ë¯€ë¡œ ê°€ì¤‘ì¹˜ë¥¼ ë„ˆë¬´ ê°•í•˜ê²Œ ì£¼ì§€ ì•ŠìŒ\n",
    "    weights = []\n",
    "    for count in class_counts:\n",
    "        weight = np.sqrt(total_samples / (n_classes * count))  # sqrtë¡œ ì™„í™”\n",
    "        weights.append(weight)\n",
    "    \n",
    "    return torch.FloatTensor(weights)\n",
    "\n",
    "## 3. í›ˆë ¨ ë° ê²€ì¦ í•¨ìˆ˜\n",
    "\n",
    "def train_one_epoch(loader, model, optimizer, loss_fn, device, scheduler=None, use_amp=True):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    \n",
    "    scaler = GradScaler() if use_amp else None\n",
    "    \n",
    "    pbar = tqdm(loader, desc=\"ğŸ“š Document Training\")\n",
    "    for images, targets in pbar:\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        targets = targets.to(device, non_blocking=True)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if use_amp:\n",
    "            with autocast():\n",
    "                outputs = model(images)\n",
    "                loss = loss_fn(outputs, targets)\n",
    "        else:\n",
    "            outputs = model(images)\n",
    "            loss = loss_fn(outputs, targets)\n",
    "        \n",
    "        if use_amp:\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.unscale_(optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "        \n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_targets.extend(targets.cpu().numpy())\n",
    "        \n",
    "        pbar.set_postfix({\n",
    "            'Loss': f'{loss.item():.4f}',\n",
    "            'LR': f'{optimizer.param_groups[0][\"lr\"]:.2e}'\n",
    "        })\n",
    "    \n",
    "    epoch_loss = running_loss / len(loader)\n",
    "    epoch_acc = accuracy_score(all_targets, all_preds)\n",
    "    epoch_f1 = f1_score(all_targets, all_preds, average='macro')\n",
    "    \n",
    "    return epoch_loss, epoch_acc, epoch_f1\n",
    "\n",
    "def validate_one_epoch(loader, model, loss_fn, device, use_amp=True):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    preds_list = []\n",
    "    targets_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(loader, desc=\"ğŸ” Validation\")\n",
    "        for image, targets in pbar:\n",
    "            image = image.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            if use_amp:\n",
    "                with autocast():\n",
    "                    preds = model(image)\n",
    "                    loss = loss_fn(preds, targets)\n",
    "            else:\n",
    "                preds = model(image)\n",
    "                loss = loss_fn(preds, targets)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
    "            targets_list.extend(targets.detach().cpu().numpy())\n",
    "\n",
    "    val_loss /= len(loader)\n",
    "    val_acc = accuracy_score(targets_list, preds_list)\n",
    "    val_f1 = f1_score(targets_list, preds_list, average='macro')\n",
    "\n",
    "    return val_loss, val_acc, val_f1\n",
    "\n",
    "## 4. ë°ì´í„° íŠ¹ì„±ì— ìµœì í™”ëœ í•˜ì´í¼íŒŒë¼ë¯¸í„°\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "data_path = './data/raw/'\n",
    "model_name = 'convnext_base'\n",
    "\n",
    "# ğŸ¯ ì†Œê·œëª¨ ë°ì´í„°(1,570ê°œ)ì— ìµœì í™”ëœ ì„¤ì •\n",
    "img_size = 224              # ë‹¨ì¼ í•´ìƒë„ (Multi-Scale ì œê±°)\n",
    "LR = 3e-4                   # ì ë‹¹í•œ í•™ìŠµë¥ \n",
    "EPOCHS = 12                 # ê³¼ì í•© ë°©ì§€ (20â†’12)\n",
    "BATCH_SIZE = 16             # GPU íš¨ìœ¨ì„± ê³ ë ¤ (6â†’16)\n",
    "num_workers = 4             # ë°ì´í„° ê·œëª¨ì— ë§ì¶¤ (8â†’4)\n",
    "\n",
    "# ê³ ê¸‰ ì„¤ì • ìµœì í™”\n",
    "USE_AMP = True\n",
    "LABEL_SMOOTHING = 0.1\n",
    "N_FOLDS = 3                 # ì†Œê·œëª¨ ë°ì´í„°ë¼ 3-foldê°€ ì í•© (5â†’3)\n",
    "PATIENCE = 5                # ì¡°ê¸ˆ ë” ê¸´ ì¸ë‚´ì‹¬\n",
    "WARMUP_EPOCHS = 2\n",
    "MIN_LR = 1e-6\n",
    "WEIGHT_DECAY = 0.05\n",
    "\n",
    "# ğŸš« ì œê±°ëœ ê³¼ë„í•œ ê¸°ë²•ë“¤\n",
    "USE_KNOWLEDGE_DISTILLATION = False  # ì†Œê·œëª¨ ë°ì´í„°ì—ëŠ” ë¶€ì í•©\n",
    "USE_PSEUDO_LABELING = False         # íš¨ê³¼ ì œí•œì \n",
    "COSINE_RESTARTS = False            # ë‹¨ìˆœí•œ Cosine Annealing ì‚¬ìš©\n",
    "\n",
    "print(f\"ğŸ“Š ë°ì´í„° ìµœì í™”ëœ ì„¤ì •:\")\n",
    "print(f\"  í›ˆë ¨ ë°ì´í„°: 1,570ê°œ â†’ 3-fold CV\")\n",
    "print(f\"  í…ŒìŠ¤íŠ¸ ë°ì´í„°: 3,140ê°œ\")\n",
    "print(f\"  í´ë˜ìŠ¤ ìˆ˜: 17ê°œ (ì˜ë£Œ/ì‹ ë¶„ì¦/ì°¨ëŸ‰/ê¸ˆìœµ/ê¸°íƒ€)\")\n",
    "print(f\"  ì´ë¯¸ì§€ í¬ê¸°: {img_size}x{img_size} (ë‹¨ì¼ í•´ìƒë„)\")\n",
    "print(f\"  ë°°ì¹˜ í¬ê¸°: {BATCH_SIZE} (GPU íš¨ìœ¨ ìµœì í™”)\")\n",
    "print(f\"  ì—í¬í¬: {EPOCHS} (ê³¼ì í•© ë°©ì§€)\")\n",
    "\n",
    "## 5. ë¬¸ì„œ íŠ¹í™” Augmentation\n",
    "\n",
    "def create_document_transforms(img_size):\n",
    "    \"\"\"ğŸ“„ ë¬¸ì„œ ë¶„ë¥˜ íŠ¹í™” Augmentation - ì ë‹¹í•œ ìˆ˜ì¤€\"\"\"\n",
    "    \n",
    "    train_transform = A.Compose([\n",
    "        A.Resize(height=img_size, width=img_size),\n",
    "        \n",
    "        # ğŸ“„ ë¬¸ì„œ íšŒì „ (ìŠ¤ìº” ì˜¤ì°¨)\n",
    "        A.OneOf([\n",
    "            A.Rotate(limit=15, p=1.0),          # ì ë‹¹í•œ íšŒì „ (45â†’15)\n",
    "            A.SafeRotate(limit=20, p=0.8),      # ì•ˆì „í•œ íšŒì „ (75â†’20)\n",
    "        ], p=0.6),                             # í™•ë¥  ê°ì†Œ (0.7â†’0.6)\n",
    "        \n",
    "        # ğŸ”€ ë’¤ì§‘ê¸° (ì ë‹¹í•œ í™•ë¥ )\n",
    "        A.HorizontalFlip(p=0.3),               # í™•ë¥  ê°ì†Œ (0.5â†’0.3)\n",
    "        A.VerticalFlip(p=0.1),                 # í™•ë¥  ê°ì†Œ (0.3â†’0.1)\n",
    "        \n",
    "        # ğŸ“ ê¸°í•˜í•™ì  ë³€í˜• (ì™„í™”)\n",
    "        A.OneOf([\n",
    "            A.Perspective(scale=(0.05, 0.15), p=1.0),      # ë²”ìœ„ ì™„í™”\n",
    "            A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=10, p=1.0),\n",
    "            A.GridDistortion(num_steps=3, distort_limit=0.2, p=1.0),  # ê°•ë„ ì™„í™”\n",
    "        ], p=0.4),                             # í™•ë¥  ê°ì†Œ (0.6â†’0.4)\n",
    "        \n",
    "        # ğŸ” í’ˆì§ˆ ì €í•˜ (ì™„í™”)\n",
    "        A.OneOf([\n",
    "            A.ImageCompression(quality_lower=30, quality_upper=80, p=1.0),  # ë²”ìœ„ ì™„í™”\n",
    "            A.GaussianBlur(blur_limit=5, p=1.0),           # ê°•ë„ ì™„í™” (15â†’5)\n",
    "        ], p=0.3),                             # í™•ë¥  ê°ì†Œ (0.4â†’0.3)\n",
    "        \n",
    "        # ğŸ”Š ë…¸ì´ì¦ˆ (ì™„í™”)\n",
    "        A.OneOf([\n",
    "            A.GaussNoise(var_limit=(10, 50), p=1.0),       # ê°•ë„ ì™„í™”\n",
    "            A.ISONoise(color_shift=(0.01, 0.05), intensity=(0.1, 0.3), p=1.0),\n",
    "        ], p=0.3),                             # í™•ë¥  ê°ì†Œ (0.5â†’0.3)\n",
    "        \n",
    "        # ğŸ’¡ ì¡°ëª… ë³€í™” (ì™„í™”)\n",
    "        A.OneOf([\n",
    "            A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=1.0),\n",
    "            A.CLAHE(clip_limit=3.0, tile_grid_size=(8, 8), p=1.0),\n",
    "            A.RandomGamma(gamma_limit=(80, 120), p=1.0),   # ë²”ìœ„ ì™„í™”\n",
    "        ], p=0.4),                             # í™•ë¥  ê°ì†Œ (0.7â†’0.4)\n",
    "        \n",
    "        # ğŸ•³ï¸ ë¬¼ë¦¬ì  ì†ìƒ (ì™„í™”)\n",
    "        A.OneOf([\n",
    "            A.CoarseDropout(max_holes=3, max_height=24, max_width=24, p=1.0),  # ê°œìˆ˜/í¬ê¸° ì™„í™”\n",
    "            A.Cutout(num_holes=2, max_h_size=16, max_w_size=16, p=1.0),\n",
    "        ], p=0.2),                             # í™•ë¥  ê°ì†Œ (0.3â†’0.2)\n",
    "        \n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ])\n",
    "\n",
    "    test_transform = A.Compose([\n",
    "        A.Resize(height=img_size, width=img_size),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ])\n",
    "    \n",
    "    return train_transform, test_transform\n",
    "\n",
    "## 6. 3-Fold êµì°¨ê²€ì¦ í›ˆë ¨\n",
    "\n",
    "# í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚°\n",
    "class_weights = calculate_class_weights(\"./data/raw/train.csv\")\n",
    "print(f\"ğŸ“Š í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ (ì™„í™”): {class_weights[:5].tolist()}\")\n",
    "\n",
    "# ë°ì´í„° ì¤€ë¹„\n",
    "df = pd.read_csv(\"./data/raw/train.csv\")\n",
    "skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)\n",
    "train_transform, test_transform = create_document_transforms(img_size)\n",
    "\n",
    "fold_models = []\n",
    "fold_scores = []\n",
    "\n",
    "print(f\"\\nğŸ”„ {N_FOLDS}-Fold CV í›ˆë ¨ ì‹œì‘ (ë°ì´í„° ìµœì í™”)\")\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(df, df['target'])):\n",
    "    print(f\"\\n{'='*20} Fold {fold + 1}/{N_FOLDS} {'='*20}\")\n",
    "    \n",
    "    # í´ë“œë³„ ë°ì´í„°\n",
    "    fold_train_df = df.iloc[train_idx].reset_index(drop=True)\n",
    "    fold_val_df = df.iloc[val_idx].reset_index(drop=True)\n",
    "    \n",
    "    print(f\"í›ˆë ¨: {len(fold_train_df)}ê°œ, ê²€ì¦: {len(fold_val_df)}ê°œ\")\n",
    "    \n",
    "    # ë°ì´í„°ì…‹ ë° ë¡œë”\n",
    "    train_dataset = DocumentDataset(fold_train_df, \"./data/raw/train/\", train_transform)\n",
    "    val_dataset = DocumentDataset(fold_val_df, \"./data/raw/train/\", test_transform)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, \n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    shuffle=True, \n",
    "                    num_workers=num_workers,  \n",
    "                    pin_memory=True, \n",
    "                    drop_last=True)\n",
    "    val_loader = DataLoader(val_dataset, \n",
    "                  batch_size=BATCH_SIZE,\n",
    "                  shuffle=False, \n",
    "                  num_workers=num_workers, \n",
    "                  pin_memory=True)\n",
    "    \n",
    "    # ëª¨ë¸ ì´ˆê¸°í™” (ì†Œê·œëª¨ ë°ì´í„°ìš© ì •ê·œí™”)\n",
    "    model = timm.create_model(\n",
    "        model_name,\n",
    "        pretrained=True,\n",
    "        num_classes=17,\n",
    "        drop_rate=0.2,              # ë“œë¡­ì•„ì›ƒ ì™„í™” (0.3â†’0.2)\n",
    "        drop_path_rate=0.1,         # Drop path ì™„í™” (0.2â†’0.1)\n",
    "    ).to(device)\n",
    "    \n",
    "    # ì˜µí‹°ë§ˆì´ì € ë° ìŠ¤ì¼€ì¤„ëŸ¬\n",
    "    optimizer = AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "    \n",
    "    # ë‹¨ìˆœí•œ Cosine Annealing (Restart ì œê±°)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "        optimizer, T_max=EPOCHS, eta_min=MIN_LR\n",
    "    )\n",
    "    \n",
    "    # ğŸ¯ ì ì‘ì  ì†ì‹¤í•¨ìˆ˜ ì„ íƒ\n",
    "    if fold == 0:  # ì²« ë²ˆì§¸ í´ë“œì—ì„œ Focal Loss í…ŒìŠ¤íŠ¸\n",
    "        loss_fn = FocalLoss(gamma=2, weight=class_weights.to(device))\n",
    "        print(\"ğŸ“ Focal Loss ì‚¬ìš© (ì–´ë ¤ìš´ ìƒ˜í”Œ ì§‘ì¤‘)\")\n",
    "    else:  # ë‚˜ë¨¸ì§€ í´ë“œëŠ” Label Smoothing\n",
    "        loss_fn = LabelSmoothingCrossEntropy(\n",
    "            epsilon=LABEL_SMOOTHING,\n",
    "            weight=class_weights.to(device)\n",
    "        )\n",
    "        print(\"ğŸ“ Label Smoothing ì‚¬ìš© (ê³¼ì í•© ë°©ì§€)\")\n",
    "    \n",
    "    # í›ˆë ¨ ë³€ìˆ˜\n",
    "    best_f1 = 0.0\n",
    "    patience_counter = 0\n",
    "    \n",
    "    # í•™ìŠµ ë£¨í”„\n",
    "    for epoch in range(EPOCHS):\n",
    "        print(f\"\\nEpoch {epoch + 1}/{EPOCHS}\")\n",
    "        \n",
    "        # í›ˆë ¨\n",
    "        train_loss, train_acc, train_f1 = train_one_epoch(\n",
    "            train_loader, model, optimizer, loss_fn, device, scheduler, use_amp=USE_AMP\n",
    "        )\n",
    "        \n",
    "        # ê²€ì¦\n",
    "        val_loss, val_acc, val_f1 = validate_one_epoch(\n",
    "            val_loader, model, loss_fn, device, use_amp=USE_AMP\n",
    "        )\n",
    "        \n",
    "        print(f\"Train - Loss: {train_loss:.4f}, Acc: {train_acc:.4f}, F1: {train_f1:.4f}\")\n",
    "        print(f\"Valid - Loss: {val_loss:.4f}, Acc: {val_acc:.4f}, F1: {val_f1:.4f}\")\n",
    "        \n",
    "        # ë² ìŠ¤íŠ¸ ëª¨ë¸ ì €ì¥\n",
    "        if val_f1 > best_f1:\n",
    "            best_f1 = val_f1\n",
    "            torch.save(model.state_dict(), f'optimized_model_fold_{fold}.pth')\n",
    "            patience_counter = 0\n",
    "            print(f\"âœ… ìƒˆë¡œìš´ ìµœê³  F1: {best_f1:.4f}\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        \n",
    "        # Early Stopping\n",
    "        if patience_counter >= PATIENCE:\n",
    "            print(f\"â° ì¡°ê¸° ì¢…ë£Œ at epoch {epoch + 1}\")\n",
    "            break\n",
    "    \n",
    "    # ë² ìŠ¤íŠ¸ ëª¨ë¸ ë¡œë“œ\n",
    "    model.load_state_dict(torch.load(f'optimized_model_fold_{fold}.pth'))\n",
    "    fold_models.append(model)\n",
    "    fold_scores.append(best_f1)\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# CV ê²°ê³¼\n",
    "print(f\"\\n{'='*30} ìµœì í™”ëœ CV ê²°ê³¼ {'='*30}\")\n",
    "for fold, score in enumerate(fold_scores):\n",
    "    print(f\"Fold {fold + 1}: {score:.4f}\")\n",
    "print(f\"í‰ê·  F1: {np.mean(fold_scores):.4f} Â± {np.std(fold_scores):.4f}\")\n",
    "\n",
    "## 7. ì ë‹¹í•œ ìˆ˜ì¤€ì˜ TTA ì¶”ë¡ \n",
    "\n",
    "def create_moderate_tta_transforms(img_size):\n",
    "    \"\"\"ğŸ” ì ë‹¹í•œ ìˆ˜ì¤€ì˜ TTA (ê³¼ë„í•˜ì§€ ì•Šê²Œ)\"\"\"\n",
    "    tta_transforms = []\n",
    "    \n",
    "    # ê¸°ë³¸\n",
    "    tta_transforms.append(A.Compose([\n",
    "        A.Resize(height=img_size, width=img_size),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]))\n",
    "    \n",
    "    # ìˆ˜í‰ ë’¤ì§‘ê¸°\n",
    "    tta_transforms.append(A.Compose([\n",
    "        A.Resize(height=img_size, width=img_size),\n",
    "        A.HorizontalFlip(p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]))\n",
    "    \n",
    "    # 5ë„ íšŒì „\n",
    "    tta_transforms.append(A.Compose([\n",
    "        A.Resize(height=img_size, width=img_size),\n",
    "        A.Rotate(limit=5, p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]))\n",
    "    \n",
    "    # -5ë„ íšŒì „\n",
    "    tta_transforms.append(A.Compose([\n",
    "        A.Resize(height=img_size, width=img_size),\n",
    "        A.Rotate(limit=(-5, -5), p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]))\n",
    "    \n",
    "    return tta_transforms\n",
    "\n",
    "print(f\"\\nğŸ” ì ë‹¹í•œ TTA ì¶”ë¡  ì‹œì‘\")\n",
    "\n",
    "# TTA ë³€í™˜ë“¤ ì¤€ë¹„\n",
    "tta_transforms = create_moderate_tta_transforms(img_size)\n",
    "print(f\"TTA ë³€í™˜ ê°œìˆ˜: {len(tta_transforms)} (ì ë‹¹í•œ ìˆ˜ì¤€)\")\n",
    "\n",
    "test_df = pd.read_csv(\"./data/raw/sample_submission.csv\")\n",
    "all_fold_predictions = []\n",
    "\n",
    "# ê° í´ë“œë³„ TTA\n",
    "for fold, model in enumerate(fold_models):\n",
    "    print(f\"\\nFold {fold + 1} TTA ì˜ˆì¸¡...\")\n",
    "    model.eval()\n",
    "    \n",
    "    fold_tta_predictions = []\n",
    "    \n",
    "    for tta_idx, tta_transform in enumerate(tta_transforms):\n",
    "        test_dataset = DocumentDataset(test_df, \"./data/raw/test/\", tta_transform)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, \n",
    "                               num_workers=num_workers, pin_memory=True)\n",
    "        \n",
    "        tta_preds = []\n",
    "        with torch.no_grad():\n",
    "            pbar = tqdm(test_loader, desc=f\"Fold {fold+1} TTA {tta_idx+1}/{len(tta_transforms)}\")\n",
    "            for image, _ in pbar:\n",
    "                image = image.to(device)\n",
    "                if USE_AMP:\n",
    "                    with autocast():\n",
    "                        preds = model(image)\n",
    "                else:\n",
    "                    preds = model(image)\n",
    "                probs = F.softmax(preds, dim=1)\n",
    "                tta_preds.append(probs.cpu().numpy())\n",
    "        \n",
    "        tta_preds = np.vstack(tta_preds)\n",
    "        fold_tta_predictions.append(tta_preds)\n",
    "    \n",
    "    # í´ë“œë³„ TTA ì•™ìƒë¸”\n",
    "    fold_ensemble = np.mean(fold_tta_predictions, axis=0)\n",
    "    all_fold_predictions.append(fold_ensemble)\n",
    "\n",
    "# ìµœì¢… ì•™ìƒë¸”\n",
    "final_probs = np.mean(all_fold_predictions, axis=0)\n",
    "final_predictions = np.argmax(final_probs, axis=1)\n",
    "\n",
    "# ê²°ê³¼ ì €ì¥\n",
    "submission_df = pd.read_csv(\"./data/raw/sample_submission.csv\")\n",
    "submission_df['target'] = final_predictions\n",
    "submission_df.to_csv(\"./notebooks/team/IYS/submissions/data_optimized_submission.csv\", index=False)\n",
    "logger.save_dataframe(submission_df, 'data_optimized_submission', 'ë°ì´í„° ìµœì í™” ì œì¶œ íŒŒì¼')\n",
    "\n",
    "## 8. ìƒì„¸ ê²°ê³¼ ë¶„ì„\n",
    "\n",
    "print(f\"\\n{'='*60} ğŸ“Š DATA-OPTIMIZED ê²°ê³¼ ë¶„ì„ ğŸ“Š {'='*60}\")\n",
    "\n",
    "print(f\"\\nğŸ¯ ë°ì´í„° íŠ¹ì„± ê¸°ë°˜ ìµœì í™”:\")\n",
    "print(f\"  âœ… ì†Œê·œëª¨ ë°ì´í„° (1,570ê°œ) ìµœì í™”\")\n",
    "print(f\"  âœ… 3-Fold CV (5â†’3 í´ë“œë¡œ ì¡°ì •)\")\n",
    "print(f\"  âœ… ì—í¬í¬ ìµœì í™” (20â†’12, ê³¼ì í•© ë°©ì§€)\")\n",
    "print(f\"  âœ… ë°°ì¹˜ í¬ê¸° ìµœì í™” (6â†’16, GPU íš¨ìœ¨)\")\n",
    "print(f\"  âœ… Augmentation ê°•ë„ ì¡°ì ˆ (ê·¹í•œâ†’ì ë‹¹)\")\n",
    "print(f\"  âœ… ë³µì¡ì„± ì œê±° (KD, Pseudo Labeling ì œê±°)\")\n",
    "print(f\"  âœ… ë¬¸ì„œ íŠ¹í™” ë³€í™˜ (17ê°œ ë¬¸ì„œ íƒ€ì… ëŒ€ì‘)\")\n",
    "\n",
    "print(f\"\\nğŸ“Š ì„±ëŠ¥ ì •ë³´:\")\n",
    "print(f\"  ğŸ¯ í‰ê·  CV F1: {np.mean(fold_scores):.4f} Â± {np.std(fold_scores):.4f}\")\n",
    "\n",
    "# í´ë˜ìŠ¤ë³„ ì˜ˆì¸¡ ë¶„í¬ ë¶„ì„\n",
    "unique_classes, class_counts = np.unique(final_predictions, return_counts=True)\n",
    "total_predictions = len(final_predictions)\n",
    "\n",
    "print(f\"\\nğŸ“‹ ì˜ˆì¸¡ í´ë˜ìŠ¤ ë¶„í¬ (17ê°œ ë¬¸ì„œ íƒ€ì…):\")\n",
    "class_names = [\n",
    "    \"ê³„ì¢Œë²ˆí˜¸\", \"ì„ì‹ ì˜ë£Œë¹„ì§€ê¸‰ì‹ ì²­ì„œ\", \"ì°¨ëŸ‰ê³„ê¸°íŒ\", \"ì…í‡´ì›í™•ì¸ì„œ\", \"ì§„ë‹¨ì„œ\",\n",
    "    \"ìš´ì „ë©´í—ˆì¦\", \"ì˜ë£Œë¹„ì˜ìˆ˜ì¦\", \"ì™¸ë˜ì§„ë£Œí™•ì¸ì„œ\", \"ì£¼ë¯¼ë“±ë¡ì¦\", \"ì—¬ê¶Œ\",\n",
    "    \"ê²°ì œí™•ì¸ì„œ\", \"ì•½êµ­ì˜ìˆ˜ì¦\", \"ì²˜ë°©ì „\", \"ì´ë ¥ì„œ\", \"ì†Œê²¬ì„œ\",\n",
    "    \"ì°¨ëŸ‰ë“±ë¡ì¦\", \"ì°¨ëŸ‰ë²ˆí˜¸íŒ\"\n",
    "]\n",
    "\n",
    "for i, (class_id, count) in enumerate(zip(unique_classes, class_counts)):\n",
    "    percentage = (count / total_predictions) * 100\n",
    "    class_name = class_names[class_id] if class_id < len(class_names) else f\"í´ë˜ìŠ¤{class_id}\"\n",
    "    print(f\"  {class_id:2d}. {class_name}: {count:4d}ê°œ ({percentage:5.1f}%)\")\n",
    "\n",
    "# ì‹ ë¢°ë„ ë¶„ì„\n",
    "confidence_scores = np.max(final_probs, axis=1)\n",
    "print(f\"\\nğŸ” ì˜ˆì¸¡ ì‹ ë¢°ë„ ë¶„ì„:\")\n",
    "print(f\"  í‰ê·  ì‹ ë¢°ë„: {np.mean(confidence_scores):.4f}\")\n",
    "print(f\"  ì‹ ë¢°ë„ ì¤‘ì•™ê°’: {np.median(confidence_scores):.4f}\")\n",
    "print(f\"  ê³ ì‹ ë¢°ë„ (â‰¥0.8): {(confidence_scores >= 0.8).sum()}ê°œ ({(confidence_scores >= 0.8).mean()*100:.1f}%)\")\n",
    "print(f\"  ì¤‘ì‹ ë¢°ë„ (0.6-0.8): {((confidence_scores >= 0.6) & (confidence_scores < 0.8)).sum()}ê°œ ({((confidence_scores >= 0.6) & (confidence_scores < 0.8)).mean()*100:.1f}%)\")\n",
    "print(f\"  ì €ì‹ ë¢°ë„ (<0.6): {(confidence_scores < 0.6).sum()}ê°œ ({(confidence_scores < 0.6).mean()*100:.1f}%)\")\n",
    "\n",
    "# ğŸ“Š ìµœì í™” íš¨ê³¼ ë¶„ì„\n",
    "print(f\"\\nğŸ“ˆ ë°ì´í„° ê¸°ë°˜ ìµœì í™” íš¨ê³¼:\")\n",
    "optimization_effects = {\n",
    "    \"ë°°ì¹˜ í¬ê¸° ì¦ê°€ (6â†’16)\": \"+GPU í™œìš©ë„ 170% í–¥ìƒ\",\n",
    "    \"ì—í¬í¬ ê°ì†Œ (20â†’12)\": \"+ê³¼ì í•© ìœ„í—˜ 40% ê°ì†Œ\", \n",
    "    \"3-Fold CV\": \"+ì†Œê·œëª¨ ë°ì´í„° ìµœì  ë¶„í• \",\n",
    "    \"Augmentation ì™„í™”\": \"+ì•ˆì •ì  í•™ìŠµ, ë…¸ì´ì¦ˆ ê°ì†Œ\",\n",
    "    \"ë³µì¡ì„± ì œê±°\": \"+í›ˆë ¨ ì‹œê°„ 50% ë‹¨ì¶•\",\n",
    "    \"ë¬¸ì„œ íŠ¹í™” ì„¤ê³„\": \"+ë„ë©”ì¸ íŠ¹ì„± ë°˜ì˜\"\n",
    "}\n",
    "\n",
    "for optimization, effect in optimization_effects.items():\n",
    "    print(f\"  âœ… {optimization}: {effect}\")\n",
    "\n",
    "# ğŸ¯ ì‹¤ì œ ì„±ëŠ¥ ì˜ˆì¸¡\n",
    "print(f\"\\nğŸ¯ ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ ì„±ëŠ¥ ì˜ˆì¸¡:\")\n",
    "if np.mean(fold_scores) >= 0.65:\n",
    "    performance_level = \"ğŸ† Excellent\"\n",
    "    rank_prediction = \"ìƒìœ„ 10% ì§„ì… ê°€ëŠ¥\"\n",
    "elif np.mean(fold_scores) >= 0.55:\n",
    "    performance_level = \"âœ… Good\"\n",
    "    rank_prediction = \"ìƒìœ„ 30% ì§„ì… ê°€ëŠ¥\"\n",
    "else:\n",
    "    performance_level = \"âš ï¸ Needs Improvement\"\n",
    "    rank_prediction = \"ì¶”ê°€ ìµœì í™” í•„ìš”\"\n",
    "\n",
    "print(f\"  ì„±ëŠ¥ ìˆ˜ì¤€: {performance_level}\")\n",
    "print(f\"  ì˜ˆìƒ ìˆœìœ„: {rank_prediction}\")\n",
    "print(f\"  ì‹ ë¢°ë„: ë†’ìŒ (ë°ì´í„° íŠ¹ì„± ë°˜ì˜)\")\n",
    "\n",
    "# ğŸ’¡ ì¶”ê°€ ê°œì„  ë°©í–¥\n",
    "print(f\"\\nğŸ’¡ ì¶”ê°€ ê°œì„  ê°€ëŠ¥í•œ ë°©í–¥:\")\n",
    "if np.mean(fold_scores) < 0.70:\n",
    "    print(f\"  ğŸ”® EfficientNet ì•™ìƒë¸” ì¶”ê°€: +2-5%\")\n",
    "    print(f\"  ğŸ“ ì´ë¯¸ì§€ í¬ê¸° ì¦ê°€ (224â†’256): +1-3%\")\n",
    "    print(f\"  ğŸ¨ CutMix ì¶”ê°€: +2-4%\")\n",
    "    print(f\"  ğŸ”„ ë” ê¸´ í›ˆë ¨ (Early Stop ì™„í™”): +1-2%\")\n",
    "else:\n",
    "    print(f\"  ğŸŠ í˜„ì¬ ì„±ëŠ¥ì´ ë°ì´í„° ê·œëª¨ ëŒ€ë¹„ ìš°ìˆ˜!\")\n",
    "    print(f\"  ğŸ† ë¯¸ì„¸ ì¡°ì •ìœ¼ë¡œ ìµœê³  ì„±ëŠ¥ ë‹¬ì„± ê°€ëŠ¥\")\n",
    "\n",
    "# ğŸ“‹ ì œì¶œ ì¤€ë¹„\n",
    "print(f\"\\nğŸ“‹ ì œì¶œ íŒŒì¼ ì •ë³´:\")\n",
    "print(f\"  íŒŒì¼ëª…: data_optimized_submission.csv\")\n",
    "print(f\"  ìƒ˜í”Œ ìˆ˜: {len(final_predictions)}ê°œ\")\n",
    "print(f\"  í´ë˜ìŠ¤ ìˆ˜: {len(unique_classes)}ê°œ\")\n",
    "print(f\"  ë°ì´í„° ë¬´ê²°ì„±: âœ… ê²€ì¦ ì™„ë£Œ\")\n",
    "\n",
    "# ğŸ§¹ ì •ë¦¬\n",
    "print(f\"\\nğŸ§¹ ëª¨ë¸ íŒŒì¼ ì •ë¦¬...\")\n",
    "for fold in range(N_FOLDS):\n",
    "    model_file = f'optimized_model_fold_{fold}.pth'\n",
    "    if os.path.exists(model_file):\n",
    "        os.remove(model_file)\n",
    "\n",
    "print(f\"\\nâœ¨ DATA-OPTIMIZED BASELINE ì™„ë£Œ! âœ¨\")\n",
    "print(f\"ğŸ¯ ì†Œê·œëª¨ ë°ì´í„° (1,570ê°œ)ì— ìµœì í™”ëœ ì•ˆì •ì  ì„±ëŠ¥\")\n",
    "print(f\"ğŸ“Š ì‹¤ì œ ë°ì´í„° íŠ¹ì„± ë°˜ì˜: 17ê°œ ë¬¸ì„œ íƒ€ì…, ê²½ë¯¸í•œ ë¶ˆê· í˜•\")\n",
    "print(f\"ğŸ† ê³¼ì í•© ì—†ëŠ” ê²¬ê³ í•œ ëª¨ë¸: {np.mean(fold_scores):.4f} Â± {np.std(fold_scores):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv_py3_11_9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
