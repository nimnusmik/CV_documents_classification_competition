{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18bbe02e",
   "metadata": {},
   "source": [
    "# ğŸ“„ Document type classification baseline code with WandB Integration\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92dc69ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: '../requirements.txt'\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# 0. Prepare Environments & Install Libraries\n",
    "# =============================================================================\n",
    "\n",
    "# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤.\n",
    "!pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f264cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ ë…¸íŠ¸ë¶ ì‘ì—… ì‹œì‘: base_line_wandb\n",
      "ğŸ“ ë¡œê·¸ ë””ë ‰í† ë¦¬: /home/ieyeppo/AI_Lab/computer-vision-competition-1SEN/notebooks/team/KSM/base_line_wandb/20250908_100101\n",
      "âœ… KSM WandB ë² ì´ìŠ¤ë¼ì¸ ë…¸íŠ¸ë¶ ë¡œê±° ì„¤ì • ì™„ë£Œ!\n",
      "ğŸ“ ë¡œê·¸ ê²½ë¡œ: /home/ieyeppo/AI_Lab/computer-vision-competition-1SEN/notebooks/team/KSM/base_line_wandb/20250908_100101/logs\n"
     ]
    }
   ],
   "source": [
    "# [ì¶”ê°€] KSM ë…¸íŠ¸ë¶ ë¡œê±° ì„¤ì •\n",
    "# ê²°ê³¼ ì €ì¥ì„ ìœ„í•œ ë¡œê±° ì´ˆê¸°í™”\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('../../../')  # í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¡œ ê²½ë¡œ ì¶”ê°€\n",
    "\n",
    "from src.logging.notebook_logger import create_notebook_logger\n",
    "\n",
    "# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ ì°¾ê¸°\n",
    "current_dir = os.getcwd()\n",
    "if 'notebooks/team/KSM' in current_dir:\n",
    "    project_root = current_dir.replace('/notebooks/team/KSM', '')\n",
    "else:\n",
    "    project_root = os.path.abspath('../../../')\n",
    "\n",
    "# ì ˆëŒ€ ê²½ë¡œë¡œ íŒ€ ë…¸íŠ¸ë¶ ë¡œê±° ì´ˆê¸°í™”\n",
    "base_log_path = os.path.join(project_root, \"notebooks/team\")\n",
    "logger = create_notebook_logger(\n",
    "    base_log_dir=base_log_path,\n",
    "    folder_name=\"KSM\", \n",
    "    file_name=\"base_line_wandb\"\n",
    ")\n",
    "\n",
    "print(\"âœ… KSM WandB ë² ì´ìŠ¤ë¼ì¸ ë…¸íŠ¸ë¶ ë¡œê±° ì„¤ì • ì™„ë£Œ!\")\n",
    "print(f\"ğŸ“ ë¡œê·¸ ê²½ë¡œ: {logger.log_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "773408ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 1. Import Libraries & Define Functions\n",
    "# =============================================================================\n",
    "\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import copy\n",
    "\n",
    "import optuna, math\n",
    "import timm\n",
    "import torch\n",
    "import albumentations as A\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.optim import Adam\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.cuda.amp import autocast, GradScaler  # Mixed Precisionìš©\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# WandB ê´€ë ¨ import ì¶”ê°€\n",
    "import wandb\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e142354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WandB ë¡œê·¸ì¸ ìƒíƒœ: ieyeppo-job\n",
      "í”„ë¡œì íŠ¸: document-classification-team\n",
      "ì‹¤í—˜ëª…: efficientnet-b3-baseline\n",
      "EXPERIMENT_NAMEì„ ê°ì ë‹¤ë¥´ê²Œ ë³€ê²½í•´ì£¼ì„¸ìš”!\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 1-1. WandB Login and Configuration\n",
    "# =============================================================================\n",
    "\"\"\"\n",
    "ğŸš€ ì‚¬ìš© ê°€ì´ë“œ:\n",
    "\n",
    "1. WandB ê³„ì • ìƒì„±: https://wandb.ai/signup\n",
    "2. ì´ ì…€ ì‹¤í–‰ ì‹œ ë¡œê·¸ì¸ í”„ë¡¬í”„íŠ¸ê°€ ë‚˜íƒ€ë‚˜ë©´ ê°œì¸ API í‚¤ ì…ë ¥\n",
    "3. EXPERIMENT_NAMEì„ ë‹¤ìŒê³¼ ê°™ì´ ë³€ê²½:\n",
    "   - \"member1-baseline\"\n",
    "   - \"member2-augmentation-test\"  \n",
    "   - \"member3-hyperparameter-tuning\"\n",
    "   ë“±ë“± ê°ì ë‹¤ë¥¸ ì´ë¦„ ì‚¬ìš©\n",
    "\n",
    "4. íŒ€ ëŒ€ì‹œë³´ë“œ URL: [ì—¬ê¸°ì— ë‹¹ì‹ ì˜ í”„ë¡œì íŠ¸ URL ì¶”ê°€]\n",
    "\n",
    "âš ï¸ ì£¼ì˜ì‚¬í•­:\n",
    "- ì ˆëŒ€ API í‚¤ë¥¼ ì½”ë“œì— í•˜ë“œì½”ë”©í•˜ì§€ ë§ˆì„¸ìš”\n",
    "- EXPERIMENT_NAMEë§Œ ë³€ê²½í•˜ê³  PROJECT_NAMEì€ ê·¸ëŒ€ë¡œ ë‘ì„¸ìš”\n",
    "- ê°ì ê°œì¸ ê³„ì •ìœ¼ë¡œ ë¡œê·¸ì¸í•´ì„œ ì‹¤í—˜ì„ ì¶”ê°€í•˜ì„¸ìš”\n",
    "\"\"\"\n",
    "\n",
    "# WandB ë¡œê·¸ì¸ (ê°ì ì‹¤í–‰)\n",
    "try:\n",
    "    if wandb.api.api_key is None:\n",
    "        print(\"WandBì— ë¡œê·¸ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤.\")\n",
    "        wandb.login()\n",
    "    else:\n",
    "        print(f\"WandB ë¡œê·¸ì¸ ìƒíƒœ: {wandb.api.viewer()['username']}\")\n",
    "except:\n",
    "    print(\"WandB ë¡œê·¸ì¸ì„ ì§„í–‰í•©ë‹ˆë‹¤...\")\n",
    "    wandb.login()\n",
    "\n",
    "# í”„ë¡œì íŠ¸ ì„¤ì • (ê°ì ìˆ˜ì •í•  ë¶€ë¶„)\n",
    "PROJECT_NAME = \"document-classification-team\"  # ëª¨ë“  ë™ì¼\n",
    "ENTITY = None  # ê°ì ê°œì¸ ê³„ì • ì‚¬ìš©\n",
    "EXPERIMENT_NAME = \"efficientnet-b3-baseline\"  # íŒ€ì›ë³„ë¡œ ë³€ê²½ (ì˜ˆ: \"member1-hyperopt\", \"member2-augmentation\")\n",
    "\n",
    "print(f\"í”„ë¡œì íŠ¸: {PROJECT_NAME}\")\n",
    "print(f\"ì‹¤í—˜ëª…: {EXPERIMENT_NAME}\")\n",
    "print(\"EXPERIMENT_NAMEì„ ê°ì ë‹¤ë¥´ê²Œ ë³€ê²½í•´ì£¼ì„¸ìš”!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "448a2f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 3. Seed & basic augmentations (Mixup)\n",
    "# =============================================================================\n",
    "\n",
    "# ì‹œë“œë¥¼ ê³ ì •í•©ë‹ˆë‹¤.\n",
    "SEED = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.benchmark = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f9d1a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# 4. Dataset Class\n",
    "# =============================================================================\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, data, path, transform=None):\n",
    "        # CSV íŒŒì¼ì´ë©´ ì½ê³ , DataFrameì´ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©\n",
    "        if isinstance(data, str):\n",
    "            self.df = pd.read_csv(data).values\n",
    "        else:\n",
    "            self.df = data.values  # DataFrameì„ numpy arrayë¡œ ë³€í™˜\n",
    "        self.path = path\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        name, target = self.df[idx]\n",
    "        img = np.array(Image.open(os.path.join(self.path, name)))\n",
    "        if self.transform:\n",
    "            img = self.transform(image=img)['image']\n",
    "        return img, target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0cacecd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import wandb\n",
    "\n",
    "# Cutout (Random Erasing) í•¨ìˆ˜ ì •ì˜\n",
    "def random_erasing(image, p=0.5, scale=(0.02, 0.33), ratio=(0.3, 3.3)):\n",
    "    if random.random() > p:\n",
    "        return image\n",
    "    img_c, img_h, img_w = image.shape[1], image.shape[2], image.shape[3]\n",
    "    area = img_h * img_w\n",
    "    \n",
    "    target_area = random.uniform(scale[0], scale[1]) * area\n",
    "    aspect_ratio = random.uniform(ratio[0], ratio[1])\n",
    "    h = int(round(math.sqrt(target_area * aspect_ratio)))\n",
    "    w = int(round(math.sqrt(target_area / aspect_ratio)))\n",
    "    \n",
    "    if h < img_h and w < img_w:\n",
    "        x = random.randint(0, img_w - w)\n",
    "        y = random.randint(0, img_h - h)\n",
    "        image[:, :, y:y+h, x:x+w] = 0.0  # ì œê±°ëœ ì˜ì—­ì„ 0ìœ¼ë¡œ ì„¤ì •\n",
    "    return image\n",
    "\n",
    "# RandomCrop í•¨ìˆ˜ ì •ì˜\n",
    "def random_crop(image, crop_size=0.8):\n",
    "    img_c, img_h, img_w = image.shape[1], image.shape[2], image.shape[3]\n",
    "    crop_h = int(img_h * crop_size)\n",
    "    crop_w = int(img_w * crop_size)\n",
    "    \n",
    "    if crop_h >= img_h or crop_w >= img_w:\n",
    "        return image\n",
    "    \n",
    "    x = random.randint(0, img_w - crop_w)\n",
    "    y = random.randint(0, img_h - crop_h)\n",
    "    cropped_image = image[:, :, y:y+crop_h, x:x+crop_w]\n",
    "    \n",
    "    # ì›ë˜ ì´ë¯¸ì§€ í¬ê¸°ë¡œ ë³µì› (íŒ¨ë”© ë˜ëŠ” ë¦¬ì‚¬ì´ì¦ˆ)\n",
    "    cropped_image = torch.nn.functional.interpolate(cropped_image, size=(img_h, img_w), mode='bilinear', align_corners=False)\n",
    "    return cropped_image\n",
    "\n",
    "# Mixup í•¨ìˆ˜ ì •ì˜\n",
    "def mixup_data(x, y, alpha=1.0):\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "    batch_size = x.size()[0]\n",
    "    index = torch.randperm(batch_size).cuda()\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "def train_one_epoch(loader, model, optimizer, loss_fn, device, epoch=None, fold=None):\n",
    "    scaler = GradScaler()\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    preds_list = []\n",
    "    targets_list = []\n",
    "\n",
    "    pbar = tqdm(loader, desc=f\"Training Epoch {epoch+1 if epoch else '?'}\")\n",
    "    batch_count = 0\n",
    "    \n",
    "    for image, targets in pbar:\n",
    "        image = image.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        # ì¦ê°• ê¸°ë²• ì„ íƒ (Mixup 25%, Cutout 25%, RandomCrop 25%, None 25%)\n",
    "        aug_type = random.choices(['mixup', 'cutout', 'random_crop', 'none'], weights=[0.25, 0.25, 0.25, 0.25])[0]\n",
    "        mixup_applied = False\n",
    "        cutout_applied = False\n",
    "        random_crop_applied = False\n",
    "        \n",
    "        if aug_type == 'mixup':\n",
    "            mixed_x, y_a, y_b, lam = mixup_data(image, targets, alpha=1.0)\n",
    "            with autocast(): \n",
    "                preds = model(mixed_x)\n",
    "            loss = lam * loss_fn(preds, y_a) + (1 - lam) * loss_fn(preds, y_b)\n",
    "            mixup_applied = True\n",
    "        elif aug_type == 'cutout':\n",
    "            image = random_erasing(image, p=0.5, scale=(0.02, 0.33), ratio=(0.3, 3.3))\n",
    "            with autocast(): \n",
    "                preds = model(image)\n",
    "            loss = loss_fn(preds, targets)\n",
    "            cutout_applied = True\n",
    "        elif aug_type == 'random_crop':\n",
    "            image = random_crop(image, crop_size=0.8)\n",
    "            with autocast(): \n",
    "                preds = model(image)\n",
    "            loss = loss_fn(preds, targets)\n",
    "            random_crop_applied = True\n",
    "        else:\n",
    "            with autocast(): \n",
    "                preds = model(image)\n",
    "            loss = loss_fn(preds, targets)\n",
    "\n",
    "        model.zero_grad(set_to_none=True)\n",
    "        scaler.scale(loss).backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
    "        targets_list.extend(targets.detach().cpu().numpy())\n",
    "\n",
    "        # ë°°ì¹˜ë³„ ìƒì„¸ ë¡œê¹… (100 ë°°ì¹˜ë§ˆë‹¤)\n",
    "        if batch_count % 100 == 0 and wandb.run is not None:\n",
    "            step = epoch * len(loader) + batch_count if epoch is not None else batch_count\n",
    "            wandb.log({\n",
    "                f\"fold_{fold}/train_batch_loss\": loss.item(),\n",
    "                f\"fold_{fold}/mixup_applied\": int(mixup_applied),\n",
    "                f\"fold_{fold}/cutout_applied\": int(cutout_applied),\n",
    "                f\"fold_{fold}/random_crop_applied\": int(random_crop_applied),\n",
    "                f\"fold_{fold}/batch_step\": step\n",
    "            })\n",
    "        \n",
    "        batch_count += 1\n",
    "        pbar.set_description(f\"Loss: {loss.item():.4f}, Mixup: {mixup_applied}, Cutout: {cutout_applied}, RandomCrop: {random_crop_applied}\")\n",
    "\n",
    "    train_loss /= len(loader)\n",
    "    train_acc = accuracy_score(targets_list, preds_list)\n",
    "    train_f1 = f1_score(targets_list, preds_list, average='macro')\n",
    "\n",
    "    ret = {\n",
    "        \"train_loss\": train_loss,\n",
    "        \"train_acc\": train_acc,\n",
    "        \"train_f1\": train_f1,\n",
    "    }\n",
    "\n",
    "    return ret\n",
    "\n",
    "def validate_one_epoch(loader, model, loss_fn, device, epoch=None, fold=None, log_confusion=False):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    preds_list = []\n",
    "    targets_list = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(loader, desc=f\"Validating Epoch {epoch+1 if epoch else '?'}\")\n",
    "        for image, targets in pbar:\n",
    "            image = image.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            preds = model(image)\n",
    "            loss = loss_fn(preds, targets)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
    "            targets_list.extend(targets.detach().cpu().numpy())\n",
    "            \n",
    "            pbar.set_description(f\"Val Loss: {loss.item():.4f}\")\n",
    "    \n",
    "    val_loss /= len(loader)\n",
    "    val_acc = accuracy_score(targets_list, preds_list)\n",
    "    val_f1 = f1_score(targets_list, preds_list, average='macro')\n",
    "    \n",
    "    # Confusion Matrix ë¡œê¹… (ë§ˆì§€ë§‰ epochì—ë§Œ)\n",
    "    if log_confusion and wandb.run is not None:\n",
    "        try:\n",
    "            wandb.log({\n",
    "                f\"fold_{fold}/confusion_matrix\": wandb.plot.confusion_matrix(\n",
    "                    probs=None,\n",
    "                    y_true=targets_list,\n",
    "                    preds=preds_list,\n",
    "                    class_names=[f\"Class_{i}\" for i in range(17)]\n",
    "                )\n",
    "            })\n",
    "            \n",
    "            # í´ë˜ìŠ¤ë³„ F1 ìŠ¤ì½”ì–´\n",
    "            class_f1_scores = f1_score(targets_list, preds_list, average=None)\n",
    "            for i, class_f1 in enumerate(class_f1_scores):\n",
    "                wandb.log({f\"fold_{fold}/class_{i}_f1\": class_f1})\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\" Confusion matrix ë¡œê¹… ì‹¤íŒ¨: {e}\")\n",
    "    \n",
    "    ret = {\n",
    "        \"val_loss\": val_loss,\n",
    "        \"val_acc\": val_acc,  \n",
    "        \"val_f1\": val_f1,\n",
    "    }\n",
    "    \n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "193dae06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Using device: cuda\n",
      " í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì • ì™„ë£Œ!\n",
      " ëª¨ë¸: efficientnet_b3\n",
      " ì´ë¯¸ì§€ í¬ê¸°: 384x384\n",
      " ë°°ì¹˜ í¬ê¸°: 32\n",
      " í•™ìŠµë¥ : 0.0005\n",
      " ì—í­: 20\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 6. Hyper-parameters with WandB Config\n",
    "# =============================================================================\n",
    "\n",
    "# device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\" Using device: {device}\")\n",
    "\n",
    "# data config\n",
    "data_path = '../data/'\n",
    "\n",
    "# model config\n",
    "model_name = 'efficientnet_b3' # 'resnet50' 'efficientnet-b0', ...\n",
    "\n",
    "# training config\n",
    "img_size = 384\n",
    "LR = 5e-4\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 32\n",
    "num_workers = 30\n",
    "\n",
    "# K-Fold config\n",
    "N_FOLDS = 5  # 5-foldë¡œ ì„¤ì •\n",
    "\n",
    "# WandB Config ì„¤ì •\n",
    "config = {\n",
    "    # Model config\n",
    "    \"model_name\": model_name,\n",
    "    \"img_size\": img_size,\n",
    "    \"num_classes\": 17,\n",
    "    \"architecture\": \"EfficientNet-B3\",\n",
    "    \n",
    "    # Training config  \n",
    "    \"lr\": LR,\n",
    "    \"epochs\": EPOCHS,\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"num_workers\": num_workers,\n",
    "    \"device\": str(device),\n",
    "    \n",
    "    # K-Fold config\n",
    "    \"n_folds\": N_FOLDS,\n",
    "    \"seed\": SEED,\n",
    "    \"cv_strategy\": \"StratifiedKFold\",\n",
    "    \n",
    "    # Augmentation & Training techniques\n",
    "    \"mixup_alpha\": 1.0,\n",
    "    \"mixup_prob\": 0.3,\n",
    "    \"label_smoothing\": 0.2,\n",
    "    \"gradient_clipping\": 1.0,\n",
    "    \"mixed_precision\": True,\n",
    "    \n",
    "    # Optimizer & Scheduler\n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"scheduler\": \"CosineAnnealingLR\",\n",
    "    \n",
    "    # Data\n",
    "    \"data_path\": data_path,\n",
    "    \"train_transforms\": \"Advanced\",\n",
    "    \"test_transforms\": \"Basic\",\n",
    "}\n",
    "\n",
    "print(\" í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì • ì™„ë£Œ!\")\n",
    "print(f\" ëª¨ë¸: {model_name}\")\n",
    "print(f\" ì´ë¯¸ì§€ í¬ê¸°: {img_size}x{img_size}\")\n",
    "print(f\" ë°°ì¹˜ í¬ê¸°: {BATCH_SIZE}\")\n",
    "print(f\" í•™ìŠµë¥ : {LR}\")\n",
    "print(f\" ì—í­: {EPOCHS}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a4e28f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â­ï¸ Optuna íŠœë‹ ê±´ë„ˆë›°ê¸° (USE_OPTUNA=False)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# 7. Optuna Hyperparameter Tuning (ì„ íƒì )\n",
    "# =============================================================================\n",
    "\n",
    "USE_OPTUNA = False  # Trueë¡œ ë°”ê¾¸ë©´ íŠœë‹ ì‹¤í–‰\n",
    "\n",
    "if USE_OPTUNA:\n",
    "    print(\"ğŸ” Optuna í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ì‹œì‘...\")\n",
    "    \n",
    "    def objective(trial):\n",
    "        lr = trial.suggest_loguniform('lr', 1e-5, 1e-2)\n",
    "        batch_size = trial.suggest_categorical('batch_size', [32, 64, 128])\n",
    "        \n",
    "        # WandBì— Optuna ì‹œí–‰ ë¡œê¹…\n",
    "        optuna_run = wandb.init(\n",
    "            project=PROJECT_NAME,\n",
    "            entity=ENTITY,\n",
    "            name=f\"optuna-trial-{trial.number}\",\n",
    "            config={**config, \"lr\": lr, \"batch_size\": batch_size},\n",
    "            tags=[\"optuna\", \"hyperparameter-tuning\"],\n",
    "            group=\"optuna-study\",\n",
    "            job_type=\"hyperparameter-optimization\",\n",
    "            reinit=True\n",
    "        )\n",
    "        \n",
    "        # ê°„ë‹¨í•œ 3-fold CVë¡œ ë¹ ë¥¸ í‰ê°€\n",
    "        skf_simple = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "        fold_scores = []\n",
    "        \n",
    "        # ê°„ë‹¨í•œ í‰ê°€ ë¡œì§ (ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ë” ë‹¨ìˆœí™”)\n",
    "        # ... (Optuna ë¡œì§ì€ ë³µì¡í•˜ë¯€ë¡œ ê¸°ë³¸ì ìœ¼ë¡œ ë¹„í™œì„±í™”)\n",
    "        \n",
    "        optuna_run.finish()\n",
    "        return np.random.random()  # placeholder\n",
    "    \n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=10)\n",
    "    \n",
    "    # ìµœì  íŒŒë¼ë¯¸í„° ì ìš©\n",
    "    best_params = study.best_params\n",
    "    LR = best_params.get('lr', LR)\n",
    "    BATCH_SIZE = best_params.get('batch_size', BATCH_SIZE)\n",
    "    config.update(best_params)\n",
    "    print(f\"ğŸ¯ Optuna ìµœì  íŒŒë¼ë¯¸í„°: {best_params}\")\n",
    "else:\n",
    "    print(\"â­ï¸ Optuna íŠœë‹ ê±´ë„ˆë›°ê¸° (USE_OPTUNA=False)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6514acaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ë°ì´í„° ë³€í™˜ ì„¤ì • ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 8. Data Transforms\n",
    "# =============================================================================\n",
    "\n",
    "# augmentationì„ ìœ„í•œ transform ì½”ë“œ\n",
    "trn_transform = A.Compose([\n",
    "    # ë¹„ìœ¨ ë³´ì¡´ ë¦¬ì‚¬ì´ì§• (í•µì‹¬ ê°œì„ )\n",
    "    A.LongestMaxSize(max_size=img_size),\n",
    "    A.PadIfNeeded(min_height=img_size, min_width=img_size, \n",
    "                  border_mode=0, value=0),\n",
    "    \n",
    "    # ë¬¸ì„œ íŠ¹í™” íšŒì „ + ë¯¸ì„¸ íšŒì „ ì¶”ê°€\n",
    "    A.OneOf([\n",
    "        A.Rotate(limit=[90,90], p=1.0),\n",
    "        A.Rotate(limit=[180,180], p=1.0),\n",
    "        A.Rotate(limit=[270,270], p=1.0),\n",
    "        A.Rotate(limit=(-15, 15), p=1.0),  # ë¯¸ì„¸ íšŒì „ ì¶”ê°€\n",
    "    ], p=0.7),\n",
    "    \n",
    "    # ê¸°í•˜í•™ì  ë³€í™˜ ê°•í™”\n",
    "    A.OneOf([\n",
    "        A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.2, rotate_limit=5, p=1.0),\n",
    "        A.ElasticTransform(alpha=50, sigma=5, p=1.0),\n",
    "        A.GridDistortion(num_steps=5, distort_limit=0.2, p=1.0),\n",
    "        A.OpticalDistortion(distort_limit=0.2, shift_limit=0.1, p=1.0),\n",
    "    ], p=0.6),\n",
    "    \n",
    "    # ìƒ‰ìƒ ë° ì¡°ëª… ë³€í™˜ ê°•í™”\n",
    "    A.OneOf([\n",
    "        A.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.3, hue=0.1, p=1.0),\n",
    "        A.RandomBrightnessContrast(brightness_limit=0.4, contrast_limit=0.4, p=1.0),\n",
    "        A.CLAHE(clip_limit=4.0, tile_grid_size=(8, 8), p=1.0),\n",
    "        A.RandomGamma(gamma_limit=(70, 130), p=1.0),\n",
    "    ], p=0.9),\n",
    "    \n",
    "    # ë¸”ëŸ¬ ë° ë…¸ì´ì¦ˆ ê°•í™”\n",
    "    A.OneOf([\n",
    "        A.MotionBlur(blur_limit=(5, 15), p=1.0),\n",
    "        A.GaussianBlur(blur_limit=(3, 15), p=1.0),\n",
    "        A.MedianBlur(blur_limit=7, p=1.0),\n",
    "        A.Blur(blur_limit=7, p=1.0),\n",
    "    ], p=0.8),\n",
    "    \n",
    "    # ë‹¤ì–‘í•œ ë…¸ì´ì¦ˆ ì¶”ê°€\n",
    "    A.OneOf([\n",
    "        A.GaussNoise(var_limit=(10.0, 150.0), p=1.0),\n",
    "        A.ISONoise(color_shift=(0.01, 0.08), intensity=(0.1, 0.8), p=1.0),\n",
    "        A.MultiplicativeNoise(multiplier=(0.9, 1.1), p=1.0),\n",
    "    ], p=0.8),\n",
    "    \n",
    "    # ë¬¸ì„œ í’ˆì§ˆ ì‹œë®¬ë ˆì´ì…˜ (ìŠ¤ìº”/ë³µì‚¬ íš¨ê³¼)\n",
    "    A.OneOf([\n",
    "        A.Downscale(scale_min=0.7, scale_max=0.9, p=1.0),\n",
    "        A.ImageCompression(quality_lower=60, quality_upper=95, p=1.0),\n",
    "        A.Posterize(num_bits=6, p=1.0),\n",
    "    ], p=0.5),\n",
    "    \n",
    "    # í”½ì…€ ë ˆë²¨ ë³€í™˜\n",
    "    A.OneOf([\n",
    "        A.ChannelShuffle(p=1.0),\n",
    "        A.InvertImg(p=1.0),\n",
    "        A.Solarize(threshold=128, p=1.0),\n",
    "        A.Equalize(p=1.0),\n",
    "    ], p=0.3),\n",
    "    \n",
    "    # ê³µê°„ ë³€í™˜\n",
    "    A.OneOf([\n",
    "        A.HorizontalFlip(p=1.0),\n",
    "        A.VerticalFlip(p=1.0),  # ë¬¸ì„œì—ì„œë„ ìœ ìš©í•  ìˆ˜ ìˆìŒ\n",
    "        A.Transpose(p=1.0),\n",
    "    ], p=0.6),\n",
    "    \n",
    "    # ì¡°ê° ì œê±° (Cutout ê³„ì—´)\n",
    "    A.OneOf([\n",
    "        A.CoarseDropout(max_holes=8, max_height=32, max_width=32, \n",
    "                       min_holes=1, min_height=8, min_width=8, \n",
    "                       fill_value=0, p=1.0),\n",
    "        A.GridDropout(ratio=0.3, unit_size_min=8, unit_size_max=32, \n",
    "                     holes_number_x=5, holes_number_y=5, p=1.0),\n",
    "    ], p=0.4),\n",
    "    \n",
    "    # ìµœì¢… ì •ê·œí™”\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "# test image ë³€í™˜ì„ ìœ„í•œ transform ì½”ë“œ\n",
    "tst_transform = A.Compose([\n",
    "    A.LongestMaxSize(max_size=img_size),\n",
    "    A.PadIfNeeded(min_height=img_size, min_width=img_size, \n",
    "                  border_mode=0, value=0),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "print(\"âœ… ë°ì´í„° ë³€í™˜ ì„¤ì • ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c320bb7",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# =============================================================================\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# 9. Load Data & Start K-Fold Cross Validation with WandB\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# =============================================================================\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# ì „ì²´ í•™ìŠµ ë°ì´í„° ë¡œë“œ\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m train_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../data/train.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mğŸ“Š í•™ìŠµ ë°ì´í„°: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(train_df)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mê°œ ìƒ˜í”Œ\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# í´ë˜ìŠ¤ ë¶„í¬ í™•ì¸\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/cv_py3_11_9/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/cv_py3_11_9/lib/python3.11/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/.pyenv/versions/cv_py3_11_9/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/cv_py3_11_9/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/.pyenv/versions/cv_py3_11_9/lib/python3.11/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/train.csv'"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 9. Load Data & Start K-Fold Cross Validation with WandB\n",
    "# =============================================================================\n",
    "\n",
    "# ì „ì²´ í•™ìŠµ ë°ì´í„° ë¡œë“œ\n",
    "train_df = pd.read_csv(\"../data/train.csv\")\n",
    "print(f\"ğŸ“Š í•™ìŠµ ë°ì´í„°: {len(train_df)}ê°œ ìƒ˜í”Œ\")\n",
    "\n",
    "# í´ë˜ìŠ¤ ë¶„í¬ í™•ì¸\n",
    "class_counts = train_df['target'].value_counts().sort_index()\n",
    "print(f\"ğŸ“Š í´ë˜ìŠ¤ ë¶„í¬: {dict(class_counts)}\")\n",
    "\n",
    "# K-Fold ì„¤ì •\n",
    "skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)\n",
    "\n",
    "# K-Fold ê²°ê³¼ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸\n",
    "fold_results = []\n",
    "fold_models = []  # ê° foldì˜ ìµœê³  ì„±ëŠ¥ ëª¨ë¸ì„ ì €ì¥\n",
    "\n",
    "# ğŸ”¥ WandB ë©”ì¸ ì‹¤í—˜ ì‹œì‘\n",
    "main_run = wandb.init(\n",
    "    project=PROJECT_NAME,\n",
    "    entity=ENTITY,\n",
    "    name=f\"{EXPERIMENT_NAME}-{datetime.now().strftime('%m%d-%H%M')}\",\n",
    "    config=config,\n",
    "    tags=[\"k-fold-cv\", \"ensemble\", model_name, \"baseline\", \"main-experiment\"],\n",
    "    group=\"k-fold-experiment\",\n",
    "    job_type=\"cross-validation\",\n",
    "    notes=f\"{N_FOLDS}-Fold Cross Validation with {model_name}\"\n",
    ")\n",
    "\n",
    "print(f\"\\nğŸš€ WandB ì‹¤í—˜ ì‹œì‘!\")\n",
    "print(f\"ğŸ“Š ëŒ€ì‹œë³´ë“œ: {main_run.url}\")\n",
    "print(f\"ğŸ“‹ ì‹¤í—˜ëª…: {main_run.name}\")\n",
    "\n",
    "# ğŸ”¥ ë°ì´í„°ì…‹ ì •ë³´ ë¡œê¹…\n",
    "wandb.log({\n",
    "    \"dataset/total_samples\": len(train_df),\n",
    "    \"dataset/num_classes\": 17,\n",
    "    \"dataset/samples_per_fold\": len(train_df) // N_FOLDS,\n",
    "})\n",
    "\n",
    "# í´ë˜ìŠ¤ ë¶„í¬ ì‹œê°í™”\n",
    "class_dist_data = [[f\"Class_{i}\", count] for i, count in enumerate(class_counts)]\n",
    "wandb.log({\n",
    "    \"dataset/class_distribution\": wandb.plot.bar(\n",
    "        wandb.Table(data=class_dist_data, columns=[\"Class\", \"Count\"]),\n",
    "        \"Class\", \"Count\", \n",
    "        title=\"Training Data Class Distribution\"\n",
    "    )\n",
    "})\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"ğŸ¯ {N_FOLDS}-FOLD CROSS VALIDATION ì‹œì‘\")\n",
    "print(f\"{'='*60}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1675898e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      " FOLD 1/5\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to True."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>dataset/num_classes</td><td>â–</td></tr><tr><td>dataset/samples_per_fold</td><td>â–</td></tr><tr><td>dataset/total_samples</td><td>â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>dataset/num_classes</td><td>17</td></tr><tr><td>dataset/samples_per_fold</td><td>314</td></tr><tr><td>dataset/total_samples</td><td>1570</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">efficientnet-b3-baseline-0904-0754</strong> at: <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/33mcvmnd' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/33mcvmnd</a><br> View project at: <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team</a><br>Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250904_075452-33mcvmnd/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "creating run (0.0s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/ephemeral/home/computervisioncompetition-cv-1/wandb/wandb/run-20250904_075454-ntt230pg</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/ntt230pg' target=\"_blank\">fold-1-efficientnet_b3-0754</a></strong> to <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/ntt230pg' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/ntt230pg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Fold 1 Dashboard: https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/ntt230pg\n",
      "Train samples: 1256, Validation samples: 314\n",
      " ëª¨ë¸ í•™ìŠµ ì‹œì‘ - Fold 1\n",
      "\n",
      "ğŸ“ˆ Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.0938, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:22<00:00,  1.80it/s] \n",
      "Val Loss: 1.9117: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:02<00:00,  4.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  1 | Train Loss: 2.6401 | Train F1: 0.2732 | Val Loss: 1.7623 | Val F1: 0.6438 | LR: 5.00e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.6438\n",
      "\n",
      "ğŸ“ˆ Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.6455, Mixup: False, Cutout: False, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.40it/s]\n",
      "Val Loss: 1.5206: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  2 | Train Loss: 1.9741 | Train F1: 0.4973 | Val Loss: 1.4790 | Val F1: 0.7849 | LR: 4.97e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.7849\n",
      "\n",
      "ğŸ“ˆ Epoch 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.4590, Mixup: False, Cutout: False, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.37it/s]\n",
      "Val Loss: 1.3645: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  3 | Train Loss: 1.8228 | Train F1: 0.5685 | Val Loss: 1.3636 | Val F1: 0.8620 | LR: 4.88e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.8620\n",
      "\n",
      "ğŸ“ˆ Epoch 4/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.4844, Mixup: True, Cutout: False, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.54it/s] \n",
      "Val Loss: 1.2827: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  6.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  4 | Train Loss: 1.7240 | Train F1: 0.6141 | Val Loss: 1.3204 | Val F1: 0.8541 | LR: 4.73e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 5/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3564, Mixup: False, Cutout: False, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.43it/s]\n",
      "Val Loss: 1.2952: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  6.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  5 | Train Loss: 1.5353 | Train F1: 0.7256 | Val Loss: 1.3177 | Val F1: 0.8583 | LR: 4.52e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 6/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3896, Mixup: False, Cutout: True, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.54it/s] \n",
      "Val Loss: 1.2469: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  6.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  6 | Train Loss: 1.5157 | Train F1: 0.7389 | Val Loss: 1.2839 | Val F1: 0.8861 | LR: 4.27e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.8861\n",
      "\n",
      "ğŸ“ˆ Epoch 7/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3828, Mixup: False, Cutout: True, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.42it/s] \n",
      "Val Loss: 1.2499: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  7 | Train Loss: 1.5113 | Train F1: 0.7232 | Val Loss: 1.2654 | Val F1: 0.8769 | LR: 3.97e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 8/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.4023, Mixup: False, Cutout: True, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.48it/s] \n",
      "Val Loss: 1.2177: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  8 | Train Loss: 1.4392 | Train F1: 0.7772 | Val Loss: 1.2375 | Val F1: 0.9160 | LR: 3.63e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.9160\n",
      "\n",
      "ğŸ“ˆ Epoch 9/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.6074, Mixup: True, Cutout: False, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.45it/s] \n",
      "Val Loss: 1.2170: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  6.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  9 | Train Loss: 1.4630 | Train F1: 0.7505 | Val Loss: 1.2220 | Val F1: 0.9192 | LR: 3.27e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.9192\n",
      "\n",
      "ğŸ“ˆ Epoch 10/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.4307, Mixup: False, Cutout: False, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.50it/s]\n",
      "Val Loss: 1.2012: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 10 | Train Loss: 1.3925 | Train F1: 0.7538 | Val Loss: 1.2135 | Val F1: 0.9094 | LR: 2.89e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 11/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.9121, Mixup: True, Cutout: False, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.45it/s] \n",
      "Val Loss: 1.1859: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  6.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 11 | Train Loss: 1.3645 | Train F1: 0.8073 | Val Loss: 1.2133 | Val F1: 0.9117 | LR: 2.50e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 12/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.9707, Mixup: True, Cutout: False, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.36it/s] \n",
      "Val Loss: 1.1706: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  6.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 12 | Train Loss: 1.3486 | Train F1: 0.8122 | Val Loss: 1.1891 | Val F1: 0.9112 | LR: 2.11e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 13/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3848, Mixup: False, Cutout: False, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.49it/s]\n",
      "Val Loss: 1.1733: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  6.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 13 | Train Loss: 1.3942 | Train F1: 0.7625 | Val Loss: 1.1865 | Val F1: 0.9129 | LR: 1.73e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 14/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3848, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.57it/s] \n",
      "Val Loss: 1.1805: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 14 | Train Loss: 1.3367 | Train F1: 0.8155 | Val Loss: 1.1879 | Val F1: 0.9118 | LR: 1.37e-04\n",
      "â¸ï¸ Early stopping at epoch 14 (patience: 5)\n",
      "\n",
      " Fold 1 ì™„ë£Œ!\n",
      " ìµœê³  Validation F1: 0.9192\n",
      " í•™ìŠµëœ ì—í­: 14/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>best_performance/epoch</td><td>â–â–‚â–ƒâ–…â–‡â–ˆ</td></tr><tr><td>best_performance/val_acc</td><td>â–â–…â–‡â–‡â–ˆâ–ˆ</td></tr><tr><td>best_performance/val_f1</td><td>â–â–…â–‡â–‡â–ˆâ–ˆ</td></tr><tr><td>best_performance/val_loss</td><td>â–ˆâ–„â–ƒâ–‚â–â–</td></tr><tr><td>early_stopping/epoch</td><td>â–</td></tr><tr><td>epoch</td><td>â–â–‚â–‚â–ƒâ–ƒâ–„â–„â–…â–…â–†â–†â–‡â–‡â–ˆ</td></tr><tr><td>fold</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>fold_1/batch_step</td><td>â–â–‚â–‚â–ƒâ–ƒâ–„â–„â–…â–…â–†â–†â–‡â–‡â–ˆ</td></tr><tr><td>fold_1/cutout_applied</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆ</td></tr><tr><td>fold_1/mixup_applied</td><td>â–â–ˆâ–â–ˆâ–ˆâ–â–ˆâ–ˆâ–â–ˆâ–â–â–ˆâ–</td></tr><tr><td>+22</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_performance/epoch</td><td>9</td></tr><tr><td>best_performance/val_acc</td><td>0.92038</td></tr><tr><td>best_performance/val_f1</td><td>0.91925</td></tr><tr><td>best_performance/val_loss</td><td>1.22202</td></tr><tr><td>early_stopping/epoch</td><td>14</td></tr><tr><td>epoch</td><td>14</td></tr><tr><td>fold</td><td>1</td></tr><tr><td>fold_1/batch_step</td><td>520</td></tr><tr><td>fold_1/cutout_applied</td><td>1</td></tr><tr><td>fold_1/mixup_applied</td><td>0</td></tr><tr><td>+23</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fold-1-efficientnet_b3-0754</strong> at: <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/ntt230pg' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/ntt230pg</a><br> View project at: <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250904_075454-ntt230pg/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      " FOLD 2/5\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "creating run (0.2s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/ephemeral/home/computervisioncompetition-cv-1/wandb/wandb/run-20250904_075817-7evzevji</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/7evzevji' target=\"_blank\">fold-2-efficientnet_b3-0758</a></strong> to <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/7evzevji' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/7evzevji</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Fold 2 Dashboard: https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/7evzevji\n",
      "Train samples: 1256, Validation samples: 314\n",
      " ëª¨ë¸ í•™ìŠµ ì‹œì‘ - Fold 2\n",
      "\n",
      "ğŸ“ˆ Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.7520, Mixup: False, Cutout: True, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.38it/s] \n",
      "Val Loss: 1.7706: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  6.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  1 | Train Loss: 2.6738 | Train F1: 0.2635 | Val Loss: 1.7295 | Val F1: 0.6444 | LR: 5.00e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.6444\n",
      "\n",
      "ğŸ“ˆ Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.5371, Mixup: False, Cutout: True, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.45it/s] \n",
      "Val Loss: 1.4631: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  6.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  2 | Train Loss: 2.0344 | Train F1: 0.4750 | Val Loss: 1.5403 | Val F1: 0.7463 | LR: 4.97e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.7463\n",
      "\n",
      "ğŸ“ˆ Epoch 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.6445, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.37it/s] \n",
      "Val Loss: 1.3431: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  3 | Train Loss: 1.8692 | Train F1: 0.5374 | Val Loss: 1.4240 | Val F1: 0.7881 | LR: 4.88e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.7881\n",
      "\n",
      "ğŸ“ˆ Epoch 4/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1758, Mixup: False, Cutout: False, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.39it/s]\n",
      "Val Loss: 1.2829: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  4 | Train Loss: 1.6638 | Train F1: 0.6592 | Val Loss: 1.3933 | Val F1: 0.7911 | LR: 4.73e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.7911\n",
      "\n",
      "ğŸ“ˆ Epoch 5/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.5371, Mixup: False, Cutout: False, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.39it/s]\n",
      "Val Loss: 1.2342: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  6.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  5 | Train Loss: 1.5699 | Train F1: 0.6724 | Val Loss: 1.3434 | Val F1: 0.8136 | LR: 4.52e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.8136\n",
      "\n",
      "ğŸ“ˆ Epoch 6/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1621, Mixup: False, Cutout: False, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.40it/s]\n",
      "Val Loss: 1.2431: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  6 | Train Loss: 1.5816 | Train F1: 0.6486 | Val Loss: 1.2639 | Val F1: 0.8562 | LR: 4.27e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.8562\n",
      "\n",
      "ğŸ“ˆ Epoch 7/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.4316, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.45it/s] \n",
      "Val Loss: 1.2097: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  7 | Train Loss: 1.4582 | Train F1: 0.7425 | Val Loss: 1.2582 | Val F1: 0.8401 | LR: 3.97e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 8/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1914, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.44it/s] \n",
      "Val Loss: 1.2060: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  8 | Train Loss: 1.4659 | Train F1: 0.7609 | Val Loss: 1.2543 | Val F1: 0.8633 | LR: 3.63e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.8633\n",
      "\n",
      "ğŸ“ˆ Epoch 9/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.4062, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.34it/s] \n",
      "Val Loss: 1.2070: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  9 | Train Loss: 1.3693 | Train F1: 0.7763 | Val Loss: 1.2246 | Val F1: 0.8793 | LR: 3.27e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.8793\n",
      "\n",
      "ğŸ“ˆ Epoch 10/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.4062, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.46it/s] \n",
      "Val Loss: 1.1994: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 10 | Train Loss: 1.4686 | Train F1: 0.7348 | Val Loss: 1.2243 | Val F1: 0.8833 | LR: 2.89e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.8833\n",
      "\n",
      "ğŸ“ˆ Epoch 11/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.6064, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.43it/s] \n",
      "Val Loss: 1.1883: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  6.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 11 | Train Loss: 1.4028 | Train F1: 0.7998 | Val Loss: 1.2267 | Val F1: 0.8850 | LR: 2.50e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.8850\n",
      "\n",
      "ğŸ“ˆ Epoch 12/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.4883, Mixup: True, Cutout: False, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.46it/s] \n",
      "Val Loss: 1.1917: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  6.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 12 | Train Loss: 1.4041 | Train F1: 0.7761 | Val Loss: 1.2082 | Val F1: 0.8892 | LR: 2.11e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.8892\n",
      "\n",
      "ğŸ“ˆ Epoch 13/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1973, Mixup: False, Cutout: False, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.35it/s]\n",
      "Val Loss: 1.1864: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 13 | Train Loss: 1.4141 | Train F1: 0.7496 | Val Loss: 1.2055 | Val F1: 0.8908 | LR: 1.73e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.8908\n",
      "\n",
      "ğŸ“ˆ Epoch 14/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1367, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.39it/s] \n",
      "Val Loss: 1.1915: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 14 | Train Loss: 1.3296 | Train F1: 0.8128 | Val Loss: 1.2028 | Val F1: 0.8872 | LR: 1.37e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 15/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2207, Mixup: False, Cutout: False, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.37it/s]\n",
      "Val Loss: 1.1823: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  6.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 15 | Train Loss: 1.3956 | Train F1: 0.8291 | Val Loss: 1.2018 | Val F1: 0.8900 | LR: 1.03e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 16/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1729, Mixup: False, Cutout: False, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.42it/s]\n",
      "Val Loss: 1.1807: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  6.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 16 | Train Loss: 1.3757 | Train F1: 0.8046 | Val Loss: 1.1951 | Val F1: 0.8932 | LR: 7.32e-05\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.8932\n",
      "\n",
      "ğŸ“ˆ Epoch 17/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1797, Mixup: False, Cutout: True, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.53it/s] \n",
      "Val Loss: 1.1887: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 17 | Train Loss: 1.3500 | Train F1: 0.7719 | Val Loss: 1.1961 | Val F1: 0.9013 | LR: 4.77e-05\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.9013\n",
      "\n",
      "ğŸ“ˆ Epoch 18/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.6318, Mixup: True, Cutout: False, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.39it/s] \n",
      "Val Loss: 1.1778: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  6.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 18 | Train Loss: 1.3928 | Train F1: 0.7797 | Val Loss: 1.1935 | Val F1: 0.8894 | LR: 2.72e-05\n",
      "\n",
      "ğŸ“ˆ Epoch 19/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.4385, Mixup: False, Cutout: False, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.47it/s]\n",
      "Val Loss: 1.1823: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 19 | Train Loss: 1.3652 | Train F1: 0.7895 | Val Loss: 1.1990 | Val F1: 0.8943 | LR: 1.22e-05\n",
      "\n",
      "ğŸ“ˆ Epoch 20/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.4355, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.44it/s] \n",
      "Val Loss: 1.1783: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  6.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 20 | Train Loss: 1.3849 | Train F1: 0.7775 | Val Loss: 1.1906 | Val F1: 0.9044 | LR: 3.08e-06\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.9044\n",
      "\n",
      " Fold 2 ì™„ë£Œ!\n",
      " ìµœê³  Validation F1: 0.9044\n",
      " í•™ìŠµëœ ì—í­: 20/20\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>best_performance/epoch</td><td>â–â–â–‚â–‚â–‚â–ƒâ–„â–„â–„â–…â–…â–…â–‡â–‡â–ˆ</td></tr><tr><td>best_performance/val_acc</td><td>â–â–ƒâ–…â–†â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>best_performance/val_f1</td><td>â–â–„â–…â–…â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>best_performance/val_loss</td><td>â–ˆâ–†â–„â–„â–ƒâ–‚â–‚â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch</td><td>â–â–â–‚â–‚â–‚â–ƒâ–ƒâ–„â–„â–„â–…â–…â–…â–†â–†â–‡â–‡â–‡â–ˆâ–ˆ</td></tr><tr><td>fold</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>fold_2/batch_step</td><td>â–â–â–‚â–‚â–‚â–ƒâ–ƒâ–„â–„â–„â–…â–…â–…â–†â–†â–‡â–‡â–‡â–ˆâ–ˆ</td></tr><tr><td>fold_2/class_0_f1</td><td>â–</td></tr><tr><td>fold_2/class_10_f1</td><td>â–</td></tr><tr><td>fold_2/class_11_f1</td><td>â–</td></tr><tr><td>+38</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_performance/epoch</td><td>20</td></tr><tr><td>best_performance/val_acc</td><td>0.91401</td></tr><tr><td>best_performance/val_f1</td><td>0.90444</td></tr><tr><td>best_performance/val_loss</td><td>1.19062</td></tr><tr><td>epoch</td><td>20</td></tr><tr><td>fold</td><td>2</td></tr><tr><td>fold_2/batch_step</td><td>760</td></tr><tr><td>fold_2/class_0_f1</td><td>1</td></tr><tr><td>fold_2/class_10_f1</td><td>0.97561</td></tr><tr><td>fold_2/class_11_f1</td><td>0.97436</td></tr><tr><td>+39</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fold-2-efficientnet_b3-0758</strong> at: <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/7evzevji' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/7evzevji</a><br> View project at: <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team</a><br>Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250904_075817-7evzevji/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      " FOLD 3/5\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "creating run (0.2s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/ephemeral/home/computervisioncompetition-cv-1/wandb/wandb/run-20250904_080252-r4x6xv1j</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/r4x6xv1j' target=\"_blank\">fold-3-efficientnet_b3-0802</a></strong> to <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/r4x6xv1j' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/r4x6xv1j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Fold 3 Dashboard: https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/r4x6xv1j\n",
      "Train samples: 1256, Validation samples: 314\n",
      " ëª¨ë¸ í•™ìŠµ ì‹œì‘ - Fold 3\n",
      "\n",
      "ğŸ“ˆ Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.4102, Mixup: False, Cutout: True, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.41it/s] \n",
      "Val Loss: 1.6706: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  6.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  1 | Train Loss: 2.6402 | Train F1: 0.2743 | Val Loss: 1.8420 | Val F1: 0.6640 | LR: 5.00e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.6640\n",
      "\n",
      "ğŸ“ˆ Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.2852, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.44it/s] \n",
      "Val Loss: 1.5030: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  6.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  2 | Train Loss: 2.0035 | Train F1: 0.4779 | Val Loss: 1.5414 | Val F1: 0.7738 | LR: 4.97e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.7738\n",
      "\n",
      "ğŸ“ˆ Epoch 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.6328, Mixup: False, Cutout: False, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.36it/s]\n",
      "Val Loss: 1.3036: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  3 | Train Loss: 1.8453 | Train F1: 0.5796 | Val Loss: 1.4037 | Val F1: 0.8275 | LR: 4.88e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.8275\n",
      "\n",
      "ğŸ“ˆ Epoch 4/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.7676, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.40it/s] \n",
      "Val Loss: 1.2570: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  4 | Train Loss: 1.6822 | Train F1: 0.6650 | Val Loss: 1.3447 | Val F1: 0.8335 | LR: 4.73e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.8335\n",
      "\n",
      "ğŸ“ˆ Epoch 5/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2129, Mixup: False, Cutout: True, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:12<00:00,  3.33it/s] \n",
      "Val Loss: 1.2888: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  5 | Train Loss: 1.6298 | Train F1: 0.6681 | Val Loss: 1.3003 | Val F1: 0.8494 | LR: 4.52e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.8494\n",
      "\n",
      "ğŸ“ˆ Epoch 6/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.4727, Mixup: False, Cutout: False, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.40it/s]\n",
      "Val Loss: 1.2134: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  6.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  6 | Train Loss: 1.5290 | Train F1: 0.6814 | Val Loss: 1.2893 | Val F1: 0.8502 | LR: 4.27e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.8502\n",
      "\n",
      "ğŸ“ˆ Epoch 7/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.7129, Mixup: True, Cutout: False, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.45it/s] \n",
      "Val Loss: 1.1917: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  6.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  7 | Train Loss: 1.5687 | Train F1: 0.6248 | Val Loss: 1.2784 | Val F1: 0.8742 | LR: 3.97e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.8742\n",
      "\n",
      "ğŸ“ˆ Epoch 8/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.6123, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.48it/s] \n",
      "Val Loss: 1.1879: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  6.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  8 | Train Loss: 1.4762 | Train F1: 0.7810 | Val Loss: 1.3029 | Val F1: 0.8301 | LR: 3.63e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 9/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3418, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.41it/s] \n",
      "Val Loss: 1.1923: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  9 | Train Loss: 1.3884 | Train F1: 0.8296 | Val Loss: 1.2429 | Val F1: 0.8873 | LR: 3.27e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.8873\n",
      "\n",
      "ğŸ“ˆ Epoch 10/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.4336, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:12<00:00,  3.27it/s] \n",
      "Val Loss: 1.1728: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 10 | Train Loss: 1.3858 | Train F1: 0.8131 | Val Loss: 1.2224 | Val F1: 0.9110 | LR: 2.89e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.9110\n",
      "\n",
      "ğŸ“ˆ Epoch 11/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1914, Mixup: False, Cutout: False, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.46it/s]\n",
      "Val Loss: 1.1582: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 11 | Train Loss: 1.3786 | Train F1: 0.7365 | Val Loss: 1.2069 | Val F1: 0.9008 | LR: 2.50e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 12/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2480, Mixup: False, Cutout: False, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.48it/s]\n",
      "Val Loss: 1.1326: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 12 | Train Loss: 1.4666 | Train F1: 0.7583 | Val Loss: 1.2023 | Val F1: 0.9058 | LR: 2.11e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 13/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.7109, Mixup: True, Cutout: False, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:12<00:00,  3.33it/s] \n",
      "Val Loss: 1.1337: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 13 | Train Loss: 1.3352 | Train F1: 0.8182 | Val Loss: 1.1997 | Val F1: 0.8947 | LR: 1.73e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 14/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1836, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.41it/s] \n",
      "Val Loss: 1.1592: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 14 | Train Loss: 1.3543 | Train F1: 0.8598 | Val Loss: 1.2030 | Val F1: 0.8923 | LR: 1.37e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 15/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2490, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.45it/s] \n",
      "Val Loss: 1.1135: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  6.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 15 | Train Loss: 1.3207 | Train F1: 0.8179 | Val Loss: 1.1900 | Val F1: 0.9265 | LR: 1.03e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.9265\n",
      "\n",
      "ğŸ“ˆ Epoch 16/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.6074, Mixup: False, Cutout: False, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.43it/s]\n",
      "Val Loss: 1.1307: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 16 | Train Loss: 1.3486 | Train F1: 0.8386 | Val Loss: 1.1832 | Val F1: 0.9254 | LR: 7.32e-05\n",
      "\n",
      "ğŸ“ˆ Epoch 17/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2119, Mixup: False, Cutout: False, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.45it/s]\n",
      "Val Loss: 1.1164: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 17 | Train Loss: 1.3418 | Train F1: 0.8049 | Val Loss: 1.1879 | Val F1: 0.9197 | LR: 4.77e-05\n",
      "\n",
      "ğŸ“ˆ Epoch 18/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3184, Mixup: False, Cutout: True, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.45it/s] \n",
      "Val Loss: 1.1211: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  6.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 18 | Train Loss: 1.4034 | Train F1: 0.7640 | Val Loss: 1.1828 | Val F1: 0.9172 | LR: 2.72e-05\n",
      "\n",
      "ğŸ“ˆ Epoch 19/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.9990, Mixup: True, Cutout: False, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.42it/s] \n",
      "Val Loss: 1.1241: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  6.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 19 | Train Loss: 1.4034 | Train F1: 0.7406 | Val Loss: 1.1869 | Val F1: 0.9125 | LR: 1.22e-05\n",
      "\n",
      "ğŸ“ˆ Epoch 20/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3359, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.36it/s] \n",
      "Val Loss: 1.1189: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  6.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 20 | Train Loss: 1.3301 | Train F1: 0.8194 | Val Loss: 1.1881 | Val F1: 0.9254 | LR: 3.08e-06\n",
      "â¸ï¸ Early stopping at epoch 20 (patience: 5)\n",
      "\n",
      " Fold 3 ì™„ë£Œ!\n",
      " ìµœê³  Validation F1: 0.9265\n",
      " í•™ìŠµëœ ì—í­: 20/20\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>best_performance/epoch</td><td>â–â–â–‚â–ƒâ–ƒâ–ƒâ–„â–…â–…â–ˆ</td></tr><tr><td>best_performance/val_acc</td><td>â–â–…â–…â–†â–†â–†â–‡â–‡â–ˆâ–ˆ</td></tr><tr><td>best_performance/val_f1</td><td>â–â–„â–…â–†â–†â–†â–‡â–‡â–ˆâ–ˆ</td></tr><tr><td>best_performance/val_loss</td><td>â–ˆâ–…â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–â–</td></tr><tr><td>early_stopping/epoch</td><td>â–</td></tr><tr><td>epoch</td><td>â–â–â–‚â–‚â–‚â–ƒâ–ƒâ–„â–„â–„â–…â–…â–…â–†â–†â–‡â–‡â–‡â–ˆâ–ˆ</td></tr><tr><td>fold</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>fold_3/batch_step</td><td>â–â–â–‚â–‚â–‚â–ƒâ–ƒâ–„â–„â–„â–…â–…â–…â–†â–†â–‡â–‡â–‡â–ˆâ–ˆ</td></tr><tr><td>fold_3/class_0_f1</td><td>â–</td></tr><tr><td>fold_3/class_10_f1</td><td>â–</td></tr><tr><td>+39</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_performance/epoch</td><td>15</td></tr><tr><td>best_performance/val_acc</td><td>0.92994</td></tr><tr><td>best_performance/val_f1</td><td>0.92646</td></tr><tr><td>best_performance/val_loss</td><td>1.19002</td></tr><tr><td>early_stopping/epoch</td><td>20</td></tr><tr><td>epoch</td><td>20</td></tr><tr><td>fold</td><td>3</td></tr><tr><td>fold_3/batch_step</td><td>760</td></tr><tr><td>fold_3/class_0_f1</td><td>1</td></tr><tr><td>fold_3/class_10_f1</td><td>0.97561</td></tr><tr><td>+40</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fold-3-efficientnet_b3-0802</strong> at: <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/r4x6xv1j' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/r4x6xv1j</a><br> View project at: <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team</a><br>Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250904_080252-r4x6xv1j/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      " FOLD 4/5\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "creating run (0.2s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/ephemeral/home/computervisioncompetition-cv-1/wandb/wandb/run-20250904_080726-163vzl9h</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/163vzl9h' target=\"_blank\">fold-4-efficientnet_b3-0807</a></strong> to <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/163vzl9h' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/163vzl9h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Fold 4 Dashboard: https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/163vzl9h\n",
      "Train samples: 1256, Validation samples: 314\n",
      " ëª¨ë¸ í•™ìŠµ ì‹œì‘ - Fold 4\n",
      "\n",
      "ğŸ“ˆ Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.1406, Mixup: False, Cutout: True, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.41it/s] \n",
      "Val Loss: 1.6792: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  1 | Train Loss: 2.6917 | Train F1: 0.2255 | Val Loss: 1.8451 | Val F1: 0.6301 | LR: 5.00e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.6301\n",
      "\n",
      "ğŸ“ˆ Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.0449, Mixup: True, Cutout: False, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.37it/s] \n",
      "Val Loss: 1.4110: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  2 | Train Loss: 2.0737 | Train F1: 0.4742 | Val Loss: 1.5523 | Val F1: 0.7422 | LR: 4.97e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.7422\n",
      "\n",
      "ğŸ“ˆ Epoch 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.4883, Mixup: True, Cutout: False, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.39it/s] \n",
      "Val Loss: 1.3267: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  3 | Train Loss: 1.8374 | Train F1: 0.5897 | Val Loss: 1.4371 | Val F1: 0.8072 | LR: 4.88e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.8072\n",
      "\n",
      "ğŸ“ˆ Epoch 4/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.9893, Mixup: True, Cutout: False, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.40it/s] \n",
      "Val Loss: 1.3116: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  4 | Train Loss: 1.5992 | Train F1: 0.7112 | Val Loss: 1.3592 | Val F1: 0.8242 | LR: 4.73e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.8242\n",
      "\n",
      "ğŸ“ˆ Epoch 5/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.3281, Mixup: True, Cutout: False, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.34it/s] \n",
      "Val Loss: 1.2396: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  5 | Train Loss: 1.5490 | Train F1: 0.7364 | Val Loss: 1.3080 | Val F1: 0.8528 | LR: 4.52e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.8528\n",
      "\n",
      "ğŸ“ˆ Epoch 6/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1934, Mixup: False, Cutout: True, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.34it/s] \n",
      "Val Loss: 1.2123: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  6 | Train Loss: 1.5487 | Train F1: 0.7681 | Val Loss: 1.3052 | Val F1: 0.8433 | LR: 4.27e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 7/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.7500, Mixup: True, Cutout: False, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.45it/s] \n",
      "Val Loss: 1.1508: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  7 | Train Loss: 1.5261 | Train F1: 0.7736 | Val Loss: 1.2868 | Val F1: 0.8729 | LR: 3.97e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.8729\n",
      "\n",
      "ğŸ“ˆ Epoch 8/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.5684, Mixup: False, Cutout: False, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.40it/s]\n",
      "Val Loss: 1.1705: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  8 | Train Loss: 1.4707 | Train F1: 0.7543 | Val Loss: 1.2541 | Val F1: 0.8730 | LR: 3.63e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.8730\n",
      "\n",
      "ğŸ“ˆ Epoch 9/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1240, Mixup: False, Cutout: False, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.34it/s]\n",
      "Val Loss: 1.1497: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  9 | Train Loss: 1.3894 | Train F1: 0.8111 | Val Loss: 1.2536 | Val F1: 0.8643 | LR: 3.27e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 10/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3945, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:12<00:00,  3.26it/s] \n",
      "Val Loss: 1.1505: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 10 | Train Loss: 1.4487 | Train F1: 0.7726 | Val Loss: 1.2585 | Val F1: 0.8779 | LR: 2.89e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.8779\n",
      "\n",
      "ğŸ“ˆ Epoch 11/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1064, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.37it/s] \n",
      "Val Loss: 1.1334: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 11 | Train Loss: 1.3683 | Train F1: 0.7620 | Val Loss: 1.2478 | Val F1: 0.8844 | LR: 2.50e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.8844\n",
      "\n",
      "ğŸ“ˆ Epoch 12/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2324, Mixup: False, Cutout: True, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.35it/s] \n",
      "Val Loss: 1.1087: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 12 | Train Loss: 1.3586 | Train F1: 0.7946 | Val Loss: 1.2240 | Val F1: 0.8792 | LR: 2.11e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 13/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.0820, Mixup: False, Cutout: False, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.39it/s]\n",
      "Val Loss: 1.0997: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 13 | Train Loss: 1.3780 | Train F1: 0.7871 | Val Loss: 1.2172 | Val F1: 0.8921 | LR: 1.73e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.8921\n",
      "\n",
      "ğŸ“ˆ Epoch 14/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1650, Mixup: False, Cutout: True, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:12<00:00,  3.32it/s] \n",
      "Val Loss: 1.1342: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 14 | Train Loss: 1.3663 | Train F1: 0.7710 | Val Loss: 1.2123 | Val F1: 0.8968 | LR: 1.37e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.8968\n",
      "\n",
      "ğŸ“ˆ Epoch 15/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.9727, Mixup: True, Cutout: False, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.37it/s] \n",
      "Val Loss: 1.1040: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 15 | Train Loss: 1.3880 | Train F1: 0.8063 | Val Loss: 1.2114 | Val F1: 0.8948 | LR: 1.03e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 16/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1543, Mixup: False, Cutout: False, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.39it/s]\n",
      "Val Loss: 1.0868: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 16 | Train Loss: 1.3710 | Train F1: 0.7617 | Val Loss: 1.2044 | Val F1: 0.8840 | LR: 7.32e-05\n",
      "\n",
      "ğŸ“ˆ Epoch 17/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1504, Mixup: False, Cutout: True, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.36it/s] \n",
      "Val Loss: 1.0826: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 17 | Train Loss: 1.3151 | Train F1: 0.8399 | Val Loss: 1.2002 | Val F1: 0.8862 | LR: 4.77e-05\n",
      "\n",
      "ğŸ“ˆ Epoch 18/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2246, Mixup: True, Cutout: False, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.39it/s] \n",
      "Val Loss: 1.0825: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 18 | Train Loss: 1.3750 | Train F1: 0.8142 | Val Loss: 1.2096 | Val F1: 0.9018 | LR: 2.72e-05\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.9018\n",
      "\n",
      "ğŸ“ˆ Epoch 19/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.4648, Mixup: False, Cutout: True, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:12<00:00,  3.32it/s] \n",
      "Val Loss: 1.0845: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 19 | Train Loss: 1.3540 | Train F1: 0.8152 | Val Loss: 1.2041 | Val F1: 0.8925 | LR: 1.22e-05\n",
      "\n",
      "ğŸ“ˆ Epoch 20/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3057, Mixup: False, Cutout: True, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.36it/s] \n",
      "Val Loss: 1.0833: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 20 | Train Loss: 1.3095 | Train F1: 0.7919 | Val Loss: 1.1991 | Val F1: 0.8957 | LR: 3.08e-06\n",
      "\n",
      " Fold 4 ì™„ë£Œ!\n",
      " ìµœê³  Validation F1: 0.9018\n",
      " í•™ìŠµëœ ì—í­: 20/20\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>best_performance/epoch</td><td>â–â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–ˆ</td></tr><tr><td>best_performance/val_acc</td><td>â–â–„â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>best_performance/val_f1</td><td>â–â–„â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>best_performance/val_loss</td><td>â–ˆâ–…â–„â–ƒâ–‚â–‚â–â–‚â–â–â–â–</td></tr><tr><td>epoch</td><td>â–â–â–‚â–‚â–‚â–ƒâ–ƒâ–„â–„â–„â–…â–…â–…â–†â–†â–‡â–‡â–‡â–ˆâ–ˆ</td></tr><tr><td>fold</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>fold_4/batch_step</td><td>â–â–â–‚â–‚â–‚â–ƒâ–ƒâ–„â–„â–„â–…â–…â–…â–†â–†â–‡â–‡â–‡â–ˆâ–ˆ</td></tr><tr><td>fold_4/class_0_f1</td><td>â–</td></tr><tr><td>fold_4/class_10_f1</td><td>â–</td></tr><tr><td>fold_4/class_11_f1</td><td>â–</td></tr><tr><td>+38</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_performance/epoch</td><td>18</td></tr><tr><td>best_performance/val_acc</td><td>0.91083</td></tr><tr><td>best_performance/val_f1</td><td>0.90183</td></tr><tr><td>best_performance/val_loss</td><td>1.20964</td></tr><tr><td>epoch</td><td>20</td></tr><tr><td>fold</td><td>4</td></tr><tr><td>fold_4/batch_step</td><td>760</td></tr><tr><td>fold_4/class_0_f1</td><td>1</td></tr><tr><td>fold_4/class_10_f1</td><td>0.95238</td></tr><tr><td>fold_4/class_11_f1</td><td>0.97436</td></tr><tr><td>+39</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fold-4-efficientnet_b3-0807</strong> at: <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/163vzl9h' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/163vzl9h</a><br> View project at: <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team</a><br>Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250904_080726-163vzl9h/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      " FOLD 5/5\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "creating run (0.1s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/ephemeral/home/computervisioncompetition-cv-1/wandb/wandb/run-20250904_081204-8yksq1wj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/8yksq1wj' target=\"_blank\">fold-5-efficientnet_b3-0812</a></strong> to <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/8yksq1wj' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/8yksq1wj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Fold 5 Dashboard: https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/8yksq1wj\n",
      "Train samples: 1256, Validation samples: 314\n",
      " ëª¨ë¸ í•™ìŠµ ì‹œì‘ - Fold 5\n",
      "\n",
      "ğŸ“ˆ Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.2012, Mixup: False, Cutout: False, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.38it/s]\n",
      "Val Loss: 1.5064: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  1 | Train Loss: 2.6446 | Train F1: 0.2751 | Val Loss: 1.7031 | Val F1: 0.6697 | LR: 5.00e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.6697\n",
      "\n",
      "ğŸ“ˆ Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.6357, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.42it/s] \n",
      "Val Loss: 1.4501: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  2 | Train Loss: 2.0776 | Train F1: 0.4621 | Val Loss: 1.4837 | Val F1: 0.7563 | LR: 4.97e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.7563\n",
      "\n",
      "ğŸ“ˆ Epoch 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.4199, Mixup: False, Cutout: False, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.43it/s]\n",
      "Val Loss: 1.3335: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  3 | Train Loss: 1.7302 | Train F1: 0.6339 | Val Loss: 1.4094 | Val F1: 0.8046 | LR: 4.88e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.8046\n",
      "\n",
      "ğŸ“ˆ Epoch 4/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.9062, Mixup: True, Cutout: False, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.34it/s] \n",
      "Val Loss: 1.2759: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  4 | Train Loss: 1.6755 | Train F1: 0.6616 | Val Loss: 1.3467 | Val F1: 0.8449 | LR: 4.73e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.8449\n",
      "\n",
      "ğŸ“ˆ Epoch 5/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.4424, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.41it/s] \n",
      "Val Loss: 1.3042: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  5 | Train Loss: 1.6271 | Train F1: 0.6825 | Val Loss: 1.3463 | Val F1: 0.8140 | LR: 4.52e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 6/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3477, Mixup: False, Cutout: True, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.36it/s] \n",
      "Val Loss: 1.2070: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  6 | Train Loss: 1.6422 | Train F1: 0.7196 | Val Loss: 1.2879 | Val F1: 0.8673 | LR: 4.27e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.8673\n",
      "\n",
      "ğŸ“ˆ Epoch 7/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.5049, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.38it/s] \n",
      "Val Loss: 1.2214: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  7 | Train Loss: 1.4339 | Train F1: 0.8043 | Val Loss: 1.2782 | Val F1: 0.8714 | LR: 3.97e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.8714\n",
      "\n",
      "ğŸ“ˆ Epoch 8/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.6260, Mixup: False, Cutout: True, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.49it/s] \n",
      "Val Loss: 1.1724: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  8 | Train Loss: 1.4801 | Train F1: 0.7811 | Val Loss: 1.2626 | Val F1: 0.8646 | LR: 3.63e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 9/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3730, Mixup: False, Cutout: True, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.39it/s] \n",
      "Val Loss: 1.1226: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  9 | Train Loss: 1.4188 | Train F1: 0.8018 | Val Loss: 1.2430 | Val F1: 0.8848 | LR: 3.27e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.8848\n",
      "\n",
      "ğŸ“ˆ Epoch 10/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.4727, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.39it/s] \n",
      "Val Loss: 1.1518: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 10 | Train Loss: 1.4720 | Train F1: 0.7429 | Val Loss: 1.2294 | Val F1: 0.8900 | LR: 2.89e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.8900\n",
      "\n",
      "ğŸ“ˆ Epoch 11/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.7383, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.37it/s] \n",
      "Val Loss: 1.2056: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 11 | Train Loss: 1.4065 | Train F1: 0.7534 | Val Loss: 1.2264 | Val F1: 0.8820 | LR: 2.50e-04\n",
      "\n",
      "ğŸ“ˆ Epoch 12/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.9287, Mixup: True, Cutout: False, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.42it/s] \n",
      "Val Loss: 1.1097: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  6.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 12 | Train Loss: 1.3601 | Train F1: 0.7947 | Val Loss: 1.2159 | Val F1: 0.8903 | LR: 2.11e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.8903\n",
      "\n",
      "ğŸ“ˆ Epoch 13/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.0596, Mixup: False, Cutout: False, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.44it/s]\n",
      "Val Loss: 1.0938: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 13 | Train Loss: 1.3048 | Train F1: 0.8415 | Val Loss: 1.2032 | Val F1: 0.8974 | LR: 1.73e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.8974\n",
      "\n",
      "ğŸ“ˆ Epoch 14/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1016, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.38it/s] \n",
      "Val Loss: 1.0985: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 14 | Train Loss: 1.4739 | Train F1: 0.6990 | Val Loss: 1.2045 | Val F1: 0.9051 | LR: 1.37e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.9051\n",
      "\n",
      "ğŸ“ˆ Epoch 15/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1621, Mixup: True, Cutout: False, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.40it/s] \n",
      "Val Loss: 1.1045: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 15 | Train Loss: 1.4612 | Train F1: 0.7266 | Val Loss: 1.1888 | Val F1: 0.9069 | LR: 1.03e-04\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.9069\n",
      "\n",
      "ğŸ“ˆ Epoch 16/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2637, Mixup: False, Cutout: True, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:12<00:00,  3.25it/s] \n",
      "Val Loss: 1.1070: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 16 | Train Loss: 1.4022 | Train F1: 0.8060 | Val Loss: 1.1809 | Val F1: 0.9217 | LR: 7.32e-05\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.9217\n",
      "\n",
      "ğŸ“ˆ Epoch 17/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.5713, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.45it/s] \n",
      "Val Loss: 1.1048: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 17 | Train Loss: 1.3484 | Train F1: 0.8238 | Val Loss: 1.1816 | Val F1: 0.9198 | LR: 4.77e-05\n",
      "\n",
      "ğŸ“ˆ Epoch 18/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.6270, Mixup: True, Cutout: False, RandomCrop: False: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.37it/s] \n",
      "Val Loss: 1.0994: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 18 | Train Loss: 1.3664 | Train F1: 0.8020 | Val Loss: 1.1775 | Val F1: 0.9157 | LR: 2.72e-05\n",
      "\n",
      "ğŸ“ˆ Epoch 19/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.5947, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.39it/s] \n",
      "Val Loss: 1.1034: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 19 | Train Loss: 1.3957 | Train F1: 0.7767 | Val Loss: 1.1849 | Val F1: 0.9341 | LR: 1.22e-05\n",
      "ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: 0.9341\n",
      "\n",
      "ğŸ“ˆ Epoch 20/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2988, Mixup: False, Cutout: False, RandomCrop: True: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.45it/s] \n",
      "Val Loss: 1.0994: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 20 | Train Loss: 1.3864 | Train F1: 0.8222 | Val Loss: 1.1757 | Val F1: 0.9126 | LR: 3.08e-06\n",
      "\n",
      " Fold 5 ì™„ë£Œ!\n",
      " ìµœê³  Validation F1: 0.9341\n",
      " í•™ìŠµëœ ì—í­: 20/20\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>best_performance/epoch</td><td>â–â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–†â–‡â–ˆ</td></tr><tr><td>best_performance/val_acc</td><td>â–â–„â–…â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆ</td></tr><tr><td>best_performance/val_f1</td><td>â–â–ƒâ–…â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆ</td></tr><tr><td>best_performance/val_loss</td><td>â–ˆâ–…â–„â–ƒâ–‚â–‚â–‚â–‚â–â–â–â–â–â–</td></tr><tr><td>epoch</td><td>â–â–â–‚â–‚â–‚â–ƒâ–ƒâ–„â–„â–„â–…â–…â–…â–†â–†â–‡â–‡â–‡â–ˆâ–ˆ</td></tr><tr><td>fold</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>fold_5/batch_step</td><td>â–â–â–‚â–‚â–‚â–ƒâ–ƒâ–„â–„â–„â–…â–…â–…â–†â–†â–‡â–‡â–‡â–ˆâ–ˆ</td></tr><tr><td>fold_5/class_0_f1</td><td>â–</td></tr><tr><td>fold_5/class_10_f1</td><td>â–</td></tr><tr><td>fold_5/class_11_f1</td><td>â–</td></tr><tr><td>+38</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_performance/epoch</td><td>19</td></tr><tr><td>best_performance/val_acc</td><td>0.93631</td></tr><tr><td>best_performance/val_f1</td><td>0.93409</td></tr><tr><td>best_performance/val_loss</td><td>1.1849</td></tr><tr><td>epoch</td><td>20</td></tr><tr><td>fold</td><td>5</td></tr><tr><td>fold_5/batch_step</td><td>760</td></tr><tr><td>fold_5/class_0_f1</td><td>1</td></tr><tr><td>fold_5/class_10_f1</td><td>1</td></tr><tr><td>fold_5/class_11_f1</td><td>1</td></tr><tr><td>+39</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fold-5-efficientnet_b3-0812</strong> at: <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/8yksq1wj' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/8yksq1wj</a><br> View project at: <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team</a><br>Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250904_081204-8yksq1wj/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# 10. K-Fold Cross Validation Loop with WandB\n",
    "# =============================================================================\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(train_df, train_df['target'])):\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\" FOLD {fold + 1}/{N_FOLDS}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    # ê° foldë³„ child run ìƒì„±\n",
    "    fold_run = wandb.init(\n",
    "        project=PROJECT_NAME,\n",
    "        entity=ENTITY,\n",
    "        name=f\"fold-{fold+1}-{model_name}-{datetime.now().strftime('%H%M')}\",\n",
    "        config=config,\n",
    "        tags=[\"fold\", f\"fold-{fold+1}\", model_name, \"child-run\"],\n",
    "        group=\"k-fold-experiment\",\n",
    "        job_type=f\"fold-{fold+1}\",\n",
    "        reinit=True  # ìƒˆë¡œìš´ run ì‹œì‘ í—ˆìš©\n",
    "    )\n",
    "    \n",
    "    print(f\"ğŸ“Š Fold {fold+1} Dashboard: {fold_run.url}\")\n",
    "    \n",
    "    # í˜„ì¬ foldì˜ train/validation ë°ì´í„° ë¶„í• \n",
    "    train_fold_df = train_df.iloc[train_idx].reset_index(drop=True)\n",
    "    val_fold_df = train_df.iloc[val_idx].reset_index(drop=True)\n",
    "    \n",
    "    # ë°ì´í„° ë¶„í•  ì •ë³´ ë¡œê¹…\n",
    "    wandb.log({\n",
    "        \"fold_info/fold_number\": fold + 1,\n",
    "        \"fold_info/train_samples\": len(train_fold_df),\n",
    "        \"fold_info/val_samples\": len(val_fold_df),\n",
    "        \"fold_info/train_ratio\": len(train_fold_df) / len(train_df),\n",
    "        \"fold_info/val_ratio\": len(val_fold_df) / len(train_df)\n",
    "    })\n",
    "    \n",
    "    # í˜„ì¬ foldì˜ Dataset ìƒì„±\n",
    "    trn_dataset = ImageDataset(\n",
    "        train_fold_df,\n",
    "        \"../data/train/\",\n",
    "        transform=trn_transform\n",
    "    )\n",
    "    \n",
    "    val_dataset = ImageDataset(\n",
    "        val_fold_df,\n",
    "        \"../data/train/\",\n",
    "        transform=tst_transform  # ê²€ì¦ì—ëŠ” ì¦ê°• ì ìš© ì•ˆí•¨\n",
    "    )\n",
    "    \n",
    "    # í˜„ì¬ foldì˜ DataLoader ìƒì„±\n",
    "    trn_loader = DataLoader(\n",
    "        trn_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=False\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    print(f\"Train samples: {len(trn_dataset)}, Validation samples: {len(val_dataset)}\")\n",
    "    \n",
    "    # ëª¨ë¸ ì´ˆê¸°í™” (ê° foldë§ˆë‹¤ ìƒˆë¡œìš´ ëª¨ë¸)\n",
    "    model = timm.create_model(\n",
    "        model_name,\n",
    "        pretrained=True,\n",
    "        num_classes=17\n",
    "    ).to(device)\n",
    "    \n",
    "    loss_fn = nn.CrossEntropyLoss(label_smoothing=0.2)  # Label Smoothing ì ìš©\n",
    "    optimizer = Adam(model.parameters(), lr=LR)\n",
    "    \n",
    "    # Learning Rate Scheduler ì¶”ê°€\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "    \n",
    "    # í˜„ì¬ foldì˜ ìµœê³  ì„±ëŠ¥ ì¶”ì \n",
    "    best_val_f1 = 0.0\n",
    "    best_model = None\n",
    "    patience = 0\n",
    "    max_patience = 5\n",
    "    \n",
    "    print(f\" ëª¨ë¸ í•™ìŠµ ì‹œì‘ - Fold {fold+1}\")\n",
    "    \n",
    "    # =============================================================================\n",
    "    # 11. Training Loop for Current Fold\n",
    "    # =============================================================================\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        print(f\"\\nğŸ“ˆ Epoch {epoch+1}/{EPOCHS}\")\n",
    "        \n",
    "        # Training\n",
    "        train_ret = train_one_epoch(\n",
    "            trn_loader, model, optimizer, loss_fn, device, \n",
    "            epoch=epoch, fold=fold+1\n",
    "        )\n",
    "        \n",
    "        # Validation\n",
    "        val_ret = validate_one_epoch(\n",
    "            val_loader, model, loss_fn, device, \n",
    "            epoch=epoch, fold=fold+1,\n",
    "            log_confusion=(epoch == EPOCHS-1)  # ë§ˆì§€ë§‰ epochì—ë§Œ confusion matrix\n",
    "        )\n",
    "        \n",
    "        # Learning rate ë¡œê¹…\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        \n",
    "        # WandBì— metrics ë¡œê¹…\n",
    "        log_data = {\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"fold\": fold + 1,\n",
    "            \"train/loss\": train_ret['train_loss'],\n",
    "            \"train/accuracy\": train_ret['train_acc'], \n",
    "            \"train/f1\": train_ret['train_f1'],\n",
    "            \"val/loss\": val_ret['val_loss'],\n",
    "            \"val/accuracy\": val_ret['val_acc'],\n",
    "            \"val/f1\": val_ret['val_f1'],\n",
    "            \"learning_rate\": current_lr,\n",
    "            \"optimizer/lr\": current_lr\n",
    "        }\n",
    "        \n",
    "        # GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë¡œê¹…\n",
    "        if torch.cuda.is_available():\n",
    "            gpu_memory_used = torch.cuda.memory_allocated(0) / 1e9\n",
    "            gpu_memory_total = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "            log_data.update({\n",
    "                \"system/gpu_memory_used_gb\": gpu_memory_used,\n",
    "                \"system/gpu_memory_total_gb\": gpu_memory_total,\n",
    "                \"system/gpu_utilization_pct\": (gpu_memory_used / gpu_memory_total) * 100\n",
    "            })\n",
    "        \n",
    "        wandb.log(log_data)\n",
    "        \n",
    "        # Scheduler step\n",
    "        scheduler.step()\n",
    "        \n",
    "        print(f\" Epoch {epoch+1:2d} | \"\n",
    "              f\"Train Loss: {train_ret['train_loss']:.4f} | \"\n",
    "              f\"Train F1: {train_ret['train_f1']:.4f} | \"\n",
    "              f\"Val Loss: {val_ret['val_loss']:.4f} | \"\n",
    "              f\"Val F1: {val_ret['val_f1']:.4f} | \"\n",
    "              f\"LR: {current_lr:.2e}\")\n",
    "        \n",
    "        # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥\n",
    "        if val_ret['val_f1'] > best_val_f1:\n",
    "            best_val_f1 = val_ret['val_f1']\n",
    "            best_model = copy.deepcopy(model.state_dict())\n",
    "            patience = 0\n",
    "            \n",
    "            # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì•„í‹°íŒ©íŠ¸ë¡œ ì €ì¥\n",
    "            model_path = f'best_model_fold_{fold+1}.pth'\n",
    "            torch.save(best_model, model_path)\n",
    "            wandb.save(model_path, policy=\"now\")\n",
    "            \n",
    "            # ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥ ë¡œê¹…\n",
    "            wandb.log({\n",
    "                f\"best_performance/epoch\": epoch + 1,\n",
    "                f\"best_performance/val_f1\": best_val_f1,\n",
    "                f\"best_performance/val_acc\": val_ret['val_acc'],\n",
    "                f\"best_performance/val_loss\": val_ret['val_loss'],\n",
    "            })\n",
    "            \n",
    "            print(f\"ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: {best_val_f1:.4f}\")\n",
    "        else:\n",
    "            patience += 1\n",
    "            \n",
    "        # Early stopping (ì„ íƒì )\n",
    "        if patience >= max_patience and epoch > EPOCHS // 2:\n",
    "            print(f\"â¸ï¸ Early stopping at epoch {epoch+1} (patience: {patience})\")\n",
    "            wandb.log({\"early_stopping/epoch\": epoch + 1})\n",
    "            break\n",
    "    \n",
    "    # =============================================================================\n",
    "    # 12. Fold Results Summary\n",
    "    # =============================================================================\n",
    "    \n",
    "    # í˜„ì¬ fold ê²°ê³¼ ì €ì¥\n",
    "    fold_result = {\n",
    "        'fold': fold + 1,\n",
    "        'best_val_f1': best_val_f1,\n",
    "        'final_train_f1': train_ret['train_f1'],\n",
    "        'train_samples': len(trn_dataset),\n",
    "        'val_samples': len(val_dataset),\n",
    "        'epochs_trained': epoch + 1,\n",
    "        'early_stopped': patience >= max_patience\n",
    "    }\n",
    "    \n",
    "    fold_results.append(fold_result)\n",
    "    fold_models.append(best_model)\n",
    "    \n",
    "    # Fold ìµœì¢… ìš”ì•½ ë¡œê¹…\n",
    "    wandb.log({\n",
    "        \"fold_summary/best_val_f1\": best_val_f1,\n",
    "        \"fold_summary/final_train_f1\": train_ret['train_f1'],\n",
    "        \"fold_summary/epochs_trained\": epoch + 1,\n",
    "        \"fold_summary/improvement\": best_val_f1 - val_ret['val_f1'],\n",
    "        \"fold_summary/early_stopped\": patience >= max_patience\n",
    "    })\n",
    "    \n",
    "    print(f\"\\n Fold {fold + 1} ì™„ë£Œ!\")\n",
    "    print(f\" ìµœê³  Validation F1: {best_val_f1:.4f}\")\n",
    "    print(f\" í•™ìŠµëœ ì—í­: {epoch + 1}/{EPOCHS}\")\n",
    "    \n",
    "    # Fold run ì¢…ë£Œ\n",
    "    wandb.finish()\n",
    "    \n",
    "    # ë©”ëª¨ë¦¬ ì •ë¦¬\n",
    "    del model, optimizer, scheduler, trn_loader, val_loader\n",
    "    torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5545246d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      " K-FOLD CROSS VALIDATION ìµœì¢… ê²°ê³¼\n",
      "============================================================\n",
      " í™œì„±í™”ëœ runì´ ì—†ì–´ ìƒˆë¡œìš´ summary runì„ ìƒì„±í•©ë‹ˆë‹¤.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "creating run (0.1s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/ephemeral/home/computervisioncompetition-cv-1/wandb/wandb/run-20250904_081641-1y8ppzz2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/1y8ppzz2' target=\"_blank\">SUMMARY-efficientnet-b3-baseline-0904-0816</a></strong> to <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/1y8ppzz2' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/1y8ppzz2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " CV ê²°ê³¼ ë¡œê¹… ì™„ë£Œ!\n",
      "Fold 1: 0.9192 (14 epochs)  Early Stopped\n",
      "Fold 2: 0.9044 (20 epochs)  Completed\n",
      "Fold 3: 0.9265 (20 epochs)  Early Stopped\n",
      "Fold 4: 0.9018 (20 epochs)  Completed\n",
      "Fold 5: 0.9341 (20 epochs)  Completed\n",
      "\n",
      " í‰ê·  CV F1: 0.9172 Â± 0.0124\n",
      " ìµœê³  Fold: 0.9341\n",
      " ìµœì•… Fold: 0.9018\n",
      " ì„±ëŠ¥ ë²”ìœ„: 0.0323\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 13. K-Fold Cross Validation Results Summary\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\" K-FOLD CROSS VALIDATION ìµœì¢… ê²°ê³¼\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "val_f1_scores = [result['best_val_f1'] for result in fold_results]\n",
    "mean_f1 = np.mean(val_f1_scores)\n",
    "std_f1 = np.std(val_f1_scores)\n",
    "\n",
    "try:\n",
    "    # wandb.runì´ í˜„ì¬ í™œì„±í™”ëœ runì„ ê°€ë¦¬í‚´\n",
    "    if wandb.run is None:\n",
    "        print(\" í™œì„±í™”ëœ runì´ ì—†ì–´ ìƒˆë¡œìš´ summary runì„ ìƒì„±í•©ë‹ˆë‹¤.\")\n",
    "        active_run = wandb.init(\n",
    "            project=PROJECT_NAME,\n",
    "            name=f\"SUMMARY-{EXPERIMENT_NAME}-{datetime.now().strftime('%m%d-%H%M')}\",\n",
    "            config=config,\n",
    "            tags=[\"summary\", \"cv-results\", model_name],\n",
    "            group=\"k-fold-experiment\",\n",
    "            job_type=\"summary\",\n",
    "            reinit=True\n",
    "        )\n",
    "    else:\n",
    "        print(\" ê¸°ì¡´ runì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\")\n",
    "        active_run = wandb.run\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\" Run ìƒíƒœ í™•ì¸ ì¤‘ ì—ëŸ¬: {e}\")\n",
    "    # ìƒˆë¡œìš´ run ìƒì„±\n",
    "    active_run = wandb.init(\n",
    "        project=PROJECT_NAME,\n",
    "        name=f\"SUMMARY-{EXPERIMENT_NAME}-{datetime.now().strftime('%m%d-%H%M')}\",\n",
    "        config=config,\n",
    "        tags=[\"summary\", \"cv-results\", model_name],\n",
    "        group=\"k-fold-experiment\",\n",
    "        job_type=\"summary\",\n",
    "        reinit=True\n",
    "    )\n",
    "\n",
    "# CV ìš”ì•½ í…Œì´ë¸” ìƒì„±\n",
    "fold_table = wandb.Table(columns=[\n",
    "    \"Fold\", \"Best_Val_F1\", \"Final_Train_F1\", \"Train_Samples\", \n",
    "    \"Val_Samples\", \"Epochs_Trained\", \"Early_Stopped\"\n",
    "])\n",
    "\n",
    "for result in fold_results:\n",
    "    fold_table.add_data(\n",
    "        result['fold'], \n",
    "        result['best_val_f1'], \n",
    "        result['final_train_f1'],\n",
    "        result['train_samples'], \n",
    "        result['val_samples'],\n",
    "        result['epochs_trained'],\n",
    "        result['early_stopped']\n",
    "    )\n",
    "\n",
    "# ì•ˆì „í•œ ë¡œê¹…\n",
    "try:\n",
    "    active_run.log({\n",
    "        \"cv_results/mean_f1\": mean_f1,\n",
    "        \"cv_results/std_f1\": std_f1,\n",
    "        \"cv_results/best_fold_f1\": max(val_f1_scores),\n",
    "        \"cv_results/worst_fold_f1\": min(val_f1_scores),\n",
    "        \"cv_results/f1_range\": max(val_f1_scores) - min(val_f1_scores),\n",
    "        \"cv_results/fold_results_table\": fold_table,\n",
    "        \"cv_results/n_folds\": N_FOLDS,\n",
    "        \"cv_results/total_epochs\": sum([r['epochs_trained'] for r in fold_results]),\n",
    "        \"cv_results/avg_epochs_per_fold\": np.mean([r['epochs_trained'] for r in fold_results]),\n",
    "        \"cv_results/early_stopped_folds\": sum([r['early_stopped'] for r in fold_results])\n",
    "    })\n",
    "    \n",
    "    # Foldë³„ ì„±ëŠ¥ ë°”ì°¨íŠ¸ ìƒì„±\n",
    "    fold_performance_data = [[f\"Fold {i+1}\", score] for i, score in enumerate(val_f1_scores)]\n",
    "    active_run.log({\n",
    "        \"cv_results/fold_performance_chart\": wandb.plot.bar(\n",
    "            wandb.Table(data=fold_performance_data, columns=[\"Fold\", \"F1_Score\"]),\n",
    "            \"Fold\", \"F1_Score\", \n",
    "            title=\"K-Fold Cross Validation Performance\"\n",
    "        )\n",
    "    })\n",
    "    \n",
    "    print(\" CV ê²°ê³¼ ë¡œê¹… ì™„ë£Œ!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\" WandB ë¡œê¹… ì¤‘ ì—ëŸ¬: {e}\")\n",
    "    print(\" ê²°ê³¼ë¥¼ ì½˜ì†”ì— ì¶œë ¥í•©ë‹ˆë‹¤:\")\n",
    "\n",
    "# ì–´ë–¤ ê²½ìš°ë“  ì½˜ì†”ì—ëŠ” ê²°ê³¼ ì¶œë ¥\n",
    "for result in fold_results:\n",
    "    status = \" Early Stopped\" if result['early_stopped'] else \" Completed\"\n",
    "    print(f\"Fold {result['fold']}: {result['best_val_f1']:.4f} \"\n",
    "          f\"({result['epochs_trained']} epochs) {status}\")\n",
    "\n",
    "print(f\"\\n í‰ê·  CV F1: {mean_f1:.4f} Â± {std_f1:.4f}\")\n",
    "print(f\" ìµœê³  Fold: {max(val_f1_scores):.4f}\")\n",
    "print(f\" ìµœì•… Fold: {min(val_f1_scores):.4f}\")\n",
    "print(f\" ì„±ëŠ¥ ë²”ìœ„: {max(val_f1_scores) - min(val_f1_scores):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c1ddb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”§ ì•™ìƒë¸” ëª¨ë¸ ì¤€ë¹„ ì¤‘...\n",
      "Fold 1 ëª¨ë¸ ë¡œë“œ ì™„ë£Œ\n",
      "Fold 2 ëª¨ë¸ ë¡œë“œ ì™„ë£Œ\n",
      "Fold 3 ëª¨ë¸ ë¡œë“œ ì™„ë£Œ\n",
      "Fold 4 ëª¨ë¸ ë¡œë“œ ì™„ë£Œ\n",
      "Fold 5 ëª¨ë¸ ë¡œë“œ ì™„ë£Œ\n",
      " ì´ 5ê°œ ëª¨ë¸ë¡œ ì•™ìƒë¸” êµ¬ì„±\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# 14. Ensemble Models Preparation\n",
    "# =============================================================================\n",
    "\n",
    "# 5-Fold ì•™ìƒë¸” ëª¨ë¸ ì¤€ë¹„\n",
    "ensemble_models = []\n",
    "print(f\"\\nğŸ”§ ì•™ìƒë¸” ëª¨ë¸ ì¤€ë¹„ ì¤‘...\")\n",
    "\n",
    "for i, state_dict in enumerate(fold_models):\n",
    "    fold_model = timm.create_model(model_name, pretrained=True, num_classes=17).to(device)\n",
    "    fold_model.load_state_dict(state_dict)\n",
    "    fold_model.eval()\n",
    "    ensemble_models.append(fold_model)\n",
    "    print(f\"Fold {i+1} ëª¨ë¸ ë¡œë“œ ì™„ë£Œ\")\n",
    "\n",
    "print(f\" ì´ {len(ensemble_models)}ê°œ ëª¨ë¸ë¡œ ì•™ìƒë¸” êµ¬ì„±\")\n",
    "\n",
    "try:\n",
    "    if wandb.run is not None:\n",
    "        wandb.run.log({\n",
    "            \"ensemble/num_models\": len(ensemble_models),\n",
    "            \"ensemble/model_architecture\": model_name,\n",
    "            \"ensemble/ensemble_type\": \"simple_average\"\n",
    "        })\n",
    "    else:\n",
    "        print(\"ğŸ“Š ì•™ìƒë¸” ì •ë³´:\")\n",
    "        print(f\"  - ëª¨ë¸ ê°œìˆ˜: {len(ensemble_models)}\")\n",
    "        print(f\"  - ì•„í‚¤í…ì²˜: {model_name}\")\n",
    "        print(f\"  - ì•™ìƒë¸” íƒ€ì…: simple_average\")\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ ì•™ìƒë¸” ì •ë³´ ë¡œê¹… ì‹¤íŒ¨: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c98e388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " TTA (Test Time Augmentation) ì„¤ì •...\n",
      "TTA ë³€í™˜ 5ê°œ ì¤€ë¹„ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# 15. TTA (Test Time Augmentation) Setup\n",
    "# =============================================================================\n",
    "\n",
    "# Temperature Scaling í´ë˜ìŠ¤ ì •ì˜\n",
    "class TemperatureScaling(nn.Module):\n",
    "    def __init__(self, temperature=1.5):\n",
    "        super().__init__()\n",
    "        self.temperature = nn.Parameter(torch.ones(1) * temperature)\n",
    "    \n",
    "    def forward(self, logits):\n",
    "        return logits / self.temperature\n",
    "\n",
    "print(f\"\\n TTA (Test Time Augmentation) ì„¤ì •...\")\n",
    "\n",
    "# Essential TTA transforms\n",
    "essential_tta_transforms = [\n",
    "    # ì›ë³¸\n",
    "    A.Compose([\n",
    "        A.LongestMaxSize(max_size=img_size),\n",
    "        A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "    # 90ë„ íšŒì „ë“¤\n",
    "    A.Compose([\n",
    "        A.LongestMaxSize(max_size=img_size),\n",
    "        A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "        A.Rotate(limit=[90, 90], p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "    A.Compose([\n",
    "        A.LongestMaxSize(max_size=img_size),\n",
    "        A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "        A.Rotate(limit=[180, 180], p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "    A.Compose([\n",
    "        A.LongestMaxSize(max_size=img_size),\n",
    "        A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "        A.Rotate(limit=[-90, -90], p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "    # ë°ê¸° ê°œì„ \n",
    "    A.Compose([\n",
    "        A.LongestMaxSize(max_size=img_size),\n",
    "        A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "        A.RandomBrightnessContrast(brightness_limit=[0.3, 0.3], contrast_limit=[0.3, 0.3], p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "]\n",
    "\n",
    "print(f\"TTA ë³€í™˜ {len(essential_tta_transforms)}ê°œ ì¤€ë¹„ ì™„ë£Œ\")\n",
    "\n",
    "try:\n",
    "    if wandb.run is not None:\n",
    "        wandb.run.log({\n",
    "            \"tta/num_transforms\": len(essential_tta_transforms),\n",
    "            \"tta/transforms_used\": [\"original\", \"rot_90\", \"rot_180\", \"rot_270\", \"brightness\"],\n",
    "            \"tta/batch_size\": 64  # TTAìš© ë°°ì¹˜ í¬ê¸°\n",
    "        })\n",
    "    else:\n",
    "        print(\"ğŸ“Š TTA ì„¤ì • ì •ë³´:\")\n",
    "        print(f\"  - ë³€í˜• ê°œìˆ˜: {len(essential_tta_transforms)}\")\n",
    "        print(f\"  - ë³€í˜• ì¢…ë¥˜: original, rot_90, rot_180, rot_270, brightness\")\n",
    "        print(f\"  - ë°°ì¹˜ í¬ê¸°: 64\")\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ TTA ì„¤ì • ë¡œê¹… ì‹¤íŒ¨: {e}\")\n",
    "    print(\"ğŸ“Š TTA ì„¤ì • ì •ë³´:\")\n",
    "    print(f\"  - ë³€í˜• ê°œìˆ˜: {len(essential_tta_transforms)}\")\n",
    "    print(f\"  - ë°°ì¹˜ í¬ê¸°: 64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f6fc07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " TTA Dataset: 3140ê°œ í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 16. TTA Dataset and DataLoader\n",
    "# =============================================================================\n",
    "\n",
    "class TTAImageDataset(Dataset):\n",
    "    def __init__(self, data, path, transforms):\n",
    "        if isinstance(data, str):\n",
    "            self.df = pd.read_csv(data).values\n",
    "        else:\n",
    "            self.df = data.values\n",
    "        self.path = path\n",
    "        self.transforms = transforms  # ì—¬ëŸ¬ transformì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë°›ìŒ\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        name, target = self.df[idx]\n",
    "        img = np.array(Image.open(os.path.join(self.path, name)))\n",
    "        \n",
    "        # ëª¨ë“  transformì„ ì ìš©í•œ ê²°ê³¼ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜\n",
    "        augmented_images = []\n",
    "        for transform in self.transforms:\n",
    "            aug_img = transform(image=img)['image']\n",
    "            augmented_images.append(aug_img)\n",
    "        \n",
    "        return augmented_images, target\n",
    "\n",
    "# TTA Dataset ìƒì„±\n",
    "tta_dataset = TTAImageDataset(\n",
    "    \"../data/sample_submission.csv\",\n",
    "    \"../data/test/\",\n",
    "    essential_tta_transforms\n",
    ")\n",
    "\n",
    "# TTA DataLoader (ë°°ì¹˜ í¬ê¸°ë¥¼ ì¤„ì—¬ì„œ ë©”ëª¨ë¦¬ ì ˆì•½)\n",
    "tta_loader = DataLoader(\n",
    "    tta_dataset,\n",
    "    batch_size=64,  # TTAëŠ” ë©”ëª¨ë¦¬ë¥¼ ë§ì´ ì‚¬ìš©í•˜ë¯€ë¡œ ë°°ì¹˜ í¬ê¸° ì¤„ì„\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\" TTA Dataset: {len(tta_dataset)}ê°œ í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45382398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      " ìµœì¢… ì¶”ë¡  - ì•™ìƒë¸” + TTA\n",
      "============================================================\n",
      "ì•™ìƒë¸” TTA ì¶”ë¡  ì‹œì‘...\n",
      "5ê°œ ëª¨ë¸ Ã— 5ê°œ TTA ë³€í˜• = 25ê°œ ì˜ˆì¸¡ í‰ê· \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ensemble TTA:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ensemble TTA: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [02:50<00:00,  3.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ì•™ìƒë¸” TTA ì¶”ë¡  ì™„ë£Œ!\n",
      "ì´ ì†Œìš”ì‹œê°„: 2.8ë¶„\n",
      " í‰ê·  ì‹ ë¢°ë„: 0.3960 Â± 0.1080\n",
      " ê³ ì‹ ë¢°ë„ ìƒ˜í”Œ: 0/3140 (0.0%)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# 17. Ensemble + TTA Inference with WandB Logging\n",
    "# =============================================================================\n",
    "\n",
    "def ensemble_tta_inference_with_logging(models, loader, transforms, confidence_threshold=0.9):\n",
    "    \"\"\"5-Fold ëª¨ë¸ ì•™ìƒë¸” + TTA ì¶”ë¡  with WandB ë¡œê¹…\"\"\"\n",
    "    all_predictions = []\n",
    "    all_confidences = []\n",
    "    \n",
    "    # TTA ì§„í–‰ìƒí™© ë¡œê¹…ì„ ìœ„í•œ í…Œì´ë¸”\n",
    "    tta_progress = wandb.Table(columns=[\"Batch\", \"Avg_Confidence\", \"Low_Conf_Count\", \"High_Conf_Count\"])\n",
    "    \n",
    "    # Temperature scaling ì´ˆê¸°í™”\n",
    "    temp_scaling = TemperatureScaling().to(device)\n",
    "    \n",
    "    print(f\"ì•™ìƒë¸” TTA ì¶”ë¡  ì‹œì‘...\")\n",
    "    print(f\"{len(models)}ê°œ ëª¨ë¸ Ã— {len(transforms)}ê°œ TTA ë³€í˜• = {len(models) * len(transforms)}ê°œ ì˜ˆì¸¡ í‰ê· \")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    for batch_idx, (images_list, _) in enumerate(tqdm(loader, desc=\"Ensemble TTA\")):\n",
    "        batch_size = images_list[0].size(0)\n",
    "        ensemble_probs = torch.zeros(batch_size, 17).to(device)\n",
    "        \n",
    "        # ê° fold ëª¨ë¸ë³„ ì˜ˆì¸¡\n",
    "        for model_idx, model in enumerate(models):\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                # ê° TTA ë³€í˜•ë³„ ì˜ˆì¸¡\n",
    "                for tta_idx, images in enumerate(images_list):\n",
    "                    images = images.to(device)\n",
    "                    preds = model(images)\n",
    "                    \n",
    "                    # Temperature scaling ì ìš©\n",
    "                    preds = temp_scaling(preds)\n",
    "                    probs = torch.softmax(preds, dim=1)\n",
    "                    \n",
    "                    # ì•™ìƒë¸” í™•ë¥ ì— ëˆ„ì  (í‰ê· )\n",
    "                    ensemble_probs += probs / (len(models) * len(images_list))\n",
    "        \n",
    "        # ì‹ ë¢°ë„ ê³„ì‚°\n",
    "        max_probs = torch.max(ensemble_probs, dim=1)[0]\n",
    "        batch_confidences = max_probs.cpu().numpy()\n",
    "        all_confidences.extend(batch_confidences)\n",
    "        \n",
    "        final_preds = torch.argmax(ensemble_probs, dim=1)\n",
    "        all_predictions.extend(final_preds.cpu().numpy())\n",
    "        \n",
    "        # ë°°ì¹˜ë³„ ì‹ ë¢°ë„ ë¶„ì„\n",
    "        high_conf_count = np.sum(batch_confidences >= confidence_threshold)\n",
    "        low_conf_count = batch_size - high_conf_count\n",
    "        avg_confidence = np.mean(batch_confidences)\n",
    "        \n",
    "        # ì§„í–‰ìƒí™© í…Œì´ë¸”ì— ì¶”ê°€\n",
    "        tta_progress.add_data(batch_idx, avg_confidence, low_conf_count, high_conf_count)\n",
    "        \n",
    "        # ë°°ì¹˜ë³„ ìƒì„¸ ë¡œê¹… (20ë°°ì¹˜ë§ˆë‹¤)\n",
    "        if batch_idx % 20 == 0:\n",
    "            elapsed_time = time.time() - start_time\n",
    "            estimated_total = elapsed_time * len(loader) / (batch_idx + 1)\n",
    "            remaining_time = estimated_total - elapsed_time\n",
    "            \n",
    "            wandb.log({\n",
    "                \"tta_progress/batch\": batch_idx,\n",
    "                \"tta_progress/avg_confidence\": avg_confidence,\n",
    "                \"tta_progress/high_confidence_ratio\": high_conf_count / batch_size,\n",
    "                \"tta_progress/low_confidence_count\": low_conf_count,\n",
    "                \"tta_progress/elapsed_time_min\": elapsed_time / 60,\n",
    "                \"tta_progress/estimated_remaining_min\": remaining_time / 60,\n",
    "                \"tta_progress/samples_processed\": (batch_idx + 1) * batch_size,\n",
    "            })\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    \n",
    "    # TTA ìµœì¢… ê²°ê³¼ ë¡œê¹…\n",
    "    final_avg_confidence = np.mean(all_confidences)\n",
    "    confidence_std = np.std(all_confidences)\n",
    "    high_conf_samples = np.sum(np.array(all_confidences) >= confidence_threshold)\n",
    "    \n",
    "    wandb.log({\n",
    "        \"tta_results/total_time_min\": total_time / 60,\n",
    "        \"tta_results/samples_per_second\": len(all_predictions) / total_time,\n",
    "        \"tta_results/final_avg_confidence\": final_avg_confidence,\n",
    "        \"tta_results/confidence_std\": confidence_std,\n",
    "        \"tta_results/high_confidence_samples\": high_conf_samples,\n",
    "        \"tta_results/high_confidence_ratio\": high_conf_samples / len(all_predictions),\n",
    "        \"tta_results/total_predictions\": len(all_predictions),\n",
    "        \"tta_results/confidence_histogram\": wandb.Histogram(all_confidences),\n",
    "        \"tta_results/progress_table\": tta_progress\n",
    "    })\n",
    "    \n",
    "    print(f\"\\n ì•™ìƒë¸” TTA ì¶”ë¡  ì™„ë£Œ!\")\n",
    "    print(f\"ì´ ì†Œìš”ì‹œê°„: {total_time/60:.1f}ë¶„\")\n",
    "    print(f\" í‰ê·  ì‹ ë¢°ë„: {final_avg_confidence:.4f} Â± {confidence_std:.4f}\")\n",
    "    print(f\" ê³ ì‹ ë¢°ë„ ìƒ˜í”Œ: {high_conf_samples}/{len(all_predictions)} ({high_conf_samples/len(all_predictions)*100:.1f}%)\")\n",
    "    \n",
    "    return all_predictions, all_confidences\n",
    "\n",
    "# ì•™ìƒë¸” TTA ì‹¤í–‰\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\" ìµœì¢… ì¶”ë¡  - ì•™ìƒë¸” + TTA\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "tta_predictions, confidences = ensemble_tta_inference_with_logging(\n",
    "    models=ensemble_models, \n",
    "    loader=tta_loader, \n",
    "    transforms=essential_tta_transforms,\n",
    "    confidence_threshold=0.9\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9072c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ìµœì¢… ê²°ê³¼ ì •ë¦¬ ì¤‘...\n",
      "\n",
      "ğŸ“Š ì˜ˆì¸¡ ê²°ê³¼ ë¶„í¬:\n",
      "Class  0:  202 (  6.4%)\n",
      "Class  1:   93 (  3.0%)\n",
      "Class  2:  200 (  6.4%)\n",
      "Class  3:  242 (  7.7%)\n",
      "Class  4:  189 (  6.0%)\n",
      "Class  5:  200 (  6.4%)\n",
      "Class  6:  204 (  6.5%)\n",
      "Class  7:  160 (  5.1%)\n",
      "Class  8:  200 (  6.4%)\n",
      "Class  9:  200 (  6.4%)\n",
      "Class 10:  222 (  7.1%)\n",
      "Class 11:  188 (  6.0%)\n",
      "Class 12:  198 (  6.3%)\n",
      "Class 13:  160 (  5.1%)\n",
      "Class 14:   81 (  2.6%)\n",
      "Class 15:  201 (  6.4%)\n",
      "Class 16:  200 (  6.4%)\n",
      "ìµœì¢… ê²°ê³¼ WandB ë¡œê¹… ì™„ë£Œ!\n",
      "ì´ ì˜ˆì¸¡ ìˆ˜: 3140\n",
      "ì˜ˆì¸¡ëœ í´ë˜ìŠ¤ ìˆ˜: 17\n",
      "í‰ê·  ì‹ ë¢°ë„: 0.3960\n",
      "ì‹ ë¢°ë„ ë²”ìœ„: 0.0968 ~ 0.6622\n",
      "ì˜ˆì¸¡ ë¶„í¬ ì°¨íŠ¸ ë¡œê¹… ì™„ë£Œ!\n",
      "ì‹¤í—˜ ìš”ì•½ ë¡œê¹… ì™„ë£Œ!\n",
      "\n",
      " ìµœì¢… ê²°ê³¼ ì €ì¥ ì™„ë£Œ!\n",
      " íŒŒì¼ ìœ„ì¹˜: ../output/choice2.csv\n",
      " ì´ ì˜ˆì¸¡ ìˆ˜: 3140\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 18. Final Results and Submission\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\n ìµœì¢… ê²°ê³¼ ì •ë¦¬ ì¤‘...\")\n",
    "\n",
    "# TTA ê²°ê³¼ë¡œ submission íŒŒì¼ ìƒì„±\n",
    "tta_pred_df = pd.DataFrame(tta_dataset.df, columns=['ID', 'target'])\n",
    "tta_pred_df['target'] = tta_predictions\n",
    "\n",
    "# ê¸°ì¡´ submissionê³¼ ë™ì¼í•œ ìˆœì„œì¸ì§€ í™•ì¸\n",
    "sample_submission_df = pd.read_csv(\"../data/sample_submission.csv\")\n",
    "assert (sample_submission_df['ID'] == tta_pred_df['ID']).all(), \"ID ìˆœì„œ ë¶ˆì¼ì¹˜!\"\n",
    "\n",
    "# ì˜ˆì¸¡ ë¶„í¬ ë¶„ì„\n",
    "pred_distribution = tta_pred_df['target'].value_counts().sort_index()\n",
    "pred_table = wandb.Table(columns=[\"Class\", \"Count\", \"Percentage\"])\n",
    "\n",
    "print(f\"\\nğŸ“Š ì˜ˆì¸¡ ê²°ê³¼ ë¶„í¬:\")\n",
    "for class_id in range(17):\n",
    "    count = pred_distribution.get(class_id, 0)\n",
    "    percentage = count / len(tta_pred_df) * 100\n",
    "    pred_table.add_data(class_id, count, percentage)\n",
    "    print(f\"Class {class_id:2d}: {count:4d} ({percentage:5.1f}%)\")\n",
    "\n",
    "# ì‹ ë¢°ë„ ë¶„ì„\n",
    "confidence_bins = [0.5, 0.7, 0.8, 0.9, 0.95, 1.0]\n",
    "confidence_analysis = {}\n",
    "for i, threshold in enumerate(confidence_bins):\n",
    "    if i == 0:\n",
    "        count = np.sum(np.array(confidences) >= threshold)\n",
    "    else:\n",
    "        prev_threshold = confidence_bins[i-1]\n",
    "        count = np.sum((np.array(confidences) >= prev_threshold) & (np.array(confidences) < threshold))\n",
    "    confidence_analysis[f\"conf_{threshold}\"] = count\n",
    "\n",
    "# ìµœì¢… ê²°ê³¼ ë¡œê¹…\n",
    "try:\n",
    "    if wandb.run is not None:\n",
    "        wandb.run.log({\n",
    "            \"final_results/total_predictions\": len(tta_predictions),\n",
    "            \"final_results/unique_classes_predicted\": len(np.unique(tta_predictions)),\n",
    "            \"final_results/prediction_distribution_table\": pred_table,\n",
    "            \"final_results/avg_confidence\": np.mean(confidences),\n",
    "            \"final_results/median_confidence\": np.median(confidences),\n",
    "            \"final_results/min_confidence\": np.min(confidences),\n",
    "            \"final_results/max_confidence\": np.max(confidences),\n",
    "            \"final_results/confidence_distribution\": wandb.Histogram(confidences),\n",
    "            **confidence_analysis\n",
    "        })\n",
    "        print(\"ìµœì¢… ê²°ê³¼ WandB ë¡œê¹… ì™„ë£Œ!\")\n",
    "    else:\n",
    "        print(\"í™œì„±í™”ëœ runì´ ì—†ì–´ ë¡œê¹…ì„ ê±´ë„ˆëœë‹ˆë‹¤.\")\n",
    "except Exception as e:\n",
    "    print(f\"WandB ë¡œê¹… ì¤‘ ì—ëŸ¬: {e}\")\n",
    "\n",
    "# ì½˜ì†” ì¶œë ¥ì€ í•­ìƒ ì‹¤í–‰\n",
    "print(f\"ì´ ì˜ˆì¸¡ ìˆ˜: {len(tta_predictions)}\")\n",
    "print(f\"ì˜ˆì¸¡ëœ í´ë˜ìŠ¤ ìˆ˜: {len(np.unique(tta_predictions))}\")\n",
    "print(f\"í‰ê·  ì‹ ë¢°ë„: {np.mean(confidences):.4f}\")\n",
    "print(f\"ì‹ ë¢°ë„ ë²”ìœ„: {np.min(confidences):.4f} ~ {np.max(confidences):.4f}\")\n",
    "\n",
    "\n",
    "# ì˜ˆì¸¡ ë¶„í¬ ë°”ì°¨íŠ¸\n",
    "try:\n",
    "    if wandb.run is not None:\n",
    "        pred_dist_data = [[f\"Class_{i}\", pred_distribution.get(i, 0)] for i in range(17)]\n",
    "        wandb.run.log({\n",
    "            \"final_results/prediction_distribution_chart\": wandb.plot.bar(\n",
    "                wandb.Table(data=pred_dist_data, columns=[\"Class\", \"Count\"]),\n",
    "                \"Class\", \"Count\", \n",
    "                title=\"Final Prediction Distribution\"\n",
    "            )\n",
    "        })\n",
    "        print(\"ì˜ˆì¸¡ ë¶„í¬ ì°¨íŠ¸ ë¡œê¹… ì™„ë£Œ!\")\n",
    "    else:\n",
    "        print(\"ì°¨íŠ¸ ë¡œê¹…ì„ ê±´ë„ˆëœë‹ˆë‹¤.\")\n",
    "except Exception as e:\n",
    "    print(f\"ì°¨íŠ¸ ë¡œê¹… ì¤‘ ì—ëŸ¬: {e}\")\n",
    "\n",
    "# ê²°ê³¼ ì €ì¥\n",
    "output_path = \"../output/choice2.csv\"\n",
    "tta_pred_df.to_csv(output_path, index=False)\n",
    "\n",
    "# ê²°ê³¼ íŒŒì¼ì„ WandB ì•„í‹°íŒ©íŠ¸ë¡œ ì €ì¥\n",
    "artifact = wandb.Artifact(\n",
    "    name=\"final_predictions\",\n",
    "    type=\"predictions\",\n",
    "    description=f\"Final ensemble predictions with {N_FOLDS}-fold CV + TTA\"\n",
    ")\n",
    "artifact.add_file(output_path)\n",
    "\n",
    "try:\n",
    "    if wandb.run is not None:\n",
    "        wandb.run.log_artifact(artifact)\n",
    "        print(\"ì‹¤í—˜ ìš”ì•½ ë¡œê¹… ì™„ë£Œ!\")\n",
    "    else:\n",
    "        print(\"í™œì„±í™”ëœ runì´ ì—†ì–´ ì‹¤í—˜ ìš”ì•½ ë¡œê¹…ì„ ê±´ë„ˆëœë‹ˆë‹¤.\")\n",
    "except Exception as e:\n",
    "    print(f\"ì‹¤í—˜ ìš”ì•½ ë¡œê¹… ì¤‘ ì—ëŸ¬: {e}\")\n",
    "\n",
    "\n",
    "print(f\"\\n ìµœì¢… ê²°ê³¼ ì €ì¥ ì™„ë£Œ!\")\n",
    "print(f\" íŒŒì¼ ìœ„ì¹˜: {output_path}\")\n",
    "print(f\" ì´ ì˜ˆì¸¡ ìˆ˜: {len(tta_predictions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30990203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì‹¤í—˜ ìš”ì•½ ë¡œê¹… ì™„ë£Œ!\n",
      "ìµœì¢… ìƒíƒœ ì—…ë°ì´íŠ¸ ì™„ë£Œ!\n",
      "\n",
      "ì‹¤í—˜ ì™„ë£Œ ì‹œê°„: 2025-09-04 08:20:45\n",
      "\n",
      "============================================================\n",
      "ì‹¤í—˜ ì™„ë£Œ!\n",
      "============================================================\n",
      " K-Fold CV ê²°ê³¼: 0.9172 Â± 0.0124\n",
      " ìµœê³  ì„±ëŠ¥ Fold: 0.9341\n",
      " ì•™ìƒë¸” ëª¨ë¸: 5ê°œ\n",
      " TTA ë³€í˜•: 5ê°œ\n",
      " í‰ê·  ì˜ˆì¸¡ ì‹ ë¢°ë„: 0.3960\n",
      " WandB ëŒ€ì‹œë³´ë“œ: https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/33mcvmnd\n",
      "\n",
      " ì˜ˆì¸¡ ê²°ê³¼ ìƒ˜í”Œ:\n",
      "                     ID  target\n",
      "0  0008fdb22ddce0ce.jpg       2\n",
      "1  00091bffdffd83de.jpg      12\n",
      "2  00396fbc1f6cc21d.jpg       5\n",
      "3  00471f8038d9c4b6.jpg      12\n",
      "4  00901f504008d884.jpg       2\n",
      "5  009b22decbc7220c.jpg      15\n",
      "6  00b33e0ee6d59427.jpg       0\n",
      "7  00bbdcfbbdb3e131.jpg       8\n",
      "8  00c03047e0fbef40.jpg      15\n",
      "9  00c0dabb63ca7a16.jpg      11\n",
      "\n",
      " ëª¨ë“  ì‘ì—… ì™„ë£Œ!\n",
      " ê²°ê³¼ íŒŒì¼: ../output/choice2.csv\n",
      " WandBì—ì„œ ì „ì²´ ì‹¤í—˜ ê²°ê³¼ë¥¼ í™•ì¸í•˜ì„¸ìš”!\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 19. Experiment Summary and Cleanup\n",
    "# =============================================================================\n",
    "\n",
    "# ì‹¤í—˜ ìš”ì•½ ìƒì„±\n",
    "experiment_summary = {\n",
    "    \"experiment_name\": main_run.name,\n",
    "    \"model_architecture\": model_name,\n",
    "    \"image_size\": img_size,\n",
    "    \"cv_strategy\": f\"{N_FOLDS}-Fold StratifiedKFold\",\n",
    "    \"cv_mean_f1\": mean_f1,\n",
    "    \"cv_std_f1\": std_f1,\n",
    "    \"cv_best_fold\": max(val_f1_scores),\n",
    "    \"ensemble_models\": len(ensemble_models),\n",
    "    \"tta_transforms\": len(essential_tta_transforms),\n",
    "    \"total_training_time_min\": sum([r['epochs_trained'] for r in fold_results]) * 2,  # ì¶”ì •ì¹˜\n",
    "    \"avg_prediction_confidence\": np.mean(confidences),\n",
    "    \"high_confidence_predictions\": np.sum(np.array(confidences) >= 0.9),\n",
    "    \"experiment_tags\": [\"baseline\", \"efficientnet-b3\", \"k-fold-cv\", \"tta\", \"ensemble\"]\n",
    "}\n",
    "\n",
    "# ì‹¤í—˜ ìš”ì•½\n",
    "try:\n",
    "    if wandb.run is not None:\n",
    "        wandb.run.log({\"experiment_summary\": experiment_summary})\n",
    "        print(\"ì‹¤í—˜ ìš”ì•½ ë¡œê¹… ì™„ë£Œ!\")\n",
    "    else:\n",
    "        print(\"í™œì„±í™”ëœ runì´ ì—†ì–´ ì‹¤í—˜ ìš”ì•½ ë¡œê¹…ì„ ê±´ë„ˆëœë‹ˆë‹¤.\")\n",
    "except Exception as e:\n",
    "    print(f\"ì‹¤í—˜ ìš”ì•½ ë¡œê¹… ì¤‘ ì—ëŸ¬: {e}\")\n",
    "\n",
    "\n",
    "# ë§ˆì§€ë§‰ ìƒíƒœ ì—…ë°ì´íŠ¸\n",
    "try:\n",
    "    if wandb.run is not None:\n",
    "        wandb.run.log({\n",
    "            \"status\": \"completed\",\n",
    "            \"completion_time\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "            \"total_runtime_hours\": 0  # start_time ì†ì„± ë¬¸ì œë¡œ ì¼ë‹¨ 0ìœ¼ë¡œ ì„¤ì •\n",
    "        })\n",
    "        print(\"ìµœì¢… ìƒíƒœ ì—…ë°ì´íŠ¸ ì™„ë£Œ!\")\n",
    "    else:\n",
    "        print(\"í™œì„±í™”ëœ runì´ ì—†ì–´ ìƒíƒœ ì—…ë°ì´íŠ¸ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.\")\n",
    "except Exception as e:\n",
    "    print(f\"ìƒíƒœ ì—…ë°ì´íŠ¸ ì¤‘ ì—ëŸ¬: {e}\")\n",
    "\n",
    "print(f\"\\nì‹¤í—˜ ì™„ë£Œ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"ì‹¤í—˜ ì™„ë£Œ!\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "print(f\" K-Fold CV ê²°ê³¼: {mean_f1:.4f} Â± {std_f1:.4f}\")\n",
    "print(f\" ìµœê³  ì„±ëŠ¥ Fold: {max(val_f1_scores):.4f}\")\n",
    "print(f\" ì•™ìƒë¸” ëª¨ë¸: {len(ensemble_models)}ê°œ\")\n",
    "print(f\" TTA ë³€í˜•: {len(essential_tta_transforms)}ê°œ\")\n",
    "print(f\" í‰ê·  ì˜ˆì¸¡ ì‹ ë¢°ë„: {np.mean(confidences):.4f}\")\n",
    "print(f\" WandB ëŒ€ì‹œë³´ë“œ: {main_run.url}\")\n",
    "\n",
    "# Sample predictions ì¶œë ¥\n",
    "print(f\"\\n ì˜ˆì¸¡ ê²°ê³¼ ìƒ˜í”Œ:\")\n",
    "print(tta_pred_df.head(10))\n",
    "\n",
    "# ë©”ì¸ run ì¢…ë£Œ\n",
    "main_run.finish()\n",
    "\n",
    "print(f\"\\n ëª¨ë“  ì‘ì—… ì™„ë£Œ!\")\n",
    "print(f\" ê²°ê³¼ íŒŒì¼: {output_path}\")\n",
    "print(f\" WandBì—ì„œ ì „ì²´ ì‹¤í—˜ ê²°ê³¼ë¥¼ í™•ì¸í•˜ì„¸ìš”!\")\n",
    "\n",
    "# ë©”ëª¨ë¦¬ ì •ë¦¬\n",
    "del ensemble_models\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b07f9c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0eca2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [ì¶”ê°€] KSM WandB ë² ì´ìŠ¤ë¼ì¸ ì‹¤í—˜ ê²°ê³¼ ì €ì¥\n",
    "try:\n",
    "    # ì‹¤í—˜ ì„¤ì • ì •ë³´ ì €ì¥\n",
    "    experiment_info = {\n",
    "        'notebook_type': 'baseline_wandb',\n",
    "        'team_member': 'KSM',\n",
    "        'wandb_integration': True,\n",
    "        'timestamp': pd.Timestamp.now().isoformat()\n",
    "    }\n",
    "    \n",
    "    logger.save_json(experiment_info, 'experiment_info', 'KSM WandB ë² ì´ìŠ¤ë¼ì¸ ì‹¤í—˜ ì •ë³´')\n",
    "    \n",
    "    print(\"âœ… KSM WandB ë² ì´ìŠ¤ë¼ì¸ ì‹¤í—˜ ì •ë³´ ì €ì¥ ì™„ë£Œ!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ ê²°ê³¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}\")\n",
    "\n",
    "# ë…¸íŠ¸ë¶ ì‘ì—… ì™„ë£Œ ìš”ì•½\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ KSM WandB ë² ì´ìŠ¤ë¼ì¸ ë…¸íŠ¸ë¶ ì‘ì—… ì™„ë£Œ!\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ë¡œê±° ì •ë³´ ì¶œë ¥\n",
    "logger.print_summary()\n",
    "\n",
    "print(\"\\nğŸ“„ ìƒì„±ëœ ê²°ê³¼:\")\n",
    "print(\"   âœ… WandB ì—°ë™ ë² ì´ìŠ¤ë¼ì¸ ì‹¤í—˜\")\n",
    "print(\"   âœ… ì‹¤í—˜ ì •ë³´ ë° ì„¤ì •\")\n",
    "\n",
    "print(f\"\\nğŸ’¾ ëª¨ë“  ê²°ê³¼ëŠ” ë‹¤ìŒ ë””ë ‰í† ë¦¬ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤:\")\n",
    "print(f\"   ğŸ“ {logger.log_dir}\")\n",
    "\n",
    "print(\"\\nğŸ¯ ì´ ë…¸íŠ¸ë¶ì€ íŒ€ ë…¸íŠ¸ë¶ í†µí•© ëª¨ë“ˆí™” í”„ë¡œì íŠ¸ì˜ ì¼í™˜ìœ¼ë¡œ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "print(\"ğŸ“Š WandB ì—°ë™ì„ í†µí•œ ì‹¤í—˜ ì¶”ì  ê¸°ëŠ¥ í¬í•¨\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv_py3_11_9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
