#!/usr/bin/env python
# coding: utf-8

# # 2ë‹¨ê³„ ìºìŠ¤ì¼€ì´ë“œ ë¶„ë¥˜ ì‹œìŠ¤í…œ êµ¬í˜„
# 
# ## ëª©í‘œ
# - ë¶„ë¥˜ê¸° A: 17ê°œ í´ë˜ìŠ¤ ì „ì²´ ë¶„ë¥˜ (ì´ë¯¸ ì™„ë£Œ)
# - ë¶„ë¥˜ê¸° B: ì·¨ì•½ í´ë˜ìŠ¤ 3,4,7,14ë§Œ ë¶„ë¥˜ (ìƒˆë¡œ í•™ìŠµ)
# - ìºìŠ¤ì¼€ì´ë“œ: Aê°€ ì·¨ì•½ í´ë˜ìŠ¤ë¡œ ì˜ˆì¸¡í•˜ë©´ Bë¡œ ì¬ë¶„ë¥˜
# 
# ## ì·¨ì•½ í´ë˜ìŠ¤ ë¶„ì„
# - Class 3: 61.0% ì •í™•ë„
# - Class 4: (ë¶„ì„ í•„ìš”)
# - Class 7: 60.0% ì •í™•ë„  
# - Class 14: 50.0% ì •í™•ë„
# 

# In[11]:


# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ import
import os
import time
import random
import copy
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.optim import Adam
from torch.utils.data import Dataset, DataLoader
from torch.optim.lr_scheduler import CosineAnnealingLR
from torch.cuda.amp import autocast, GradScaler
from PIL import Image
from tqdm import tqdm
from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report
from sklearn.model_selection import StratifiedKFold
import timm
import albumentations as A
from albumentations.pytorch import ToTensorV2
import warnings
warnings.filterwarnings('ignore')

# ì‹œë“œ ê³ ì •
SEED = 42
random.seed(SEED)
np.random.seed(SEED)
torch.manual_seed(SEED)
torch.cuda.manual_seed(SEED)
torch.cuda.manual_seed_all(SEED)

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"Using device: {device}")


# In[12]:


import torch, gc

def free_cuda():
    gc.collect()
    torch.cuda.empty_cache()
    torch.cuda.ipc_collect()


# In[13]:
# 1) ë³€ìˆ˜ë¡œ ê²½ë¡œ ì €ì¥
base_dir = "/root/computervisioncompetition-cv-1/mywork/experiments"

# 2) ì‘ì—… ë””ë ‰í† ë¦¬ ë³€ê²½ (ì—¬ê¸°ì„œë¶€í„° ëª¨ë“  ìƒëŒ€ ê²½ë¡œ ê¸°ì¤€)
os.chdir(base_dir)
# In[14]:


# í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •
model_name = 'convnext_base_384_in22ft1k'  # ê¸°ì¡´ê³¼ ë™ì¼í•œ ëª¨ë¸
img_size = 512
LR = 2e-4
EPOCHS = 100
BATCH_SIZE = 10
num_workers = 8

# ì·¨ì•½ í´ë˜ìŠ¤ ì„¤ì •
vulnerable_classes = [3, 4, 7, 14]
print(f"Target vulnerable classes: {vulnerable_classes}")


# In[15]:


# ë°ì´í„°ì…‹ í´ë˜ìŠ¤ ì •ì˜ (ê¸°ì¡´ê³¼ ë™ì¼, __init__ë§Œ ìˆ˜ì •)
class ImageDataset(Dataset):
    def __init__(self, data, path, epoch=0, total_epochs=10, is_train=True):
        if isinstance(data, str):
            df_temp = pd.read_csv(data)
        else:
            df_temp = data
        
        # ìˆ˜ì •: í•­ìƒ ['ID', 'target'] ì»¬ëŸ¼ë§Œ ì„ íƒí•˜ì—¬ self.df ì´ˆê¸°í™”
        self.df = df_temp[['ID', 'target']].values
        self.path = path
        self.epoch = epoch
        self.total_epochs = total_epochs
        self.is_train = is_train
        
        # Hard augmentation í™•ë¥  ê³„ì‚°
        self.p_hard = 0.2 + 0.3 * (epoch / total_epochs) if is_train else 0
        
        # Normal augmentation
        self.normal_aug = A.Compose([
            A.LongestMaxSize(max_size=img_size),
            A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),
            A.OneOf([
                A.Rotate(limit=[90, 90], p=1.0),
                A.Rotate(limit=[180, 180], p=1.0),
                A.Rotate(limit=[270, 270], p=1.0),
            ], p=0.6),
            A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=0.8),
            A.GaussNoise(var_limit=(30.0, 100.0), p=0.7),
            A.HorizontalFlip(p=0.5),
            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
            ToTensorV2(),
        ])
        
        # Hard augmentation
        self.hard_aug = A.Compose([
            A.LongestMaxSize(max_size=img_size),
            A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),
            A.OneOf([
                A.Rotate(limit=[90, 90], p=1.0),
                A.Rotate(limit=[180, 180], p=1.0),
                A.Rotate(limit=[270, 270], p=1.0),
                A.Rotate(limit=[-15, 15], p=1.0),
            ], p=0.8),
            A.OneOf([
                A.MotionBlur(blur_limit=15, p=1.0),
                A.GaussianBlur(blur_limit=15, p=1.0),
            ], p=0.95),
            A.RandomBrightnessContrast(brightness_limit=0.5, contrast_limit=0.5, p=0.9),
            A.GaussNoise(var_limit=(50.0, 150.0), p=0.8),
            A.JpegCompression(quality_lower=70, quality_upper=100, p=0.5),
            A.HorizontalFlip(p=0.5),
            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
            ToTensorV2(),
        ])

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        name, target = self.df[idx]
        img = np.array(Image.open(os.path.join(self.path, name)).convert('RGB'))
        
        # ë°°ì¹˜ë³„ ì¦ê°• ì„ íƒ
        if self.is_train and random.random() < self.p_hard:
            img = self.hard_aug(image=img)['image']
        else:
            img = self.normal_aug(image=img)['image']
        
        return img, target


# In[16]:


# Mixup í•¨ìˆ˜ ì •ì˜
def mixup_data(x, y, alpha=1.0):
    if alpha > 0:
        lam = np.random.beta(alpha, alpha)
    else:
        lam = 1
    batch_size = x.size()[0]
    index = torch.randperm(batch_size).cuda()
    mixed_x = lam * x + (1 - lam) * x[index, :]
    y_a, y_b = y, y[index]
    return mixed_x, y_a, y_b, lam

# í•™ìŠµ í•¨ìˆ˜
def train_one_epoch(loader, model, optimizer, loss_fn, device):
    scaler = GradScaler()
    model.train()
    train_loss = 0
    preds_list = []
    targets_list = []

    pbar = tqdm(loader)
    for image, targets in pbar:
        image = image.to(device)
        targets = targets.to(device)
        
        # Cutmix/Mixup ì ìš© (30% í™•ë¥ )
        if random.random() < 0.3:
            mixed_x, y_a, y_b, lam = mixup_data(image, targets, alpha=1.0)
            with autocast(): 
                preds = model(mixed_x)
            loss = lam * loss_fn(preds, y_a) + (1 - lam) * loss_fn(preds, y_b)
        else:
            with autocast(): 
                preds = model(image)
            loss = loss_fn(preds, targets)

        model.zero_grad(set_to_none=True)
        scaler.scale(loss).backward()
        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
        scaler.step(optimizer)
        scaler.update()

        train_loss += loss.item()
        preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())
        targets_list.extend(targets.detach().cpu().numpy())

        pbar.set_description(f"Loss: {loss.item():.4f}")

    train_loss /= len(loader)
    train_acc = accuracy_score(targets_list, preds_list)
    train_f1 = f1_score(targets_list, preds_list, average='macro')

    return {
        "train_loss": train_loss,
        "train_acc": train_acc,
        "train_f1": train_f1,
    }

# ê²€ì¦ í•¨ìˆ˜
def validate_one_epoch(loader, model, loss_fn, device):
    model.eval()
    val_loss = 0
    preds_list = []
    targets_list = []
    
    with torch.no_grad():
        pbar = tqdm(loader, desc="Validating")
        for image, targets in pbar:
            image = image.to(device)
            targets = targets.to(device)
            
            preds = model(image)
            loss = loss_fn(preds, targets)
            
            val_loss += loss.item()
            preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())
            targets_list.extend(targets.detach().cpu().numpy())
            
            pbar.set_description(f"Val Loss: {loss.item():.4f}")
    
    val_loss /= len(loader)
    val_acc = accuracy_score(targets_list, preds_list)
    val_f1 = f1_score(targets_list, preds_list, average='macro')
    
    return {
        "val_loss": val_loss,
        "val_acc": val_acc,
        "val_f1": val_f1,
    }


# In[17]:


# ========================================
# 1. ì·¨ì•½ í´ë˜ìŠ¤ ë°ì´í„° ì¤€ë¹„
# ========================================

# ì›ë³¸ ë°ì´í„° ë¡œë“œ
train_df = pd.read_csv("../data/train.csv")
print(f"Original dataset size: {len(train_df)}")

# ì·¨ì•½ í´ë˜ìŠ¤ë§Œ í•„í„°ë§
filtered_df = train_df[train_df['target'].isin(vulnerable_classes)].copy()
print(f"Filtered dataset size: {len(filtered_df)}")

# í´ë˜ìŠ¤ë³„ ìƒ˜í”Œ ìˆ˜ í™•ì¸
print("\nClass distribution:")
for cls in vulnerable_classes:
    count = len(filtered_df[filtered_df['target'] == cls])
    print(f"Class {cls}: {count} samples")

# ë¼ë²¨ ì¬ë§¤í•‘ (3->0, 4->1, 7->2, 14->3)
label_mapping = {3: 0, 4: 1, 7: 2, 14: 3}
filtered_df['original_target'] = filtered_df['target']  # ì›ë³¸ ë¼ë²¨ ë³´ì¡´
filtered_df['target'] = filtered_df['target'].map(label_mapping)

print("\nLabel mapping:")
for orig, new in label_mapping.items():
    print(f"Original class {orig} -> New class {new}")

# í´ë˜ìŠ¤ ë¶ˆê· í˜• í™•ì¸
print("\nNew class distribution:")
for new_cls in range(4):
    count = len(filtered_df[filtered_df['target'] == new_cls])
    print(f"New class {new_cls}: {count} samples")


# In[ ]:


# ========================================
# 2. 3-Fold Cross Validationìœ¼ë¡œ ì„œë¸Œì…‹ ëª¨ë¸ B ëª¨ë¸ í•™ìŠµ
# ========================================

# 3-Fold ì„¤ì •
N_FOLDS = 5
skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=42)

# ê²°ê³¼ ì €ì¥ìš© ë¦¬ìŠ¤íŠ¸
fold_results = []
fold_models = []

print(f"Starting {N_FOLDS}-Fold Cross Validation for Subset Model...")

for fold, (train_idx, val_idx) in enumerate(skf.split(filtered_df, filtered_df['target'])):
    print(f"\n{'='*50}")
    print(f"SUBSET FOLD {fold + 1}/{N_FOLDS}")
    print(f"{'='*50}")
    
    # í˜„ì¬ foldì˜ train/validation ë°ì´í„° ë¶„í• 
    train_fold_df = filtered_df.iloc[train_idx].reset_index(drop=True)
    val_fold_df = filtered_df.iloc[val_idx].reset_index(drop=True)
    
    # í˜„ì¬ foldì˜ Dataset ìƒì„±
    trn_dataset = ImageDataset(
        train_fold_df,
        "../data/train/",
        epoch=0,
        total_epochs=EPOCHS,
        is_train=True
    )
    
    val_dataset = ImageDataset(
        val_fold_df,
        "../data/train/",
        epoch=0,
        total_epochs=EPOCHS,
        is_train=False
    )
    
    # í˜„ì¬ foldì˜ DataLoader ìƒì„±
    trn_loader = DataLoader(
        trn_dataset,
        batch_size=BATCH_SIZE,
        shuffle=True,
        num_workers=num_workers,
        pin_memory=True,
        drop_last=False
    )
    
    val_loader = DataLoader(
        val_dataset,
        batch_size=BATCH_SIZE,
        shuffle=False,
        num_workers=num_workers,
        pin_memory=True
    )
    
    print(f"Train samples: {len(trn_dataset)}, Validation samples: {len(val_dataset)}")
    
    # ëª¨ë¸ ì´ˆê¸°í™” (4ê°œ í´ë˜ìŠ¤)
    model = timm.create_model(
        model_name,
        pretrained=True,
        num_classes=4  # ì·¨ì•½ í´ë˜ìŠ¤ 4ê°œ
    ).to(device)
    
    loss_fn = nn.CrossEntropyLoss(label_smoothing=0.05)
    optimizer = Adam(model.parameters(), lr=LR)
    scheduler = CosineAnnealingLR(optimizer, T_max=EPOCHS)
    
    # í˜„ì¬ foldì˜ ìµœê³  ì„±ëŠ¥ ì¶”ì 
    best_val_f1 = 0.0
    best_model = None
    
    # í˜„ì¬ fold í•™ìŠµ
    for epoch in range(EPOCHS):
        # Training
        train_ret = train_one_epoch(trn_loader, model, optimizer, loss_fn, device)
        
        # Validation
        val_ret = validate_one_epoch(val_loader, model, loss_fn, device)
        
        # Scheduler step
        scheduler.step()
        
        print(f"Epoch {epoch+1:2d} | "
              f"Train Loss: {train_ret['train_loss']:.4f} | "
              f"Train F1: {train_ret['train_f1']:.4f} | "
              f"Val Loss: {val_ret['val_loss']:.4f} | "
              f"Val F1: {val_ret['val_f1']:.4f}")
        
        # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥
        if val_ret['val_f1'] > best_val_f1:
            best_val_f1 = val_ret['val_f1']
            best_model = copy.deepcopy(model.state_dict())
    
    # í˜„ì¬ fold ê²°ê³¼ ì €ì¥
    fold_results.append({
        'fold': fold + 1,
        'best_val_f1': best_val_f1,
        'train_samples': len(trn_dataset),
        'val_samples': len(val_dataset)
    })
    
    fold_models.append(best_model)
    
    print(f"Subset Fold {fold + 1} Best Validation F1: {best_val_f1:.4f}")

# ê²°ê³¼ ìš”ì•½
print(f"\n{'='*60}")
print("SUBSET MODEL CROSS VALIDATION RESULTS")
print(f"{'='*60}")

val_f1_scores = [result['best_val_f1'] for result in fold_results]
mean_f1 = np.mean(val_f1_scores)
std_f1 = np.std(val_f1_scores)

for result in fold_results:
    print(f"Fold {result['fold']}: {result['best_val_f1']:.4f}")

print(f"\nMean CV F1: {mean_f1:.4f} Â± {std_f1:.4f}")
print(f"Best single fold: {max(val_f1_scores):.4f}")


# In[8]:


# ========================================
# 3. ì„œë¸Œì…‹ ëª¨ë¸ ì €ì¥
# ========================================

# ì„œë¸Œì…‹ ëª¨ë¸ë“¤ ì €ì¥
save_dir = "subset_models"
os.makedirs(save_dir, exist_ok=True)

print(f"\nSaving subset models to {save_dir}/")
for fold, state_dict in enumerate(fold_models):
    model_path = f"{save_dir}/subset_fold_{fold}_model.pth"
    torch.save({
        'model_state_dict': state_dict,
        'fold': fold,
        'classes': vulnerable_classes,
        'label_mapping': label_mapping,
        'model_name': model_name,
        'img_size': img_size,
        'num_classes': 4,
        'best_f1': fold_results[fold]['best_val_f1']
    }, model_path)
    print(f"âœ… Fold {fold} model saved: {model_path}")

print("\nğŸ‰ 4-Class subset training completed!")
print(f"ğŸ“Š Final Results Summary:")
print(f"   - Target classes: {vulnerable_classes}")
print(f"   - Training samples: {len(filtered_df)}")
print(f"   - Mean CV F1: {mean_f1:.4f} Â± {std_f1:.4f}")
print(f"   - Models saved in: {save_dir}/")


# In[ ]:


# ========================================
# 4. ìºìŠ¤ì¼€ì´ë“œ ë¶„ë¥˜ ì‹œìŠ¤í…œ êµ¬í˜„
# ========================================

class CascadeClassifier:
    """
    2ë‹¨ê³„ ìºìŠ¤ì¼€ì´ë“œ ë¶„ë¥˜ ì‹œìŠ¤í…œ
    
    1ë‹¨ê³„: ë¶„ë¥˜ê¸° A (17ê°œ í´ë˜ìŠ¤ ì „ì²´ ë¶„ë¥˜)
    2ë‹¨ê³„: ë¶„ë¥˜ê¸° B (ì·¨ì•½ í´ë˜ìŠ¤ 3,4,7,14ë§Œ ë¶„ë¥˜)
    """
    
    def __init__(self, main_models, subset_models, vulnerable_classes=[3,4,7,14], 
                 confidence_threshold=0.4):
        """
        Args:
            main_models: ë¶„ë¥˜ê¸° Aì˜ ì•™ìƒë¸” ëª¨ë¸ë“¤ (17ê°œ í´ë˜ìŠ¤)
            subset_models: ë¶„ë¥˜ê¸° Bì˜ ì•™ìƒë¸” ëª¨ë¸ë“¤ (4ê°œ í´ë˜ìŠ¤)
            vulnerable_classes: ì·¨ì•½ í´ë˜ìŠ¤ ë¦¬ìŠ¤íŠ¸
            confidence_threshold: 2ë‹¨ê³„ ë¶„ë¥˜ê¸°ë¡œ ë„˜ì–´ê°ˆ ì‹ ë¢°ë„ ì„ê³„ê°’
        """
        self.main_models = main_models
        self.subset_models = subset_models
        self.vulnerable_classes = vulnerable_classes
        self.confidence_threshold = confidence_threshold
        
        # ì·¨ì•½ í´ë˜ìŠ¤ ë§¤í•‘ (ì›ë³¸ í´ë˜ìŠ¤ -> ì„œë¸Œì…‹ í´ë˜ìŠ¤) / ê²°ê³¼: {3: 0, 4: 1, 7: 2, 14: 3}
        self.class_mapping = {cls: idx for idx, cls in enumerate(vulnerable_classes)}
        
        print(f"ìºìŠ¤ì¼€ì´ë“œ ë¶„ë¥˜ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
        print(f"- ì·¨ì•½ í´ë˜ìŠ¤: {vulnerable_classes}")
        print(f"- ì‹ ë¢°ë„ ì„ê³„ê°’: {confidence_threshold}")
        print(f"- ë©”ì¸ ëª¨ë¸ ìˆ˜: {len(main_models)}")
        print(f"- ì„œë¸Œì…‹ ëª¨ë¸ ìˆ˜: {len(subset_models)}")
    
    def predict_single(self, image, device):
        """
        ë‹¨ì¼ ì´ë¯¸ì§€ì— ëŒ€í•œ ìºìŠ¤ì¼€ì´ë“œ ì˜ˆì¸¡
        
        Args:
            image: ì „ì²˜ë¦¬ëœ ì´ë¯¸ì§€ í…ì„œ [C, H, W]
            device: GPU/CPU ë””ë°”ì´ìŠ¤
            
        Returns:
            final_prediction: ìµœì¢… ì˜ˆì¸¡ í´ë˜ìŠ¤
            confidence: ì˜ˆì¸¡ ì‹ ë¢°ë„
            used_cascade: ì‚¬ìš©ëœ ë¶„ë¥˜ê¸° ('main' ë˜ëŠ” 'cascade')
        """
        image = image.unsqueeze(0).to(device)  # ë°°ì¹˜ ì°¨ì› ì¶”ê°€
        
        # 1ë‹¨ê³„: ë©”ì¸ ë¶„ë¥˜ê¸°ë¡œ ì˜ˆì¸¡
        main_probs = self._predict_main_ensemble(image)
        main_pred = torch.argmax(main_probs, dim=1).item()
        main_confidence = torch.max(main_probs).item()
        
        # 1ë‹¨ê³„ ì˜ˆì¸¡ì´ ì·¨ì•½ í´ë˜ìŠ¤ì´ê³  ì‹ ë¢°ë„ê°€ ë‚®ìœ¼ë©´ 2ë‹¨ê³„ë¡œ
        if (main_pred in self.vulnerable_classes and 
            main_confidence < self.confidence_threshold):
            
            # 2ë‹¨ê³„: ì„œë¸Œì…‹ ë¶„ë¥˜ê¸°ë¡œ ì¬ì˜ˆì¸¡
            subset_probs = self._predict_subset_ensemble(image)
            subset_pred_idx = torch.argmax(subset_probs, dim=1).item()
            subset_confidence = torch.max(subset_probs).item()
            
            # ì„œë¸Œì…‹ ì˜ˆì¸¡ì„ ì›ë³¸ í´ë˜ìŠ¤ë¡œ ë³€í™˜
            final_prediction = self.vulnerable_classes[subset_pred_idx]
            final_confidence = subset_confidence
            used_cascade = 'cascade'
            
            print(f"ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: {main_pred}({main_confidence:.3f}) -> {final_prediction}({subset_confidence:.3f})")
            
        else:
            # 1ë‹¨ê³„ ì˜ˆì¸¡ ê·¸ëŒ€ë¡œ ì‚¬ìš©
            final_prediction = main_pred
            final_confidence = main_confidence
            used_cascade = 'main'
        
        return final_prediction, final_confidence, used_cascade
    
    def _predict_main_ensemble(self, image):
        """ë©”ì¸ ë¶„ë¥˜ê¸° ì•™ìƒë¸” ì˜ˆì¸¡"""
        ensemble_probs = torch.zeros(1, 17).to(image.device)
        
        with torch.no_grad():
            for model in self.main_models:
                model.eval()
                preds = model(image)
                probs = torch.softmax(preds, dim=1)
                ensemble_probs += probs / len(self.main_models)
        
        return ensemble_probs
    
    def _predict_subset_ensemble(self, image):
        """ì„œë¸Œì…‹ ë¶„ë¥˜ê¸° ì•™ìƒë¸” ì˜ˆì¸¡"""
        ensemble_probs = torch.zeros(1, 4).to(image.device)
        
        with torch.no_grad():
            for model in self.subset_models:
                model.eval()
                preds = model(image)
                probs = torch.softmax(preds, dim=1)
                ensemble_probs += probs / len(self.subset_models)
        
        return ensemble_probs
    
    def predict_batch(self, dataloader, device):
        """
        ë°°ì¹˜ ë°ì´í„°ì— ëŒ€í•œ ìºìŠ¤ì¼€ì´ë“œ ì˜ˆì¸¡
        
        Args:
            dataloader: í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œë”
            device: GPU/CPU ë””ë°”ì´ìŠ¤
            
        Returns:
            predictions: ìµœì¢… ì˜ˆì¸¡ ë¦¬ìŠ¤íŠ¸
            confidences: ì˜ˆì¸¡ ì‹ ë¢°ë„ ë¦¬ìŠ¤íŠ¸
            cascade_usage: ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš© í†µê³„
        """
        all_predictions = []
        all_confidences = []
        cascade_usage = {'main': 0, 'cascade': 0}
        
        for images, _ in tqdm(dataloader, desc="Cascade Prediction"):
            batch_predictions = []
            batch_confidences = []
            
            for i in range(images.size(0)):
                single_image = images[i]
                pred, conf, used = self.predict_single(single_image, device)
                
                batch_predictions.append(pred)
                batch_confidences.append(conf)
                cascade_usage[used] += 1
            
            all_predictions.extend(batch_predictions)
            all_confidences.extend(batch_confidences)
        
        return all_predictions, all_confidences, cascade_usage


# In[19]:


# ========================================
# 5. ë©”ì¸ ëª¨ë¸ê³¼ ì„œë¸Œì…‹ ëª¨ë¸ ë¡œë“œ
# ========================================

# ë©”ì¸ ëª¨ë¸ë“¤ ë¡œë“œ (17ê°œ í´ë˜ìŠ¤)
print("ë©”ì¸ ëª¨ë¸ë“¤ ë¡œë“œ ì¤‘...")
main_models = []
for fold in range(5):

    #model_path = f"best_model_fold_{fold+1}.pth"
    #model_path = f"fold_{fold+1}_best.pth"
    model_path = f"BH_512_base_best_model_fold_{fold+1}.pth"
    
    if os.path.exists(model_path):
        # ë©”ì¸ ëª¨ë¸ ìƒì„± (17ê°œ í´ë˜ìŠ¤)
        main_model = timm.create_model(model_name, pretrained=True, num_classes=17).to(device)
        main_model.load_state_dict(torch.load(model_path, map_location=device))
        main_model.eval()
        
        main_models.append(main_model)
        print(f"âœ… ë©”ì¸ ëª¨ë¸ {fold+1} ë¡œë“œ ì™„ë£Œ")
    else:
        print(f"âŒ ë©”ì¸ ëª¨ë¸ {fold+1} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path}")

print(f"ì´ {len(main_models)}ê°œì˜ ë©”ì¸ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")

# ì„œë¸Œì…‹ ëª¨ë¸ë“¤ ë¡œë“œ (4ê°œ í´ë˜ìŠ¤)
print("\nì„œë¸Œì…‹ ëª¨ë¸ë“¤ ë¡œë“œ ì¤‘...")
subset_models = []
for fold in range(5):
    model_path = f"{save_dir}/subset_fold_{fold}_model.pth"
    
    if os.path.exists(model_path):
        # ì„œë¸Œì…‹ ëª¨ë¸ ìƒì„± (4ê°œ í´ë˜ìŠ¤)
        subset_model = timm.create_model(model_name, pretrained=True, num_classes=4).to(device)
        checkpoint = torch.load(model_path, map_location=device)
        subset_model.load_state_dict(checkpoint['model_state_dict'])
        subset_model.eval()
        
        subset_models.append(subset_model)
        print(f"âœ… ì„œë¸Œì…‹ ëª¨ë¸ {fold} ë¡œë“œ ì™„ë£Œ (F1: {checkpoint['best_f1']:.4f})")
    else:
        print(f"âŒ ì„œë¸Œì…‹ ëª¨ë¸ {fold} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path}")

print(f"ì´ {len(subset_models)}ê°œì˜ ì„œë¸Œì…‹ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")


# In[15]:


# ========================================
# 6. ìºìŠ¤ì¼€ì´ë“œ ë¶„ë¥˜ê¸° ì´ˆê¸°í™” ë° í…ŒìŠ¤íŠ¸
# ========================================

# ìºìŠ¤ì¼€ì´ë“œ ë¶„ë¥˜ê¸° ì´ˆê¸°í™”
cascade_classifier = CascadeClassifier(
    main_models=main_models,      # ë¶„ë¥˜ê¸° A (17ê°œ í´ë˜ìŠ¤)
    subset_models=subset_models,  # ë¶„ë¥˜ê¸° B (4ê°œ í´ë˜ìŠ¤)
    vulnerable_classes=vulnerable_classes, # ì·¨ì•½ í´ë˜ìŠ¤
    confidence_threshold=0.7      # ì‹ ë¢°ë„ ì„ê³„ê°’ (ì¡°ì • ê°€ëŠ¥)
)

# ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ (ì·¨ì•½ í´ë˜ìŠ¤ ìƒ˜í”Œë¡œ)
print("\n" + "="*50)
print("ìºìŠ¤ì¼€ì´ë“œ ë¶„ë¥˜ê¸° í…ŒìŠ¤íŠ¸")
print("="*50)

# ì·¨ì•½ í´ë˜ìŠ¤ ìƒ˜í”Œ í•˜ë‚˜ ê°€ì ¸ì˜¤ê¸°
test_sample = filtered_df.iloc[0]
test_image_path = f"../data/train/{test_sample['ID']}"
test_image = Image.open(test_image_path).convert('RGB')

# ì´ë¯¸ì§€ ì „ì²˜ë¦¬
transform = A.Compose([
    A.LongestMaxSize(max_size=img_size),
    A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),
    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    ToTensorV2(),
])

test_tensor = transform(image=np.array(test_image))['image']
true_class = test_sample['original_target']  # ì›ë³¸ í´ë˜ìŠ¤

print(f"í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€: {test_sample['ID']}")
print(f"ì‹¤ì œ í´ë˜ìŠ¤: {true_class}")

# ìºìŠ¤ì¼€ì´ë“œ ì˜ˆì¸¡
pred, conf, used = cascade_classifier.predict_single(test_tensor, device)

print(f"ì˜ˆì¸¡ ê²°ê³¼: {pred}")
print(f"ì˜ˆì¸¡ ì‹ ë¢°ë„: {conf:.4f}")
print(f"ì‚¬ìš©ëœ ë¶„ë¥˜ê¸°: {used}")
print(f"ì •ë‹µ ì—¬ë¶€: {'âœ…' if pred == true_class else 'âŒ'}")


# In[16]:


# ========================================
# 7. ìºìŠ¤ì¼€ì´ë“œ ì‹œìŠ¤í…œìœ¼ë¡œ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡
# ========================================


# í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ
test_df = pd.read_csv("../data/sample_submission.csv")
print(f"í…ŒìŠ¤íŠ¸ ë°ì´í„° í¬ê¸°: {len(test_df)}")

# í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ìƒì„±
test_dataset = ImageDataset(
    test_df,
    "../data/test/",
    epoch=0,
    total_epochs=EPOCHS,
    is_train=False  # í…ŒìŠ¤íŠ¸ì´ë¯€ë¡œ ì¦ê°• ì—†ìŒ
)

test_loader = DataLoader(
    test_dataset,
    batch_size=32,  # ë°°ì¹˜ í¬ê¸° ì¤„ì„
    shuffle=False,
    num_workers=num_workers,
    pin_memory=True
)

print("ìºìŠ¤ì¼€ì´ë“œ ì‹œìŠ¤í…œìœ¼ë¡œ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡ ì‹œì‘...")

# ìºìŠ¤ì¼€ì´ë“œ ì˜ˆì¸¡ ì‹¤í–‰
test_predictions, test_confidences, cascade_usage = cascade_classifier.predict_batch(
    test_loader, device
)

print(f"\nìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš© í†µê³„:")
print(f"- ë©”ì¸ ë¶„ë¥˜ê¸°ë§Œ ì‚¬ìš©: {cascade_usage['main']}ê°œ ({cascade_usage['main']/len(test_predictions)*100:.1f}%)")
print(f"- ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©: {cascade_usage['cascade']}ê°œ ({cascade_usage['cascade']/len(test_predictions)*100:.1f}%)")

# ê²°ê³¼ ì €ì¥
result_df = test_df.copy()
result_df['target'] = test_predictions
result_df['confidence'] = test_confidences




print(f"\nâœ… ìºìŠ¤ì¼€ì´ë“œ ì˜ˆì¸¡ ì™„ë£Œ!")

print(f"ğŸ“Š ì˜ˆì¸¡ í†µê³„:")
print(f"   - í‰ê·  ì‹ ë¢°ë„: {np.mean(test_confidences):.4f}")
print(f"   - ìµœì†Œ ì‹ ë¢°ë„: {np.min(test_confidences):.4f}")
print(f"   - ìµœëŒ€ ì‹ ë¢°ë„: {np.max(test_confidences):.4f}")

# í´ë˜ìŠ¤ë³„ ì˜ˆì¸¡ ë¶„í¬
print(f"\nğŸ“ˆ í´ë˜ìŠ¤ë³„ ì˜ˆì¸¡ ë¶„í¬:")
for cls in range(17):
    count = sum(1 for p in test_predictions if p == cls)
    print(f"   Class {cls}: {count}ê°œ ({count/len(test_predictions)*100:.1f}%)")


# In[ ]:


# ê²°ê³¼ ì €ì¥
result_df = test_df.copy()
result_df['target'] = test_predictions
result_df['confidence'] = test_confidences

# submission íŒŒì¼ ì €ì¥
output_path = "../data/output/cascade_submission3.csv"
print(f"ğŸ“ ê²°ê³¼ ì €ì¥: {output_path}")
result_df[['ID', 'target']].to_csv(output_path, index=False)


# In[ ]:




