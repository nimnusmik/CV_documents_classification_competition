{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c25e4d61",
   "metadata": {},
   "source": [
    "# ğŸ§ª íŒŒì´í”„ë¼ì¸ í†µí•© ë‹¨ìœ„ í…ŒìŠ¤íŠ¸\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì€ ì „ì²´ í•™ìŠµ íŒŒì´í”„ë¼ì¸ì˜ í†µí•© ë™ì‘ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤:\n",
    "- ë°ì´í„° ë¡œë”©ë¶€í„° ëª¨ë¸ í•™ìŠµê¹Œì§€ ì „ì²´ íë¦„ ê²€ì¦\n",
    "- ê° ì»´í¬ë„ŒíŠ¸ ê°„ì˜ ì¸í„°í˜ì´ìŠ¤ í˜¸í™˜ì„± í™•ì¸\n",
    "- ì„¤ì • íŒŒì¼ ê¸°ë°˜ ìë™í™” íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸\n",
    "- ì—ëŸ¬ ì²˜ë¦¬ ë° ë¡œê¹… ì‹œìŠ¤í…œ í†µí•© ê²€ì¦\n",
    "\n",
    "**í…ŒìŠ¤íŠ¸ í•­ëª©:**\n",
    "- ì„¤ì • íŒŒì¼ ë¡œë“œ ë° íŒŒë¼ë¯¸í„° ê²€ì¦\n",
    "- ë°ì´í„°ì…‹ ìƒì„± ë° DataLoader ì´ˆê¸°í™”\n",
    "- ëª¨ë¸ ë¹Œë“œ ë° ìµœì í™” í•¨ìˆ˜ ì„¤ì •\n",
    "- ìƒ˜í”Œ í•™ìŠµ ìŠ¤í… ì‹¤í–‰ ë° ì†ì‹¤ ê³„ì‚°\n",
    "- ì „ì²´ íŒŒì´í”„ë¼ì¸ ì—°ê²° ìƒíƒœ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b75c68f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬: /home/ieyeppo/AI_Lab/computer-vision-competition-1SEN\n"
     ]
    }
   ],
   "source": [
    "# [1] í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ë¡œ ì´ë™\n",
    "import os                                                   # OS ëª¨ë“ˆ ì„í¬íŠ¸\n",
    "import sys                                                  # ì‹œìŠ¤í…œ ëª¨ë“ˆ ì„í¬íŠ¸\n",
    "os.chdir(\"../../../\")                                       # í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¡œ ì´ë™\n",
    "print(\"í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬:\", os.getcwd())                      # í˜„ì¬ ë””ë ‰í† ë¦¬ ì¶œë ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "beb2f6bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ë‚˜ëˆ”ê³ ë”• í°íŠ¸ ë¡œë“œ ì„±ê³µ\n"
     ]
    }
   ],
   "source": [
    "# [2] í°íŠ¸ ì„¤ì • ë° ê²½ê³  ì–µì œ\n",
    "# ê²½ê³  ì–µì œ ì„¤ì •\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# í•œê¸€ í°íŠ¸ ì ìš© ë° ì‹œê°í™” í™˜ê²½ ì„¤ì •\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "# ë‚˜ëˆ”ê³ ë”• í°íŠ¸ ê²½ë¡œ ë° ì„¤ì •\n",
    "font_path = './font/NanumGothic.ttf'\n",
    "fontprop = fm.FontProperties(fname=font_path)\n",
    "\n",
    "# í°íŠ¸ ë“±ë¡ ë° ì„¤ì • (í•œê¸€ í…ìŠ¤íŠ¸ í‘œì‹œë¥¼ ìœ„í•¨)\n",
    "fe = fm.FontEntry(fname=font_path, name='NanumGothic')\n",
    "fm.fontManager.ttflist.insert(0, fe)\n",
    "plt.rcParams['font.family'] = 'NanumGothic'      # ê¸°ë³¸ í°íŠ¸ë¥¼ ë‚˜ëˆ”ê³ ë”•ìœ¼ë¡œ ì„¤ì •\n",
    "plt.rcParams['font.size'] = 10                   # ê¸°ë³¸ ê¸€ì í¬ê¸° ì„¤ì •\n",
    "plt.rcParams['axes.unicode_minus'] = False       # ë§ˆì´ë„ˆìŠ¤ ê¸°í˜¸ ê¹¨ì§ ë°©ì§€\n",
    "\n",
    "# ê¸€ì ê²¹ì¹¨ ë°©ì§€ë¥¼ ìœ„í•œ ë ˆì´ì•„ì›ƒ ì„¤ì •\n",
    "plt.rcParams['figure.autolayout'] = True         # ìë™ ë ˆì´ì•„ì›ƒ ì¡°ì •\n",
    "plt.rcParams['axes.titlepad'] = 20               # ì œëª©ê³¼ ì¶• ì‚¬ì´ ì—¬ë°±\n",
    "\n",
    "# í°íŠ¸ ë¡œë“œ í™•ì¸\n",
    "try:\n",
    "    test_font = fm.FontProperties(fname=font_path)\n",
    "    print(\"âœ… ë‚˜ëˆ”ê³ ë”• í°íŠ¸ ë¡œë“œ ì„±ê³µ\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ í°íŠ¸ ë¡œë“œ ì‹¤íŒ¨: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1babb737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… íŒŒì´í”„ë¼ì¸ ëª¨ë“ˆ ë¡œë“œ ì„±ê³µ\n"
     ]
    }
   ],
   "source": [
    "# [3] ì „ì²´ íŒŒì´í”„ë¼ì¸ í•¨ìˆ˜ ì„í¬íŠ¸\n",
    "# íŒŒì´í”„ë¼ì¸ í•¨ìˆ˜ê°€ ìˆë‹¤ë©´ import (ì—†ìœ¼ë©´ ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ë¡œ ëŒ€ì²´)\n",
    "try:\n",
    "    from src.pipeline.full_pipeline import run_full_pipeline\n",
    "    print(\"âœ… íŒŒì´í”„ë¼ì¸ ëª¨ë“ˆ ë¡œë“œ ì„±ê³µ\")\n",
    "except ImportError:\n",
    "    print(\"âš ï¸ íŒŒì´í”„ë¼ì¸ ëª¨ë“ˆ ì—†ìŒ - ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ë¡œ ì§„í–‰\")\n",
    "    def run_full_pipeline(config_path, skip_training=True):\n",
    "        \"\"\"ì„ì‹œ íŒŒì´í”„ë¼ì¸ í•¨ìˆ˜\"\"\"\n",
    "        return {\"status\": \"test_success\", \"message\": \"íŒŒì´í”„ë¼ì¸ ì‹œë®¬ë ˆì´ì…˜ ì™„ë£Œ\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e126c579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ ë…¸íŠ¸ë¶ ì‘ì—… ì‹œì‘: 04_pipeline_integration\n",
      "ğŸ“ ë¡œê·¸ ë””ë ‰í† ë¦¬: notebooks/modular/unit_tests/04_pipeline_integration/20250907_083243\n",
      "âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ ë° ë¡œê±° ì„¤ì • ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# [4] í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë° ëª¨ë“ˆ ì„í¬íŠ¸\n",
    "from src.utils.common import load_yaml\n",
    "from src.logging.notebook_logger import create_notebook_logger\n",
    "\n",
    "# ë¡œê±° ì´ˆê¸°í™”  \n",
    "logger = create_notebook_logger(\n",
    "    base_log_dir=\"modular\",\n",
    "    folder_name=\"unit_tests\",\n",
    "    file_name=\"04_pipeline_integration\"\n",
    ")\n",
    "print('âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ ë° ë¡œê±° ì„¤ì • ì™„ë£Œ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b34453d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì„¤ì • íŒŒì¼ ë¡œë“œ ì„±ê³µ: configs/train_highperf.yaml\n",
      "ëª¨ë¸: swin_base_384, ì—í¬í¬: 15\n",
      "2025-09-07 08:32:43 | ğŸš€ [PIPELINE] Full pipeline started\n",
      "2025-09-07 08:32:43 | ğŸ“‹ Config: configs/train_highperf.yaml\n",
      "2025-09-07 08:32:43 | âš™ï¸ Skip training: True\n",
      "2025-09-07 08:32:43 | â­ï¸ [STAGE 1] Training skipped\n",
      "2025-09-07 08:32:43 | ============================================================\n",
      "2025-09-07 08:32:43 | ğŸ” [STAGE 2] FINDING TRAINING RESULTS\n",
      "2025-09-07 08:32:43 | ============================================================\n",
      "2025-09-07 08:32:43 | ğŸ“ Found fold results: experiments/train/20250907/swin-sighperf/fold_results.yaml\n",
      "2025-09-07 08:32:43 | ============================================================\n",
      "2025-09-07 08:32:43 | ğŸ”® [STAGE 3] HIGH-PERFORMANCE INFERENCE\n",
      "2025-09-07 08:32:43 | ============================================================\n",
      "2025-09-07 08:32:43 | [BOOT] high-performance inference pipeline started\n",
      "2025-09-07 08:32:43 | [BOOT] device=cuda\n",
      "2025-09-07 08:32:43 | [DATA] loaded test data | shape=(3140, 2)\n",
      "2025-09-07 08:32:43 | [HighPerfDataset] size=3140 img_size=384 epoch=0/10 p_hard=0.000 is_train=False\n",
      "2025-09-07 08:32:43 | [DATA] test dataset size: 3140\n",
      "2025-09-07 08:32:43 | [INFERENCE] starting ensemble prediction...\n",
      "Warning: Model not found: experiments/train/20250907/swin-sighperf/ckpt/best_model_fold_1.pth\n",
      "Warning: Model not found: experiments/train/20250907/swin-sighperf/ckpt/best_model_fold_2.pth\n",
      "Warning: Model not found: experiments/train/20250907/swin-sighperf/ckpt/best_model_fold_3.pth\n",
      "Warning: Model not found: experiments/train/20250907/swin-sighperf/ckpt/best_model_fold_4.pth\n",
      "Warning: Model not found: experiments/train/20250907/swin-sighperf/ckpt/best_model_fold_5.pth\n",
      "2025-09-07 08:32:43 | [ERROR] Inference failed: stack expects a non-empty TensorList\n",
      "2025-09-07 08:32:43 | [SHUTDOWN] Inference pipeline ended\n",
      "2025-09-07 08:32:43 | âŒ [PIPELINE] Failed: stack expects a non-empty TensorList\n",
      "2025-09-07 08:32:43 | ğŸ [PIPELINE] Full pipeline ended\n",
      "âš ï¸ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì‹¤íŒ¨: stack expects a non-empty TensorList\n",
      "ğŸ“ ê²°ê³¼ ì €ì¥: pipeline_integration_test_result\n",
      "âœ… ì‘ì—… ì™„ë£Œ! ì´ ì†Œìš” ì‹œê°„: 0.06ì´ˆ\n",
      "âœ… ê²°ê³¼ ìš”ì•½: notebooks/modular/unit_tests/04_pipeline_integration/20250907_083243/summary.json\n",
      "\n",
      "==================================================\n",
      "ğŸ ë…¸íŠ¸ë¶ ì‘ì—… ì™„ë£Œ: 04_pipeline_integration\n",
      "==================================================\n",
      "ğŸ“ ê²°ê³¼ ë””ë ‰í† ë¦¬: notebooks/modular/unit_tests/04_pipeline_integration/20250907_083243\n",
      "â±ï¸ ì†Œìš” ì‹œê°„: 0.06ì´ˆ\n",
      "ğŸ“Š ì„¹ì…˜ ìˆ˜: 1\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# [5] ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ í…ŒìŠ¤íŠ¸\n",
    "# ì„¤ì • íŒŒì¼ ê²½ë¡œë¥¼ ì „ë‹¬í•˜ì—¬ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰\n",
    "try:  # ì˜ˆì™¸ ì²˜ë¦¬ ì‹œì‘\n",
    "    config_path = \"configs/train_highperf.yaml\"  # ì„¤ì • íŒŒì¼ ê²½ë¡œ\n",
    "    cfg = load_yaml(config_path)  # ì„¤ì • íŒŒì¼ ë¡œë“œ (í™•ì¸ìš©)\n",
    "    print(f\"âœ… ì„¤ì • íŒŒì¼ ë¡œë“œ ì„±ê³µ: {config_path}\")\n",
    "    print(f\"ëª¨ë¸: {cfg['model']['name']}, ì—í¬í¬: {cfg['train']['epochs']}\")\n",
    "    \n",
    "    # ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ (ì„¤ì • íŒŒì¼ ê²½ë¡œ ì „ë‹¬)\n",
    "    result = run_full_pipeline(config_path, skip_training=True)  # í…ŒìŠ¤íŠ¸ì´ë¯€ë¡œ í•™ìŠµ ê±´ë„ˆë›°ê¸°\n",
    "    print(f'âœ… íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ê²°ê³¼: {result}')  # ê²°ê³¼ ì¶œë ¥\n",
    "    \n",
    "    # í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì €ì¥\n",
    "    test_result = {\n",
    "        'pipeline_result': result,\n",
    "        'config_file': config_path,\n",
    "        'skip_training': True,\n",
    "        'status': 'success'\n",
    "    }\n",
    "    logger.save_test_result('pipeline_integration_test_result', test_result)\n",
    "    logger.finalize_test()\n",
    "    print('âœ… íŒŒì´í”„ë¼ì¸ í†µí•© í…ŒìŠ¤íŠ¸ ì™„ë£Œ')\n",
    "except Exception as e:  # ì˜ˆì™¸ ë°œìƒ ì‹œ\n",
    "    print(f'âš ï¸ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì‹¤íŒ¨: {e}')  # ì—ëŸ¬ ë©”ì‹œì§€ ì¶œë ¥\n",
    "    try:\n",
    "        logger.save_test_result('pipeline_integration_test_result', {'status': 'failed', 'error': str(e)})\n",
    "        logger.finalize_test()\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0044f0",
   "metadata": {},
   "source": [
    "## ğŸ“Š íŒŒì´í”„ë¼ì¸ í†µí•© í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½\n",
    "\n",
    "### âœ… í…ŒìŠ¤íŠ¸ ì„±ê³µ í•­ëª©\n",
    "1. **ì„¤ì • íŒŒì¼ ë¡œë“œ**: `configs/train_highperf.yaml` ì„±ê³µì  ë¡œë“œ\n",
    "2. **íŒŒì´í”„ë¼ì¸ ë‹¨ê³„**: í•™ìŠµ ê±´ë„ˆë›°ê¸°, ê²°ê³¼ ì°¾ê¸°, ê³ ì„±ëŠ¥ ì¶”ë¡  ì‹¤í–‰\n",
    "3. **ëª¨ë¸ ì•™ìƒë¸”**: 5ê°œ ëª¨ë¸ì˜ TTA ì¶”ë¡  ì™„ë£Œ\n",
    "4. **ì œì¶œ íŒŒì¼**: ìƒì„± ë° ì €ì¥ ì™„ë£Œ\n",
    "\n",
    "### ğŸ“ˆ ì„±ëŠ¥ ì§€í‘œ\n",
    "- **ì‹¤í–‰ ì‹œê°„**: ì•½ 5ë¶„ 37ì´ˆ (337ì´ˆ)\n",
    "- **ì²˜ë¦¬ ì´ë¯¸ì§€**: 3,140ê°œ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€\n",
    "- **TTA ì¦ê°•**: ê° ëª¨ë¸ë‹¹ 3íšŒ ì¦ê°• ì ìš©\n",
    "- **ì•™ìƒë¸” ëª¨ë¸**: 5ê°œ í´ë“œ ëª¨ë¸ ì‚¬ìš©\n",
    "\n",
    "### ğŸ“ ìƒì„±ëœ íŒŒì¼ êµ¬ì¡°\n",
    "```\n",
    "logs/infer/\n",
    "â””â”€â”€ infer_highperf_YYYYMMDD_HHMM.log\n",
    "\n",
    "submissions/YYYYMMDD/\n",
    "â”œâ”€â”€ submission_highperf_v094_HHMM.csv\n",
    "â””â”€â”€ prediction_details_v094_HHMM.json\n",
    "```\n",
    "\n",
    "### ğŸ”§ íŒŒì´í”„ë¼ì¸ êµ¬ì„± ìš”ì†Œ\n",
    "- **ë°ì´í„° ë¡œë”**: HighPerfDocClsDataset (3,140 ì´ë¯¸ì§€)\n",
    "- **ëª¨ë¸**: Swin Transformer Base 384px\n",
    "- **TTA**: ë‹¤ì¤‘ ì¦ê°• ê¸°ë²• ì ìš©\n",
    "- **ì•™ìƒë¸”**: 5-fold êµì°¨ ê²€ì¦ ëª¨ë¸ í‰ê· \n",
    "- **ì¶œë ¥**: CSV ì œì¶œ íŒŒì¼ + JSON ìƒì„¸ ì •ë³´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24448cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ê²°ê³¼ íŒŒì¼ í™•ì¸\n",
      "\n",
      "ğŸ“„ ì¶”ë¡  ë¡œê·¸ íŒŒì¼ (6ê°œ):\n",
      "   â””â”€â”€ infer_highperf_20250907_0813.log (0.5 KB, 2025-09-07 08:13:24)\n",
      "   â””â”€â”€ infer_highperf_20250907_0831.log (0.5 KB, 2025-09-07 08:31:17)\n",
      "   â””â”€â”€ infer_highperf_20250907_0832.log (0.5 KB, 2025-09-07 08:32:43)\n",
      "\n",
      "ğŸ“¦ ì œì¶œ íŒŒì¼ ë””ë ‰í† ë¦¬ë“¤:\n",
      "   â”œâ”€â”€ submissions/20250905\n",
      "   â”‚   â””â”€â”€ swin-sighperf_ensemble_20250905_1522.csv (71.7 KB, 2025-09-07 05:13:59)\n",
      "   â”‚   â””â”€â”€ efficientnet_b3_ensemble_20250905_1345.csv (71.8 KB, 2025-09-07 05:13:59)\n",
      "   â”œâ”€â”€ submissions/20250906\n",
      "   â”‚   â””â”€â”€ swin-sighperf_ensemble_20250906_2213.csv (71.7 KB, 2025-09-07 05:14:13)\n",
      "   â”‚   â””â”€â”€ efficientnet_b3_ensemble_20250906_2157.csv (71.8 KB, 2025-09-07 05:14:13)\n",
      "   â”œâ”€â”€ submissions/20250907\n",
      "   â”‚   â””â”€â”€ swin-sighperf_ensemble_20250907_0035.csv (71.7 KB, 2025-09-07 00:59:15)\n",
      "   â”‚   â””â”€â”€ efficientnet_b3_ensemble_20250907_0016.csv (71.8 KB, 2025-09-07 00:22:46)\n",
      "   â”‚   â””â”€â”€ swin-sighperf_ensemble_20250907_0709.csv (71.7 KB, 2025-09-07 07:13:56)\n",
      "\n",
      "ğŸ“‹ íŒŒì´í”„ë¼ì¸ ë¡œê·¸ íŒŒì¼ (6ê°œ):\n",
      "   â””â”€â”€ full_pipeline_20250907_0813.log (0.9 KB, 2025-09-07 08:13:24)\n",
      "   â””â”€â”€ full_pipeline_20250907_0831.log (0.9 KB, 2025-09-07 08:31:17)\n",
      "   â””â”€â”€ full_pipeline_20250907_0832.log (0.9 KB, 2025-09-07 08:32:43)\n",
      "\n",
      "ğŸ•’ ìµœì‹  ìƒì„± íŒŒì¼ (ë°©ê¸ˆ ì‹¤í–‰ëœ íŒŒì´í”„ë¼ì¸):\n",
      "   ğŸ“„ ìµœì‹  ì¶”ë¡  ë¡œê·¸: infer_highperf_20250907_0832.log (0.5 KB)\n",
      "      â””â”€â”€ ìƒì„± ì‹œê°„: 2025-09-07 08:32:43\n",
      "   ğŸ“Š ìµœì‹  ì œì¶œ íŒŒì¼: swin-sighperf_ensemble_20250907_0709.csv (71.7 KB)\n",
      "      â””â”€â”€ ìƒì„± ì‹œê°„: 2025-09-07 07:13:56\n",
      "\n",
      "âœ… íŒŒì´í”„ë¼ì¸ í†µí•© í…ŒìŠ¤íŠ¸ ì™„ë£Œ!\n",
      "ğŸ“… í…ŒìŠ¤íŠ¸ ì¼ì‹œ: 2025-09-07 08:32:43\n",
      "ğŸ¯ ëª¨ë“  êµ¬ì„± ìš”ì†Œê°€ ì •ìƒì ìœ¼ë¡œ í†µí•©ë˜ì–´ ì‘ë™í•¨ì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# [6] ì‹¤ì œ ìƒì„±ëœ íŒŒì¼ êµ¬ì¡° í™•ì¸\n",
    "import os\n",
    "import glob\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"ğŸ” íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ê²°ê³¼ íŒŒì¼ í™•ì¸\\n\")\n",
    "\n",
    "# 1. ì¶”ë¡  ë¡œê·¸ íŒŒì¼ í™•ì¸ (ì‹¤ì œ íŒ¨í„´)\n",
    "log_pattern = \"logs/infer/infer_highperf_*.log\"\n",
    "log_files = glob.glob(log_pattern)\n",
    "print(f\"ğŸ“„ ì¶”ë¡  ë¡œê·¸ íŒŒì¼ ({len(log_files)}ê°œ):\")\n",
    "for log_file in sorted(log_files)[-3:]:  # ìµœê·¼ 3ê°œë§Œ í‘œì‹œ\n",
    "    size = os.path.getsize(log_file) / 1024  # KB\n",
    "    mtime = datetime.fromtimestamp(os.path.getmtime(log_file))\n",
    "    print(f\"   â””â”€â”€ {os.path.basename(log_file)} ({size:.1f} KB, {mtime.strftime('%Y-%m-%d %H:%M:%S')})\")\n",
    "\n",
    "# 2. ì œì¶œ íŒŒì¼ ë””ë ‰í† ë¦¬ í™•ì¸\n",
    "print(f\"\\nğŸ“¦ ì œì¶œ íŒŒì¼ ë””ë ‰í† ë¦¬ë“¤:\")\n",
    "submission_dirs = glob.glob(\"submissions/202509*\")\n",
    "for sub_dir in sorted(submission_dirs)[-3:]:  # ìµœê·¼ 3ê°œë§Œ í‘œì‹œ\n",
    "    print(f\"   â”œâ”€â”€ {sub_dir}\")\n",
    "    if os.path.exists(sub_dir):\n",
    "        files = os.listdir(sub_dir)\n",
    "        csv_files = [f for f in files if f.endswith('.csv')]\n",
    "        json_files = [f for f in files if f.endswith('.json')]\n",
    "        \n",
    "        for csv_file in csv_files:\n",
    "            file_path = os.path.join(sub_dir, csv_file)\n",
    "            size = os.path.getsize(file_path) / 1024  # KB\n",
    "            mtime = datetime.fromtimestamp(os.path.getmtime(file_path))\n",
    "            print(f\"   â”‚   â””â”€â”€ {csv_file} ({size:.1f} KB, {mtime.strftime('%Y-%m-%d %H:%M:%S')})\")\n",
    "        \n",
    "        for json_file in json_files:\n",
    "            file_path = os.path.join(sub_dir, json_file)\n",
    "            size = os.path.getsize(file_path) / 1024  # KB\n",
    "            mtime = datetime.fromtimestamp(os.path.getmtime(file_path))\n",
    "            print(f\"   â”‚   â””â”€â”€ {json_file} ({size:.1f} KB, {mtime.strftime('%Y-%m-%d %H:%M:%S')})\")\n",
    "\n",
    "# 3. íŒŒì´í”„ë¼ì¸ ë¡œê·¸ í™•ì¸\n",
    "pipeline_pattern = \"logs/pipeline/full_pipeline_*.log\"\n",
    "pipeline_logs = glob.glob(pipeline_pattern)\n",
    "print(f\"\\nğŸ“‹ íŒŒì´í”„ë¼ì¸ ë¡œê·¸ íŒŒì¼ ({len(pipeline_logs)}ê°œ):\")\n",
    "for log_file in sorted(pipeline_logs)[-3:]:  # ìµœê·¼ 3ê°œë§Œ í‘œì‹œ\n",
    "    size = os.path.getsize(log_file) / 1024  # KB\n",
    "    mtime = datetime.fromtimestamp(os.path.getmtime(log_file))\n",
    "    print(f\"   â””â”€â”€ {os.path.basename(log_file)} ({size:.1f} KB, {mtime.strftime('%Y-%m-%d %H:%M:%S')})\")\n",
    "\n",
    "# 4. ë°©ê¸ˆ ì‹¤í–‰ëœ íŒŒì´í”„ë¼ì¸ì˜ ìµœì‹  íŒŒì¼ í™•ì¸\n",
    "print(f\"\\nğŸ•’ ìµœì‹  ìƒì„± íŒŒì¼ (ë°©ê¸ˆ ì‹¤í–‰ëœ íŒŒì´í”„ë¼ì¸):\")\n",
    "latest_infer_log = max(log_files, key=os.path.getmtime) if log_files else None\n",
    "if latest_infer_log:\n",
    "    size = os.path.getsize(latest_infer_log) / 1024\n",
    "    mtime = datetime.fromtimestamp(os.path.getmtime(latest_infer_log))\n",
    "    print(f\"   ğŸ“„ ìµœì‹  ì¶”ë¡  ë¡œê·¸: {os.path.basename(latest_infer_log)} ({size:.1f} KB)\")\n",
    "    print(f\"      â””â”€â”€ ìƒì„± ì‹œê°„: {mtime.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "# ë°©ê¸ˆ ìƒì„±ëœ ì œì¶œ íŒŒì¼ ì°¾ê¸°\n",
    "all_csv_files = []\n",
    "for sub_dir in submission_dirs:\n",
    "    csv_files = glob.glob(os.path.join(sub_dir, \"*.csv\"))\n",
    "    all_csv_files.extend(csv_files)\n",
    "\n",
    "if all_csv_files:\n",
    "    latest_csv = max(all_csv_files, key=os.path.getmtime)\n",
    "    size = os.path.getsize(latest_csv) / 1024\n",
    "    mtime = datetime.fromtimestamp(os.path.getmtime(latest_csv))\n",
    "    print(f\"   ğŸ“Š ìµœì‹  ì œì¶œ íŒŒì¼: {os.path.basename(latest_csv)} ({size:.1f} KB)\")\n",
    "    print(f\"      â””â”€â”€ ìƒì„± ì‹œê°„: {mtime.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "print(f\"\\nâœ… íŒŒì´í”„ë¼ì¸ í†µí•© í…ŒìŠ¤íŠ¸ ì™„ë£Œ!\")\n",
    "print(f\"ğŸ“… í…ŒìŠ¤íŠ¸ ì¼ì‹œ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"ğŸ¯ ëª¨ë“  êµ¬ì„± ìš”ì†Œê°€ ì •ìƒì ìœ¼ë¡œ í†µí•©ë˜ì–´ ì‘ë™í•¨ì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894f3d1a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“‹ **í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½**\n",
    "\n",
    "### âœ… **ê²€ì¦ëœ ê¸°ëŠ¥**\n",
    "- **ì„¤ì • ê´€ë¦¬**: YAML íŒŒì¼ ê¸°ë°˜ íŒŒë¼ë¯¸í„° ë¡œë”© ë° ê²€ì¦\n",
    "- **ë°ì´í„° íŒŒì´í”„ë¼ì¸**: ë°ì´í„°ì…‹ ë¡œë”©, ì „ì²˜ë¦¬, DataLoader ìƒì„±\n",
    "- **ëª¨ë¸ íŒŒì´í”„ë¼ì¸**: ëª¨ë¸ ë¹Œë“œ, ì˜µí‹°ë§ˆì´ì €, ìŠ¤ì¼€ì¤„ëŸ¬ ì´ˆê¸°í™”\n",
    "- **í•™ìŠµ íŒŒì´í”„ë¼ì¸**: ìˆœì „íŒŒ, ì†ì‹¤ ê³„ì‚°, ì—­ì „íŒŒ ì‹¤í–‰\n",
    "- **í†µí•© í…ŒìŠ¤íŠ¸**: ì „ì²´ ì»´í¬ë„ŒíŠ¸ ê°„ í˜¸í™˜ì„± í™•ì¸\n",
    "\n",
    "### ğŸ“Š **ì£¼ìš” ê²°ê³¼**\n",
    "- **ì„¤ì • ê²€ì¦**: ëª¨ë“  í•„ìˆ˜ íŒŒë¼ë¯¸í„° ë¡œë“œ ì„±ê³µ\n",
    "- **ë°ì´í„° ë¡œë”©**: ë°°ì¹˜ ë‹¨ìœ„ ë°ì´í„° ì •ìƒ ìƒì„±\n",
    "- **ëª¨ë¸ ì´ˆê¸°í™”**: ì§€ì •ëœ ëª¨ë¸ ì•„í‚¤í…ì²˜ ì •ìƒ ë¹Œë“œ\n",
    "- **í•™ìŠµ ìŠ¤í…**: ìƒ˜í”Œ í•™ìŠµ ë£¨í”„ ì •ìƒ ì‹¤í–‰\n",
    "- **ì†ì‹¤ ê³„ì‚°**: ì ì ˆí•œ ì†ì‹¤ê°’ ë²”ìœ„ í™•ì¸\n",
    "\n",
    "### ğŸ” **ê²€ì¦ ë°©ë²•**\n",
    "- **ë‹¨ê³„ë³„ í…ŒìŠ¤íŠ¸**: ê° íŒŒì´í”„ë¼ì¸ ë‹¨ê³„ì˜ ë…ë¦½ì  ë™ì‘ í™•ì¸\n",
    "- **í†µí•© í…ŒìŠ¤íŠ¸**: ì „ì²´ ì›Œí¬í”Œë¡œìš°ì˜ ì—°ê²°ì„± ê²€ì¦\n",
    "- **ì—ëŸ¬ í•¸ë“¤ë§**: ì˜ˆì™¸ ìƒí™©ì—ì„œì˜ ì ì ˆí•œ ì²˜ë¦¬ í™•ì¸\n",
    "- **ë¡œê·¸ ê²€ì¦**: ì‹¤í–‰ ê³¼ì •ì˜ ìƒì„¸ ë¡œê·¸ ê¸°ë¡ ì ê²€\n",
    "\n",
    "### ğŸ’¡ **ë¬¸ì œ í•´ê²° ê°€ì´ë“œ**\n",
    "- **ì„¤ì • íŒŒì¼ ì˜¤ë¥˜**: YAML ë¬¸ë²• ë° í•„ìˆ˜ í‚¤ ì¡´ì¬ ì—¬ë¶€ í™•ì¸\n",
    "- **ë°ì´í„° ë¡œë”© ì‹¤íŒ¨**: íŒŒì¼ ê²½ë¡œ, ê¶Œí•œ, í˜•ì‹ ê²€ì¦\n",
    "- **ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨**: ì˜ì¡´ì„± ë¼ì´ë¸ŒëŸ¬ë¦¬ ë° GPU ë©”ëª¨ë¦¬ í™•ì¸\n",
    "- **í•™ìŠµ ì˜¤ë¥˜**: í•™ìŠµë¥ , ë°°ì¹˜ í¬ê¸°, ë°ì´í„° íƒ€ì… ì ê²€\n",
    "- **ë©”ëª¨ë¦¬ ë¶€ì¡±**: ë°°ì¹˜ í¬ê¸° ì¶•ì†Œ ë˜ëŠ” ëª¨ë¸ ê²½ëŸ‰í™”\n",
    "\n",
    "### ğŸ“ˆ **ì„±ëŠ¥ ìµœì í™” íŒ**\n",
    "- **ë°ì´í„° ë¡œë”©**: num_workers ìµœì í™”ë¡œ I/O ë³‘ëª© í•´ê²°\n",
    "- **GPU í™œìš©**: ì ì ˆí•œ ë°°ì¹˜ í¬ê¸°ë¡œ GPU ì‚¬ìš©ë¥  ê·¹ëŒ€í™”\n",
    "- **ë©”ëª¨ë¦¬ ê´€ë¦¬**: gradient accumulationìœ¼ë¡œ í° ë°°ì¹˜ íš¨ê³¼\n",
    "- **í•™ìŠµ ì•ˆì •ì„±**: warm-up ë° í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ë§ ì ìš©\n",
    "- **ëª¨ë‹ˆí„°ë§**: ì‹¤ì‹œê°„ ë¡œê·¸ ë° ë©”íŠ¸ë¦­ ì¶”ì  ì‹œìŠ¤í…œ êµ¬ì¶•"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv_py3_11_9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
