{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b10f2bb4",
   "metadata": {},
   "source": [
    "# ğŸ§ª ì „ì²´ íŒŒì´í”„ë¼ì¸ í†µí•© í…ŒìŠ¤íŠ¸\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì€ ì „ì²´ í•™ìŠµ/ì¶”ë¡  íŒŒì´í”„ë¼ì¸ì˜ í†µí•© ë™ì‘ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤:\n",
    "- ë°ì´í„°ì…‹, ëª¨ë¸, í•™ìŠµ, ì¶”ë¡  ëª¨ë“ˆ ì—°ë™\n",
    "- ì£¼ìš” ì…ì¶œë ¥ ë° ë¡œê·¸ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2a4642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬: /home/ieyeppo/AI_Lab/computer-vision-competition-1SEN\n"
     ]
    }
   ],
   "source": [
    "# [1] í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ë¡œ ì´ë™\n",
    "import os                                                   # OS ëª¨ë“ˆ ì„í¬íŠ¸\n",
    "import sys                                                  # ì‹œìŠ¤í…œ ëª¨ë“ˆ ì„í¬íŠ¸\n",
    "os.chdir(\"../../../\")                                       # í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¡œ ì´ë™\n",
    "print(\"í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬:\", os.getcwd())                      # í˜„ì¬ ë””ë ‰í† ë¦¬ ì¶œë ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9e126ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [2] í°íŠ¸ ì„¤ì • ë° ê²½ê³  ì–µì œ\n",
    "\n",
    "# ê²½ê³  ë©”ì‹œì§€ ì–µì œìš© ëª¨ë“ˆ ì„í¬íŠ¸\n",
    "#!sudo apt -get install -y fonts-nanum  # ë‚˜ëˆ”í°íŠ¸ ì„¤ì¹˜ (í•„ìš”ì‹œ ì£¼ì„ í•´ì œ) ì„¤ì¹˜ í›„ vscode ì¬ì‹œì‘ í•„ìš”\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# í•œê¸€ í°íŠ¸ ì ìš© ë° ì‹œê°í™” í™˜ê²½ ì„¤ì •\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "# ë‚˜ëˆ”ê³ ë”• í°íŠ¸ ê²½ë¡œ ë° ì„¤ì •\n",
    "font_path = '/usr/share/fonts/truetype/nanum/NanumGothic.ttf'\n",
    "fontprop = fm.FontProperties(fname=font_path)\n",
    "\n",
    "# í°íŠ¸ ë“±ë¡ ë° ì„¤ì •\n",
    "fe = fm.FontEntry(fname=font_path, name='NanumGothic')\n",
    "fm.fontManager.ttflist.insert(0, fe)\n",
    "plt.rcParams['font.family'] = 'NanumGothic'\n",
    "plt.rcParams['font.size'] = 10\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# ê¸€ì ê²¹ì¹¨ ë°©ì§€ë¥¼ ìœ„í•œ ë ˆì´ì•„ì›ƒ ì„¤ì •\n",
    "plt.rcParams['figure.autolayout'] = True\n",
    "plt.rcParams['axes.titlepad'] = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fea3c0f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‹œì‘: pipeline_integration\n",
      "ğŸ“ ë¡œê·¸ ë””ë ‰í† ë¦¬: notebooks/modular/unit_tests/pipeline_integration/20250906_000831\n"
     ]
    }
   ],
   "source": [
    "# [3] ë¼ì´ë¸ŒëŸ¬ë¦¬ ë° ìœ í‹¸ë¦¬í‹° ì„í¬íŠ¸\n",
    "# íŒŒì´í”„ë¼ì¸, ì„¤ì •, ë¡œê±° ë“± í•„ìš”í•œ ëª¨ë“ˆ ì„í¬íŠ¸\n",
    "import torch  # íŒŒì´í† ì¹˜ ì„í¬íŠ¸\n",
    "from src.pipeline.full_pipeline import run_full_pipeline  # ì „ì²´ íŒŒì´í”„ë¼ì¸ í•¨ìˆ˜ ì„í¬íŠ¸\n",
    "from src.utils.common import load_yaml  # ì„¤ì • ë¡œë“œ í•¨ìˆ˜ ì„í¬íŠ¸\n",
    "from src.logging.unit_test_logger import create_test_logger  # ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ë¡œê±° ìƒì„± í•¨ìˆ˜ ì„í¬íŠ¸\n",
    "test_logger = create_test_logger(\"pipeline_integration\")  # ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ë¡œê±° ì´ˆê¸°í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d91592ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… GPU ì‚¬ìš© ê°€ëŠ¥: NVIDIA GeForce RTX 4090\n"
     ]
    }
   ],
   "source": [
    "# [4] GPU ìë™ ì²´í¬\n",
    "# GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸\n",
    "if torch.cuda.is_available():  # GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸\n",
    "    print(f'âœ… GPU ì‚¬ìš© ê°€ëŠ¥: {torch.cuda.get_device_name(0)}')  # GPU ì´ë¦„ ì¶œë ¥\n",
    "else:\n",
    "    print('âš ï¸ GPU ì‚¬ìš© ë¶ˆê°€, CPUë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤')  # CPU ì‚¬ìš© ì•ˆë‚´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b34453d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì„¤ì • íŒŒì¼ ë¡œë“œ ì„±ê³µ: configs/train_highperf.yaml\n",
      "ëª¨ë¸: swin_base_384, ì—í¬í¬: 15\n",
      "2025-09-06 00:14:58 | ğŸš€ [PIPELINE] Full pipeline started\n",
      "2025-09-06 00:14:58 | ğŸ“‹ Config: configs/train_highperf.yaml\n",
      "2025-09-06 00:14:58 | âš™ï¸ Skip training: True\n",
      "2025-09-06 00:14:58 | â­ï¸ [STAGE 1] Training skipped\n",
      "2025-09-06 00:14:58 | ============================================================\n",
      "2025-09-06 00:14:58 | ğŸ” [STAGE 2] FINDING TRAINING RESULTS\n",
      "2025-09-06 00:14:58 | ============================================================\n",
      "2025-09-06 00:14:58 | ğŸ“ Found fold results: experiments/train/20250906/v094-swin-highperf/fold_results.yaml\n",
      "2025-09-06 00:14:58 | ============================================================\n",
      "2025-09-06 00:14:58 | ğŸ”® [STAGE 3] HIGH-PERFORMANCE INFERENCE\n",
      "2025-09-06 00:14:58 | ============================================================\n",
      "2025-09-06 00:14:58 | [BOOT] high-performance inference pipeline started\n",
      "2025-09-06 00:14:58 | [BOOT] device=cuda\n",
      "2025-09-06 00:14:58 | [DATA] loaded test data | shape=(3140, 2)\n",
      "2025-09-06 00:14:58 | [HighPerfDataset] size=3140 img_size=384 epoch=0/10 p_hard=0.000 is_train=False\n",
      "2025-09-06 00:14:58 | [DATA] test dataset size: 3140\n",
      "2025-09-06 00:14:58 | [INFERENCE] starting ensemble prediction...\n",
      "Processing model 1/5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Inference: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 99/99 [00:22<00:00,  4.39it/s]\n",
      "TTA Inference: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 99/99 [00:21<00:00,  4.56it/s]\n",
      "TTA Inference: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 99/99 [00:21<00:00,  4.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing model 2/5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Inference: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 99/99 [00:21<00:00,  4.57it/s]\n",
      "TTA Inference: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 99/99 [00:21<00:00,  4.55it/s]\n",
      "TTA Inference: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 99/99 [00:21<00:00,  4.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing model 3/5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Inference: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 99/99 [00:21<00:00,  4.54it/s]\n",
      "TTA Inference: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 99/99 [00:21<00:00,  4.54it/s]\n",
      "TTA Inference: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 99/99 [00:22<00:00,  4.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing model 4/5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Inference: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 99/99 [00:21<00:00,  4.54it/s]\n",
      "TTA Inference: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 99/99 [00:21<00:00,  4.53it/s]\n",
      "TTA Inference: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 99/99 [00:21<00:00,  4.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing model 5/5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Inference: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 99/99 [00:21<00:00,  4.53it/s]\n",
      "TTA Inference: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 99/99 [00:21<00:00,  4.52it/s]\n",
      "TTA Inference: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 99/99 [00:21<00:00,  4.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-06 00:20:33 | [SUCCESS] Inference completed | output: submissions/20250906/v094-swin-highperf_ensemble_20250906_0014.csv\n",
      "2025-09-06 00:20:33 | [RESULT] Prediction distribution:\n",
      "2025-09-06 00:20:33 | Class 0: 200 samples (6.4%)\n",
      "2025-09-06 00:20:33 | Class 1: 92 samples (2.9%)\n",
      "2025-09-06 00:20:33 | Class 2: 200 samples (6.4%)\n",
      "2025-09-06 00:20:33 | Class 3: 187 samples (6.0%)\n",
      "2025-09-06 00:20:33 | Class 4: 214 samples (6.8%)\n",
      "2025-09-06 00:20:33 | Class 5: 200 samples (6.4%)\n",
      "2025-09-06 00:20:33 | Class 6: 207 samples (6.6%)\n",
      "2025-09-06 00:20:33 | Class 7: 219 samples (7.0%)\n",
      "2025-09-06 00:20:33 | Class 8: 200 samples (6.4%)\n",
      "2025-09-06 00:20:33 | Class 9: 200 samples (6.4%)\n",
      "2025-09-06 00:20:33 | Class 10: 205 samples (6.5%)\n",
      "2025-09-06 00:20:33 | Class 11: 190 samples (6.1%)\n",
      "2025-09-06 00:20:33 | Class 12: 202 samples (6.4%)\n",
      "2025-09-06 00:20:33 | Class 13: 153 samples (4.9%)\n",
      "2025-09-06 00:20:33 | Class 14: 71 samples (2.3%)\n",
      "2025-09-06 00:20:33 | Class 15: 200 samples (6.4%)\n",
      "2025-09-06 00:20:33 | Class 16: 200 samples (6.4%)\n",
      "2025-09-06 00:20:33 | [SHUTDOWN] Inference pipeline ended\n",
      "2025-09-06 00:20:33 | âœ… [STAGE 3] Inference completed successfully\n",
      "2025-09-06 00:20:33 | ============================================================\n",
      "2025-09-06 00:20:33 | ğŸ‰ [PIPELINE] COMPLETION SUMMARY\n",
      "2025-09-06 00:20:33 | ============================================================\n",
      "2025-09-06 00:20:33 | ğŸ“Š Final submission file: submissions/20250906/v094-swin-highperf_ensemble_20250906_0014.csv\n",
      "2025-09-06 00:20:33 | ğŸ“ˆ Model config: swin_base_384\n",
      "2025-09-06 00:20:33 | ğŸ¯ Target F1 score: ~0.934\n",
      "2025-09-06 00:20:33 | ğŸ’¾ Experiment results: experiments/train/20250906/v094-swin-highperf\n",
      "2025-09-06 00:20:33 | ğŸ [PIPELINE] Full pipeline ended\n",
      "âœ… íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ê²°ê³¼: submissions/20250906/v094-swin-highperf_ensemble_20250906_0014.csv\n",
      "ğŸ“ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì €ì¥: pipeline_integration_test\n",
      "âœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ! ì´ ì†Œìš” ì‹œê°„: 722.55ì´ˆ\n",
      "âœ… ê²°ê³¼ ìš”ì•½: notebooks/modular/unit_tests/pipeline_integration/20250906_000831/test_summary.json\n",
      "\n",
      "==================================================\n",
      "ğŸ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì™„ë£Œ: pipeline_integration\n",
      "==================================================\n",
      "ğŸ“ ê²°ê³¼ ë””ë ‰í† ë¦¬: notebooks/modular/unit_tests/pipeline_integration/20250906_000831\n",
      "â±ï¸ ì†Œìš” ì‹œê°„: 722.55ì´ˆ\n",
      "ğŸ“Š í…ŒìŠ¤íŠ¸ ì„¹ì…˜ ìˆ˜: 1\n",
      "==================================================\n",
      "âœ… íŒŒì´í”„ë¼ì¸ í†µí•© í…ŒìŠ¤íŠ¸ ì™„ë£Œ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# [5] ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ í…ŒìŠ¤íŠ¸\n",
    "# ì„¤ì • íŒŒì¼ ê²½ë¡œë¥¼ ì „ë‹¬í•˜ì—¬ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰\n",
    "try:  # ì˜ˆì™¸ ì²˜ë¦¬ ì‹œì‘\n",
    "    config_path = \"configs/train_highperf.yaml\"  # ì„¤ì • íŒŒì¼ ê²½ë¡œ\n",
    "    cfg = load_yaml(config_path)  # ì„¤ì • íŒŒì¼ ë¡œë“œ (í™•ì¸ìš©)\n",
    "    print(f\"âœ… ì„¤ì • íŒŒì¼ ë¡œë“œ ì„±ê³µ: {config_path}\")\n",
    "    print(f\"ëª¨ë¸: {cfg['model']['name']}, ì—í¬í¬: {cfg['train']['epochs']}\")\n",
    "    \n",
    "    # ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ (ì„¤ì • íŒŒì¼ ê²½ë¡œ ì „ë‹¬)\n",
    "    result = run_full_pipeline(config_path, skip_training=True)  # í…ŒìŠ¤íŠ¸ì´ë¯€ë¡œ í•™ìŠµ ê±´ë„ˆë›°ê¸°\n",
    "    print(f'âœ… íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ê²°ê³¼: {result}')  # ê²°ê³¼ ì¶œë ¥\n",
    "    \n",
    "    # í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì €ì¥\n",
    "    test_result = {\n",
    "        'pipeline_result': result,\n",
    "        'config_file': config_path,\n",
    "        'skip_training': True,\n",
    "        'status': 'success'\n",
    "    }\n",
    "    test_logger.save_test_result('pipeline_integration_test', test_result)\n",
    "    test_logger.finalize_test()\n",
    "    print('âœ… íŒŒì´í”„ë¼ì¸ í†µí•© í…ŒìŠ¤íŠ¸ ì™„ë£Œ')\n",
    "except Exception as e:  # ì˜ˆì™¸ ë°œìƒ ì‹œ\n",
    "    print(f'âš ï¸ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì‹¤íŒ¨: {e}')  # ì—ëŸ¬ ë©”ì‹œì§€ ì¶œë ¥\n",
    "    # ì—ëŸ¬ ë°œìƒ ì‹œì—ë„ ë¡œê±° ì •ë¦¬\n",
    "    try:\n",
    "        test_logger.save_test_result('pipeline_integration_test', {'status': 'failed', 'error': str(e)})\n",
    "        test_logger.finalize_test()\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0044f0",
   "metadata": {},
   "source": [
    "## ğŸ“Š íŒŒì´í”„ë¼ì¸ í†µí•© í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½\n",
    "\n",
    "### âœ… í…ŒìŠ¤íŠ¸ ì„±ê³µ í•­ëª©\n",
    "1. **ì„¤ì • íŒŒì¼ ë¡œë“œ**: `configs/train_highperf.yaml` ì„±ê³µì  ë¡œë“œ\n",
    "2. **íŒŒì´í”„ë¼ì¸ ë‹¨ê³„**: í•™ìŠµ ê±´ë„ˆë›°ê¸°, ê²°ê³¼ ì°¾ê¸°, ê³ ì„±ëŠ¥ ì¶”ë¡  ì‹¤í–‰\n",
    "3. **ëª¨ë¸ ì•™ìƒë¸”**: 5ê°œ ëª¨ë¸ì˜ TTA ì¶”ë¡  ì™„ë£Œ\n",
    "4. **ì œì¶œ íŒŒì¼**: ìƒì„± ë° ì €ì¥ ì™„ë£Œ\n",
    "\n",
    "### ğŸ“ˆ ì„±ëŠ¥ ì§€í‘œ\n",
    "- **ì‹¤í–‰ ì‹œê°„**: ì•½ 5ë¶„ 37ì´ˆ (337ì´ˆ)\n",
    "- **ì²˜ë¦¬ ì´ë¯¸ì§€**: 3,140ê°œ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€\n",
    "- **TTA ì¦ê°•**: ê° ëª¨ë¸ë‹¹ 3íšŒ ì¦ê°• ì ìš©\n",
    "- **ì•™ìƒë¸” ëª¨ë¸**: 5ê°œ í´ë“œ ëª¨ë¸ ì‚¬ìš©\n",
    "\n",
    "### ğŸ“ ìƒì„±ëœ íŒŒì¼ êµ¬ì¡°\n",
    "```\n",
    "logs/infer/\n",
    "â””â”€â”€ infer_highperf_YYYYMMDD_HHMM.log\n",
    "\n",
    "submissions/YYYYMMDD/\n",
    "â”œâ”€â”€ submission_highperf_v094_HHMM.csv\n",
    "â””â”€â”€ prediction_details_v094_HHMM.json\n",
    "```\n",
    "\n",
    "### ğŸ”§ íŒŒì´í”„ë¼ì¸ êµ¬ì„± ìš”ì†Œ\n",
    "- **ë°ì´í„° ë¡œë”**: HighPerfDocClsDataset (3,140 ì´ë¯¸ì§€)\n",
    "- **ëª¨ë¸**: Swin Transformer Base 384px\n",
    "- **TTA**: ë‹¤ì¤‘ ì¦ê°• ê¸°ë²• ì ìš©\n",
    "- **ì•™ìƒë¸”**: 5-fold êµì°¨ ê²€ì¦ ëª¨ë¸ í‰ê· \n",
    "- **ì¶œë ¥**: CSV ì œì¶œ íŒŒì¼ + JSON ìƒì„¸ ì •ë³´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24448cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ê²°ê³¼ íŒŒì¼ í™•ì¸\n",
      "\n",
      "ğŸ“„ ì¶”ë¡  ë¡œê·¸ íŒŒì¼ (4ê°œ):\n",
      "   â””â”€â”€ infer_highperf_20250905_1734.log (1.5 KB, 2025-09-05 17:38:46)\n",
      "   â””â”€â”€ infer_highperf_20250905_2357.log (1.5 KB, 2025-09-06 00:03:31)\n",
      "   â””â”€â”€ infer_highperf_20250906_0014.log (1.5 KB, 2025-09-06 00:20:33)\n",
      "\n",
      "ğŸ“¦ ì œì¶œ íŒŒì¼ ë””ë ‰í† ë¦¬ë“¤:\n",
      "   â”œâ”€â”€ submissions/20250904\n",
      "   â”‚   â””â”€â”€ infer.csv (71.0 KB, 2025-09-05 13:02:35)\n",
      "   â”œâ”€â”€ submissions/20250905\n",
      "   â”‚   â””â”€â”€ v09328-swin-highperf_ensemble_20250905_1714.csv (71.7 KB, 2025-09-05 17:38:46)\n",
      "   â”œâ”€â”€ submissions/20250906\n",
      "   â”‚   â””â”€â”€ v094-swin-highperf_ensemble_20250906_0014.csv (71.7 KB, 2025-09-06 00:20:33)\n",
      "\n",
      "ğŸ“‹ íŒŒì´í”„ë¼ì¸ ë¡œê·¸ íŒŒì¼ (11ê°œ):\n",
      "   â””â”€â”€ full_pipeline_20250906_0011.log (0.7 KB, 2025-09-06 00:11:19)\n",
      "   â””â”€â”€ full_pipeline_20250906_0012.log (0.7 KB, 2025-09-06 00:12:24)\n",
      "   â””â”€â”€ full_pipeline_20250906_0014.log (1.4 KB, 2025-09-06 00:20:33)\n",
      "\n",
      "ğŸ•’ ìµœì‹  ìƒì„± íŒŒì¼ (ë°©ê¸ˆ ì‹¤í–‰ëœ íŒŒì´í”„ë¼ì¸):\n",
      "   ğŸ“„ ìµœì‹  ì¶”ë¡  ë¡œê·¸: infer_highperf_20250906_0014.log (1.5 KB)\n",
      "      â””â”€â”€ ìƒì„± ì‹œê°„: 2025-09-06 00:20:33\n",
      "   ğŸ“Š ìµœì‹  ì œì¶œ íŒŒì¼: v094-swin-highperf_ensemble_20250906_0014.csv (71.7 KB)\n",
      "      â””â”€â”€ ìƒì„± ì‹œê°„: 2025-09-06 00:20:33\n",
      "\n",
      "âœ… íŒŒì´í”„ë¼ì¸ í†µí•© í…ŒìŠ¤íŠ¸ ì™„ë£Œ!\n",
      "ğŸ“… í…ŒìŠ¤íŠ¸ ì¼ì‹œ: 2025-09-06 00:21:03\n",
      "ğŸ¯ ëª¨ë“  êµ¬ì„± ìš”ì†Œê°€ ì •ìƒì ìœ¼ë¡œ í†µí•©ë˜ì–´ ì‘ë™í•¨ì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# [6] ì‹¤ì œ ìƒì„±ëœ íŒŒì¼ êµ¬ì¡° í™•ì¸\n",
    "import os\n",
    "import glob\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"ğŸ” íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ê²°ê³¼ íŒŒì¼ í™•ì¸\\n\")\n",
    "\n",
    "# 1. ì¶”ë¡  ë¡œê·¸ íŒŒì¼ í™•ì¸ (ì‹¤ì œ íŒ¨í„´)\n",
    "log_pattern = \"logs/infer/infer_highperf_*.log\"\n",
    "log_files = glob.glob(log_pattern)\n",
    "print(f\"ğŸ“„ ì¶”ë¡  ë¡œê·¸ íŒŒì¼ ({len(log_files)}ê°œ):\")\n",
    "for log_file in sorted(log_files)[-3:]:  # ìµœê·¼ 3ê°œë§Œ í‘œì‹œ\n",
    "    size = os.path.getsize(log_file) / 1024  # KB\n",
    "    mtime = datetime.fromtimestamp(os.path.getmtime(log_file))\n",
    "    print(f\"   â””â”€â”€ {os.path.basename(log_file)} ({size:.1f} KB, {mtime.strftime('%Y-%m-%d %H:%M:%S')})\")\n",
    "\n",
    "# 2. ì œì¶œ íŒŒì¼ ë””ë ‰í† ë¦¬ í™•ì¸\n",
    "print(f\"\\nğŸ“¦ ì œì¶œ íŒŒì¼ ë””ë ‰í† ë¦¬ë“¤:\")\n",
    "submission_dirs = glob.glob(\"submissions/202509*\")\n",
    "for sub_dir in sorted(submission_dirs)[-3:]:  # ìµœê·¼ 3ê°œë§Œ í‘œì‹œ\n",
    "    print(f\"   â”œâ”€â”€ {sub_dir}\")\n",
    "    if os.path.exists(sub_dir):\n",
    "        files = os.listdir(sub_dir)\n",
    "        csv_files = [f for f in files if f.endswith('.csv')]\n",
    "        json_files = [f for f in files if f.endswith('.json')]\n",
    "        \n",
    "        for csv_file in csv_files:\n",
    "            file_path = os.path.join(sub_dir, csv_file)\n",
    "            size = os.path.getsize(file_path) / 1024  # KB\n",
    "            mtime = datetime.fromtimestamp(os.path.getmtime(file_path))\n",
    "            print(f\"   â”‚   â””â”€â”€ {csv_file} ({size:.1f} KB, {mtime.strftime('%Y-%m-%d %H:%M:%S')})\")\n",
    "        \n",
    "        for json_file in json_files:\n",
    "            file_path = os.path.join(sub_dir, json_file)\n",
    "            size = os.path.getsize(file_path) / 1024  # KB\n",
    "            mtime = datetime.fromtimestamp(os.path.getmtime(file_path))\n",
    "            print(f\"   â”‚   â””â”€â”€ {json_file} ({size:.1f} KB, {mtime.strftime('%Y-%m-%d %H:%M:%S')})\")\n",
    "\n",
    "# 3. íŒŒì´í”„ë¼ì¸ ë¡œê·¸ í™•ì¸\n",
    "pipeline_pattern = \"logs/pipeline/full_pipeline_*.log\"\n",
    "pipeline_logs = glob.glob(pipeline_pattern)\n",
    "print(f\"\\nğŸ“‹ íŒŒì´í”„ë¼ì¸ ë¡œê·¸ íŒŒì¼ ({len(pipeline_logs)}ê°œ):\")\n",
    "for log_file in sorted(pipeline_logs)[-3:]:  # ìµœê·¼ 3ê°œë§Œ í‘œì‹œ\n",
    "    size = os.path.getsize(log_file) / 1024  # KB\n",
    "    mtime = datetime.fromtimestamp(os.path.getmtime(log_file))\n",
    "    print(f\"   â””â”€â”€ {os.path.basename(log_file)} ({size:.1f} KB, {mtime.strftime('%Y-%m-%d %H:%M:%S')})\")\n",
    "\n",
    "# 4. ë°©ê¸ˆ ì‹¤í–‰ëœ íŒŒì´í”„ë¼ì¸ì˜ ìµœì‹  íŒŒì¼ í™•ì¸\n",
    "print(f\"\\nğŸ•’ ìµœì‹  ìƒì„± íŒŒì¼ (ë°©ê¸ˆ ì‹¤í–‰ëœ íŒŒì´í”„ë¼ì¸):\")\n",
    "latest_infer_log = max(log_files, key=os.path.getmtime) if log_files else None\n",
    "if latest_infer_log:\n",
    "    size = os.path.getsize(latest_infer_log) / 1024\n",
    "    mtime = datetime.fromtimestamp(os.path.getmtime(latest_infer_log))\n",
    "    print(f\"   ğŸ“„ ìµœì‹  ì¶”ë¡  ë¡œê·¸: {os.path.basename(latest_infer_log)} ({size:.1f} KB)\")\n",
    "    print(f\"      â””â”€â”€ ìƒì„± ì‹œê°„: {mtime.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "# ë°©ê¸ˆ ìƒì„±ëœ ì œì¶œ íŒŒì¼ ì°¾ê¸°\n",
    "all_csv_files = []\n",
    "for sub_dir in submission_dirs:\n",
    "    csv_files = glob.glob(os.path.join(sub_dir, \"*.csv\"))\n",
    "    all_csv_files.extend(csv_files)\n",
    "\n",
    "if all_csv_files:\n",
    "    latest_csv = max(all_csv_files, key=os.path.getmtime)\n",
    "    size = os.path.getsize(latest_csv) / 1024\n",
    "    mtime = datetime.fromtimestamp(os.path.getmtime(latest_csv))\n",
    "    print(f\"   ğŸ“Š ìµœì‹  ì œì¶œ íŒŒì¼: {os.path.basename(latest_csv)} ({size:.1f} KB)\")\n",
    "    print(f\"      â””â”€â”€ ìƒì„± ì‹œê°„: {mtime.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "print(f\"\\nâœ… íŒŒì´í”„ë¼ì¸ í†µí•© í…ŒìŠ¤íŠ¸ ì™„ë£Œ!\")\n",
    "print(f\"ğŸ“… í…ŒìŠ¤íŠ¸ ì¼ì‹œ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"ğŸ¯ ëª¨ë“  êµ¬ì„± ìš”ì†Œê°€ ì •ìƒì ìœ¼ë¡œ í†µí•©ë˜ì–´ ì‘ë™í•¨ì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv_py3_11_9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
