# src/pipeline/full_pipeline.py
"""
ì „ì²´ íŒŒì´í”„ë¼ì¸ (í•™ìŠµ + ì¶”ë¡  í†µí•©)
í•œ ë²ˆì˜ ëª…ë ¹ìœ¼ë¡œ í•™ìŠµ ì™„ë£Œ í›„ ìë™ìœ¼ë¡œ ì¶”ë¡  ì‹¤í–‰í•˜ì—¬ ì œì¶œ íŒŒì¼ ìƒì„±
"""

import os
import time
from typing import Optional
from pathlib import Path

from src.training.train_highperf import run_highperf_training
from src.inference.infer_highperf import run_highperf_inference
from src.utils.common import load_yaml
from src.utils.logger import Logger


def run_full_pipeline(config_path: str, skip_training: bool = False, output_dir: Optional[str] = None):
    """
    ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    
    Args:
        config_path: ì„¤ì • íŒŒì¼ ê²½ë¡œ
        skip_training: Trueì‹œ í•™ìŠµ ê±´ë„ˆë›°ê³  ì¶”ë¡ ë§Œ ì‹¤í–‰
        output_dir: ê²°ê³¼ ì €ì¥ ë””ë ‰í„°ë¦¬ (Noneì‹œ ìë™ ìƒì„±)
    """
    
    # ì„¤ì • ë¡œë“œ
    cfg = load_yaml(config_path)
    
    # ë¡œê±° ì„¤ì •
    timestamp = time.strftime("%Y%m%d_%H%M")
    log_path = f"logs/pipeline/full_pipeline_{timestamp}.log"
    os.makedirs(os.path.dirname(log_path), exist_ok=True)
    
    logger = Logger(log_path=log_path)
    logger.write("ğŸš€ [PIPELINE] Full pipeline started")
    logger.write(f"ğŸ“‹ Config: {config_path}")
    logger.write(f"âš™ï¸ Skip training: {skip_training}")
    
    try:
        # ==================== 1ë‹¨ê³„: í•™ìŠµ ====================
        if not skip_training:
            logger.write("\n" + "="*60)
            logger.write("ğŸ¯ [STAGE 1] HIGH-PERFORMANCE TRAINING")
            logger.write("="*60)
            
            # ê³ ì„±ëŠ¥ í•™ìŠµ ì‹¤í–‰
            run_highperf_training(config_path)
            
            logger.write("âœ… [STAGE 1] Training completed successfully")
        else:
            logger.write("â­ï¸ [STAGE 1] Training skipped")
        
        # ==================== 2ë‹¨ê³„: ê²°ê³¼ íŒŒì¼ ì°¾ê¸° ====================
        logger.write("\n" + "="*60)
        logger.write("ğŸ” [STAGE 2] FINDING TRAINING RESULTS")
        logger.write("="*60)
        
        # fold_results.yaml íŒŒì¼ ì°¾ê¸°
        day = time.strftime(cfg["project"]["date_format"])
        exp_base = Path(cfg["output"]["exp_dir"]) / day / cfg["project"]["run_name"]
        
        fold_results_path = None
        if exp_base.exists():
            # ê°€ì¥ ìµœê·¼ ì‹¤í—˜ í´ë”ì—ì„œ fold_results.yaml ì°¾ê¸°
            for exp_dir in sorted(exp_base.iterdir(), reverse=True):
                candidate = exp_dir / "fold_results.yaml"
                if candidate.exists():
                    fold_results_path = str(candidate)
                    break
        
        if not fold_results_path:
            raise FileNotFoundError(
                f"fold_results.yaml not found in {exp_base}. "
                "Make sure training completed successfully."
            )
        
        logger.write(f"ğŸ“ Found fold results: {fold_results_path}")
        
        # ==================== 3ë‹¨ê³„: ì¶”ë¡  ====================
        logger.write("\n" + "="*60)
        logger.write("ğŸ”® [STAGE 3] HIGH-PERFORMANCE INFERENCE")
        logger.write("="*60)
        
        # ì¶œë ¥ ê²½ë¡œ ì„¤ì •
        if output_dir is None:
            output_dir = f"submissions/{day}"
        
        output_path = os.path.join(
            output_dir, 
            f"{cfg['project']['run_name']}_ensemble_{timestamp}.csv"
        )
        
        # ê³ ì„±ëŠ¥ ì¶”ë¡  ì‹¤í–‰
        final_output = run_highperf_inference(config_path, fold_results_path, output_path)
        
        logger.write("âœ… [STAGE 3] Inference completed successfully")
        
        # ==================== 4ë‹¨ê³„: ê²°ê³¼ ìš”ì•½ ====================
        logger.write("\n" + "="*60)
        logger.write("ğŸ‰ [PIPELINE] COMPLETION SUMMARY")
        logger.write("="*60)
        
        logger.write(f"ğŸ“Š Final submission file: {final_output}")
        logger.write(f"ğŸ“ˆ Model config: {cfg['model']['name']}")
        logger.write(f"ğŸ¯ Target F1 score: ~0.934")
        logger.write(f"ğŸ’¾ Experiment results: {exp_base}")
        
        return final_output
        
    except Exception as e:
        logger.write(f"âŒ [PIPELINE] Failed: {str(e)}")
        raise
    finally:
        logger.write("ğŸ [PIPELINE] Full pipeline ended")


def main():
    """CLI ì§„ì…ì """
    import argparse
    
    parser = argparse.ArgumentParser(description="Full Pipeline (Training + Inference)")
    parser.add_argument("--config", type=str, required=True, 
                       help="Path to config YAML file")
    parser.add_argument("--skip-training", action="store_true",
                       help="Skip training and run inference only")
    parser.add_argument("--output-dir", type=str, default=None,
                       help="Output directory for submission file")
    
    args = parser.parse_args()
    
    try:
        print("ğŸš€ Starting Full Pipeline...")
        print(f"ğŸ“‹ Config: {args.config}")
        print(f"âš™ï¸ Skip training: {args.skip_training}")
        print("=" * 50)
        
        result = run_full_pipeline(
            args.config, 
            skip_training=args.skip_training,
            output_dir=args.output_dir
        )
        
        print("\n" + "=" * 50)
        print("ğŸ‰ PIPELINE COMPLETED SUCCESSFULLY!")
        print(f"ğŸ“„ Final submission: {result}")
        print("ğŸ† Ready for competition submission!")
        
    except Exception as e:
        print(f"\nâŒ PIPELINE FAILED: {str(e)}")
        exit(1)


if __name__ == "__main__":
    main()
