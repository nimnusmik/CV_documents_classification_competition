# src/inference/infer_main.py
# ì¶”ë¡  ì‹¤í–‰ ì§„ì…ì  ìŠ¤í¬ë¦½íŠ¸ (CLIì—ì„œ ì‹¤í–‰ë˜ëŠ” ë©”ì¸ íŒŒì¼)
# ğŸš€ HIGH-PERFORMANCE VERSION

# argparse: CLI ì¸ì íŒŒì‹±
# sys: í”„ë¡œê·¸ë¨ ì¢…ë£Œ ì œì–´
import argparse, sys
# run_inference: ì¶”ë¡  ì‹¤í–‰ í•¨ìˆ˜ (ë³„ë„ ëª¨ë“ˆì—ì„œ ê°€ì ¸ì˜´)
from src.inference.infer import run_inference
from src.inference.infer_highperf import run_highperf_inference  # ğŸš€ ê³ ì„±ëŠ¥ ì¶”ë¡ 


# ë©”ì¸ í•¨ìˆ˜ ì •ì˜
def main():
    # ArgumentParser ê°ì²´ ìƒì„±
    ap = argparse.ArgumentParser(description="Document Classification Inference Pipeline")
    # í•„ìˆ˜ config ì¸ì ì¶”ê°€ (ì‹¤í–‰ì— ë°˜ë“œì‹œ í•„ìš”)
    ap.add_argument("--config", type=str, required=True, help="Path to config YAML file")
    # ì¶œë ¥ ê²½ë¡œ ì§€ì • (ì˜µì…˜, ì—†ìœ¼ë©´ ê¸°ë³¸ ê²½ë¡œ ì‚¬ìš©)
    ap.add_argument("--out", type=str, default=None, help="Output CSV path")
    # ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ ì§€ì • (ì˜µì…˜, ì—†ìœ¼ë©´ config ê¸°ë°˜ ê¸°ë³¸ê°’ ì‚¬ìš©)
    ap.add_argument("--ckpt", type=str, default=None, help="Model checkpoint path")
    # ğŸš€ ëª¨ë“œ ì„ íƒ ì¶”ê°€
    ap.add_argument("--mode", type=str, choices=["basic", "highperf"], default="highperf",
                   help="Inference mode: basic (single model) or highperf (ensemble + TTA)")
    # ğŸš€ ê³ ì„±ëŠ¥ ëª¨ë“œìš© fold_results ê²½ë¡œ
    ap.add_argument("--fold-results", type=str, default=None,
                   help="Path to fold_results.yaml (required for highperf mode)")
    # CLI ì¸ì íŒŒì‹±
    args = ap.parse_args()

    # ì˜ˆì™¸ ì²˜ë¦¬ ë¸”ë¡ ì‹œì‘
    try:
        print(f"ğŸ”® Starting inference pipeline...")
        print(f"ğŸ“‹ Config: {args.config}")
        print(f"ğŸ¯ Mode: {args.mode}")
        print("=" * 50)
        
        if args.mode == "highperf":
            print("ğŸ† Running HIGH-PERFORMANCE inference (Ensemble + TTA)")
            # fold_results ê²½ë¡œ í™•ì¸
            if not args.fold_results:
                print("âŒ Error: --fold-results is required for highperf mode")
                print("ğŸ’¡ Example: --fold-results experiments/train/20250905/v094-swin-highperf/fold_results.yaml")
                sys.exit(1)
            
            # ê³ ì„±ëŠ¥ ì¶”ë¡  ì‹¤í–‰
            output_path = run_highperf_inference(args.config, args.fold_results, args.out)
            print(f"ğŸ“„ High-performance prediction saved: {output_path}")
            
        else:
            print("ğŸ“š Running BASIC inference (Single model)")
            # run_inference ì‹¤í–‰ (config ê²½ë¡œ, out, ckpt ì „ë‹¬)
            run_inference(args.config, out=args.out, ckpt=args.ckpt)
        
        # ì •ìƒ ì¢…ë£Œ ë©”ì‹œì§€ ì¶œë ¥
        print("\n" + "=" * 50)
        print("âœ… [EXIT] inference finished successfully (see logs/* for details)")
        print("ğŸ“Š Check submissions/ folder for prediction files")
        # ì¢…ë£Œ ì½”ë“œ 0 (ì„±ê³µ)
        sys.exit(0)

    # ì‚¬ìš©ìê°€ Ctrl+C ë“±ìœ¼ë¡œ ì¤‘ë‹¨í•œ ê²½ìš°
    except KeyboardInterrupt:
        print("[EXIT] inference interrupted by user (KeyboardInterrupt)")
        # ì¢…ë£Œ ì½”ë“œ 130 (SIGINT)
        sys.exit(130)

    # ê·¸ ì™¸ ëª¨ë“  ì˜ˆì™¸ ì²˜ë¦¬
    except Exception as e:
        print(f"[EXIT][ERROR] inference failed: {type(e).__name__}: {e}")
        # ì¢…ë£Œ ì½”ë“œ 1 (ì‹¤íŒ¨)
        sys.exit(1)


# ìŠ¤í¬ë¦½íŠ¸ ì§ì ‘ ì‹¤í–‰ ì‹œ main() í˜¸ì¶œ
if __name__ == "__main__":
    main()
