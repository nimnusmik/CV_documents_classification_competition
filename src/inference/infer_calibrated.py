# src/inference/infer_calibrated.py
"""
ìº˜ë¦¬ë¸Œë ˆì´ì…˜ì´ ì ìš©ëœ ê³ ì„±ëŠ¥ ì¶”ë¡  íŒŒì´í”„ë¼ì¸

Temperature Scalingì„ í†µí•œ í™•ë¥  ë³´ì •ì´ ì ìš©ëœ ì•™ìƒë¸” ì¶”ë¡ ì„ ì œê³µí•©ë‹ˆë‹¤.
"""

import os
import time
import torch
import pandas as pd
import numpy as np
from pathlib import Path
from typing import Optional, List, Tuple

# í”„ë¡œì íŠ¸ ëª¨ë“ˆ import
from src.utils import load_yaml, create_log_path
from src.logging.logger import Logger
from src.models.build import build_model
from src.data.dataset import HighPerfDocClsDataset
from src.data.transforms import get_tta_transforms_by_type
from src.inference.infer_highperf import load_fold_models, get_recommended_model
from src.calibration import TemperatureScaling, CalibrationTrainer
from torch.utils.data import DataLoader


def run_calibrated_inference(
    cfg_path: str, 
    fold_results_path: str, 
    output_path: Optional[str] = None,
    use_tta: bool = True
) -> str:
    """
    ìº˜ë¦¬ë¸Œë ˆì´ì…˜ì´ ì ìš©ëœ ê³ ì„±ëŠ¥ ì¶”ë¡  ì‹¤í–‰
    
    Args:
        cfg_path: ì¶”ë¡  ì„¤ì • íŒŒì¼ ê²½ë¡œ
        fold_results_path: í´ë“œ ê²°ê³¼ íŒŒì¼ ê²½ë¡œ (fold_results.yaml)
        output_path: ê²°ê³¼ ì €ì¥ ê²½ë¡œ (Noneì‹œ ìë™ ìƒì„±)
        use_tta: TTA ì‚¬ìš© ì—¬ë¶€
        
    Returns:
        ìƒì„±ëœ ì œì¶œ íŒŒì¼ ê²½ë¡œ
    """
    # ì„¤ì • ë¡œë“œ
    cfg = load_yaml(cfg_path)
    
    # ë¡œê±° ì„¤ì •
    timestamp = time.strftime("%Y%m%d_%H%M")
    log_path = create_log_path("infer", f"infer_calibrated_{timestamp}.log")
    os.makedirs(os.path.dirname(log_path), exist_ok=True)
    logger = Logger(log_path=log_path)
    
    logger.write("ğŸŒ¡ï¸ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì ìš© ê³ ì„±ëŠ¥ ì¶”ë¡  ì‹œì‘")
    logger.write(f"ğŸ“‹ Config: {cfg_path}")
    logger.write(f"ğŸ“Š Fold results: {fold_results_path}")
    logger.write(f"ğŸ”„ TTA: {use_tta}")
    
    # ë””ë°”ì´ìŠ¤ ì„¤ì •
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    logger.write(f"ğŸ–¥ï¸ Device: {device}")
    
    try:
        # 1. í´ë“œ ëª¨ë¸ë“¤ ë¡œë“œ
        logger.write("\n" + "="*50)
        logger.write("ğŸ“¦ ëª¨ë¸ ë¡œë”© ì¤‘...")
        logger.write("="*50)
        
        models = load_fold_models(fold_results_path, device)
        logger.write(f"âœ… {len(models)}ê°œ í´ë“œ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
        
        # 2. ê²€ì¦ ë°ì´í„°ë¡œ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ìˆ˜í–‰
        logger.write("\n" + "="*50)
        logger.write("ğŸŒ¡ï¸ Temperature Scaling ìº˜ë¦¬ë¸Œë ˆì´ì…˜...")
        logger.write("="*50)
        
        temperature_scalings = perform_calibration(cfg, models, device, logger)
        
        # 3. í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë” ìƒì„±
        logger.write("\n" + "="*50)
        logger.write("ğŸ“Š í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤€ë¹„...")
        logger.write("="*50)
        
        test_loader = create_test_loader(cfg, logger, use_tta)
        
        # 4. ìº˜ë¦¬ë¸Œë ˆì´ì…˜ëœ ì•™ìƒë¸” ì˜ˆì¸¡ ìˆ˜í–‰
        logger.write("\n" + "="*50)
        logger.write("ğŸ¯ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ëœ ì•™ìƒë¸” ì˜ˆì¸¡ ì‹¤í–‰...")
        logger.write("="*50)
        
        ensemble_probs, predictions = ensemble_predict_calibrated(
            models, temperature_scalings, test_loader, device, use_tta, logger
        )
        
        # 5. ì œì¶œ íŒŒì¼ ìƒì„±
        logger.write("\n" + "="*50)
        logger.write("ğŸ’¾ ì œì¶œ íŒŒì¼ ìƒì„±...")
        logger.write("="*50)
        
        submission_path = create_submission_file(
            cfg, ensemble_probs, predictions, output_path, logger
        )
        
        logger.write("âœ… ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì ìš© ì¶”ë¡  ì™„ë£Œ!")
        logger.write(f"ğŸ“„ ì œì¶œ íŒŒì¼: {submission_path}")
        
        return submission_path
        
    except Exception as e:
        logger.write(f"âŒ ì¶”ë¡  ì‹¤íŒ¨: {str(e)}")
        raise


def perform_calibration(
    cfg: dict, 
    models: List[dict], 
    device: torch.device, 
    logger: Logger
) -> List[TemperatureScaling]:
    """
    ëª¨ë¸ë“¤ì— ëŒ€í•œ Temperature Scaling ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ìˆ˜í–‰
    
    Args:
        cfg: ì„¤ì • ë”•ì…”ë„ˆë¦¬
        models: ë¡œë“œëœ ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ë¦¬ìŠ¤íŠ¸
        device: ì—°ì‚° ë””ë°”ì´ìŠ¤
        logger: ë¡œê±°
        
    Returns:
        ê° ëª¨ë¸ì˜ TemperatureScaling ëª¨ë“ˆ ë¦¬ìŠ¤íŠ¸
    """
    # ê²€ì¦ ë°ì´í„° ë¡œë” ìƒì„± (ìº˜ë¦¬ë¸Œë ˆì´ì…˜ìš©)
    valid_loader = create_validation_loader(cfg, logger)
    
    # ìº˜ë¦¬ë¸Œë ˆì´ì…˜ íŠ¸ë ˆì´ë„ˆ ìƒì„±
    calibration_trainer = CalibrationTrainer(device, logger)
    
    # ê° ëª¨ë¸ì„ ì‹¤ì œ nn.Moduleë¡œ ë³µì›í•˜ê³  ìº˜ë¦¬ë¸Œë ˆì´ì…˜
    temperature_scalings = []
    
    for i, checkpoint in enumerate(models):
        logger.write(f"ğŸ¯ ëª¨ë¸ {i+1}/{len(models)} ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì¤‘...")
        
        # ëª¨ë¸ ìƒì„± ë° ê°€ì¤‘ì¹˜ ë¡œë“œ
        model_name = get_recommended_model(cfg["model"]["name"])
        model = build_model(
            model_name,
            cfg["data"]["num_classes"],
            pretrained=False,
            drop_rate=cfg["model"]["drop_rate"],
            drop_path_rate=cfg["model"]["drop_path_rate"],
            pooling=cfg["model"]["pooling"]
        ).to(device)
        
        model.load_state_dict(checkpoint["model_state_dict"])
        
        # Temperature scaling ìº˜ë¦¬ë¸Œë ˆì´ì…˜
        temp_scaling = calibration_trainer.calibrate_model(model, valid_loader)
        temperature_scalings.append(temp_scaling)
        
        logger.write(f"âœ… ëª¨ë¸ {i+1} ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì™„ë£Œ (T={temp_scaling.get_temperature():.4f})")
    
    return temperature_scalings


def create_validation_loader(cfg: dict, logger: Logger) -> DataLoader:
    """
    ìº˜ë¦¬ë¸Œë ˆì´ì…˜ìš© ê²€ì¦ ë°ì´í„° ë¡œë” ìƒì„±
    
    Args:
        cfg: ì„¤ì • ë”•ì…”ë„ˆë¦¬
        logger: ë¡œê±°
        
    Returns:
        ê²€ì¦ ë°ì´í„° ë¡œë”
    """
    # ì›ë³¸ í•™ìŠµ ë°ì´í„°ì˜ ì¼ë¶€ë¥¼ ê²€ì¦ìš©ìœ¼ë¡œ ì‚¬ìš©
    train_df = pd.read_csv(cfg["data"]["train_csv"])
    
    # ê°„ë‹¨í•œ ë¶„í•  (ë§ˆì§€ë§‰ 20%ë¥¼ ê²€ì¦ìš©ìœ¼ë¡œ)
    split_idx = int(len(train_df) * 0.8)
    valid_df = train_df.iloc[split_idx:].reset_index(drop=True)
    
    logger.write(f"ğŸ“Š ìº˜ë¦¬ë¸Œë ˆì´ì…˜ìš© ê²€ì¦ ë°ì´í„°: {len(valid_df)}ê°œ ìƒ˜í”Œ")
    
    # ê²€ì¦ ë°ì´í„°ì…‹ ìƒì„±
    valid_ds = HighPerfDocClsDataset(
        valid_df,
        cfg["data"]["image_dir_train"],
        img_size=cfg["train"]["img_size"],
        epoch=1,  # ê²€ì¦ìš©ì´ë¯€ë¡œ ê³ ì •
        total_epochs=1,
        is_train=False,  # ê²€ì¦ ëª¨ë“œ
        id_col=cfg["data"]["id_col"],
        target_col=cfg["data"]["target_col"]
    )
    
    # ë°ì´í„° ë¡œë” ìƒì„±
    valid_loader = DataLoader(
        valid_ds,
        batch_size=cfg["train"]["batch_size"],
        shuffle=False,
        num_workers=cfg["project"]["num_workers"],
        pin_memory=True
    )
    
    return valid_loader


def create_test_loader(cfg: dict, logger: Logger, use_tta: bool = True) -> DataLoader:
    """
    í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë” ìƒì„± (Configurable TTA ì§€ì›)
    
    Args:
        cfg: ì„¤ì • ë”•ì…”ë„ˆë¦¬
        logger: ë¡œê±°
        use_tta: TTA ì‚¬ìš© ì—¬ë¶€
        
    Returns:
        í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë”
    """
    # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸ ìƒì„±
    test_dir = Path(cfg["data"]["image_dir_test"])
    test_files = list(test_dir.glob(f"*{cfg['data']['image_ext']}"))
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„°í”„ë ˆì„ ìƒì„±
    test_df = pd.DataFrame({
        cfg["data"]["id_col"]: [f.stem for f in test_files]
    })
    
    logger.write(f"ğŸ“Š í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(test_df)}ê°œ ì´ë¯¸ì§€")
    
    if use_tta and "inference" in cfg and "tta_type" in cfg["inference"]:
        # Configurable TTA ë°ì´í„°ì…‹ ì‚¬ìš©
        from src.inference.infer_highperf import ConfigurableTTADataset
        test_ds = ConfigurableTTADataset(
            None,  # csv_path ëŒ€ì‹  DataFrame ì‚¬ìš©
            cfg["data"]["image_dir_test"],
            img_size=cfg["train"]["img_size"],
            tta_type=cfg["inference"].get("tta_type", "essential"),
            test_df=test_df,  # DataFrame ì§ì ‘ ì „ë‹¬
            id_col=cfg["data"]["id_col"]
        )
        logger.write(f"ğŸ”„ Configurable TTA ì‚¬ìš©: {cfg['inference']['tta_type']}")
    else:
        # ê¸°ëŠ¨ HighPerfDocClsDataset ì‚¬ìš©
        test_ds = HighPerfDocClsDataset(
            test_df,
            cfg["data"]["image_dir_test"],
            img_size=cfg["train"]["img_size"],
            epoch=1,
            total_epochs=1,
            is_train=False,
            id_col=cfg["data"]["id_col"],
            target_col=None  # í…ŒìŠ¤íŠ¸ì—ëŠ” íƒ€ê²Ÿ ì—†ìŒ
        )
        logger.write("ğŸ“Š ê¸°ë³¸ ë°ì´í„°ì…‹ ì‚¬ìš©")
    
    # ë°ì´í„° ë¡œë” ìƒì„±
    test_loader = DataLoader(
        test_ds,
        batch_size=cfg["train"]["batch_size"],
        shuffle=False,
        num_workers=cfg["project"]["num_workers"],
        pin_memory=True
    )
    
    return test_loader


def ensemble_predict_calibrated(
    models: List[dict],
    temperature_scalings: List[TemperatureScaling],
    test_loader: DataLoader,
    device: torch.device,
    use_tta: bool,
    logger: Logger
) -> Tuple[np.ndarray, np.ndarray]:
    """
    ìº˜ë¦¬ë¸Œë ˆì´ì…˜ëœ ì•™ìƒë¸” ì˜ˆì¸¡ ìˆ˜í–‰
    
    Args:
        models: ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ë¦¬ìŠ¤íŠ¸
        temperature_scalings: TemperatureScaling ëª¨ë“ˆ ë¦¬ìŠ¤íŠ¸
        test_loader: í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë”
        device: ì—°ì‚° ë””ë°”ì´ìŠ¤
        use_tta: TTA ì‚¬ìš© ì—¬ë¶€
        logger: ë¡œê±°
        
    Returns:
        (ì•™ìƒë¸” í™•ë¥ , ì˜ˆì¸¡ ë¼ë²¨)
    """
    from src.calibration.temperature_scaling import ensemble_predict_with_calibration
    
    # ëª¨ë¸ë“¤ì„ ì‹¤ì œ nn.Moduleë¡œ ë³µì›
    model_list = []
    
    for i, checkpoint in enumerate(models):
        # ì„¤ì •ì—ì„œ ëª¨ë¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸° (ì„ì‹œë¡œ ê³ ì •ê°’ ì‚¬ìš©)
        model_name = "swin_base_patch4_window12_384"  # TODO: ì„¤ì •ì—ì„œ ì½ì–´ì˜¤ê¸°
        
        model = build_model(
            model_name,
            17,  # num_classes
            pretrained=False,
            drop_rate=0.1,
            drop_path_rate=0.1,
            pooling="avg"
        ).to(device)
        
        model.load_state_dict(checkpoint["model_state_dict"])
        model_list.append(model)
    
    # ìº˜ë¦¬ë¸Œë ˆì´ì…˜ëœ ì•™ìƒë¸” ì˜ˆì¸¡
    logger.write(f"ğŸ”¥ {len(model_list)}ê°œ ëª¨ë¸ë¡œ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ëœ ì•™ìƒë¸” ì˜ˆì¸¡ ì‹œì‘...")
    
    ensemble_probs, predictions = ensemble_predict_with_calibration(
        model_list, temperature_scalings, test_loader, device
    )
    
    logger.write(f"âœ… ì˜ˆì¸¡ ì™„ë£Œ: {len(predictions)}ê°œ ìƒ˜í”Œ")
    
    return ensemble_probs, predictions


def create_submission_file(
    cfg: dict,
    ensemble_probs: np.ndarray,
    predictions: np.ndarray,
    output_path: Optional[str],
    logger: Logger
) -> str:
    """
    ì œì¶œ íŒŒì¼ ìƒì„±
    
    Args:
        cfg: ì„¤ì • ë”•ì…”ë„ˆë¦¬
        ensemble_probs: ì•™ìƒë¸” í™•ë¥ 
        predictions: ì˜ˆì¸¡ ë¼ë²¨
        output_path: ì¶œë ¥ ê²½ë¡œ (Noneì‹œ ìë™ ìƒì„±)
        logger: ë¡œê±°
        
    Returns:
        ìƒì„±ëœ íŒŒì¼ ê²½ë¡œ
    """
    # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸ ë‹¤ì‹œ ìƒì„±
    test_dir = Path(cfg["data"]["image_dir_test"])
    test_files = sorted(list(test_dir.glob(f"*{cfg['data']['image_ext']}")))
    test_ids = [f.stem for f in test_files]
    
    # ì œì¶œ ë°ì´í„°í”„ë ˆì„ ìƒì„±
    submission_df = pd.DataFrame({
        cfg["data"]["id_col"]: test_ids,
        cfg["data"]["target_col"]: predictions
    })
    
    # ì¶œë ¥ ê²½ë¡œ ì„¤ì •
    if output_path is None:
        timestamp = time.strftime("%Y%m%d_%H%M")
        
        # ì¦ê°• íƒ€ì… ê²°ì • (í•™ìŠµ ì„¤ì •ê³¼ ë™ì¼í•œ ë¡œì§ ì‚¬ìš©)
        aug_type = "advanced_augmentation" if cfg["train"].get("use_advanced_augmentation", False) else "basic_augmentation"
        
        output_path = f"submissions/{timestamp}/submission_calibrated_{timestamp}_{aug_type}.csv"
    
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    
    # íŒŒì¼ ì €ì¥
    submission_df.to_csv(output_path, index=False)
    
    logger.write(f"ğŸ’¾ ì œì¶œ íŒŒì¼ ì €ì¥: {output_path}")
    logger.write(f"ğŸ“Š ì˜ˆì¸¡ ë¶„í¬: {np.bincount(predictions)}")
    
    return output_path


# ë©”ì¸ ì‹¤í–‰ ë¸”ë¡
if __name__ == "__main__":
    import sys
    
    if len(sys.argv) < 3:
        print("Usage: python infer_calibrated.py <config_path> <fold_results_path> [output_path]")
        sys.exit(1)
    
    config_path = sys.argv[1]
    fold_results_path = sys.argv[2]
    output_path = sys.argv[3] if len(sys.argv) > 3 else None
    
    result_path = run_calibrated_inference(
        config_path, 
        fold_results_path, 
        output_path,
        use_tta=True
    )
    
    print(f"ğŸ‰ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì ìš© ì¶”ë¡  ì™„ë£Œ! ê²°ê³¼: {result_path}")
