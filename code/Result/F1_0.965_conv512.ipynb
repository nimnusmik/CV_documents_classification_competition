{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "zkH9T_86lDSS"
   },
   "source": [
    "## 1. Prepare Environments\n",
    "\n",
    "* ë°ì´í„° ë¡œë“œë¥¼ ìœ„í•œ êµ¬ê¸€ ë“œë¼ì´ë¸Œë¥¼ ë§ˆìš´íŠ¸í•©ë‹ˆë‹¤.\n",
    "* í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8489,
     "status": "ok",
     "timestamp": 1700314558888,
     "user": {
      "displayName": "Ynot(ì†¡ì›í˜¸)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "NC8V-D393wY4",
    "outputId": "e9927325-26c4-4b89-9c51-c1d6541388d6"
   },
   "outputs": [],
   "source": [
    "# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤.\n",
    "# !pip install timm\n",
    "# !pip install matplotlib\n",
    "# !pip install seaborn\n",
    "# !pip install optuna"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "PXa_FPM73R9f"
   },
   "source": [
    "## 2. Import Library & Define Functions\n",
    "* í•™ìŠµ ë° ì¶”ë¡ ì— í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.\n",
    "* í•™ìŠµ ë° ì¶”ë¡ ì— í•„ìš”í•œ í•¨ìˆ˜ì™€ í´ë˜ìŠ¤ë¥¼ ì •ì˜í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9396,
     "status": "ok",
     "timestamp": 1700314592802,
     "user": {
      "displayName": "Ynot(ì†¡ì›í˜¸)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "3BaoIkv5Xwa0"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import copy\n",
    "import gc\n",
    "\n",
    "import optuna, math\n",
    "import timm\n",
    "import torch\n",
    "import albumentations as A\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.optim import Adam\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.cuda.amp import autocast, GradScaler  # Mixed Precisionìš©\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import wandb\n",
    "from datetime import datetime\n",
    "\n",
    "# í•œê¸€ í°íŠ¸ ì„¤ì • (ì‹œê°í™”ìš©)\n",
    "plt.rcParams['font.family'] = ['DejaVu Sans']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‹œë“œë¥¼ ê³ ì •í•©ë‹ˆë‹¤.\n",
    "SEED = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 241,
     "status": "ok",
     "timestamp": 1700314772722,
     "user": {
      "displayName": "Ynot(ì†¡ì›í˜¸)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "Hyl8oAy6TZAu"
   },
   "outputs": [],
   "source": [
    "def mixup_data(x, y, alpha=1.0):\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "    batch_size = x.size()[0]\n",
    "    index = torch.randperm(batch_size).cuda()\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "# ë°ì´í„°ì…‹ í´ë˜ìŠ¤ë¥¼ ì •ì˜í•©ë‹ˆë‹¤. (Hard Augmentation í¬í•¨)\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, data, path, epoch=0, total_epochs=10, is_train=True):\n",
    "        if isinstance(data, str):\n",
    "            self.df = pd.read_csv(data).values\n",
    "        else:\n",
    "            self.df = data.values\n",
    "        self.path = path\n",
    "        self.epoch = epoch\n",
    "        self.total_epochs = total_epochs\n",
    "        self.is_train = is_train\n",
    "        \n",
    "        # Hard augmentation í™•ë¥  ê³„ì‚°\n",
    "        self.p_hard = 0.2 + 0.3 * (epoch / total_epochs) if is_train else 0\n",
    "        \n",
    "        # Normal augmentation\n",
    "        self.normal_aug = A.Compose([\n",
    "            A.LongestMaxSize(max_size=img_size),\n",
    "            A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "            A.OneOf([\n",
    "                A.Rotate(limit=[90,90], p=1.0),\n",
    "                A.Rotate(limit=[180,180], p=1.0),\n",
    "                A.Rotate(limit=[270,270], p=1.0),\n",
    "            ], p=0.6),\n",
    "            A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=0.8),\n",
    "            A.GaussNoise(var_limit=(30.0, 100.0), p=0.7),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "        \n",
    "        # Hard augmentation\n",
    "        self.hard_aug = A.Compose([\n",
    "            A.LongestMaxSize(max_size=img_size),\n",
    "            A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "            A.OneOf([\n",
    "                A.Rotate(limit=[90,90], p=1.0),\n",
    "                A.Rotate(limit=[180,180], p=1.0),\n",
    "                A.Rotate(limit=[270,270], p=1.0),\n",
    "                A.Rotate(limit=[-15,15], p=1.0),\n",
    "            ], p=0.8),\n",
    "            A.OneOf([\n",
    "                A.MotionBlur(blur_limit=15, p=1.0),\n",
    "                A.GaussianBlur(blur_limit=15, p=1.0),\n",
    "            ], p=0.95),\n",
    "            A.RandomBrightnessContrast(brightness_limit=0.5, contrast_limit=0.5, p=0.9),\n",
    "            A.GaussNoise(var_limit=(50.0, 150.0), p=0.8),\n",
    "            A.JpegCompression(quality_lower=70, quality_upper=100, p=0.5),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        name, target = self.df[idx]\n",
    "        img = np.array(Image.open(os.path.join(self.path, name)).convert('RGB'))\n",
    "        \n",
    "        # ë°°ì¹˜ë³„ ì¦ê°• ì„ íƒ\n",
    "        if self.is_train and random.random() < self.p_hard:\n",
    "            img = self.hard_aug(image=img)['image']\n",
    "        else:\n",
    "            img = self.normal_aug(image=img)['image']\n",
    "        \n",
    "        return img, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 255,
     "status": "ok",
     "timestamp": 1700315066028,
     "user": {
      "displayName": "Ynot(ì†¡ì›í˜¸)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "kTECBJfVTbdl"
   },
   "outputs": [],
   "source": [
    "# one epoch í•™ìŠµì„ ìœ„í•œ í•¨ìˆ˜ì…ë‹ˆë‹¤.\n",
    "def train_one_epoch(loader, model, optimizer, loss_fn, device):\n",
    "    scaler = GradScaler()  # Mixed Precisionìš©\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    preds_list = []\n",
    "    targets_list = []\n",
    "\n",
    "    pbar = tqdm(loader)\n",
    "    for image, targets in pbar:\n",
    "        image = image.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        # Cutmix/Mixup ì ìš© (30% í™•ë¥ )\n",
    "        if random.random() < 0.3:\n",
    "            mixed_x, y_a, y_b, lam = mixup_data(image, targets, alpha=1.0)\n",
    "            with autocast(): preds = model(mixed_x)\n",
    "            loss = lam * loss_fn(preds, y_a) + (1 - lam) * loss_fn(preds, y_b)\n",
    "        else:\n",
    "            with autocast(): preds = model(image)\n",
    "            loss = loss_fn(preds, targets)\n",
    "\n",
    "        model.zero_grad(set_to_none=True)\n",
    "\n",
    "        scaler.scale(loss).backward()  # Mixed Precisionìš©\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        scaler.step(optimizer); scaler.update()  # Mixed Precisionìš©\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
    "        targets_list.extend(targets.detach().cpu().numpy())\n",
    "\n",
    "        pbar.set_description(f\"Loss: {loss.item():.4f}\")\n",
    "\n",
    "    train_loss /= len(loader)\n",
    "    train_acc = accuracy_score(targets_list, preds_list)\n",
    "    train_f1 = f1_score(targets_list, preds_list, average='macro')\n",
    "\n",
    "    ret = {\n",
    "        \"train_loss\": train_loss,\n",
    "        \"train_acc\": train_acc,\n",
    "        \"train_f1\": train_f1,\n",
    "    }\n",
    "\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validationì„ ìœ„í•œ í•¨ìˆ˜ ì¶”ê°€\n",
    "def validate_one_epoch(loader, model, loss_fn, device):\n",
    "    \"\"\"\n",
    "    í•œ ì—í­ ê²€ì¦ì„ ìˆ˜í–‰í•˜ëŠ” í•¨ìˆ˜\n",
    "    - model.eval()ë¡œ ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ ì „í™˜\n",
    "    - torch.no_grad()ë¡œ gradient ê³„ì‚° ë¹„í™œì„±í™”í•˜ì—¬ ë©”ëª¨ë¦¬ ì ˆì•½\n",
    "    - ê²€ì¦ ë°ì´í„°ì— ëŒ€í•œ loss, accuracy, f1 score ê³„ì‚°\n",
    "    \"\"\"\n",
    "    model.eval()  # ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ ì „í™˜ (dropout, batchnorm ë¹„í™œì„±í™”)\n",
    "    val_loss = 0\n",
    "    preds_list = []\n",
    "    targets_list = []\n",
    "    \n",
    "    with torch.no_grad():  # gradient ê³„ì‚° ë¹„í™œì„±í™”ë¡œ ë©”ëª¨ë¦¬ ì ˆì•½\n",
    "        pbar = tqdm(loader, desc=\"Validating\")\n",
    "        for image, targets in pbar:\n",
    "            image = image.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            preds = model(image)  # ëª¨ë¸ ì˜ˆì¸¡\n",
    "            loss = loss_fn(preds, targets)  # ì†ì‹¤ ê³„ì‚°\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())  # ì˜ˆì¸¡ í´ë˜ìŠ¤ ì €ì¥\n",
    "            targets_list.extend(targets.detach().cpu().numpy())  # ì‹¤ì œ í´ë˜ìŠ¤ ì €ì¥\n",
    "            \n",
    "            pbar.set_description(f\"Val Loss: {loss.item():.4f}\")\n",
    "    \n",
    "    val_loss /= len(loader)  # í‰ê·  ì†ì‹¤ ê³„ì‚°\n",
    "    val_acc = accuracy_score(targets_list, preds_list)  # ì •í™•ë„ ê³„ì‚°\n",
    "    val_f1 = f1_score(targets_list, preds_list, average='macro')  # Macro F1 ê³„ì‚° (ëŒ€íšŒ í‰ê°€ì§€í‘œ)\n",
    "    \n",
    "    ret = {\n",
    "        \"val_loss\": val_loss,\n",
    "        \"val_acc\": val_acc,\n",
    "        \"val_f1\": val_f1,\n",
    "    }\n",
    "    \n",
    "    return ret"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Wjom43UvoXcx"
   },
   "source": [
    "## 3. Hyper-parameters\n",
    "* í•™ìŠµ ë° ì¶”ë¡ ì— í•„ìš”í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë“¤ì„ ì •ì˜í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"timm version:\", timm.__version__)  # ì£¼ì„: timm ë²„ì „ í™•ì¸\n",
    "print([m for m in timm.list_models('convnext_large*')])  # ì£¼ì„: large ë³€í˜•ë§Œ í•„í„°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 436,
     "status": "ok",
     "timestamp": 1700315112439,
     "user": {
      "displayName": "Ynot(ì†¡ì›í˜¸)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "KByfAeRmXwYk"
   },
   "outputs": [],
   "source": [
    "# device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# data config\n",
    "data_path = '../data/'\n",
    "\n",
    "# model config\n",
    "# model_name = 'tf_efficientnetv2_b3' # 'resnet50' 'efficientnet-b0', ...\n",
    "# model_name = 'swin_base_patch4_window12_384_in22k'\n",
    "model_name = 'convnext_large_384_in22ft1k'\n",
    "\n",
    "# training config\n",
    "img_size = 512\n",
    "LR = 2e-4\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 10\n",
    "num_workers = 8\n",
    "EMA = True  # Exponential Moving Average ì‚¬ìš© ì—¬ë¶€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optunaë¥¼ ì‚¬ìš©í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ (ì„ íƒì  ì‹¤í–‰)\n",
    "USE_OPTUNA = False  # Trueë¡œ ë°”ê¾¸ë©´ íŠœë‹ ì‹¤í–‰\n",
    "\n",
    "if USE_OPTUNA:\n",
    "    def objective(trial):\n",
    "        lr = trial.suggest_loguniform('lr', 1e-5, 1e-2)\n",
    "        batch_size = trial.suggest_categorical('batch_size', [32, 64, 128])\n",
    "        \n",
    "        # ê°„ë‹¨í•œ 3-fold CVë¡œ ë¹ ë¥¸ í‰ê°€\n",
    "        skf_simple = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "        fold_scores = []\n",
    "        \n",
    "        for fold, (train_idx, val_idx) in enumerate(skf_simple.split(train_df, train_df['target'])):\n",
    "            # ëª¨ë¸ ìƒì„±\n",
    "            model = timm.create_model(model_name, pretrained=True, num_classes=17).to(device)\n",
    "            optimizer = Adam(model.parameters(), lr=lr)\n",
    "            loss_fn = nn.CrossEntropyLoss()\n",
    "            \n",
    "            # ê°„ë‹¨í•œ 2 epoch í•™ìŠµ\n",
    "            for epoch in range(2):\n",
    "                train_ret = train_one_epoch(trn_loader, model, optimizer, loss_fn, device)\n",
    "            \n",
    "            val_ret = validate_one_epoch(val_loader, model, loss_fn, device)\n",
    "            fold_scores.append(val_ret['val_f1'])\n",
    "        \n",
    "        return np.mean(fold_scores)\n",
    "    \n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=10)\n",
    "    \n",
    "    # ìµœì  íŒŒë¼ë¯¸í„° ì ìš©\n",
    "    LR = study.best_params['lr']\n",
    "    BATCH_SIZE = study.best_params['batch_size']\n",
    "    print(f\"Best params: {study.best_params}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "amum-FlIojc6"
   },
   "source": [
    "## 4. Load Data\n",
    "* í•™ìŠµ, í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ê³¼ ë¡œë”ë¥¼ ì •ì˜í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optuna íŠœë‹ (ì„ íƒì  ì‹¤í–‰)\n",
    "USE_OPTUNA = False  # Trueë¡œ ë°”ê¾¸ë©´ íŠœë‹ ì‹¤í–‰\n",
    "\n",
    "if USE_OPTUNA:\n",
    "    # ìœ„ì˜ objective í•¨ìˆ˜ì™€ study ì½”ë“œ\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Fold ì ìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Fold ì„¤ì •\n",
    "N_FOLDS = 5  # 5-foldë¡œ ì„¤ì • (ë°ì´í„°ê°€ ì ìœ¼ë¯€ë¡œ)\n",
    "skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=42)\n",
    "\n",
    "# í´ë˜ìŠ¤ë³„ ìµœì†Œ ìƒ˜í”Œ ë³´ì¥ í™•ì¸\n",
    "# for fold, (train_idx, val_idx) in enumerate(skf.split(train_df, train_df['target'])):\n",
    "#     assert len(np.unique(train_df.iloc[val_idx]['target'])) == 17\n",
    "\n",
    "# ì „ì²´ í•™ìŠµ ë°ì´í„° ë¡œë“œ\n",
    "train_df = pd.read_csv(\"../data/train.csv\")\n",
    "\n",
    "# K-Fold ê²°ê³¼ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸\n",
    "fold_results = []\n",
    "fold_models = []  # ê° foldì˜ ìµœê³  ì„±ëŠ¥ ëª¨ë¸ì„ ì €ì¥\n",
    "fold_class_accuracies = [] # ê° foldì˜ í´ë˜ìŠ¤ë³„ ì •í™•ë„ ì €ì¥\n",
    "\n",
    "print(f\"Starting {N_FOLDS}-Fold Cross Validation...\")\n",
    "\n",
    "# LR = best_params['lr']\n",
    "# BATCH_SIZE = best_params['batch_size']\n",
    "\n",
    "# K-Fold Cross Validation ì‹œì‘\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(train_df, train_df['target'])):\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"FOLD {fold + 1}/{N_FOLDS}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    current_model = model_name\n",
    "    \n",
    "    # í˜„ì¬ foldì˜ train/validation ë°ì´í„° ë¶„í• \n",
    "    train_fold_df = train_df.iloc[train_idx].reset_index(drop=True)\n",
    "    val_fold_df = train_df.iloc[val_idx].reset_index(drop=True)\n",
    "    \n",
    "    # í˜„ì¬ foldì˜ Dataset ìƒì„±\n",
    "    trn_dataset = ImageDataset(\n",
    "        train_fold_df,\n",
    "        \"../data/train/\",\n",
    "        # transform=trn_transform\n",
    "        epoch=0,  # í˜„ì¬ epoch ì „ë‹¬\n",
    "        total_epochs=EPOCHS,\n",
    "        is_train=True\n",
    "    )\n",
    "    \n",
    "    val_dataset = ImageDataset(\n",
    "        val_fold_df,\n",
    "        \"../data/train/\",\n",
    "        # transform=tst_transform  # ê²€ì¦ì—ëŠ” ì¦ê°• ì ìš© ì•ˆí•¨\n",
    "        epoch=0,  # validationì€ epoch ê´€ê³„ì—†ìŒ\n",
    "        total_epochs=EPOCHS,\n",
    "        is_train=False  # validationì´ë¯€ë¡œ hard augmentation ë¹„í™œì„±í™”\n",
    "    )\n",
    "    \n",
    "    # í˜„ì¬ foldì˜ DataLoader ìƒì„±\n",
    "    trn_loader = DataLoader(\n",
    "        trn_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=False\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    print(f\"Train samples: {len(trn_dataset)}, Validation samples: {len(val_dataset)}\")\n",
    "    \n",
    "    # ëª¨ë¸ ì´ˆê¸°í™” (ê° foldë§ˆë‹¤ ìƒˆë¡œìš´ ëª¨ë¸)\n",
    "    model = timm.create_model(\n",
    "        current_model,\n",
    "        pretrained=True,\n",
    "        num_classes=17\n",
    "    ).to(device)\n",
    "    \n",
    "    loss_fn = nn.CrossEntropyLoss(label_smoothing=0.02)  # Label Smoothing ì ìš©\n",
    "    optimizer = Adam(model.parameters(), lr=LR)\n",
    "    \n",
    "    # Learning Rate Scheduler ì¶”ê°€\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "    \n",
    "    # í˜„ì¬ foldì˜ ìµœê³  ì„±ëŠ¥ ì¶”ì \n",
    "    best_val_f1 = 0.0\n",
    "    best_model = None\n",
    "    \n",
    "    # í˜„ì¬ fold í•™ìŠµ\n",
    "    for epoch in range(EPOCHS):\n",
    "        # Training\n",
    "        train_ret = train_one_epoch(trn_loader, model, optimizer, loss_fn, device)\n",
    "        \n",
    "        # Validation\n",
    "        val_ret = validate_one_epoch(val_loader, model, loss_fn, device)\n",
    "        \n",
    "        # Scheduler step ì¶”ê°€\n",
    "        scheduler.step()\n",
    "        \n",
    "        print(f\"Epoch {epoch+1:2d} | \"\n",
    "              f\"Train Loss: {train_ret['train_loss']:.4f} | \"\n",
    "              f\"Train F1: {train_ret['train_f1']:.4f} | \"\n",
    "              f\"Val Loss: {val_ret['val_loss']:.4f} | \"\n",
    "              f\"Val F1: {val_ret['val_f1']:.4f}\")\n",
    "        \n",
    "        # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥\n",
    "        if val_ret['val_f1'] > best_val_f1:\n",
    "            best_val_f1 = val_ret['val_f1']\n",
    "            best_model = copy.deepcopy(model.state_dict())\n",
    "            \n",
    "            # Best ëª¨ë¸ ë¶„ì„\n",
    "            model.eval()\n",
    "            val_preds, val_targets = [], []\n",
    "            with torch.no_grad():\n",
    "                for image, targets in val_loader:\n",
    "                    preds = model(image.to(device)).argmax(dim=1)\n",
    "                    val_preds.extend(preds.cpu().numpy())\n",
    "                    val_targets.extend(targets.numpy())\n",
    "            \n",
    "            # í´ë˜ìŠ¤ë³„ ì •í™•ë„\n",
    "            fold_class_acc = {}\n",
    "            for c in range(17):\n",
    "                mask = np.array(val_targets) == c\n",
    "                if mask.sum() > 0:\n",
    "                    fold_class_acc[c] = (np.array(val_preds)[mask] == c).mean()\n",
    "    \n",
    "    # í˜„ì¬ fold ê²°ê³¼ ì €ì¥\n",
    "    fold_results.append({\n",
    "        'fold': fold + 1,\n",
    "        'best_val_f1': best_val_f1,\n",
    "        'train_samples': len(trn_dataset),\n",
    "        'val_samples': len(val_dataset)\n",
    "    })\n",
    "    \n",
    "    fold_models.append(best_model)\n",
    "    \n",
    "    print(f\"Fold {fold + 1} Best Validation F1: {best_val_f1:.4f}\")\n",
    "    \n",
    "    fold_class_accuracies.append(fold_class_acc) # ê° foldì˜ í´ë˜ìŠ¤ë³„ ì •í™•ë„ ì €ì¥\n",
    "\n",
    "# K-Fold ê²°ê³¼ ìš”ì•½\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"K-FOLD CROSS VALIDATION RESULTS\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "val_f1_scores = [result['best_val_f1'] for result in fold_results]\n",
    "mean_f1 = np.mean(val_f1_scores)\n",
    "std_f1 = np.std(val_f1_scores)\n",
    "\n",
    "for result in fold_results:\n",
    "    print(f\"Fold {result['fold']}: {result['best_val_f1']:.4f}\")\n",
    "\n",
    "print(f\"\\nMean CV F1: {mean_f1:.4f} Â± {std_f1:.4f}\")\n",
    "print(f\"Best single fold: {max(val_f1_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í´ë˜ìŠ¤ë³„ ì„±ëŠ¥ ì‹œê°í™”\n",
    "meta_df = pd.read_csv(\"../data/meta.csv\")\n",
    "avg_acc = {c: np.mean([f.get(c,0) for f in fold_class_accuracies]) for c in range(17)}\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "classes = list(avg_acc.keys())\n",
    "accs = [avg_acc[c] * 100 for c in classes]\n",
    "names = [f\"C{c}\" for c in classes]\n",
    "\n",
    "plt.bar(range(17), accs)\n",
    "plt.xticks(range(17), names)\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Class-wise Prediction Accuracy')\n",
    "for i, acc in enumerate(accs):\n",
    "    plt.text(i, acc + 1, f'{acc:.1f}%', ha='center', fontsize=8)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Worst 3 classes:\")\n",
    "worst = sorted(avg_acc.items(), key=lambda x: x[1])[:3]\n",
    "for c, acc in worst:\n",
    "    print(f\"Class {c}: {acc*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê¸´ê¸‰ ëª¨ë¸ ì €ì¥ - í˜„ì¬ ìƒíƒœ ê·¸ëŒ€ë¡œ ì €ì¥\n",
    "def save_models():\n",
    "    \"\"\"í•™ìŠµí•œ ëª¨ë¸ë“¤ì„ ì €ì¥\"\"\"\n",
    "    \n",
    "    # ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±\n",
    "    save_dir = \"models\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    print(\"ğŸš¨ ëª¨ë¸ ì €ì¥ ì‹œì‘...\")\n",
    "    \n",
    "    # ê° foldë³„ ëª¨ë¸ ì €ì¥ (fold_models ë¦¬ìŠ¤íŠ¸ê°€ ìˆë‹¤ê³  ê°€ì •)\n",
    "    try:\n",
    "        for fold in range(5):  # 5-foldë¼ê³  ê°€ì •\n",
    "            model_path = f\"{save_dir}/fold_{fold}_model_{timestamp}.pth\"\n",
    "            \n",
    "            # fold_models[fold]ê°€ ì¡´ì¬í•œë‹¤ë©´ ì €ì¥\n",
    "            if 'fold_models' in globals() and len(fold_models) > fold:\n",
    "                torch.save({\n",
    "                    'model_state_dict': fold_models[fold].state_dict(),\n",
    "                    'fold': fold,\n",
    "                    'timestamp': timestamp,\n",
    "                    'epoch': 'unknown',  # ì—í¬í¬ ì •ë³´ ëª¨ë¥´ë©´ unknown\n",
    "                }, model_path)\n",
    "                print(f\"âœ… Fold {fold} ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {model_path}\")\n",
    "            \n",
    "            # ë˜ëŠ” best_models ë¦¬ìŠ¤íŠ¸ê°€ ìˆë‹¤ë©´\n",
    "            elif 'best_models' in globals() and len(best_models) > fold:\n",
    "                torch.save({\n",
    "                    'model_state_dict': best_models[fold].state_dict(),\n",
    "                    'fold': fold,\n",
    "                    'timestamp': timestamp,\n",
    "                    'epoch': 'unknown',\n",
    "                }, model_path)\n",
    "                print(f\"âœ… Fold {fold} best ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {model_path}\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Foldë³„ ì €ì¥ ì‹¤íŒ¨: {e}\")\n",
    "    \n",
    "    # ì „ì²´ ë³€ìˆ˜ ìƒíƒœ ì €ì¥ (í˜¹ì‹œ ëª¨ë¥´ë‹ˆê¹Œ)\n",
    "    try:\n",
    "        state_path = f\"{save_dir}/full_state_{timestamp}.pth\"\n",
    "        \n",
    "        # í˜„ì¬ ê¸€ë¡œë²Œ ë³€ìˆ˜ì—ì„œ ëª¨ë¸ ê´€ë ¨ ê°ì²´ë“¤ ì°¾ì•„ì„œ ì €ì¥\n",
    "        save_dict = {}\n",
    "        \n",
    "        # ê°€ëŠ¥í•œ ëª¨ë¸ ë³€ìˆ˜ëª…ë“¤ ì²´í¬\n",
    "        possible_model_vars = ['model', 'models', 'fold_models', 'best_models', \n",
    "                              'tta_models', 'ensemble_models']\n",
    "        \n",
    "        for var_name in possible_model_vars:\n",
    "            if var_name in globals():\n",
    "                save_dict[var_name] = globals()[var_name]\n",
    "                print(f\"âœ… {var_name} ë³€ìˆ˜ í¬í•¨ë¨\")\n",
    "        \n",
    "        if save_dict:\n",
    "            torch.save(save_dict, state_path)\n",
    "            print(f\"âœ… ì „ì²´ ìƒíƒœ ì €ì¥ ì™„ë£Œ: {state_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ì „ì²´ ìƒíƒœ ì €ì¥ ì‹¤íŒ¨: {e}\")\n",
    "    \n",
    "    print(f\"ğŸ‰ ì €ì¥ ì™„ë£Œ! ì €ì¥ ìœ„ì¹˜: {save_dir}/\")\n",
    "    print(f\"ğŸ“ íŒŒì¼ ëª©ë¡:\")\n",
    "    for file in os.listdir(save_dir):\n",
    "        print(f\"   - {file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emergency_save_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ì €ì¥ëœ ëª¨ë¸ ë‹¤ì‹œ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "# saved_state = torch.load(\"emergency_models/full_state_20250907_091916.pth\")\n",
    "\n",
    "# fold_models = saved_state['fold_models']\n",
    "# ensemble_models = saved_state['ensemble_models']\n",
    "# model = saved_state['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5-Fold ì•™ìƒë¸” ëª¨ë¸ ì¤€ë¹„\n",
    "ensemble_models = []\n",
    "for i, state_dict in enumerate(fold_models):\n",
    "    fold_model = timm.create_model(model_name, pretrained=True, num_classes=17).to(device)\n",
    "    fold_model.load_state_dict(state_dict)\n",
    "    fold_model.eval()\n",
    "    ensemble_models.append(fold_model)\n",
    "print(f\"Using ensemble of all {len(ensemble_models)} fold models for inference\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Nmm5h3J-pXNV"
   },
   "source": [
    "## 5. Train Model\n",
    "* ëª¨ë¸ì„ ë¡œë“œí•˜ê³ , í•™ìŠµì„ ì§„í–‰í•©ë‹ˆë‹¤."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "lkwxRXoBpbaX"
   },
   "source": [
    "# 6. Inference & Save File\n",
    "* í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ì— ëŒ€í•œ ì¶”ë¡ ì„ ì§„í–‰í•˜ê³ , ê²°ê³¼ íŒŒì¼ì„ ì €ì¥í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temperature Scaling í´ë˜ìŠ¤ ì •ì˜\n",
    "class TemperatureScaling(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.temperature = nn.Parameter(torch.ones(1) * 1.5)\n",
    "    \n",
    "    def forward(self, logits):\n",
    "        return logits / self.temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ê¸°ì¡´ ë³€ìˆ˜ë“¤ ì •ë¦¬ (ëª¨ë¸ ì œì™¸)\n",
    "# if 'tta_loader' in globals():\n",
    "#     del tta_loader\n",
    "# if 'essential_tta_transforms' in globals():\n",
    "#     del essential_tta_transforms\n",
    "    \n",
    "# # GPU ë©”ëª¨ë¦¬ ì •ë¦¬\n",
    "# torch.cuda.empty_cache()\n",
    "# gc.collect()\n",
    "\n",
    "# print(f\"ğŸ” í˜„ì¬ GPU ë©”ëª¨ë¦¬: {torch.cuda.memory_allocated()/1024**3:.2f} GB\")\n",
    "# print(f\"ğŸ” ì˜ˆì•½ëœ ë©”ëª¨ë¦¬: {torch.cuda.memory_reserved()/1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "essential_tta_transforms = [\n",
    "    # ì›ë³¸\n",
    "    A.Compose([\n",
    "        A.LongestMaxSize(max_size=img_size),\n",
    "        A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "    # 90ë„ íšŒì „ë“¤\n",
    "    A.Compose([\n",
    "        A.LongestMaxSize(max_size=img_size),\n",
    "        A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "        A.Rotate(limit=[90, 90], p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "    A.Compose([\n",
    "        A.LongestMaxSize(max_size=img_size),\n",
    "        A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "        A.Rotate(limit=[180, 180], p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "    A.Compose([\n",
    "        A.LongestMaxSize(max_size=img_size),\n",
    "        A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "        A.Rotate(limit=[-90, -90], p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "    # ë°ê¸° ê°œì„ \n",
    "    A.Compose([\n",
    "        A.LongestMaxSize(max_size=img_size),\n",
    "        A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "        A.RandomBrightnessContrast(brightness_limit=[0.3, 0.3], contrast_limit=[0.3, 0.3], p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TTA ì¶”ë¡ ì„ ìœ„í•œ Dataset í´ë˜ìŠ¤\n",
    "class TTAImageDataset(Dataset):\n",
    "    def __init__(self, data, path, transforms):\n",
    "        if isinstance(data, str):\n",
    "            self.df = pd.read_csv(data).values\n",
    "        else:\n",
    "            self.df = data.values\n",
    "        self.path = path\n",
    "        self.transforms = transforms  # ì—¬ëŸ¬ transformì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë°›ìŒ\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        name, target = self.df[idx]\n",
    "        img = np.array(Image.open(os.path.join(self.path, name)).convert('RGB'))\n",
    "        \n",
    "        # ëª¨ë“  transformì„ ì ìš©í•œ ê²°ê³¼ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜\n",
    "        augmented_images = []\n",
    "        for transform in self.transforms:\n",
    "            aug_img = transform(image=img)['image']\n",
    "            augmented_images.append(aug_img)\n",
    "        \n",
    "        return augmented_images, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TTA Dataset ìƒì„±\n",
    "tta_dataset = TTAImageDataset(\n",
    "    \"../data/sample_submission.csv\",\n",
    "    \"../data/test/\",\n",
    "    essential_tta_transforms\n",
    ")\n",
    "\n",
    "# TTA DataLoader (ë°°ì¹˜ í¬ê¸°ë¥¼ ì¤„ì—¬ì„œ ë©”ëª¨ë¦¬ ì ˆì•½)\n",
    "tta_loader = DataLoader(\n",
    "    tta_dataset,\n",
    "    batch_size=16,  # TTAëŠ” ë©”ëª¨ë¦¬ë¥¼ ë§ì´ ì‚¬ìš©í•˜ë¯€ë¡œ ë°°ì¹˜ í¬ê¸° ì¤„ì„\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"TTA Dataset size: {len(tta_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_tta_inference(models, loader, transforms, confidence_threshold=0.9):\n",
    "    \"\"\"5-Fold ëª¨ë¸ ì•™ìƒë¸” + TTA ì¶”ë¡ \"\"\"\n",
    "    all_predictions = []\n",
    "    \n",
    "    for batch_idx, (images_list, _) in enumerate(tqdm(loader, desc=\"Ensemble TTA\")):\n",
    "        batch_size = images_list[0].size(0)\n",
    "        ensemble_probs = torch.zeros(batch_size, 17).to(device)\n",
    "        \n",
    "        # ê° fold ëª¨ë¸ë³„ ì˜ˆì¸¡\n",
    "        for model in models:\n",
    "            with torch.no_grad():\n",
    "                # ê° TTA ë³€í˜•ë³„ ì˜ˆì¸¡\n",
    "                for images in images_list:\n",
    "                    images = images.to(device)\n",
    "                    preds = model(images)\n",
    "                    probs = torch.softmax(preds, dim=1)\n",
    "                    ensemble_probs += probs / (len(models) * len(images_list))\n",
    "        \n",
    "        final_preds = torch.argmax(ensemble_probs, dim=1)\n",
    "        all_predictions.extend(final_preds.cpu().numpy())\n",
    "    \n",
    "    return all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì•™ìƒë¸” TTA ì‹¤í–‰\n",
    "print(\"Starting Ensemble TTA inference...\")\n",
    "tta_predictions = ensemble_tta_inference(\n",
    "    models=ensemble_models, \n",
    "    loader=tta_loader, \n",
    "    transforms=essential_tta_transforms,\n",
    "    confidence_threshold=0.9\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TTA ê²°ê³¼ë¡œ submission íŒŒì¼ ìƒì„±\n",
    "tta_pred_df = pd.DataFrame(tta_dataset.df, columns=['ID', 'target'])\n",
    "tta_pred_df['target'] = tta_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê¸°ì¡´ submissionê³¼ ë™ì¼í•œ ìˆœì„œì¸ì§€ í™•ì¸\n",
    "sample_submission_df = pd.read_csv(\"../data/sample_submission.csv\")\n",
    "assert (sample_submission_df['ID'] == tta_pred_df['ID']).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TTA ê²°ê³¼ ì €ì¥\n",
    "tta_pred_df.to_csv(\"../submission/choice.csv\", index=False)\n",
    "print(\"TTA predictions saved\")\n",
    "\n",
    "print(\"TTA Prediction sample:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 353,
     "status": "ok",
     "timestamp": 1700315247734,
     "user": {
      "displayName": "Ynot(ì†¡ì›í˜¸)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "9yMO8s6GqAwZ",
    "outputId": "9a30616f-f0ea-439f-a906-dd806737ce00"
   },
   "outputs": [],
   "source": [
    "tta_pred_df.head()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
