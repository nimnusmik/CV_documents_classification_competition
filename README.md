# ğŸ† Computer Vision Competition - Advanced ML Pipeline Framework

[![Python 3.11](https://img.shields.io/badge/python-3.11-blue.svg)](https://www.python.org/downloads/release/python-3119/)
[![F1 Score](https://img.shields.io/badge/F1_Score-0.9750+-brightgreen.svg)](https://github.com/your-repo/issues)
[![Framework](https://img.shields.io/badge/Framework-PyTorch-orange.svg)](https://pytorch.org/)
[![Optimization](https://img.shields.io/badge/Optimization-Optuna-purple.svg)](https://optuna.org/)
[![Pipeline](https://img.shields.io/badge/Pipeline-Full_Automation-green.svg)](#)

## ğŸ“‹ í”„ë¡œì íŠ¸ ê°œìš”

Computer Vision ê²½ì§„ëŒ€íšŒ í”„ë ˆì„ì›Œí¬ë¡œ, ë‹¨ì¼ í´ë“œë¶€í„° ë‹¤ì¤‘ ëª¨ë¸ ì•™ìƒë¸”ê¹Œì§€ ë‹¤ì–‘í•œ ì „ëµì„ ì§€ì›í•©ë‹ˆë‹¤.

### ğŸ¯ í•µì‹¬ íŠ¹ì§•
- ğŸ† **ìµœê³  ì„±ëŠ¥**: **F1 Score 0.9750+** ë‹¬ì„± (ë‹¤ì¤‘ ëª¨ë¸ ì•™ìƒë¸”)
- âš¡ **ìœ ì—°í•œ êµ¬ì¡°**: ë‹¨ì¼ í´ë“œ â†” K-Fold â†” ë‹¤ì¤‘ëª¨ë¸ ì›í´ë¦­ ì „í™˜
- ğŸ¤– **ì™„ì „ ìë™í™”**: í•™ìŠµ â†’ ìµœì í™” â†’ ì¶”ë¡  â†’ ì œì¶œ ì „ ê³¼ì • ìë™í™”
- ğŸ§  **ì§€ëŠ¥í˜• ìµœì í™”**: Optuna ë² ì´ì§€ì•ˆ ìµœì í™” + Temperature Scaling
- ğŸ¨ **ê³ ê¸‰ TTA**: Essential(5ê°€ì§€) / Comprehensive(15ê°€ì§€) ë³€í™˜
- ğŸ“Š **ì²´ê³„ì  ì¶”ì **: WandB í†µí•© + 200+ ì‹¤í—˜ ê¸°ë¡

---

## ğŸ—ï¸ ì „ì²´ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

```mermaid
flowchart TB
    subgraph DATA["ğŸ“Š ë°ì´í„° ê³„ì¸µ"]
        A1["data/raw/train/<br/>ğŸ“¸ ì›ë³¸ í•™ìŠµ ì´ë¯¸ì§€<br/>17í´ë˜ìŠ¤ ë¶„ë¥˜"]
        A2["data/raw/test/<br/>ğŸ“¸ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€<br/>ì˜ˆì¸¡ ëŒ€ìƒ"]
        A3["data/raw/train.csv<br/>ğŸ“‹ ë¼ë²¨ ì •ë³´<br/>ì´ë¯¸ì§€-í´ë˜ìŠ¤ ë§¤í•‘"]
        A4["src/data/dataset.py<br/>ğŸ”§ ë°ì´í„° ë¡œë”<br/>ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸"]
    end
    
    subgraph TRAIN["ğŸ“ í•™ìŠµ ê³„ì¸µ (ë‹¤ì–‘í•œ ì „ëµ)"]
        B1["ğŸ“ ë‹¨ì¼ í´ë“œ í•™ìŠµ<br/>src/training/train.py<br/>ë¹ ë¥¸ í”„ë¡œí† íƒ€ì…"]
        B2["ğŸ”€ K-Fold êµì°¨ê²€ì¦<br/>src/training/train_highperf.py<br/>ì•ˆì •ì  ê³ ì„±ëŠ¥"]
        B3["ğŸ­ ë‹¤ì¤‘ ëª¨ë¸ ì•™ìƒë¸”<br/>train_multi_model_ensemble.yaml<br/>ìµœê³  ì„±ëŠ¥"]
        B4["ğŸ” Optuna ìµœì í™”<br/>src/optimization/optuna_optimize.py<br/>ìë™ íŠœë‹"]
    end
    
    subgraph MODELS["ğŸ—ï¸ ëª¨ë¸ ê³„ì¸µ"]
        C1["ğŸ† ConvNeXt Base 384<br/>convnext_base_384<br/>Team ìµœê³  ì„±ëŠ¥"]
        C2["ğŸ¯ Swin Transformer<br/>swin_base_384<br/>Transformer ê¸°ë°˜"]
        C3["ğŸ“Š EfficientNet V2<br/>efficientnet_v2_b3<br/>íš¨ìœ¨ì„± ì¤‘ì‹¬"]
        C4["ğŸ¨ Hard Augmentation<br/>src/data/transforms.py<br/>ë™ì  í™•ë¥  ì¦ê°•"]
    end
    
    subgraph INFER["ğŸ”® ì¶”ë¡  ê³„ì¸µ (ë‹¤ì–‘í•œ ì „ëµ)"]
        D1["ğŸ“ ë‹¨ì¼ ëª¨ë¸ ì¶”ë¡ <br/>src/inference/infer.py<br/>ë¹ ë¥¸ ê²€ì¦"]
        D2["ğŸ”€ K-fold ì•™ìƒë¸”<br/>src/inference/infer_highperf.py<br/>5ëª¨ë¸ ì¡°í•©"]
        D3["ğŸ­ ë‹¤ì¤‘ ëª¨ë¸ ì•™ìƒë¸”<br/>infer_multi_model_ensemble.yaml<br/>ì—¬ëŸ¬ ì•„í‚¤í…ì²˜"]
        D4["ğŸ¨ TTA ì „ëµ<br/>Essential(5ê°€ì§€)/Comprehensive(15ê°€ì§€)<br/>ì„±ëŠ¥ í–¥ìƒ"]
    end
    
    subgraph OPTIM["ğŸ” ìµœì í™” ê³„ì¸µ"]
        E1["ğŸŒ¡ï¸ Temperature Scaling<br/>src/calibration/calibrate.py<br/>í™•ë¥  ë³´ì •"]
        E2["âš¡ GPU ìµœì í™”<br/>src/utils/gpu_optimization/<br/>ë°°ì¹˜ í¬ê¸° ìë™ ì¡°ì •"]
        E3["ğŸ“Š ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§<br/>src/logging/logger.py<br/>WandB ì‹œê°í™”"]
    end
    
    subgraph OUTPUT["ğŸ“¤ ì¶œë ¥ ê³„ì¸µ"]
        F1["ğŸ’¾ í•™ìŠµ ëª¨ë¸<br/>experiments/train/YYYYMMDD/<br/>ì²´í¬í¬ì¸íŠ¸ + fold_results.yaml"]
        F2["ğŸ“„ ì¶”ë¡  ê²°ê³¼<br/>submissions/YYYYMMDD/<br/>CSV ì œì¶œ íŒŒì¼"]
        F3["ğŸ“ ë¡œê·¸ ê¸°ë¡<br/>logs/YYYYMMDD/<br/>í•™ìŠµ/ì¶”ë¡  ì„±ëŠ¥"]
    end
    
    DATA --> TRAIN
    TRAIN --> MODELS
    MODELS --> INFER
    TRAIN --> OPTIM
    OPTIM --> INFER
    INFER --> OUTPUT
    
    A1 & A3 --> A4
    A4 --> B1 & B2 & B3
    B4 --> B1 & B2 & B3
    
    B1 --> C1
    B2 --> C1 & C2 & C3 & C4
    B3 --> C1 & C2 & C3
    
    C1 & C2 & C3 --> F1
    F1 --> D1 & D2 & D3
    D4 --> D2 & D3
    
    E1 & E2 & E3 --> D2 & D3
    
    D1 & D2 & D3 --> F2
    TRAIN --> F3
    INFER --> F3
    
    style B2 fill:#e8f5e8, color:#000000
    style B3 fill:#f3e5f5, color:#000000
    style C1 fill:#ffcdd2, color:#000000
    style D2 fill:#e1f5fe, color:#000000
    style D3 fill:#fce4ec, color:#000000
    style E1 fill:#fff3e0, color:#000000
```

## ğŸ“Š ì„±ëŠ¥ ë¹„êµ ë° ì „ëµ ë¶„ì„

### ğŸ¯ í•™ìŠµ ì „ëµë³„ ì„±ëŠ¥ ë¹„êµ

| í•™ìŠµ ì „ëµ | ì†ë„ | ì˜ˆìƒ F1 | GPU ë©”ëª¨ë¦¬ | ì „ëµ íŠ¹ì§• | ìµœì  í™œìš© ìƒí™© |
|-----------|------|---------|-----------|----------|---------------|
| **ğŸ“ ë‹¨ì¼ í´ë“œ** | âš¡ 30ë¶„ | 0.92-0.95 | 8GB | ë¹ ë¥¸ í”„ë¡œí† íƒ€ì… | ì´ˆê¸° ì‹¤í—˜, ë¹ ë¥¸ ê²€ì¦ |
| **ğŸ”€ K-fold CV** | ğŸ•°ï¸ 2ì‹œê°„ | 0.95-0.98 | 16GB | ì•ˆì •ì„± í™•ë³´ | ìµœì¢… ì œì¶œ, ëŒ€íšŒìš© |
| **ğŸ­ ë‹¤ì¤‘ ëª¨ë¸** | ğŸ”„ 3ì‹œê°„ | 0.96-0.99 | 24GB+ | ë‹¤ì–‘ì„± ê·¹ëŒ€í™” | ê³ ì‚¬ì–‘ GPU, ìš°ìŠ¹ìš© |
| **ğŸ” Optuna ìµœì í™”** | ğŸ† 5ì‹œê°„ | 0.97-0.99+ | 16GB | ìë™ íŠœë‹ | ì‹œê°„ ì—¬ìœ , ìµœê³  ì„±ëŠ¥ |

### ğŸ† ì¶”ë¡  ì „ëµë³„ ì„±ëŠ¥ ë¹„êµ

| ì¶”ë¡  ì „ëµ | ì†ë„ | ì˜ˆìƒ F1 | GPU ë©”ëª¨ë¦¬ | TTA ì „ëµ | ìµœì  í™œìš© ìƒí™© |
|-----------|------|---------|-----------|----------|---------------|
| **ğŸ“ ë‹¨ì¼ ëª¨ë¸ ì¶”ë¡ ** | âš¡ 5ë¶„ | 0.92-0.93 | 4-6GB | No TTA | ì´ˆê¸° ê²€ì¦, ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ |
| **ğŸ¯ ë‹¨ì¼ ëª¨ë¸ + TTA** | ğŸ•°ï¸ 17ë¶„ | 0.94-0.95 | 8GB | Essential | ê· í˜•ì  ì„±ëŠ¥ |
| **ğŸ”€ K-fold ì•™ìƒë¸”** | ğŸ”„ 30ë¶„ | 0.95-0.97 | 16GB | Essential/Comp | ì•ˆì •ì  ê³ ì„±ëŠ¥ |
| **ğŸ­ ë‹¤ì¤‘ ëª¨ë¸** | ğŸ† 60ë¶„ | 0.96-0.99 | 24GB+ | Comprehensive | ëŒ€íšŒ ìš°ìŠ¹ìš© |

## ğŸš€ Quick Start

### ğŸ“¦ 1. í™˜ê²½ ì„¤ì •

```bash
# ì €ì¥ì†Œ í´ë¡ 
git clone <repository-url>
cd computer-vision-competition-1SEN

# Python í™˜ê²½ (pyenv ê¶Œì¥)
pyenv install 3.11.9
pyenv virtualenv 3.11.9 cv_py3_11_9
pyenv activate cv_py3_11_9
pip install -r requirements.txt
```

### ğŸ“ 2. ë°ì´í„° ì¤€ë¹„

```bash
# ë°ì´í„° êµ¬ì¡° í™•ì¸
data/raw/
â”œâ”€â”€ train/          # í•™ìŠµ ì´ë¯¸ì§€ (17ê°œ í´ë˜ìŠ¤)
â”œâ”€â”€ test/           # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€
â”œâ”€â”€ train.csv       # í•™ìŠµ ë¼ë²¨
â””â”€â”€ sample_submission.csv  # ì œì¶œ í˜•ì‹
```

### âš¡ 3. ì „ëµë³„ ì‹¤í–‰ ê°€ì´ë“œ

#### ğŸ“ ë¹ ë¥¸ ê²€ì¦ (30ë¶„)
```bash
# ë‹¨ì¼ í´ë“œ ê¸°ë³¸ í•™ìŠµ + ì¶”ë¡ 
python src/training/train_main.py --config configs/train.yaml --mode basic
python src/inference/infer_main.py --config configs/infer.yaml --mode basic
# ì˜ˆìƒ F1: 0.920-0.930
```

#### ğŸ”€ ì•ˆì •ì  ê³ ì„±ëŠ¥ (2ì‹œê°„, ì¶”ì²œ)
```bash
# K-fold êµì°¨ê²€ì¦ + Essential TTA
python src/training/train_main.py --config configs/train_highperf.yaml --mode highperf
python src/inference/infer_main.py --config configs/infer_highperf.yaml --mode highperf \
    --fold-results experiments/train/latest-train/fold_results.yaml
# ì˜ˆìƒ F1: 0.950-0.965
```

#### ğŸ­ ìµœê³  ì„±ëŠ¥ ë‹¬ì„± (4ì‹œê°„+)
```bash
# ë‹¤ì¤‘ ëª¨ë¸ ì•™ìƒë¸” + Comprehensive TTA
python src/training/train_main.py --config configs/train_multi_model_ensemble.yaml --mode highperf
python src/inference/infer_main.py --config configs/infer_multi_model_ensemble.yaml --mode highperf
# ì˜ˆìƒ F1: 0.965-0.980+
```

#### ğŸ” ìš°ìŠ¹ ìˆ˜ì¤€ (6ì‹œê°„+, Optuna)
```bash
# ì „ì²´ ìµœì í™” íŒŒì´í”„ë¼ì¸
python src/training/train_main.py \
    --config configs/train_multi_model_ensemble.yaml \
    --mode full-pipeline \
    --optimize --n-trials 50 \
    --use-calibration \
    --auto-continue
# ì˜ˆìƒ F1: 0.970-0.990+
```

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
computer-vision-competition-1SEN/
â”œâ”€â”€ ğŸ“Š ë°ì´í„° ë° ì„¤ì •
â”‚   â”œâ”€â”€ data/raw/                           # ì›ë³¸ ë°ì´í„° (ì´ë¯¸ì§€ + CSV)
â”‚   â”œâ”€â”€ configs/                            # ì„¤ì • íŒŒì¼ ëª¨ìŒ
â”‚   â”‚   â”œâ”€â”€ train.yaml                      # ë‹¨ì¼ í´ë“œ ê¸°ë³¸ ì„¤ì •
â”‚   â”‚   â”œâ”€â”€ train_highperf.yaml             # K-fold ê³ ì„±ëŠ¥ ì„¤ì •  
â”‚   â”‚   â”œâ”€â”€ train_multi_model_ensemble.yaml # ë‹¤ì¤‘ ëª¨ë¸ ì„¤ì •
â”‚   â”‚   â”œâ”€â”€ infer_highperf.yaml             # ê³ ì„±ëŠ¥ ì¶”ë¡  ì„¤ì •
â”‚   â”‚   â”œâ”€â”€ infer_multi_model_ensemble.yaml # ë‹¤ì¤‘ ëª¨ë¸ ì¶”ë¡  ì„¤ì •
â”‚   â”‚   â””â”€â”€ optuna_config.yaml              # ìµœì í™” ì„¤ì •
â”‚   
â”œâ”€â”€ ğŸ§  í•µì‹¬ ì†ŒìŠ¤ì½”ë“œ
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ training/                       # í•™ìŠµ ì‹œìŠ¤í…œ
â”‚   â”‚   â”‚   â”œâ”€â”€ train_main.py              # ë©”ì¸ CLI ì¸í„°í˜ì´ìŠ¤
â”‚   â”‚   â”‚   â”œâ”€â”€ train.py                   # ê¸°ë³¸ í•™ìŠµ (ë‹¨ì¼/K-fold)
â”‚   â”‚   â”‚   â””â”€â”€ train_highperf.py          # ê³ ì„±ëŠ¥ í•™ìŠµ
â”‚   â”‚   â”œâ”€â”€ inference/                      # ì¶”ë¡  ì‹œìŠ¤í…œ  
â”‚   â”‚   â”‚   â”œâ”€â”€ infer_main.py              # ë©”ì¸ CLI ì¸í„°í˜ì´ìŠ¤
â”‚   â”‚   â”‚   â”œâ”€â”€ infer.py                   # ë‹¨ì¼ ëª¨ë¸ ì¶”ë¡ 
â”‚   â”‚   â”‚   â”œâ”€â”€ infer_highperf.py          # K-fold ì•™ìƒë¸” ì¶”ë¡ 
â”‚   â”‚   â”‚   â””â”€â”€ infer_calibrated.py        # ë³´ì •ëœ ì¶”ë¡ 
â”‚   â”‚   â”œâ”€â”€ models/build.py                 # ëª¨ë¸ ì•„í‚¤í…ì²˜ ë¹Œë”
â”‚   â”‚   â”œâ”€â”€ data/                          # ë°ì´í„° ì²˜ë¦¬
â”‚   â”‚   â”‚   â”œâ”€â”€ dataset.py                 # ë°ì´í„° ë¡œë”
â”‚   â”‚   â”‚   â””â”€â”€ transforms.py              # TTA + ì¦ê°•
â”‚   â”‚   â”œâ”€â”€ optimization/optuna_optimize.py # í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”
â”‚   â”‚   â”œâ”€â”€ calibration/calibrate.py       # Temperature Scaling
â”‚   â”‚   â”œâ”€â”€ pipeline/full_pipeline.py      # í†µí•© íŒŒì´í”„ë¼ì¸
â”‚   â”‚   â””â”€â”€ utils/                         # ìœ í‹¸ë¦¬í‹°
â”‚   â”‚       â”œâ”€â”€ gpu_optimization/          # GPU ìµœì í™”
â”‚   â”‚       â”œâ”€â”€ logging/                   # ë¡œê¹… ì‹œìŠ¤í…œ
â”‚   â”‚       â””â”€â”€ visualizations/            # ì‹œê°í™”
â”‚
â”œâ”€â”€ ğŸ“¤ ê²°ê³¼ ë° ë¡œê·¸
â”‚   â”œâ”€â”€ experiments/train/YYYYMMDD/         # í•™ìŠµ ê²°ê³¼ (ëª¨ë¸ + ë©”íƒ€ë°ì´í„°)
â”‚   â”œâ”€â”€ submissions/YYYYMMDD/               # ì¶”ë¡  ê²°ê³¼ (CSV íŒŒì¼)
â”‚   â”œâ”€â”€ logs/YYYYMMDD/                     # ìƒì„¸ ë¡œê·¸
â”‚   â””â”€â”€ wandb/                             # WandB ì‹¤í—˜ ì¶”ì 
â”‚
â”œâ”€â”€ ğŸ“š ë¬¸ì„œí™”
â”‚   â”œâ”€â”€ docs/íŒŒì´í”„ë¼ì¸/
â”‚   â”‚   â”œâ”€â”€ í•™ìŠµ_íŒŒì´í”„ë¼ì¸_ê°€ì´ë“œ.md        # í•™ìŠµ ì „ëµ ìƒì„¸ ê°€ì´ë“œ  
â”‚   â”‚   â”œâ”€â”€ ì¶”ë¡ _íŒŒì´í”„ë¼ì¸_ê°€ì´ë“œ.md        # ì¶”ë¡  ì „ëµ ìƒì„¸ ê°€ì´ë“œ
â”‚   â”‚   â””â”€â”€ ì „ì²´_íŒŒì´í”„ë¼ì¸_ê°€ì´ë“œ.md        # í†µí•© ê°€ì´ë“œ
â”‚   â””â”€â”€ docs/ìµœì í™”/                       # ì„±ëŠ¥ ìµœì í™” ê°€ì´ë“œ
â”‚
â””â”€â”€ ğŸ”§ ê¸°íƒ€
    â”œâ”€â”€ notebooks/team/                     # íŒ€ë³„ ì‹¤í—˜ ë…¸íŠ¸ë¶
    â”œâ”€â”€ scripts/                           # í¸ì˜ ìŠ¤í¬ë¦½íŠ¸  
    â””â”€â”€ requirements.txt                   # Python ì˜ì¡´ì„±
```

## ğŸ¨ ì§€ì›í•˜ëŠ” ê³ ê¸‰ ê¸°ë²•

### ğŸ§  ëª¨ë¸ ì•„í‚¤í…ì²˜
- **ConvNeXt Base 384**: ImageNet-22k ì‚¬ì „í•™ìŠµ, ìµœê³  ì„±ëŠ¥
- **Swin Transformer**: Vision Transformer ê¸°ë°˜, ë‹¤ì–‘ì„± í™•ë³´
- **EfficientNet V2**: íš¨ìœ¨ì„±ê³¼ ì„±ëŠ¥ì˜ ê· í˜•

### ğŸ¨ ë°ì´í„° ì¦ê°•
- **Hard Augmentation**: ë™ì  í™•ë¥  ìŠ¤ì¼€ì¤„ë§
- **Mixup & CutMix**: ë°ì´í„° ë¯¹ì‹± ê¸°ë²•
- **Essential TTA**: 5ê°€ì§€ í•µì‹¬ ë³€í™˜ (íšŒì „ + ë°ê¸°)
- **Comprehensive TTA**: 15ê°€ì§€ í¬ê´„ ë³€í™˜ (ë¸”ëŸ¬, ë…¸ì´ì¦ˆ ë“±)

### ğŸ” ìµœì í™” ê¸°ë²•
- **Optuna ë² ì´ì§€ì•ˆ ìµœì í™”**: í•˜ì´í¼íŒŒë¼ë¯¸í„° ìë™ íŠœë‹
- **Temperature Scaling**: í™•ë¥  ë³´ì • ë° ì‹ ë¢°ë„ í–¥ìƒ
- **GPU ë©”ëª¨ë¦¬ ìµœì í™”**: ìë™ ë°°ì¹˜ í¬ê¸° ì¡°ì •
- **Early Stopping**: ê³¼ì í•© ë°©ì§€

### ğŸ”„ ì•™ìƒë¸” ì „ëµ
- **K-Fold ì•™ìƒë¸”**: 5ê°œ ëª¨ë¸ ê°€ì¤‘ í‰ê· 
- **ë‹¤ì¤‘ ëª¨ë¸ ì•™ìƒë¸”**: ì„œë¡œ ë‹¤ë¥¸ ì•„í‚¤í…ì²˜ ì¡°í•©
- **TTA ì•™ìƒë¸”**: ì—¬ëŸ¬ ë³€í™˜ ê²°ê³¼ í†µí•©

## ğŸ”§ CLI ëª…ë ¹ì–´ ë ˆí¼ëŸ°ìŠ¤

### í•™ìŠµ ëª…ë ¹ì–´
```bash
# ê¸°ë³¸ í•™ìŠµ
python src/training/train_main.py --config configs/train.yaml --mode basic

# ê³ ì„±ëŠ¥ í•™ìŠµ (K-fold)
python src/training/train_main.py --config configs/train_highperf.yaml --mode highperf

# ë‹¤ì¤‘ ëª¨ë¸ ì•™ìƒë¸”
python src/training/train_main.py --config configs/train_multi_model_ensemble.yaml --mode highperf

# Optuna ìµœì í™”
python src/training/train_main.py --config configs/train.yaml --optimize --n-trials 20

# ì „ì²´ íŒŒì´í”„ë¼ì¸ (ì¶”ì²œ)
python src/training/train_main.py \
    --config configs/train_highperf.yaml \
    --mode full-pipeline \
    --use-calibration
```

### ì¶”ë¡  ëª…ë ¹ì–´
```bash
# ë‹¨ì¼ ëª¨ë¸ ì¶”ë¡ 
python src/inference/infer_main.py --config configs/infer.yaml --mode basic

# K-fold ì•™ìƒë¸” ì¶”ë¡ 
python src/inference/infer_main.py \
    --config configs/infer_highperf.yaml \
    --mode highperf \
    --fold-results experiments/train/latest-train/fold_results.yaml

# ë‹¤ì¤‘ ëª¨ë¸ ì•™ìƒë¸” ì¶”ë¡ 
python src/inference/infer_main.py \
    --config configs/infer_multi_model_ensemble.yaml \
    --mode highperf
```

## ğŸ“Š ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬

### ğŸ† ìµœê³  ì„±ëŠ¥ ê¸°ë¡

| ìˆœìœ„ | F1 Score | ì „ëµ | ëª¨ë¸ | ì‹œê°„ | íŠ¹ì§• |
|-----|----------|------|------|------|------|
| ğŸ¥‡ | **0.9836** | Team ìµœì í™” | ConvNeXt Base 384 | 23ë¶„ | Optuna + Hard Aug |
| ğŸ¥ˆ | 0.9791 | K-fold CV | ConvNeXt Base 384 | 2ì‹œê°„ | 5-fold ì•ˆì •ì„± |
| ğŸ¥‰ | 0.9705 | ë‹¤ì¤‘ ëª¨ë¸ | Multi-Architecture | 4ì‹œê°„ | 3ëª¨ë¸ ì•™ìƒë¸” |

### âš¡ ì†ë„ vs ì„±ëŠ¥ íŠ¸ë ˆì´ë“œì˜¤í”„

```mermaid
graph LR
    A[ğŸ“ ë‹¨ì¼ í´ë“œ<br/>30ë¶„, F1: 0.93] --> B[ğŸ”€ K-fold<br/>2ì‹œê°„, F1: 0.96]
    B --> C[ğŸ­ ë‹¤ì¤‘ëª¨ë¸<br/>4ì‹œê°„, F1: 0.97]
    C --> D[ğŸ” Optuna<br/>6ì‹œê°„, F1: 0.98+]
    
    style A fill:#e1f5fe, color:#000000
    style B fill:#e8f5e8, color:#000000
    style C fill:#f3e5f5, color:#000000
    style D fill:#fff3e0, color:#000000
```

## ğŸ” ëª¨ë‹ˆí„°ë§ ë° ë””ë²„ê¹…

### ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§
```bash
# í•™ìŠµ ë¡œê·¸ ì‹¤ì‹œê°„ í™•ì¸
tail -f logs/$(date +%Y%m%d)/train/*.log

# GPU ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§
watch -n 1 nvidia-smi

# WandB ëŒ€ì‹œë³´ë“œ
wandb server  # localhost:8080
```

### ê²°ê³¼ ë¶„ì„
```bash
# ìµœì‹  ì‹¤í—˜ ê²°ê³¼ í™•ì¸
ls -la experiments/train/$(date +%Y%m%d)/

# ì„±ëŠ¥ ìš”ì•½
find experiments/train -name "fold_results.yaml" -exec grep "best_f1" {} \; | head -10

# ì œì¶œ íŒŒì¼ ê²€ì¦
python -c "
import pandas as pd
df = pd.read_csv('submissions/latest/final_submission.csv')
print(f'Shape: {df.shape}, Missing: {df.isnull().sum().sum()}')
"
```

## âš ï¸ ì£¼ì˜ì‚¬í•­ ë° íŒ

### GPU ë©”ëª¨ë¦¬ ìµœì í™”
```bash
# ë©”ëª¨ë¦¬ ë¶€ì¡± ì‹œ ìë™ ë°°ì¹˜ í¬ê¸° ì¡°ì •
python src/utils/gpu_optimization/auto_batch_size.py --config configs/train_highperf.yaml

# ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì— ë”°ë¥¸ ì„¤ì • ì¡°ì •
# RTX 3080 (10GB): batch_size: 32, img_size: 320
# RTX 4090 (24GB): batch_size: 64, img_size: 384
```

### ì„±ëŠ¥ ìµœì í™” íŒ
- **ë‹¨ì¼ í´ë“œ**: ë¹ ë¥¸ ì‹¤í—˜, í•˜ì´í¼íŒŒë¼ë¯¸í„° íƒìƒ‰
- **K-fold**: ì•ˆì •ì  ì„±ëŠ¥, ìµœì¢… ì œì¶œìš©
- **ë‹¤ì¤‘ ëª¨ë¸**: ìµœê³  ì„±ëŠ¥, ëŒ€íšŒ ìš°ìŠ¹ìš©
- **Optuna**: ì‹œê°„ ì—¬ìœ  ìˆì„ ë•Œ, ìë™ ìµœì í™”

### ì¼ë°˜ì ì¸ ë¬¸ì œ í•´ê²°
```bash
# CUDA ë©”ëª¨ë¦¬ ë¶€ì¡±
export CUDA_VISIBLE_DEVICES=0,1  # ë©€í‹° GPU ì‚¬ìš©

# ë””ìŠ¤í¬ ê³µê°„ ë¶€ì¡±
rm -rf wandb/  # WandB ë¡œê·¸ ì •ë¦¬
rm -rf experiments/train/2025090*/  # ì˜¤ë˜ëœ ì‹¤í—˜ ì •ë¦¬

# íŒ¨í‚¤ì§€ ì¶©ëŒ
pip install --force-reinstall torch torchvision
```

## ğŸ¤ Contributing / ê¸°ì—¬í•˜ê¸°

1. íŒ€ Repo -> ê°œì¸ Repo í¬í¬
2. ê¸°ëŠ¥ ë¸Œëœì¹˜ë¥¼ ìƒì„±í•˜ì„¸ìš” (`git checkout -b feature/ê¸°ëŠ¥ëª…`)
3. ë³€ê²½ì‚¬í•­ì„ ì»¤ë°‹í•˜ì„¸ìš” (`git commit -m 'feat: ì»¤ë°‹ ë‚´ìš©'`)
4. ë¸Œëœì¹˜ì— í‘¸ì‹œí•˜ì„¸ìš” (`git push origin feature/ê¸°ëŠ¥ëª…`)
5. ê°œì¸ Repo -> íŒ€ Repoë¡œ Pull Request


## ğŸ™ Acknowledgments

- **ConvNeXt Base 384**: F1 0.98362 ë‹¬ì„±ì˜ í•µì‹¬ ëª¨ë¸
- **Optuna**: í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” í”„ë ˆì„ì›Œí¬
- **ë‹¨ì¼ í´ë“œ ìµœì í™”**: ê²½ì§„ëŒ€íšŒë¥¼ ìœ„í•œ ê³ ì† ìµœì í™” ì „ëµ  
- **ë°ì´í„°ì…‹ ìºì‹±**: ë§¤ trial 2ì´ˆ ë‹¬ì„±ì˜ í•µì‹¬ ê¸°ìˆ 
- **WandB**: 100+ ì‹¤í—˜ ì¶”ì  ë° ì‹œê°í™”