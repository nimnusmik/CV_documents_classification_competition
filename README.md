# ğŸ† Computer Vision Competition

## Team

| í”„ë¡œí•„ | ì´ë¦„ (ê¹ƒí—ˆë¸Œ) | MBTI | ì „ê³µ/í•™ê³¼ | ë‹´ë‹¹ ì—­í•  |
|:------:|:-------------:|:----:|:---------:|:----------|
| <img src="https://github.com/user-attachments/assets/a24cf78c-2c8f-47b9-b53b-867557872d88" width="200" height="200"> | [ê¹€ì„ ë¯¼](https://github.com/nimnusmik) | ENFJ | ê²½ì˜&AI ìœµí•© í•™ë¶€ | íŒ€ ë¦¬ë“œ, EDA/ëª¨ë¸ë§, ì„±ëŠ¥ ê³ ë„í™” |
| <img src="https://github.com/user-attachments/assets/489d401e-f5f5-4998-91a0-3b0f37f4490f" width="200" height="200"> | [ê¹€ë³‘í˜„](https://github.com/Bkankim) | ENFP | ì •ë³´ë³´ì•ˆ | ì „ì²˜ë¦¬, ì‹œìŠ¤í…œ/ëª¨ë¸ ê°œë°œ, ì„±ëŠ¥ ê³ ë„í™” |
| <img src="https://github.com/user-attachments/assets/55180131-9401-457e-a600-312eda87ded9" width="200" height="200"> | [ì„ì˜ˆìŠ¬](https://github.com/joy007fun/joy007fun) | ENTP | ê´€ê´‘ê²½ì˜&ì»´í“¨í„°ê³µí•™, í´ë¼ìš°ë“œ ì¸í”„ë¼ | EDA/ëª¨ë¸ë§, ì„±ëŠ¥ ê³ ë„í™” |
| <img src="https://github.com/user-attachments/assets/10a2c088-72cb-45cd-8772-b683bc2fb550" width="200" height="200"> | [ì •ì„œìš°](https://github.com/Seowoo-C) | INFJ | í™”í•™ | EDA/ëª¨ë¸ë§, ì„±ëŠ¥ ê³ ë„í™” |
| <img src="https://github.com/user-attachments/assets/5c04a858-46ed-4043-9762-b7eaf7b1149a" width="200" height="200"> | [ìµœí˜„í™”](https://github.com/AIBootcamp14/computervisioncompetition-cv-1) | ISTP | ML&AI/ì»´í“¨í„°ê³µí•™ | EDA/ëª¨ë¸ë§, ì„±ëŠ¥ ê³ ë„í™”, ëª¨ë“ˆí™” ì„¤ê³„/êµ¬í˜„, Git ë¸Œëœì¹˜Â·ë³‘í•©Â·ì¶©ëŒ ê´€ë¦¬ |


## ğŸ† ê²½ì§„ëŒ€íšŒ ê²°ê³¼ (2ë“±)
<img width="990" height="560" alt="Image" src="https://github.com/user-attachments/assets/1730d221-ab6b-46ea-b94e-0afbc33d4ea2" />

## ğŸ“‹ í”„ë¡œì íŠ¸ ê°œìš”

Computer Vision ê²½ì§„ëŒ€íšŒ í”„ë ˆì„ì›Œí¬ë¡œ, ë‹¨ì¼ í´ë“œë¶€í„° ë‹¤ì¤‘ ëª¨ë¸ ì•™ìƒë¸”ê¹Œì§€ ë‹¤ì–‘í•œ ì „ëµì„ ì§€ì›í•©ë‹ˆë‹¤.

### ğŸ¯ í•µì‹¬ íŠ¹ì§•
- ğŸ† **ìµœê³  ì„±ëŠ¥**: **F1 Score 0.9750+** ë‹¬ì„± (ë‹¤ì¤‘ ëª¨ë¸ ì•™ìƒë¸”)
- âš¡ **ìœ ì—°í•œ êµ¬ì¡°**: ë‹¨ì¼ í´ë“œ â†” K-Fold â†” ë‹¤ì¤‘ëª¨ë¸ ì›í´ë¦­ ì „í™˜
- ğŸ¤– **ì™„ì „ ìë™í™”**: í•™ìŠµ â†’ ìµœì í™” â†’ ì¶”ë¡  â†’ ì œì¶œ ì „ ê³¼ì • ìë™í™”
- ğŸ§  **ì§€ëŠ¥í˜• ìµœì í™”**: Optuna ë² ì´ì§€ì•ˆ ìµœì í™” + Temperature Scaling
- ğŸ¨ **ê³ ê¸‰ TTA**: Essential(5ê°€ì§€) / Comprehensive(15ê°€ì§€) ë³€í™˜
- ğŸ“Š **ì²´ê³„ì  ì¶”ì **: WandB í†µí•© + 200+ ì‹¤í—˜ ê¸°ë¡

---

## ğŸ—ï¸ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

### ì „ì²´ íŒŒì´í”„ë¼ì¸ ì•„í‚¤í…ì²˜
<img width="3840" height="3707" alt="Image" src="https://github.com/user-attachments/assets/9fef3942-03b5-4569-8811-4dea79d8ecd5" />

### í•™ìŠµ íŒŒì´í”„ë¼ì¸ ì•„í‚¤í…ì²˜
<img width="3018" height="3840" alt="Image" src="https://github.com/user-attachments/assets/b4fb17e4-dd88-4fa3-9e14-7719cb3b2340" />

### ì¶”ë¡  íŒŒì´í”„ë¼ì¸ ì•„í‚¤í…ì²˜
<img width="3840" height="1024" alt="Image" src="https://github.com/user-attachments/assets/0e4e6777-537c-4421-b171-2578a37414c8" />

## ğŸ“Š ì„±ëŠ¥ ë¹„êµ ë° ì „ëµ ë¶„ì„

### ğŸ¯ í•™ìŠµ ì „ëµë³„ ì„±ëŠ¥ ë¹„êµ

| í•™ìŠµ ì „ëµ | ì†ë„ | ì˜ˆìƒ F1 | GPU ë©”ëª¨ë¦¬ | ì „ëµ íŠ¹ì§• | ìµœì  í™œìš© ìƒí™© |
|-----------|------|---------|-----------|----------|---------------|
| **ğŸ“ ë‹¨ì¼ í´ë“œ** | âš¡ 30ë¶„ | 0.92-0.95 | 8GB | ë¹ ë¥¸ í”„ë¡œí† íƒ€ì… | ì´ˆê¸° ì‹¤í—˜, ë¹ ë¥¸ ê²€ì¦ |
| **ğŸ”€ K-fold CV** | ğŸ•°ï¸ 2ì‹œê°„ | 0.95-0.98 | 16GB | ì•ˆì •ì„± í™•ë³´ | ìµœì¢… ì œì¶œ, ëŒ€íšŒìš© |
| **ğŸ­ ë‹¤ì¤‘ ëª¨ë¸** | ğŸ”„ 3ì‹œê°„ | 0.96-0.99 | 24GB+ | ë‹¤ì–‘ì„± ê·¹ëŒ€í™” | ê³ ì‚¬ì–‘ GPU, ìš°ìŠ¹ìš© |
| **ğŸ” Optuna ìµœì í™”** | ğŸ† 5ì‹œê°„ | 0.97-0.99+ | 16GB | ìë™ íŠœë‹ | ì‹œê°„ ì—¬ìœ , ìµœê³  ì„±ëŠ¥ |

### ğŸ† ì¶”ë¡  ì „ëµë³„ ì„±ëŠ¥ ë¹„êµ

| ì¶”ë¡  ì „ëµ | ì†ë„ | ì˜ˆìƒ F1 | GPU ë©”ëª¨ë¦¬ | TTA ì „ëµ | ìµœì  í™œìš© ìƒí™© |
|-----------|------|---------|-----------|----------|---------------|
| **ğŸ“ ë‹¨ì¼ ëª¨ë¸ ì¶”ë¡ ** | âš¡ 5ë¶„ | 0.92-0.93 | 4-6GB | No TTA | ì´ˆê¸° ê²€ì¦, ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ |
| **ğŸ¯ ë‹¨ì¼ ëª¨ë¸ + TTA** | ğŸ•°ï¸ 17ë¶„ | 0.94-0.95 | 8GB | Essential | ê· í˜•ì  ì„±ëŠ¥ |
| **ğŸ”€ K-fold ì•™ìƒë¸”** | ğŸ”„ 30ë¶„ | 0.95-0.97 | 16GB | Essential/Comp | ì•ˆì •ì  ê³ ì„±ëŠ¥ |
| **ğŸ­ ë‹¤ì¤‘ ëª¨ë¸** | ğŸ† 60ë¶„ | 0.96-0.99 | 24GB+ | Comprehensive | ëŒ€íšŒ ìš°ìŠ¹ìš© |

## ğŸš€ Quick Start

### ğŸ“¦ 1. í™˜ê²½ ì„¤ì •

```bash
# ì €ì¥ì†Œ í´ë¡ 
git clone <repository-url>
cd computer-vision-competition-1SEN

# Python í™˜ê²½ (pyenv ê¶Œì¥)
pyenv install 3.11.9
pyenv virtualenv 3.11.9 cv_py3_11_9
pyenv activate cv_py3_11_9
pip install -r requirements.txt
```

### ğŸ“ 2. ë°ì´í„° ì¤€ë¹„

```bash
# ë°ì´í„° êµ¬ì¡° í™•ì¸
data/raw/
â”œâ”€â”€ train/          # í•™ìŠµ ì´ë¯¸ì§€ (17ê°œ í´ë˜ìŠ¤)
â”œâ”€â”€ test/           # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€
â”œâ”€â”€ train.csv       # í•™ìŠµ ë¼ë²¨
â””â”€â”€ sample_submission.csv  # ì œì¶œ í˜•ì‹
```

### âš¡ 3. ì „ëµë³„ ì‹¤í–‰ ê°€ì´ë“œ

#### ğŸ“ ë¹ ë¥¸ ê²€ì¦ (30ë¶„)
```bash
# ë‹¨ì¼ í´ë“œ ê¸°ë³¸ í•™ìŠµ + ì¶”ë¡ 
python src/training/train_main.py --config configs/train.yaml --mode basic
python src/inference/infer_main.py --config configs/infer.yaml --mode basic
# ì˜ˆìƒ F1: 0.920-0.930
```

#### ğŸ”€ ì•ˆì •ì  ê³ ì„±ëŠ¥ (2ì‹œê°„, ì¶”ì²œ)
```bash
# K-fold êµì°¨ê²€ì¦ + Essential TTA
python src/training/train_main.py --config configs/train_highperf.yaml --mode highperf
python src/inference/infer_main.py --config configs/infer_highperf.yaml --mode highperf \
    --fold-results experiments/train/latest-train/fold_results.yaml
# ì˜ˆìƒ F1: 0.950-0.965
```

#### ğŸ­ ìµœê³  ì„±ëŠ¥ ë‹¬ì„± (4ì‹œê°„+)
```bash
# ë‹¤ì¤‘ ëª¨ë¸ ì•™ìƒë¸” + Comprehensive TTA
python src/training/train_main.py --config configs/train_multi_model_ensemble.yaml --mode highperf
python src/inference/infer_main.py --config configs/infer_multi_model_ensemble.yaml --mode highperf
# ì˜ˆìƒ F1: 0.965-0.980+
```

#### ğŸ” ìš°ìŠ¹ ìˆ˜ì¤€ (6ì‹œê°„+, Optuna)
```bash
# ì „ì²´ ìµœì í™” íŒŒì´í”„ë¼ì¸
python src/training/train_main.py \
    --config configs/train_multi_model_ensemble.yaml \
    --mode full-pipeline \
    --optimize --n-trials 50 \
    --use-calibration \
    --auto-continue
# ì˜ˆìƒ F1: 0.970-0.990+
```

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
computer-vision-competition-1SEN/
â”œâ”€â”€ ğŸ“Š ë°ì´í„° ë° ì„¤ì •
â”‚   â”œâ”€â”€ data/raw/                           # ì›ë³¸ ë°ì´í„° (17í´ë˜ìŠ¤ ë¶„ë¥˜)
â”‚   â”‚   â”œâ”€â”€ train/                          # í•™ìŠµ ì´ë¯¸ì§€ (1570ê°œ)
â”‚   â”‚   â”œâ”€â”€ test/                           # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€
â”‚   â”‚   â”œâ”€â”€ train.csv                       # í•™ìŠµ ë¼ë²¨
â”‚   â”‚   â””â”€â”€ sample_submission.csv           # ì œì¶œ í˜•ì‹
â”‚   â”œâ”€â”€ configs/                            # ì„¤ì • íŒŒì¼ ëª¨ìŒ (ë‚ ì§œë³„ ë°±ì—…)
â”‚   â”‚   â”œâ”€â”€ train.yaml                      # ë‹¨ì¼ í´ë“œ ê¸°ë³¸ ì„¤ì •
â”‚   â”‚   â”œâ”€â”€ train_highperf.yaml             # K-fold ê³ ì„±ëŠ¥ ì„¤ì •  
â”‚   â”‚   â”œâ”€â”€ train_multi_model_ensemble.yaml # ë‹¤ì¤‘ ëª¨ë¸ ì„¤ì •
â”‚   â”‚   â”œâ”€â”€ infer_highperf.yaml             # ê³ ì„±ëŠ¥ ì¶”ë¡  ì„¤ì •
â”‚   â”‚   â”œâ”€â”€ infer_multi_model_ensemble.yaml # ë‹¤ì¤‘ ëª¨ë¸ ì¶”ë¡  ì„¤ì •
â”‚   â”‚   â”œâ”€â”€ optuna_config.yaml              # ìµœì í™” ì„¤ì •
â”‚   â”‚   â”œâ”€â”€ 20250909/                       # ì‹¤í—˜ ì„¤ì • ë°±ì—…
â”‚   â”‚   â”œâ”€â”€ 20250910/                       # F1 0.98362 ë‹¬ì„± ì„¤ì •
â”‚   â”‚   â””â”€â”€ 20250911/                       # ìµœì‹  ì‹¤í—˜ ì„¤ì •
â”‚   
â”œâ”€â”€ ğŸ§  í•µì‹¬ ì†ŒìŠ¤ì½”ë“œ (54ê°œ íŒŒì¼)
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ training/                       # í•™ìŠµ ì‹œìŠ¤í…œ
â”‚   â”‚   â”‚   â”œâ”€â”€ train_main.py              # ğŸš€ í†µí•© CLI ì¸í„°í˜ì´ìŠ¤
â”‚   â”‚   â”‚   â”œâ”€â”€ train.py                   # ê¸°ë³¸ í•™ìŠµ (ë‹¨ì¼/K-fold)
â”‚   â”‚   â”‚   â””â”€â”€ train_highperf.py          # ê³ ì„±ëŠ¥ í•™ìŠµ (Mixup, Hard Aug)
â”‚   â”‚   â”œâ”€â”€ inference/                      # ì¶”ë¡  ì‹œìŠ¤í…œ  
â”‚   â”‚   â”‚   â”œâ”€â”€ infer_main.py              # ì¶”ë¡  CLI ì¸í„°í˜ì´ìŠ¤
â”‚   â”‚   â”‚   â”œâ”€â”€ infer.py                   # ë‹¨ì¼ ëª¨ë¸ ì¶”ë¡ 
â”‚   â”‚   â”‚   â”œâ”€â”€ infer_highperf.py          # K-fold ì•™ìƒë¸” ì¶”ë¡ 
â”‚   â”‚   â”‚   â””â”€â”€ infer_calibrated.py        # Temperature Scaling ì¶”ë¡ 
â”‚   â”‚   â”œâ”€â”€ models/                         # ëª¨ë¸ ì•„í‚¤í…ì²˜ (10ê°œ ì§€ì›)
â”‚   â”‚   â”‚   â””â”€â”€ build.py                   # RECOMMENDED_MODELS ë ˆì§€ìŠ¤íŠ¸ë¦¬
â”‚   â”‚   â”œâ”€â”€ data/                          # ë°ì´í„° ì²˜ë¦¬
â”‚   â”‚   â”‚   â”œâ”€â”€ dataset.py                 # HighPerfDocClsDataset + Mixup
â”‚   â”‚   â”‚   â””â”€â”€ transforms.py              # Essential/Comprehensive TTA
â”‚   â”‚   â”œâ”€â”€ optimization/                   # í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”
â”‚   â”‚   â”‚   â”œâ”€â”€ optuna_optimize.py         # Optuna ìë™ íŠœë‹
â”‚   â”‚   â”‚   â””â”€â”€ optuna_tuner.py            # ìºì‹±ëœ ìµœì í™” (2ì´ˆ/trial)
â”‚   â”‚   â”œâ”€â”€ calibration/                    # ëª¨ë¸ ìº˜ë¦¬ë¸Œë ˆì´ì…˜
â”‚   â”‚   â”‚   â””â”€â”€ calibrate.py               # Temperature Scaling
â”‚   â”‚   â”œâ”€â”€ pipeline/                       # í†µí•© íŒŒì´í”„ë¼ì¸
â”‚   â”‚   â”‚   â””â”€â”€ full_pipeline.py           # í•™ìŠµâ†’ì¶”ë¡  í†µí•© ì‹¤í–‰
â”‚   â”‚   â”œâ”€â”€ logging/                        # ë¡œê¹… ì‹œìŠ¤í…œ
â”‚   â”‚   â”‚   â”œâ”€â”€ wandb_logger.py            # WandB í†µí•© ë¡œê±°
â”‚   â”‚   â”‚   â””â”€â”€ logger.py                  # ê¸°ë³¸ ë¡œê±°
â”‚   â”‚   â”œâ”€â”€ metrics/                        # í‰ê°€ ë©”íŠ¸ë¦­
â”‚   â”‚   â”‚   â””â”€â”€ f1.py                      # F1 ìŠ¤ì½”ì–´ ê³„ì‚°
â”‚   â”‚   â””â”€â”€ utils/                         # ìœ í‹¸ë¦¬í‹° (23ê°œ íŒŒì¼)
â”‚   â”‚       â”œâ”€â”€ gpu_optimization/          # GPU ë©”ëª¨ë¦¬ ìë™ ìµœì í™”
â”‚   â”‚       â”œâ”€â”€ config/                    # ì„¤ì • ê´€ë¦¬
â”‚   â”‚       â”œâ”€â”€ visualizations/            # ìë™ ì‹œê°í™” ì‹œìŠ¤í…œ
â”‚   â”‚       â””â”€â”€ core/                      # í•µì‹¬ ìœ í‹¸ë¦¬í‹°
â”‚
â”œâ”€â”€ ğŸ“¤ ê²°ê³¼ ë° ë¡œê·¸ (ë‚ ì§œë³„ ì²´ê³„ ê´€ë¦¬)
â”‚   â”œâ”€â”€ experiments/                        # ì‹¤í—˜ ê²°ê³¼ ì €ì¥
â”‚   â”‚   â”œâ”€â”€ train/20250910/                 # ğŸ† F1 0.98362 ì‹¤í—˜ ê²°ê³¼
â”‚   â”‚   â”œâ”€â”€ optimization/                   # Optuna ìµœì í™” ê²°ê³¼
â”‚   â”‚   â””â”€â”€ infer/                          # ì¶”ë¡  ê²°ê³¼
â”‚   â”œâ”€â”€ submissions/                        # ì œì¶œ íŒŒì¼ (ë‚ ì§œë³„)
â”‚   â”‚   â”œâ”€â”€ 20250910/                       # ìµœê³  ì„±ëŠ¥ ì œì¶œ
â”‚   â”‚   â””â”€â”€ 20250911/                       # ìµœì‹  ì œì¶œ
â”‚   â”œâ”€â”€ logs/                              # ìƒì„¸ ë¡œê·¸ (ë‚ ì§œë³„)
â”‚   â”‚   â”œâ”€â”€ 20250910/train/                 # ìµœê³  ì„±ëŠ¥ ë‹¬ì„± ë¡œê·¸
â”‚   â”‚   â””â”€â”€ 20250911/                       # ìµœì‹  ì‹¤í—˜ ë¡œê·¸
â”‚   â””â”€â”€ wandb/                             # WandB ì‹¤í—˜ ì¶”ì  (100+ ì‹¤í—˜)
â”‚
â”œâ”€â”€ ğŸ“š í¬ê´„ì  ë¬¸ì„œí™” ì‹œìŠ¤í…œ (15ê°œ ë¬¸ì„œ, 8000+ ë¼ì¸)
â”‚   â”œâ”€â”€ docs/íŒŒì´í”„ë¼ì¸/                    # ğŸ“Š íŒŒì´í”„ë¼ì¸ ì•„í‚¤í…ì²˜
â”‚   â”‚   â”œâ”€â”€ í•™ìŠµ_íŒŒì´í”„ë¼ì¸_ê°€ì´ë“œ.md        # ë‹¨ì¼/K-fold/ë‹¤ì¤‘ëª¨ë¸ í•™ìŠµ
â”‚   â”‚   â”œâ”€â”€ ì¶”ë¡ _íŒŒì´í”„ë¼ì¸_ê°€ì´ë“œ.md        # TTA ì•™ìƒë¸” ì¶”ë¡  ì „ëµ
â”‚   â”‚   â””â”€â”€ ì „ì²´_íŒŒì´í”„ë¼ì¸_ê°€ì´ë“œ.md        # End-to-End ì›Œí¬í”Œë¡œìš°
â”‚   â”œâ”€â”€ docs/configs_í´ë”_ì„¤ì •_íŒŒì¼_ìƒì„±/     # âš™ï¸ ì„¤ì • íŒŒì¼ ìƒì„± ê°€ì´ë“œ
â”‚   â”‚   â”œâ”€â”€ í•™ìŠµ_ì„¤ì •_íŒŒì¼_ìƒì„±_ê°€ì´ë“œ.md     # í•™ìŠµ ì„¤ì • ì‘ì„±ë²•
â”‚   â”‚   â”œâ”€â”€ ì¶”ë¡ _ì„¤ì •_íŒŒì¼_ìƒì„±_ê°€ì´ë“œ.md     # ì¶”ë¡  ì„¤ì • ì‘ì„±ë²•
â”‚   â”‚   â””â”€â”€ ìµœì í™”_ì„¤ì •_íŒŒì¼_ìƒì„±_ê°€ì´ë“œ.md   # Optuna ì„¤ì • ì‘ì„±ë²•
â”‚   â”œâ”€â”€ docs/ëª¨ë¸/                         # ğŸ§  ëª¨ë¸ ì•„í‚¤í…ì²˜
â”‚   â”‚   â””â”€â”€ ëª¨ë¸_ì„¤ì •_ê°€ì´ë“œ.md             # 10ê°œ ëª¨ë¸ êµ¬ì„± ë° ì„±ëŠ¥ ë¹„êµ
â”‚   â”œâ”€â”€ docs/ìµœì í™”/                       # âš¡ ì„±ëŠ¥ ìµœì í™” ê¸°ë²•
â”‚   â”‚   â”œâ”€â”€ GPU_ìµœì í™”_ê°€ì´ë“œ.md           # í•˜ë“œì›¨ì–´ë³„ ë©”ëª¨ë¦¬ ìµœì í™”
â”‚   â”‚   â”œâ”€â”€ Optuna_ìµœì í™”_íš¨ê³¼_ë°_ì „ëµë¶„ì„.md # 150x ì†ë„ í–¥ìƒ ë¶„ì„
â”‚   â”‚   â””â”€â”€ ì‹œê°„_ìµœì í™”_ê°€ì´ë“œ.md           # í•™ìŠµ/ì¶”ë¡  ì‹œê°„ ìµœì í™”
â”‚   â”œâ”€â”€ docs/ì‹œìŠ¤í…œ/                       # ğŸ› ï¸ ì‹œìŠ¤í…œ ê´€ë¦¬
â”‚   â”‚   â”œâ”€â”€ ê¸°ë³¸_vs_ê³ ì„±ëŠ¥_íŒŒì´í”„ë¼ì¸_ë¹„êµë¶„ì„.md # ì„±ëŠ¥ ì°¨ì´ ìƒì„¸ ë¶„ì„
â”‚   â”‚   â”œâ”€â”€ ë¬¸ì œí•´ê²°_ê°€ì´ë“œ.md              # íŠ¸ëŸ¬ë¸”ìŠˆíŒ… ê°€ì´ë“œ
â”‚   â”‚   â””â”€â”€ ì‹œê°í™”_ì‹œìŠ¤í…œ_ê°€ì´ë“œ.md         # ìë™ ì‹œê°í™” ì‹œìŠ¤í…œ
â”‚   â”œâ”€â”€ docs/ì „ëµë¶„ì„/                     # ğŸ¯ ì „ëµ ë¶„ì„
â”‚   â”‚   â””â”€â”€ ë‹¨ì¼í´ë“œ_ê³¼ì í•©_ìœ„í—˜_ë°_ëŒ€ì‘ì „ëµ.md # ë‹¨ì¼ í´ë“œ vs K-fold ë¶„ì„
â”‚   â”œâ”€â”€ docs/í•™ìŠµê²°ê³¼/                     # ğŸ“ˆ í•™ìŠµ ê²°ê³¼ ë¶„ì„
â”‚   â”‚   â””â”€â”€ ConvNeXt_ìµœê³ ì„±ëŠ¥_í•™ìŠµê²°ê³¼_ë¶„ì„_20250910.md # F1 0.98362 ë‹¬ì„± ë¶„ì„
â”‚   â”œâ”€â”€ docs/ëŒ€íšŒì „ëµë¶„ì„/                 # ğŸ† ê²½ì§„ëŒ€íšŒ ì „ëµ
â”‚   â”‚   â””â”€â”€ ê²½ì§„ëŒ€íšŒ_ìµœì í•™ìŠµì „ëµ_ë¹„êµë¶„ì„_20250910.md # 5ê°€ì§€ ì „ëµ ë¹„êµ
â”‚   â””â”€â”€ docs/FAQ/                          # â“ ì „ë¬¸ê°€ ìˆ˜ì¤€ FAQ
â”‚       â””â”€â”€ ì§ˆë¬¸_ëŒ€ì‘_FAQ.md               # ì‹¤ì¦ ë°ì´í„° ê¸°ë°˜ ë‹µë³€
â”‚
â”œâ”€â”€ ğŸ“” ì‹¤í—˜ ë…¸íŠ¸ë¶ (íŒ€ë³„ ë¶„ë¥˜)
â”‚   â”œâ”€â”€ notebooks/team/                     # íŒ€ì›ë³„ ì‹¤í—˜ ë…¸íŠ¸ë¶
â”‚   â”‚   â”œâ”€â”€ CHH/                           # ìµœí˜„í™” (ëª¨ë“ˆí™” ë‹´ë‹¹)
â”‚   â”‚   â”œâ”€â”€ IYS/                           # ì„ì˜ˆìŠ¬
â”‚   â”‚   â”œâ”€â”€ JSW/                           # ì •ì„œìš°
â”‚   â”‚   â”œâ”€â”€ KBH/                           # ê¹€ë³‘í˜„
â”‚   â”‚   â””â”€â”€ KSM/                           # ê¹€ì„ ë¯¼
â”‚   â”œâ”€â”€ notebooks/modular/                  # ëª¨ë“ˆí˜• ë¶„ì„ ë…¸íŠ¸ë¶
â”‚   â”‚   â”œâ”€â”€ results_comparison/            # ê²°ê³¼ ë¹„êµ ë¶„ì„
â”‚   â”‚   â””â”€â”€ unit_tests/                    # ë‹¨ìœ„ í…ŒìŠ¤íŠ¸
â”‚   â””â”€â”€ notebooks/base/                     # ê¸°ë³¸ ì‹¤í—˜ ë…¸íŠ¸ë¶
â”‚
â””â”€â”€ ğŸ”§ ê¸°íƒ€ ë„êµ¬
    â”œâ”€â”€ scripts/                           # í¸ì˜ ìŠ¤í¬ë¦½íŠ¸
    â”œâ”€â”€ font/                              # ì‹œê°í™”ìš© í°íŠ¸
    â””â”€â”€ requirements.txt                   # Python ì˜ì¡´ì„± ê´€ë¦¬
```

## ğŸ¨ ì§€ì›í•˜ëŠ” ê³ ê¸‰ ê¸°ë²•

### ğŸ§  ëª¨ë¸ ì•„í‚¤í…ì²˜ (10ê°œ ëª¨ë¸ ì§€ì›)
- **ConvNeXt Base 384**: ImageNet-22k ì‚¬ì „í•™ìŠµ, **F1 0.98362** ë‹¬ì„± ğŸ†
- **Swin Transformer Base 384**: Vision Transformer ê¸°ë°˜, F1 0.9489
- **EfficientNet V2 B3**: íš¨ìœ¨ì„±ê³¼ ì„±ëŠ¥ì˜ ê· í˜•, F1 0.9305
- **Vision Transformer Large**: 384px ê³ í•´ìƒë„ ì²˜ë¦¬
- **MaxViT Base**: ìµœì‹  Multi-axis Attention

**RECOMMENDED_MODELS ë ˆì§€ìŠ¤íŠ¸ë¦¬**ë¡œ ê°„ë‹¨í•œ í‚¤ì›Œë“œë¡œ ë³µì¡í•œ ëª¨ë¸ëª… ê´€ë¦¬
```yaml
models:
  fold_0: "efficientnet_b3"     # ë¹ ë¥¸ ì‹¤í—˜ìš©
  fold_1: "swin_base_384"       # Transformer ê¸°ë°˜
  fold_2: "convnext_base_384"   # ìµœê³  ì„±ëŠ¥
  fold_3: "vit_large"           # ê³ í•´ìƒë„ ì²˜ë¦¬
  fold_4: "maxvit_base"         # ìµœì‹  ì•„í‚¤í…ì²˜
```

### ğŸ¨ ë°ì´í„° ì¦ê°• ì‹œìŠ¤í…œ
- **Hard Augmentation**: ì—í¬í¬ë³„ ë™ì  í™•ë¥  ìŠ¤ì¼€ì¤„ë§
- **Mixup & CutMix**: ë°ì´í„° ë¯¹ì‹± ê¸°ë²• (Alpha ìµœì í™”)
- **Essential TTA (5ê°€ì§€)**: íšŒì „ + ë°ê¸° ì¡°ì • (17ë¶„ ì¶”ë¡ )
- **Comprehensive TTA (15ê°€ì§€)**: ì „ì²´ ë³€í™˜ ì„¸íŠ¸ (50ë¶„+ ì¶”ë¡ )
  - íšŒì „: 90Â°, 180Â°, 270Â° 
  - ìŠ¤ì¼€ì¼ë§: 0.9x, 1.1x
  - ë°ê¸°/ëŒ€ë¹„: 0.9x, 1.1x ì¡°ì •
  - ë¸”ëŸ¬/ìƒ¤í”ˆ: Gaussian ë¸”ëŸ¬, ìƒ¤í”ˆ í•„í„°
- **HighPerfDocClsDataset**: ê³ ì„±ëŠ¥ ë°ì´í„° ë¡œë” + Mixup í†µí•©

### ğŸ” ìµœì í™” ê¸°ë²•
#### **Optuna í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”**
- **ìºì‹± ì‹œìŠ¤í…œ**: 150-300x ì†ë„ í–¥ìƒ (2ì´ˆ/trial)
- **ì„±ê³µ ì‚¬ë¡€**: ConvNeXt F1 0.8234 â†’ 0.9478 (+15.09% ê°œì„ )
- **TPE Sampler**: ë² ì´ì§€ì•ˆ ìµœì í™” ì•Œê³ ë¦¬ì¦˜
- **Median Pruner**: ì¡°ê¸° ì¢…ë£Œë¡œ íš¨ìœ¨ì„± ê·¹ëŒ€í™”

#### **Temperature Scaling & ìº˜ë¦¬ë¸Œë ˆì´ì…˜**
- **í™•ë¥  ë³´ì •**: ëª¨ë¸ ì‹ ë¢°ë„ í–¥ìƒ
- **Calibrated Inference**: ë³´ì •ëœ ì˜ˆì¸¡ ê²°ê³¼
- **ì‹ ë¢°ë„ ì„ê³„ê°’**: ì•™ìƒë¸” ì˜ˆì¸¡ í’ˆì§ˆ ê´€ë¦¬

#### **GPU ë©”ëª¨ë¦¬ ìµœì í™”**
- **í•˜ë“œì›¨ì–´ë³„ ì§€ì›**: RTX 4090 (24GB) â†’ RTX 3060 (8GB)
- **ìë™ ë°°ì¹˜ í¬ê¸° ì¡°ì •**: ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê¸°ë°˜ ë™ì  ì¡°ì •
- **Mixed Precision Training**: FP16 ê°€ì†í™”
- **ë©”ëª¨ë¦¬ í”„ë¡œíŒŒì¼ë§**: ìƒì„¸ ì‚¬ìš©ëŸ‰ ë¶„ì„ ë° ìµœì í™”

### ğŸ”„ ì•™ìƒë¸” ì „ëµ
#### **K-Fold ì•™ìƒë¸”**
- **5ê°œ ëª¨ë¸**: í´ë“œë³„ ë…ë¦½ í•™ìŠµ
- **ê°€ì¤‘ í‰ê· **: ì„±ëŠ¥ ê¸°ë°˜ ì•™ìƒë¸” ê°€ì¤‘ì¹˜
- **ì•ˆì •ì„± í™•ë³´**: F1 0.95-0.98 ë‹¬ì„±

#### **ë‹¤ì¤‘ ëª¨ë¸ ì•™ìƒë¸”**
- **ì•„í‚¤í…ì²˜ ë‹¤ì–‘ì„±**: ConvNeXt + Swin + EfficientNet ì¡°í•©
- **ì„±ëŠ¥ ê·¹ëŒ€í™”**: F1 0.96-0.99 ë‹¬ì„± ê°€ëŠ¥
- **GPU í• ë‹¹**: ëª¨ë¸ë³„ ìµœì  GPU ë°°ì •

#### **TTA ì•™ìƒë¸”**
- **ë³€í™˜ ê²°ê³¼ í†µí•©**: ì—¬ëŸ¬ augmentation ê²°ê³¼ í‰ê· 
- **Essential vs Comprehensive**: ì†ë„ vs ì„±ëŠ¥ íŠ¸ë ˆì´ë“œì˜¤í”„
- **ì‹ ë¢°ë„ ê¸°ë°˜**: ë³€í™˜ë³„ ê°€ì¤‘ì¹˜ ì¡°ì •

## ğŸ”§ CLI ëª…ë ¹ì–´ ë ˆí¼ëŸ°ìŠ¤

### í•™ìŠµ ëª…ë ¹ì–´
```bash
# ê¸°ë³¸ í•™ìŠµ
python src/training/train_main.py --config configs/train.yaml --mode basic

# ê³ ì„±ëŠ¥ í•™ìŠµ (K-fold)
python src/training/train_main.py --config configs/train_highperf.yaml --mode highperf

# ë‹¤ì¤‘ ëª¨ë¸ ì•™ìƒë¸”
python src/training/train_main.py --config configs/train_multi_model_ensemble.yaml --mode highperf

# Optuna ìµœì í™”
python src/training/train_main.py --config configs/train.yaml --optimize --n-trials 20

# ì „ì²´ íŒŒì´í”„ë¼ì¸ + ìµœì í™” (ì¶”ì²œ)
python src/training/train_main.py \
    --config configs/train_highperf.yaml \
    --mode full-pipeline \
    --use-calibration \
    --optimize \
    --optuna-config configs/optuna_config.yaml \
    --auto-continue
```

### ì¶”ë¡  ëª…ë ¹ì–´
```bash
# ë‹¨ì¼ ëª¨ë¸ ì¶”ë¡ 
python src/inference/infer_main.py --config configs/infer.yaml --mode basic

# K-fold ì•™ìƒë¸” ì¶”ë¡ 
python src/inference/infer_main.py \
    --config configs/infer_highperf.yaml \
    --mode highperf \
    --fold-results experiments/train/latest-train/fold_results.yaml

# ë‹¤ì¤‘ ëª¨ë¸ ì•™ìƒë¸” ì¶”ë¡ 
python src/inference/infer_main.py \
    --config configs/infer_multi_model_ensemble.yaml \
    --mode highperf
```

## âš™ï¸ ì„¤ì • íŒŒì¼ ìƒì„± ì‹œìŠ¤í…œ

### ğŸ“ í•™ìŠµ ì„¤ì • íŒŒì¼ ì‘ì„±ë²•
**ë‹¨ì¼ í´ë“œ ì„¤ì • (configs/train.yaml)**
```yaml
data:
  folds: 1                    # ë‹¨ì¼ í´ë“œ í™œì„±í™”
  valid_fold: 0               # ì‚¬ìš©í•  í´ë“œ ë²ˆí˜¸ (0-4)
  stratify: true              # ê³„ì¸µì  ë¶„í• 

model:
  name: "convnext_base_384"   # RECOMMENDED_MODELSì—ì„œ ì„ íƒ
  drop_rate: 0.0              # ë“œë¡­ì•„ì›ƒ ë¹„ìœ¨
  drop_path_rate: 0.1         # DropPath ë¹„ìœ¨

train:
  epochs: 15                  # ë¹ ë¥¸ ì‹¤í—˜ìš©
  batch_size: 32              # GPU ë©”ëª¨ë¦¬ì— ë”°ë¼ ì¡°ì •
  lr: 1e-4                    # í•™ìŠµë¥ 
  use_mixup: true             # Mixup ë°ì´í„° ì¦ê°•
  use_ema: true               # EMA ì•ˆì •í™”
```

**K-fold ê³ ì„±ëŠ¥ ì„¤ì • (configs/train_highperf.yaml)**
```yaml
data:
  folds: 5                    # K-fold í™œì„±í™”
  valid_fold: "all"           # ì „ì²´ í´ë“œ í•™ìŠµ
  stratify: true              # í´ë˜ìŠ¤ ê· í˜• ìœ ì§€

model:
  name: "convnext_base_384"   # ìµœê³  ì„±ëŠ¥ ëª¨ë¸
  drop_rate: 0.1              # ì •ê·œí™” ê°•í™”
  drop_path_rate: 0.2         # ê³¼ì í•© ë°©ì§€

train:
  epochs: 50                  # ì¶©ë¶„í•œ í•™ìŠµ
  batch_size: 64              # ê³ ì„±ëŠ¥ GPU í™œìš©
  use_advanced_augmentation: true  # Hard Augmentation
  temperature_scaling: true   # í™•ë¥  ë³´ì •
```

### ğŸ”® ì¶”ë¡  ì„¤ì • íŒŒì¼ ì‘ì„±ë²•
**K-fold ì•™ìƒë¸” ì¶”ë¡  (configs/infer_highperf.yaml)**
```yaml
inference:
  model_paths:
    - "experiments/train/latest-train/fold_0/best_model.pth"
    - "experiments/train/latest-train/fold_1/best_model.pth"
    - "experiments/train/latest-train/fold_2/best_model.pth"
    - "experiments/train/latest-train/fold_3/best_model.pth"
    - "experiments/train/latest-train/fold_4/best_model.pth"
  
  tta:
    enabled: true
    strategy: "essential"     # essential | comprehensive
    transformations: 5        # Essential TTA
  
  ensemble:
    method: "weighted_average"
    weights: [0.2, 0.2, 0.2, 0.2, 0.2]  # ê· ë“± ê°€ì¤‘ì¹˜
```

**ë‹¤ì¤‘ ëª¨ë¸ ì•™ìƒë¸” (configs/infer_multi_model_ensemble.yaml)**
```yaml
models:
  convnext:
    name: "convnext_base_384"
    weight: 0.4               # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ë†’ì€ ê°€ì¤‘ì¹˜
    model_paths: 
      - "experiments/convnext/fold_0/best_model.pth"
      - "experiments/convnext/fold_1/best_model.pth"
  
  swin:
    name: "swin_base_384"
    weight: 0.35              # Transformer ë‹¤ì–‘ì„±
    model_paths:
      - "experiments/swin/fold_0/best_model.pth"
      - "experiments/swin/fold_1/best_model.pth"
  
  efficientnet:
    name: "efficientnet_v2_b3"
    weight: 0.25              # íš¨ìœ¨ì„± ëª¨ë¸
    model_paths:
      - "experiments/eff/fold_0/best_model.pth"
      - "experiments/eff/fold_1/best_model.pth"

tta:
  strategy: "comprehensive"   # ìµœê³  ì„±ëŠ¥ì„ ìœ„í•œ 15ê°€ì§€ ë³€í™˜
```

### ğŸ” Optuna ìµœì í™” ì„¤ì • (configs/optuna_config.yaml)
```yaml
optuna:
  study_name: "convnext_optimization"
  n_trials: 50                # ìµœì í™” ì‹œë„ íšŸìˆ˜
  timeout: 3600               # 1ì‹œê°„ ì œí•œ
  
  search_space:
    learning_rate:
      type: "loguniform"
      low: 1e-6
      high: 1e-2
    weight_decay:
      type: "loguniform"
      low: 1e-4
      high: 1e-1
    dropout:
      type: "uniform"
      low: 0.0
      high: 0.3
    batch_size:
      type: "categorical"
      choices: [16, 32, 64, 128]
    mixup_alpha:
      type: "uniform"
      low: 0.1
      high: 1.0

  pruning:
    enabled: true
    patience: 3               # ì¡°ê¸° ì¢…ë£Œ ê¸°ì¤€
```

## ğŸ“Š ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ë° ì‹¤ì¦ ë¶„ì„

### ğŸ† ìµœê³  ì„±ëŠ¥ ê¸°ë¡ (F1 0.98362 ë‹¬ì„±)

| ìˆœìœ„ | F1 Score | ì „ëµ | ëª¨ë¸ | ì‹œê°„ | ìµœì í™” ê¸°ë²• | ì¬í˜„ ê°€ëŠ¥ |
|-----|----------|------|------|------|-----------|-----------|
| ğŸ¥‡ | **0.98362** | ë‹¨ì¼ í´ë“œ ìµœì í™” | ConvNeXt Base 384 | 23ë¶„ | Optuna + Hard Aug + EMA | âœ… ì™„ì „ ì¬í˜„ |
| ğŸ¥ˆ | **0.97918** | ì¥ê¸° í•™ìŠµ | ConvNeXt Base 384 | 300 epoch | ê¸°ë³¸ ì„¤ì • | âœ… ê²€ì¦ë¨ |
| ğŸ¥‰ | **0.96909** | ê¸°ì¤€ ëª¨ë¸ | ConvNeXt Base 384 | 100 epoch | í‘œì¤€ ì„¤ì • | âœ… ì•ˆì •ì  |
| 4ìœ„ | 0.95568 | ìµœì‹  ì‹¤í—˜ | ConvNeXt Base 384 | ë‹¤ì–‘í•¨ | ì‹¤í—˜ì  | âœ… ë¡œê·¸ ë³´ê´€ |

### ğŸ“ˆ ì „ëµë³„ ìƒì„¸ ì„±ëŠ¥ ë¶„ì„

#### **ë‹¨ì¼ í´ë“œ vs K-fold ë¹„êµ ë¶„ì„**
| ë¹„êµ í•­ëª© | ë‹¨ì¼ í´ë“œ | K-fold | ìŠ¹ì |
|----------|----------|--------|------|
| **ìµœê³  F1 ì ìˆ˜** | **0.98362** | 0.97918 | ğŸ† ë‹¨ì¼ í´ë“œ |
| **í‰ê·  í•™ìŠµ ì‹œê°„** | **30ë¶„** | 2.5ì‹œê°„ | ğŸ† ë‹¨ì¼ í´ë“œ |
| **GPU ë©”ëª¨ë¦¬** | **8-12GB** | 16GB+ | ğŸ† ë‹¨ì¼ í´ë“œ |
| **ì•ˆì •ì„±** | 0.96-0.98 | **0.95-0.98** | ğŸ† K-fold |
| **ì¬í˜„ì„±** | **ë§¤ìš° ë†’ìŒ** | ë†’ìŒ | ğŸ† ë‹¨ì¼ í´ë“œ |

**ê²°ë¡ **: ë‹¨ì¼ í´ë“œ + ì ì ˆí•œ ì •ê·œí™”ê°€ **ê²½ì§„ëŒ€íšŒ í™˜ê²½ì—ì„œ ìµœì **

#### **Optuna ìµœì í™” íš¨ê³¼ ë¶„ì„**
- **ì„±ê³µë¥ **: 80% (10íšŒ ì¤‘ 8íšŒ ì„±ëŠ¥ í–¥ìƒ)
- **í‰ê·  ê°œì„ í­**: F1 Score +0.05 ~ +0.15
- **ìµœê³  ê°œì„  ì‚¬ë¡€**: ConvNeXt F1 0.8234 â†’ 0.9478 (**+15.09%**)
- **ROI ë¶„ì„**: 1ì‹œê°„ ìµœì í™”ë¡œ í‰ê·  3% ì„±ëŠ¥ í–¥ìƒ

#### **ëª¨ë¸ë³„ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬**
| ëª¨ë¸ | Best F1 | í‰ê·  F1 | í•™ìŠµì‹œê°„ | ì¶”ë¡ ì†ë„ | GPU ë©”ëª¨ë¦¬ | ì•ˆì •ì„± |
|------|---------|---------|----------|----------|-----------|--------|
| **ConvNeXt Base 384** | **0.9836** | **0.9652** | 52ë¶„ | 28ms/img | 12GB | â­â­â­â­â­ |
| Swin Base 384 | 0.9489 | 0.9324 | 63ë¶„ | 35ms/img | 14GB | â­â­â­â­ |
| EfficientNet V2 B3 | 0.9305 | 0.9156 | 45ë¶„ | 23ms/img | 10GB | â­â­â­ |
| Vision Transformer Large | 0.9278 | 0.9098 | 78ë¶„ | 42ms/img | 16GB | â­â­â­ |

### âš¡ TTA ì „ëµë³„ ì„±ëŠ¥ vs ì‹œê°„ ë¶„ì„

| TTA ì „ëµ | ë³€í™˜ ìˆ˜ | ì¶”ë¡  ì‹œê°„ | F1 í–¥ìƒ | ë©”ëª¨ë¦¬ ì‚¬ìš© | ê¶Œì¥ ìƒí™© |
|---------|--------|----------|---------|-------------|-----------|
| **No TTA** | 1 | **5ë¶„** | ê¸°ì¤€ì  | **4GB** | ë¹ ë¥¸ ê²€ì¦ |
| **Essential TTA** | 5 | **17ë¶„** | +0.015 | **8GB** | ê· í˜•ì  ì„±ëŠ¥ |
| **Comprehensive TTA** | 15 | **50ë¶„+** | **+0.035** | **24GB+** | ìµœê³  ì„±ëŠ¥ |

**ìµœì  ì „ëµ**: Essential TTAê°€ **ì‹œê°„ ëŒ€ë¹„ ì„±ëŠ¥ ìµœê³  íš¨ìœ¨**

### âš¡ ì†ë„ vs ì„±ëŠ¥ íŠ¸ë ˆì´ë“œì˜¤í”„

```mermaid
graph LR
    A[ğŸ“ ë‹¨ì¼ í´ë“œ<br/>30ë¶„, F1: 0.93] --> B[ğŸ”€ K-fold<br/>2ì‹œê°„, F1: 0.96]
    B --> C[ğŸ­ ë‹¤ì¤‘ëª¨ë¸<br/>4ì‹œê°„, F1: 0.97]
    C --> D[ğŸ” Optuna<br/>6ì‹œê°„, F1: 0.98+]
    
    style A fill:#e1f5fe, color:#000000
    style B fill:#e8f5e8, color:#000000
    style C fill:#f3e5f5, color:#000000
    style D fill:#fff3e0, color:#000000
```

## ğŸ” ì‹œìŠ¤í…œ ê´€ë¦¬ ë° ëª¨ë‹ˆí„°ë§

### ğŸ“Š ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ
#### **WandB í†µí•© ëª¨ë‹ˆí„°ë§**
```bash
# WandB ëŒ€ì‹œë³´ë“œ ì‹¤í–‰
wandb server --port 8080

# ì‹¤í—˜ ë™ê¸°í™”
wandb sync wandb/latest-run

# í”„ë¡œì íŠ¸ë³„ ì¶”ì 
wandb sweep configs/wandb_sweep.yaml
```

#### **ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§**
```bash
# GPU ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ (1ì´ˆ ê°„ê²©)
watch -n 1 nvidia-smi

# ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¶”ì 
python src/utils/gpu_optimization/memory_profiler.py

# í•™ìŠµ ë¡œê·¸ ì‹¤ì‹œê°„ í™•ì¸
tail -f logs/$(date +%Y%m%d)/train/*.log
```

#### **ìë™ ì‹œê°í™” ì‹œìŠ¤í…œ**
- **í•™ìŠµ ê³¡ì„ **: ì†ì‹¤/ì •í™•ë„ ìë™ ê·¸ë˜í”„ ìƒì„±
- **ì„±ëŠ¥ ë¹„êµ**: ëª¨ë¸ë³„/ì „ëµë³„ ë²¤ì¹˜ë§ˆí¬ ì°¨íŠ¸
- **GPU ì‚¬ìš©ë¥ **: ì‹¤ì‹œê°„ í•˜ë“œì›¨ì–´ ëª¨ë‹ˆí„°ë§
- **Mermaid ë‹¤ì´ì–´ê·¸ë¨**: ì•„í‚¤í…ì²˜ ìë™ ì‹œê°í™”

### ğŸ› ï¸ íŠ¸ëŸ¬ë¸”ìŠˆíŒ… ê°€ì´ë“œ

#### **ì¼ë°˜ì ì¸ GPU ë©”ëª¨ë¦¬ ë¬¸ì œ**
```bash
# CUDA Out of Memory í•´ê²°
export CUDA_VISIBLE_DEVICES=0,1  # ë©€í‹° GPU í™œìš©

# ìë™ ë°°ì¹˜ í¬ê¸° ì¡°ì •
python src/utils/gpu_optimization/auto_batch_size.py \
    --config configs/train_highperf.yaml \
    --target-memory 0.9  # 90% ë©”ëª¨ë¦¬ ì‚¬ìš©

# ë©”ëª¨ë¦¬ ì •ë¦¬
python -c "import torch; torch.cuda.empty_cache()"
```

#### **ëª¨ë¸ ë¡œë”© ë° ì²´í¬í¬ì¸íŠ¸ ë¬¸ì œ**
```bash
# ì²´í¬í¬ì¸íŠ¸ ê²€ì¦
python src/utils/core/validate_checkpoint.py \
    --checkpoint experiments/train/latest-train/fold_0/best_model.pth

# ëª¨ë¸ êµ¬ì¡° í˜¸í™˜ì„± í™•ì¸
python src/models/verify_model_compatibility.py \
    --config configs/train_highperf.yaml
```

#### **ì„¤ì • íŒŒì¼ ê²€ì¦**
```bash
# YAML êµ¬ë¬¸ ê²€ì‚¬
python src/utils/config/validate_config.py \
    --config configs/train_highperf.yaml

# ê²½ë¡œ ì¡´ì¬ì„± í™•ì¸
python src/utils/config/check_paths.py \
    --config configs/infer_highperf.yaml
```

### ğŸ“ˆ ê²°ê³¼ ë¶„ì„ ì‹œìŠ¤í…œ

#### **ì„±ëŠ¥ ë¶„ì„ ë„êµ¬**
```bash
# ìµœì‹  ì‹¤í—˜ ê²°ê³¼ ìš”ì•½
python src/utils/core/experiment_summary.py \
    --date $(date +%Y%m%d) \
    --top 10

# F1 ì ìˆ˜ ìˆœìœ„
find experiments/train -name "fold_results.yaml" \
    -exec grep "best_f1" {} \; | sort -nr | head -10

# ëª¨ë¸ë³„ ì„±ëŠ¥ ë¹„êµ
python src/utils/visualizations/performance_comparison.py \
    --experiments experiments/train/20250910/
```

#### **ì œì¶œ íŒŒì¼ ê²€ì¦**
```bash
# CSV í˜•ì‹ ê²€ì¦
python src/utils/core/validate_submission.py \
    --submission submissions/latest/final_submission.csv \
    --sample data/raw/sample_submission.csv

# ë¼ë²¨ ë¶„í¬ í™•ì¸
python -c "
import pandas as pd
df = pd.read_csv('submissions/latest/final_submission.csv')
print(f'Shape: {df.shape}')
print(f'Missing: {df.isnull().sum().sum()}')
print(f'Label distribution:\n{df.iloc[:, 1].value_counts()}')
"
```

#### **ì‹¤í—˜ ì¬í˜„ ì‹œìŠ¤í…œ**
```bash
# íŠ¹ì • ì‹¤í—˜ ì™„ì „ ì¬í˜„
python src/utils/core/reproduce_experiment.py \
    --experiment-id 20250910_1213 \
    --config-backup configs/20250910/train_optimized_*_1213.yaml

# ì‹œë“œ ê³ ì • ê²€ì¦
python src/utils/core/seed_verification.py \
    --config configs/train_highperf.yaml \
    --seed 42 \
    --runs 3
```

## âš ï¸ ì£¼ì˜ì‚¬í•­ ë° íŒ

### GPU ë©”ëª¨ë¦¬ ìµœì í™”
```bash
# ë©”ëª¨ë¦¬ ë¶€ì¡± ì‹œ ìë™ ë°°ì¹˜ í¬ê¸° ì¡°ì •
python src/utils/gpu_optimization/auto_batch_size.py --config configs/train_highperf.yaml

# ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì— ë”°ë¥¸ ì„¤ì • ì¡°ì •
# RTX 3080 (10GB): batch_size: 32, img_size: 320
# RTX 4090 (24GB): batch_size: 64, img_size: 384
```

### ì„±ëŠ¥ ìµœì í™” íŒ
- **ë‹¨ì¼ í´ë“œ**: ë¹ ë¥¸ ì‹¤í—˜, í•˜ì´í¼íŒŒë¼ë¯¸í„° íƒìƒ‰
- **K-fold**: ì•ˆì •ì  ì„±ëŠ¥, ìµœì¢… ì œì¶œìš©
- **ë‹¤ì¤‘ ëª¨ë¸**: ìµœê³  ì„±ëŠ¥, ëŒ€íšŒ ìš°ìŠ¹ìš©
- **Optuna**: ì‹œê°„ ì—¬ìœ  ìˆì„ ë•Œ, ìë™ ìµœì í™”

### ì¼ë°˜ì ì¸ ë¬¸ì œ í•´ê²°
```bash
# CUDA ë©”ëª¨ë¦¬ ë¶€ì¡±
export CUDA_VISIBLE_DEVICES=0,1  # ë©€í‹° GPU ì‚¬ìš©

# ë””ìŠ¤í¬ ê³µê°„ ë¶€ì¡±
rm -rf wandb/  # WandB ë¡œê·¸ ì •ë¦¬
rm -rf experiments/train/2025090*/  # ì˜¤ë˜ëœ ì‹¤í—˜ ì •ë¦¬

# íŒ¨í‚¤ì§€ ì¶©ëŒ
pip install --force-reinstall torch torchvision
```

## ğŸ“š ìƒì„¸ ë¬¸ì„œ ê°€ì´ë“œ

### ğŸ“Š íŒŒì´í”„ë¼ì¸ ì•„í‚¤í…ì²˜ ([docs/íŒŒì´í”„ë¼ì¸/](docs/íŒŒì´í”„ë¼ì¸/))
#### **ğŸ“ í•™ìŠµ íŒŒì´í”„ë¼ì¸ ì™„ì „ ê°€ì´ë“œ**
- **4ê°€ì§€ í•™ìŠµ ëª¨ë“œ**: basic, highperf, full-pipeline, optimize
- **ê²€ì¦ ì „ëµ**: ë‹¨ì¼ í´ë“œ vs K-fold vs ë‹¤ì¤‘ ëª¨ë¸ ìƒì„¸ ë¹„êµ  
- **ê³ ì„±ëŠ¥ ê¸°ë²•**: Hard Augmentation, Mixup, Temperature Scaling
- **ì•„í‚¤í…ì²˜ ë‹¤ì´ì–´ê·¸ë¨**: Mermaid ê¸°ë°˜ ì‹œê°ì  ì›Œí¬í”Œë¡œìš°

#### **ğŸ”® ì¶”ë¡  íŒŒì´í”„ë¼ì¸ ê°€ì´ë“œ**
- **TTA ì‹œìŠ¤í…œ**: Essential(5ê°€ì§€) vs Comprehensive(15ê°€ì§€)
- **ì•™ìƒë¸” ì „ëµ**: K-fold, ë‹¤ì¤‘ ëª¨ë¸, TTA ì•™ìƒë¸”
- **ì„±ëŠ¥ ìµœì í™”**: GPU ë©”ëª¨ë¦¬, ë°°ì¹˜ ì²˜ë¦¬, ë³‘ë ¬ ì¶”ë¡ 
- **ì‹¤í–‰ ì‹œê°„ ë¶„ì„**: 5ë¶„(ë‹¨ì¼) â†’ 17ë¶„(Essential) â†’ 50ë¶„+(Comprehensive)

#### **ğŸŒŸ ì „ì²´ íŒŒì´í”„ë¼ì¸ í†µí•© ê°€ì´ë“œ**
- **End-to-End ì›Œí¬í”Œë¡œìš°**: ë°ì´í„° â†’ í•™ìŠµ â†’ ì¶”ë¡  â†’ ì œì¶œ
- **ì „ëµ ë¡œë“œë§µ**: í”„ë¡œí† íƒ€ì… â†’ ê³ ì„±ëŠ¥ â†’ ê²½ì§„ëŒ€íšŒ ìš°ìŠ¹
- **ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜**: 6ê³„ì¸µ í†µí•© êµ¬ì¡°

### âš™ï¸ ì„¤ì • ê´€ë¦¬ ([docs/configs_í´ë”_ì„¤ì •_íŒŒì¼_ìƒì„±/](docs/configs_í´ë”_ì„¤ì •_íŒŒì¼_ìƒì„±/))
- **í•™ìŠµ ì„¤ì • ê°€ì´ë“œ**: ë‹¨ì¼/K-fold/ë‹¤ì¤‘ëª¨ë¸ ì„¤ì • ì‘ì„±ë²•
- **ì¶”ë¡  ì„¤ì • ê°€ì´ë“œ**: TTA, ì•™ìƒë¸”, ëª¨ë¸ ê²½ë¡œ ì„¤ì •
- **ìµœì í™” ì„¤ì • ê°€ì´ë“œ**: í•˜ì´í¼íŒŒë¼ë¯¸í„° ê²€ìƒ‰ ê³µê°„ ì •ì˜

### ğŸ§  ëª¨ë¸ ì‹œìŠ¤í…œ ([docs/ëª¨ë¸/](docs/ëª¨ë¸/))
- **10ê°œ ëª¨ë¸ ì•„í‚¤í…ì²˜**: ConvNeXt, Swin, EfficientNet, ViT ë“± ì™„ì „ ì§€ì›
- **ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬**: F1 ì ìˆ˜, í•™ìŠµì‹œê°„, ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìƒì„¸ ë¹„êµ
- **RECOMMENDED_MODELS**: ê°„í¸í•œ ëª¨ë¸ ì„ íƒ ì‹œìŠ¤í…œ

### âš¡ ìµœì í™” ì „ëµ ([docs/ìµœì í™”/](docs/ìµœì í™”/))
#### **GPU ìµœì í™” ê°€ì´ë“œ**
- **í•˜ë“œì›¨ì–´ë³„ ì„¤ì •**: RTX 4090 â†’ RTX 3060 ì™„ì „ ì§€ì›
- **ë©”ëª¨ë¦¬ ìµœì í™”**: ìë™ ë°°ì¹˜ í¬ê¸°, Mixed Precision í™œìš©
- **ì„±ëŠ¥ í”„ë¡œíŒŒì¼ë§**: ë³‘ëª© ì§€ì  ë¶„ì„ ë° í•´ê²° ë°©ë²•

#### **Optuna ìµœì í™” íš¨ê³¼ ë° ì „ëµ ë¶„ì„**
- **ìºì‹± ì‹œìŠ¤í…œ**: 150-300x ì†ë„ í–¥ìƒì˜ ë¹„ë°€
- **ì„±ê³µ/ì‹¤íŒ¨ ì‚¬ë¡€**: ROI ê¸°ë°˜ ìµœì í™” ì „ëµ ë¶„ì„
- **ì‹¤ì¦ ë°ì´í„°**: ConvNeXt F1 0.8234 â†’ 0.9478 (+15.09%) ë‹¬ì„± ê³¼ì •

#### **ì‹œê°„ ìµœì í™” ê°€ì´ë“œ**  
- **ë‹¨ê³„ë³„ ì‹œê°„ ì „ëµ**: 5ë¶„ â†’ 17ë¶„ â†’ 50ë¶„+ ìµœì í™” ë¡œë“œë§µ
- **íš¨ìœ¨ì„± ë§¤íŠ¸ë¦­ìŠ¤**: ì‹œê°„ ëŒ€ë¹„ ì„±ëŠ¥ í–¥ìƒ ë¶„ì„

### ğŸ› ï¸ ì‹œìŠ¤í…œ ê´€ë¦¬ ([docs/ì‹œìŠ¤í…œ/](docs/ì‹œìŠ¤í…œ/))
#### **ê¸°ë³¸ vs ê³ ì„±ëŠ¥ íŒŒì´í”„ë¼ì¸ ë¹„êµë¶„ì„**
- **ì„±ëŠ¥ ì°¨ì´**: F1 85% vs 98% ë‹¬ì„± ìš”ì¸ ë¶„ì„
- **ê¸°ìˆ ì  ì°¨ì´ì **: ê³ ê¸‰ ì¦ê°•, ì•™ìƒë¸”, ìµœì í™” ê¸°ë²• ìƒì„¸
- **ë¦¬ì†ŒìŠ¤ ìš”êµ¬ì‚¬í•­**: GPU, ë©”ëª¨ë¦¬, ì‹œê°„ ì™„ì „ ë¹„êµ

#### **ë¬¸ì œí•´ê²° ê°€ì´ë“œ**
- **GPU ë©”ëª¨ë¦¬ ë¬¸ì œ**: CUDA OOM ì™„ì „ í•´ê²° ë°©ë²•
- **ëª¨ë¸ ë¡œë”© ì˜¤ë¥˜**: ì²´í¬í¬ì¸íŠ¸ í˜¸í™˜ì„± ë¬¸ì œ í•´ê²°
- **ì„±ëŠ¥ ì§„ë‹¨**: ë³‘ëª© ì§€ì  ë¶„ì„ ë„êµ¬ í™œìš©ë²•

#### **ì‹œê°í™” ì‹œìŠ¤í…œ ê°€ì´ë“œ**
- **ìë™ ì‹œê°í™”**: í•™ìŠµ ê³¡ì„ , ì„±ëŠ¥ ë¹„êµ, GPU ëª¨ë‹ˆí„°ë§
- **Mermaid ë‹¤ì´ì–´ê·¸ë¨**: ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜ ìë™ ìƒì„±
- **ì‹¤ì‹œê°„ ëŒ€ì‹œë³´ë“œ**: WandB í†µí•© ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ

### ğŸ¯ ì „ëµ ë¶„ì„ ([docs/ì „ëµë¶„ì„/](docs/ì „ëµë¶„ì„/))
#### **ë‹¨ì¼í´ë“œ ê³¼ì í•© ìœ„í—˜ ë° ëŒ€ì‘ì „ëµ**
- **ì‹¤ì¦ ë¶„ì„**: ë‹¨ì¼ í´ë“œ F1 0.9691 vs K-fold F1 0.9653
- **ê³¼ì í•© ëŒ€ì‘**: ì •ê·œí™”, Mixup, EMA íš¨ê³¼ì  í™œìš©ë²•
- **ê²½ì§„ëŒ€íšŒ ìµœì í™”**: ì‹œê°„ vs ì„±ëŠ¥ íŠ¸ë ˆì´ë“œì˜¤í”„ ì „ëµ

### ğŸ“ˆ ì‹¤í—˜ ê²°ê³¼ ([docs/í•™ìŠµê²°ê³¼/](docs/í•™ìŠµê²°ê³¼/))
#### **ConvNeXt ìµœê³ ì„±ëŠ¥ í•™ìŠµê²°ê³¼ ë¶„ì„**
- **F1 0.98362 ë‹¬ì„±**: 2025-09-10 12:13 ì™„ì „ ì¬í˜„ ê°€ëŠ¥
- **ë‹¨ê³„ë³„ ì„±ëŠ¥ í–¥ìƒ**: ì²´ê³„ì  ê°œì„  ê³¼ì • ë¶„ì„
- **ì„¤ì • ë°±ì—…**: ì™„ì „í•œ ì¬í˜„ì„±ì„ ìœ„í•œ ì„¤ì • ë³´ì¡´

### ğŸ† ê²½ì§„ëŒ€íšŒ ì „ëµ ([docs/ëŒ€íšŒì „ëµë¶„ì„/](docs/ëŒ€íšŒì „ëµë¶„ì„/))
#### **ê²½ì§„ëŒ€íšŒ ìµœì í•™ìŠµì „ëµ ë¹„êµë¶„ì„**
- **5ê°€ì§€ ì „ëµ ì‹¤ì¦ ë¹„êµ**: ì‹¤ì œ ì‹¤í–‰ ì‹œê°„ê³¼ ì„±ëŠ¥ ë°ì´í„°
- **ì‹œê°„ íš¨ìœ¨ì„± ë¶„ì„**: ë‹¨ì¼ í´ë“œ 6x ë¹ ë¥¸ í•™ìŠµì˜ ë¹„ë°€
- **ìµœì¢… ê¶Œì¥ ì „ëµ**: ë‹¨ì¼ í´ë“œ multi-seed ì•™ìƒë¸”

### â“ ì „ë¬¸ê°€ FAQ ([docs/FAQ/](docs/FAQ/))
- **ì‹¤ì¦ ë°ì´í„° ê¸°ë°˜ ë‹µë³€**: ëª¨ë“  ì§ˆë¬¸ì— ì‹¤í—˜ ê²°ê³¼ ì²¨ë¶€
- **ê¸°ìˆ ì  ì‹¬í™” ì§ˆë¬¸**: ë‹¨ì¼ í´ë“œ, Optuna, ConvNeXt ì„ íƒ ê·¼ê±°
- **ì¬í˜„ì„± ë³´ì¥**: F1 0.98362 ì™„ì „ ì¬í˜„ ê°€ëŠ¥í•œ ìƒì„¸ ê°€ì´ë“œ

---

### ìƒˆë¡œìš´ ëª¨ë¸ ì¶”ê°€ í”„ë¡œì„¸ìŠ¤
1. **ëª¨ë¸ ì •ì˜**: `src/models/build.py`ì˜ `RECOMMENDED_MODELS`ì— ì¶”ê°€
2. **ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬**: ê¸°ì¡´ ëª¨ë¸ ëŒ€ë¹„ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
3. **ì„¤ì • íŒŒì¼**: `configs/`ì— ìµœì í™”ëœ ì„¤ì • ìƒì„±
4. **ë¬¸ì„œí™”**: `docs/ëª¨ë¸/`ì— ì„±ëŠ¥ ë¶„ì„ ë° ê°€ì´ë“œ ì¶”ê°€

### ìƒˆë¡œìš´ TTA ê¸°ë²• ê°œë°œ
1. **ë³€í™˜ í•¨ìˆ˜**: `src/data/transforms.py`ì— ë³€í™˜ ë¡œì§ êµ¬í˜„
2. **ì„±ëŠ¥ ê²€ì¦**: Essential/Comprehensive ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜
3. **ì„¤ì • í†µí•©**: `configs/infer_*.yaml`ì— ì˜µì…˜ ì¶”ê°€
4. **ë²¤ì¹˜ë§ˆí¬**: ì‹œê°„ vs ì„±ëŠ¥ ë¶„ì„ ë° ë¬¸ì„œí™”

### ìµœì í™” ê¸°ë²• ê°œì„ 
1. **ì•Œê³ ë¦¬ì¦˜ êµ¬í˜„**: `src/optimization/`ì— ìƒˆ ìµœì í™” ë¡œì§
2. **Optuna í†µí•©**: ê²€ìƒ‰ ê³µê°„ ë° pruning ì „ëµ ì„¤ì •
3. **ì„±ëŠ¥ ê²€ì¦**: ê¸°ì¡´ ëŒ€ë¹„ ê°œì„  íš¨ê³¼ ì •ëŸ‰ ì¸¡ì •
4. **ê°€ì´ë“œ ì—…ë°ì´íŠ¸**: `docs/ìµœì í™”/`ì— ê²°ê³¼ ë¶„ì„ ì¶”ê°€

## ğŸ™ Acknowledgments

- **ConvNeXt Base 384**: F1 0.98362 ë‹¬ì„±ì˜ í•µì‹¬ ëª¨ë¸
- **Optuna**: í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” í”„ë ˆì„ì›Œí¬
- **ë‹¨ì¼ í´ë“œ ìµœì í™”**: ê²½ì§„ëŒ€íšŒë¥¼ ìœ„í•œ ê³ ì† ìµœì í™” ì „ëµ  
- **ë°ì´í„°ì…‹ ìºì‹±**: ë§¤ trial 2ì´ˆ ë‹¬ì„±ì˜ í•µì‹¬ ê¸°ìˆ 
- **WandB**: 100+ ì‹¤í—˜ ì¶”ì  ë° ì‹œê°í™”
