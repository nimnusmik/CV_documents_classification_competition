"""
ë°ì´í„° ë³€í™˜(Augmentation) ì •ì˜
"""

import albumentations as A
from albumentations.pytorch import ToTensorV2
from typing import List
from ..config import Config


def get_train_transforms(config: Config) -> A.Compose:
    """
    í›ˆë ¨ìš© ë°ì´í„° ë³€í™˜ íŒŒì´í”„ë¼ì¸
    
    Features:
        - ë¹„ìœ¨ ë³´ì¡´ ë¦¬ì‚¬ì´ì§• (ë¬¸ì„œ íŠ¹í™”)
        - ì •í™•í•œ 90ë„ ë‹¨ìœ„ íšŒì „ (ë¬¸ì„œ íŠ¹ì„± ê³ ë ¤)
        - í…ŒìŠ¤íŠ¸ íŠ¹í™” ë…¸ì´ì¦ˆ/ë¸”ëŸ¬ ê°•í™”
        - ImageNet ì •ê·œí™”
    
    Args:
        config (Config): ì„¤ì • ê°ì²´
        
    Returns:
        A.Compose: í›ˆë ¨ìš© ë³€í™˜ íŒŒì´í”„ë¼ì¸
    """
    
    return A.Compose([
        # 1. ë¹„ìœ¨ ë³´ì¡´ ë¦¬ì‚¬ì´ì§• (í•µì‹¬ ê°œì„ )
        A.LongestMaxSize(max_size=config.img_size),
        A.PadIfNeeded(
            min_height=config.img_size, 
            min_width=config.img_size,
            border_mode=0,  # ìƒìˆ˜ê°’ìœ¼ë¡œ íŒ¨ë”© (ê²€ì€ìƒ‰)
            value=0
        ),
        
        # 2. ë¬¸ì„œ íŠ¹í™” íšŒì „ (ì •í™•í•œ 90ë„ ë°°ìˆ˜ë§Œ)
        A.OneOf([
            A.Rotate(limit=[90, 90], p=1.0),    # 90ë„ íšŒì „
            A.Rotate(limit=[180, 180], p=1.0),  # 180ë„ íšŒì „  
            A.Rotate(limit=[270, 270], p=1.0),  # 270ë„ íšŒì „
        ], p=config.rotation_prob),
        
        # 3. í…ŒìŠ¤íŠ¸ íŠ¹í™” ê°•í™” ì¦ê°• (ë¸”ëŸ¬)
        A.OneOf([
            A.MotionBlur(blur_limit=7, p=1.0),   # ì›€ì§ìž„ ë¸”ëŸ¬
            A.GaussianBlur(blur_limit=7, p=1.0), # ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬
        ], p=config.blur_prob),
        
        # 4. ë°ê¸°/ëŒ€ë¹„ ì¡°ì • (ë¬¸ì„œ ì¡°ëª… ë³€í™” ëŒ€ì‘)
        A.RandomBrightnessContrast(
            brightness_limit=0.3,
            contrast_limit=0.3,
            p=config.brightness_prob
        ),
        
        # 5. ê°€ìš°ì‹œì•ˆ ë…¸ì´ì¦ˆ (ìŠ¤ìº”/ì´¬ì˜ ë…¸ì´ì¦ˆ ì‹œë®¬ë ˆì´ì…˜)
        A.GaussNoise(
            var_limit=(30.0, 100.0),  # ë…¸ì´ì¦ˆ ê°•ë„ ë²”ìœ„
            p=config.noise_prob
        ),
        
        # 6. ìˆ˜í‰ í”Œë¦½ (ì¼ë°˜ì ì¸ ê¸°í•˜í•™ì  ë³€í™˜)
        A.HorizontalFlip(p=config.flip_prob),
        
        # 7. ì •ê·œí™” (ImageNet í‰ê· /í‘œì¤€íŽ¸ì°¨)
        A.Normalize(
            mean=config.imagenet_mean,
            std=config.imagenet_std
        ),
        
        # 8. PyTorch í…ì„œë¡œ ë³€í™˜
        ToTensorV2(),
    ])


def get_test_transforms(config: Config) -> A.Compose:
    """
    í…ŒìŠ¤íŠ¸/ê²€ì¦ìš© ë°ì´í„° ë³€í™˜ íŒŒì´í”„ë¼ì¸
    
    Features:
        - ì¦ê°• ì—†ì´ ê¸°ë³¸ ì „ì²˜ë¦¬ë§Œ
        - í›ˆë ¨ê³¼ ë™ì¼í•œ ë¦¬ì‚¬ì´ì§•/ì •ê·œí™”
    
    Args:
        config (Config): ì„¤ì • ê°ì²´
        
    Returns:
        A.Compose: í…ŒìŠ¤íŠ¸ìš© ë³€í™˜ íŒŒì´í”„ë¼ì¸
    """
    
    return A.Compose([
        # ë¹„ìœ¨ ë³´ì¡´ ë¦¬ì‚¬ì´ì§•
        A.LongestMaxSize(max_size=config.img_size),
        A.PadIfNeeded(
            min_height=config.img_size,
            min_width=config.img_size,
            border_mode=0,
            value=0
        ),
        
        # ì •ê·œí™”
        A.Normalize(
            mean=config.imagenet_mean,
            std=config.imagenet_std
        ),
        
        # í…ì„œ ë³€í™˜
        ToTensorV2(),
    ])


def get_tta_transforms(config: Config) -> List[A.Compose]:
    """
    Test Time Augmentationìš© ë³€í™˜ ë¦¬ìŠ¤íŠ¸
    
    Features:
        - í•µì‹¬ TTA ë³€í˜•ë“¤ë§Œ ì„ ë³„ (ì„±ëŠ¥ vs ì†ë„ ìµœì í™”)
        - ì›ë³¸ + íšŒì „ 3ê°œ + ë°ê¸° 1ê°œ = ì´ 5ê°œ ë³€í˜•
        - ë¬¸ì„œ íŠ¹ì„±ì— ìµœì í™”ëœ ë³€í˜•ë“¤
    
    Args:
        config (Config): ì„¤ì • ê°ì²´
        
    Returns:
        List[A.Compose]: TTA ë³€í™˜ ë¦¬ìŠ¤íŠ¸
    """
    
    base_transforms = [
        A.LongestMaxSize(max_size=config.img_size),
        A.PadIfNeeded(
            min_height=config.img_size,
            min_width=config.img_size,
            border_mode=0,
            value=0
        )
    ]
    
    tta_transforms = []
    
    # 1. ì›ë³¸ (ì¦ê°• ì—†ìŒ)
    tta_transforms.append(A.Compose(
        base_transforms + [
            A.Normalize(mean=config.imagenet_mean, std=config.imagenet_std),
            ToTensorV2()
        ]
    ))
    
    # 2-4. 90ë„ ë‹¨ìœ„ íšŒì „ë“¤
    rotation_angles = [90, 180, -90]
    for angle in rotation_angles:
        tta_transforms.append(A.Compose(
            base_transforms + [
                A.Rotate(limit=[angle, angle], p=1.0),
                A.Normalize(mean=config.imagenet_mean, std=config.imagenet_std),
                ToTensorV2()
            ]
        ))
    
    # 5. ë°ê¸° ê°œì„  (ì–´ë‘ìš´ ë¬¸ì„œ ëŒ€ì‘)
    tta_transforms.append(A.Compose(
        base_transforms + [
            A.RandomBrightnessContrast(
                brightness_limit=[0.3, 0.3],  # ê³ ì •ëœ ë°ê¸° ì¦ê°€
                contrast_limit=[0.3, 0.3],    # ê³ ì •ëœ ëŒ€ë¹„ ì¦ê°€
                p=1.0
            ),
            A.Normalize(mean=config.imagenet_mean, std=config.imagenet_std),
            ToTensorV2()
        ]
    ))
    
    return tta_transforms


def get_heavy_tta_transforms(config: Config) -> List[A.Compose]:
    """
    ë” ë§Žì€ TTA ë³€í˜• (ê³ ì„±ëŠ¥ ì¶”êµ¬ì‹œ ì‚¬ìš©)
    
    Features:
        - 15ê°œ ë³€í˜•ìœ¼ë¡œ í™•ìž¥
        - ë‹¤ì–‘í•œ ë…¸ì´ì¦ˆ/ë¸”ëŸ¬ ì¡°í•©
        - ê³„ì‚° ì‹œê°„ ì¦ê°€í•˜ì§€ë§Œ ì„±ëŠ¥ í–¥ìƒ ê¸°ëŒ€
    
    Args:
        config (Config): ì„¤ì • ê°ì²´
        
    Returns:
        List[A.Compose]: í™•ìž¥ëœ TTA ë³€í™˜ ë¦¬ìŠ¤íŠ¸
    """
    
    # ê¸°ë³¸ TTA ë³€í˜•ë“¤ ê°€ì ¸ì˜¤ê¸°
    transforms = get_tta_transforms(config)
    
    base_transforms = [
        A.LongestMaxSize(max_size=config.img_size),
        A.PadIfNeeded(
            min_height=config.img_size,
            min_width=config.img_size,
            border_mode=0,
            value=0
        )
    ]
    
    # ì¶”ê°€ ë³€í˜•ë“¤
    additional_transforms = [
        # ë¸”ëŸ¬ ë³€í˜•ë“¤
        A.Compose(base_transforms + [
            A.GaussianBlur(blur_limit=3, p=1.0),
            A.Normalize(mean=config.imagenet_mean, std=config.imagenet_std),
            ToTensorV2()
        ]),
        
        A.Compose(base_transforms + [
            A.MotionBlur(blur_limit=5, p=1.0),
            A.Normalize(mean=config.imagenet_mean, std=config.imagenet_std),
            ToTensorV2()
        ]),
        
        # ë…¸ì´ì¦ˆ ë³€í˜•ë“¤
        A.Compose(base_transforms + [
            A.GaussNoise(var_limit=(50.0, 100.0), p=1.0),
            A.Normalize(mean=config.imagenet_mean, std=config.imagenet_std),
            ToTensorV2()
        ]),
        
        # ìˆ˜í‰ í”Œë¦½ + íšŒì „ ì¡°í•©
        A.Compose(base_transforms + [
            A.HorizontalFlip(p=1.0),
            A.Normalize(mean=config.imagenet_mean, std=config.imagenet_std),
            ToTensorV2()
        ]),
        
        A.Compose(base_transforms + [
            A.HorizontalFlip(p=1.0),
            A.Rotate(limit=[90, 90], p=1.0),
            A.Normalize(mean=config.imagenet_mean, std=config.imagenet_std),
            ToTensorV2()
        ]),
        
        # ëŒ€ë¹„ ì¡°ì • ë³€í˜•ë“¤
        A.Compose(base_transforms + [
            A.RandomBrightnessContrast(
                brightness_limit=[-0.2, -0.2],  # ì–´ë‘¡ê²Œ
                contrast_limit=[0.2, 0.2],      # ëŒ€ë¹„ ì¦ê°€
                p=1.0
            ),
            A.Normalize(mean=config.imagenet_mean, std=config.imagenet_std),
            ToTensorV2()
        ])
    ]
    
    return transforms + additional_transforms


def create_custom_transforms(
    img_size: int = 384,
    rotation_prob: float = 0.6,
    blur_prob: float = 0.9,
    brightness_prob: float = 0.8,
    noise_prob: float = 0.7,
    flip_prob: float = 0.5,
    mean: List[float] = None,
    std: List[float] = None
) -> A.Compose:
    """
    ì»¤ìŠ¤í…€ ë³€í™˜ ìƒì„± í•¨ìˆ˜
    
    Args:
        img_size: ì´ë¯¸ì§€ í¬ê¸°
        rotation_prob: íšŒì „ í™•ë¥ 
        blur_prob: ë¸”ëŸ¬ í™•ë¥ 
        brightness_prob: ë°ê¸° ì¡°ì • í™•ë¥ 
        noise_prob: ë…¸ì´ì¦ˆ í™•ë¥ 
        flip_prob: í”Œë¦½ í™•ë¥ 
        mean: ì •ê·œí™” í‰ê· ê°’
        std: ì •ê·œí™” í‘œì¤€íŽ¸ì°¨
        
    Returns:
        A.Compose: ì»¤ìŠ¤í…€ ë³€í™˜ íŒŒì´í”„ë¼ì¸
    """
    
    if mean is None:
        mean = [0.485, 0.456, 0.406]
    if std is None:
        std = [0.229, 0.224, 0.225]
    
    return A.Compose([
        A.LongestMaxSize(max_size=img_size),
        A.PadIfNeeded(
            min_height=img_size,
            min_width=img_size,
            border_mode=0,
            value=0
        ),
        
        A.OneOf([
            A.Rotate(limit=[90, 90], p=1.0),
            A.Rotate(limit=[180, 180], p=1.0),
            A.Rotate(limit=[270, 270], p=1.0),
        ], p=rotation_prob),
        
        A.OneOf([
            A.MotionBlur(blur_limit=7, p=1.0),
            A.GaussianBlur(blur_limit=7, p=1.0),
        ], p=blur_prob),
        
        A.RandomBrightnessContrast(
            brightness_limit=0.3,
            contrast_limit=0.3,
            p=brightness_prob
        ),
        
        A.GaussNoise(var_limit=(30.0, 100.0), p=noise_prob),
        A.HorizontalFlip(p=flip_prob),
        
        A.Normalize(mean=mean, std=std),
        ToTensorV2(),
    ])


# Alias for backward compatibility
get_val_transforms = get_test_transforms

if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì½”ë“œ
    import numpy as np
    from PIL import Image
    
    # ì„¤ì • ìƒì„±
    config = Config()
    
    # ê°€ìƒ ì´ë¯¸ì§€ ìƒì„± (ë¬¸ì„œ í˜•íƒœ)
    img = np.random.randint(0, 255, (600, 400, 3), dtype=np.uint8)  # ì„¸ë¡œê°€ ê¸´ ë¬¸ì„œ
    
    print("=== Transform Test ===")
    print(f"Original image shape: {img.shape}")
    
    # ê° ë³€í™˜ í…ŒìŠ¤íŠ¸
    transforms = {
        "Train": get_train_transforms(config),
        "Test": get_test_transforms(config),
    }
    
    for name, transform in transforms.items():
        transformed = transform(image=img)
        result = transformed['image']
        print(f"{name} transform result shape: {result.shape}")
    
    # TTA ë³€í™˜ í…ŒìŠ¤íŠ¸
    tta_transforms = get_tta_transforms(config)
    print(f"\nTTA transforms count: {len(tta_transforms)}")
    
    for i, transform in enumerate(tta_transforms):
        transformed = transform(image=img)
        result = transformed['image']
        print(f"TTA {i+1} result shape: {result.shape}")
    
    # Heavy TTA í…ŒìŠ¤íŠ¸
    heavy_tta = get_heavy_tta_transforms(config)
    print(f"\nHeavy TTA transforms count: {len(heavy_tta)}")
    
    print("\n=== Memory Usage Estimation ===")
    
    # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¶”ì •
    def estimate_memory_usage(img_size: int, batch_size: int, num_transforms: int):
        # ë‹¨ì¼ ì´ë¯¸ì§€: H x W x C x 4bytes (float32)
        single_img_bytes = img_size * img_size * 3 * 4
        # ë°°ì¹˜ ë©”ëª¨ë¦¬
        batch_memory = single_img_bytes * batch_size * num_transforms
        # GPU ì˜¤ë²„í—¤ë“œ ê³ ë ¤ (ì•½ 2ë°°)
        gpu_memory = batch_memory * 2
        
        # GB ë‹¨ìœ„ë¡œ ë³€í™˜
        gb = gpu_memory / (1024**3)
        return gb
    
    standard_memory = estimate_memory_usage(384, 64, 5)
    heavy_memory = estimate_memory_usage(384, 64, len(heavy_tta))
    
    print(f"Standard TTA memory usage: {standard_memory:.2f} GB")
    print(f"Heavy TTA memory usage: {heavy_memory:.2f} GB")
    
    # ê¶Œìž¥ì‚¬í•­
    print(f"\n=== Recommendations ===")
    if heavy_memory > 8:
        print("âš ï¸  Heavy TTA requires >8GB GPU memory")
        print("ðŸ’¡ Consider reducing batch size or using standard TTA")
    else:
        print("âœ… Heavy TTA should work with current settings")
