"""
K-Fold Cross Validation ì‹¤í—˜ ê´€ë¦¬
"""

import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import pandas as pd
from sklearn.model_selection import StratifiedKFold
from torch.utils.data import DataLoader, Subset
from typing import List, Dict, Any, Tuple, Optional
from pathlib import Path
import json
from datetime import datetime

from ..config import Config
from ..models.model import create_model
from ..data.dataset import ImageDataset
from ..data.transforms import get_train_transforms, get_val_transforms
from ..training.trainer import Trainer
from ..training.validator import Validator
from ..training.loss import get_loss_function
from ..training.scheduler import get_scheduler
from ..utils.seed import set_seed


class KFoldExperiment:
    """
    K-Fold Cross Validation ì‹¤í—˜ì„ ê´€ë¦¬í•˜ëŠ” í´ë˜ìŠ¤
    
    Features:
        - Stratified K-Fold ë¶„í• 
        - ê° Foldë³„ ëª¨ë¸ í•™ìŠµ ë° ê²€ì¦
        - êµì°¨ ê²€ì¦ ê²°ê³¼ ì§‘ê³„
        - ëª¨ë¸ ì €ì¥ ë° ë¡œë“œ
        - ì‹¤í—˜ ì¬í˜„ì„± ë³´ì¥
    """
    
    def __init__(self, config: Config):
        """
        Args:
            config: ì‹¤í—˜ ì„¤ì • ê°ì²´
        """
        
        self.config = config
        self.trainer = Trainer(config)
        self.validator = Validator(config)
        
        # ê²°ê³¼ ì €ì¥ìš©
        self.fold_results = []
        self.fold_models = []
        
        print("âœ… K-Fold Experiment initialized")
        print(f"   - Number of folds: {config.n_folds}")
        print(f"   - Random state: {config.fold_random_state}")
        print(f"   - Device: {config.device}")
    
    def prepare_data_splits(self, train_df: pd.DataFrame) -> List[Tuple[List[int], List[int]]]:
        """
        Stratified K-Fold ë°ì´í„° ë¶„í• 
        
        Args:
            train_df: í›ˆë ¨ ë°ì´í„°í”„ë ˆì„ (ID, target ì»¬ëŸ¼ í•„ìš”)
            
        Returns:
            List[Tuple[List[int], List[int]]]: (train_indices, val_indices) íŠœí”Œë“¤ì˜ ë¦¬ìŠ¤íŠ¸
        """
        
        # Stratified K-Fold ì„¤ì •
        skf = StratifiedKFold(
            n_splits=self.config.n_folds,
            shuffle=True,
            random_state=self.config.fold_random_state
        )
        
        # ì¸ë±ìŠ¤ì™€ íƒ€ê²Ÿ ì¶”ì¶œ
        indices = np.arange(len(train_df))
        targets = train_df['target'].values
        
        # ë¶„í•  ìˆ˜í–‰
        splits = []
        for fold_idx, (train_idx, val_idx) in enumerate(skf.split(indices, targets)):
            splits.append((train_idx.tolist(), val_idx.tolist()))
            
            print(f"Fold {fold_idx + 1}: Train={len(train_idx)}, Val={len(val_idx)}")
            
            # í´ë˜ìŠ¤ ë¶„í¬ í™•ì¸
            train_targets = targets[train_idx]
            val_targets = targets[val_idx]
            print(f"  Train classes: {np.bincount(train_targets)}")
            print(f"  Val classes: {np.bincount(val_targets)}")
        
        return splits
    
    def create_fold_dataloaders(
        self, 
        train_dataset: ImageDataset,
        train_indices: List[int],
        val_indices: List[int]
    ) -> Tuple[DataLoader, DataLoader]:
        """
        Foldë³„ ë°ì´í„°ë¡œë” ìƒì„±
        
        Args:
            train_dataset: ì „ì²´ í›ˆë ¨ ë°ì´í„°ì…‹
            train_indices: í›ˆë ¨ìš© ì¸ë±ìŠ¤
            val_indices: ê²€ì¦ìš© ì¸ë±ìŠ¤
            
        Returns:
            Tuple[DataLoader, DataLoader]: (train_loader, val_loader)
        """
        
        # ì„œë¸Œì…‹ ìƒì„±
        train_subset = Subset(train_dataset, train_indices)
        val_subset = Subset(train_dataset, val_indices)
        
        # ê²€ì¦ìš© ë³€í™˜ì„ ì‚¬ìš©í•˜ëŠ” ê²€ì¦ ë°ì´í„°ì…‹ ìƒì„±
        val_dataset_transforms = ImageDataset(
            train_dataset.image_paths, 
            train_dataset.targets,
            transform=get_val_transforms(self.config)
        )
        val_subset_with_transforms = Subset(val_dataset_transforms, val_indices)
        
        # ë°ì´í„°ë¡œë” ìƒì„±
        train_loader = DataLoader(
            train_subset,
            batch_size=self.config.batch_size,
            shuffle=True,
            num_workers=self.config.num_workers,
            pin_memory=True,
            drop_last=True
        )
        
        val_loader = DataLoader(
            val_subset_with_transforms,
            batch_size=self.config.batch_size,
            shuffle=False,
            num_workers=self.config.num_workers,
            pin_memory=True
        )
        
        return train_loader, val_loader
    
    def train_single_fold(
        self,
        fold_idx: int,
        train_loader: DataLoader,
        val_loader: DataLoader,
        save_model: bool = True
    ) -> Dict[str, Any]:
        """
        ë‹¨ì¼ Fold í•™ìŠµ ìˆ˜í–‰
        
        Args:
            fold_idx: Fold ë²ˆí˜¸ (0ë¶€í„° ì‹œì‘)
            train_loader: í›ˆë ¨ ë°ì´í„°ë¡œë”
            val_loader: ê²€ì¦ ë°ì´í„°ë¡œë”
            save_model: ëª¨ë¸ ì €ì¥ ì—¬ë¶€
            
        Returns:
            Dict[str, Any]: Fold í•™ìŠµ ê²°ê³¼
        """
        
        print(f"\n{'='*60}")
        print(f"FOLD {fold_idx + 1}/{self.config.n_folds} TRAINING")
        print(f"{'='*60}")
        
        # ì‹œë“œ ê³ ì • (ì¬í˜„ì„±)
        set_seed(self.config.seed + fold_idx)
        
        # ëª¨ë¸, ì˜µí‹°ë§ˆì´ì €, ìŠ¤ì¼€ì¤„ëŸ¬, ì†ì‹¤í•¨ìˆ˜ ìƒì„±
        model = create_model(self.config)
        optimizer = optim.AdamW(
            model.parameters(),
            lr=self.config.learning_rate,
            weight_decay=1e-4
        )
        scheduler = get_scheduler(optimizer, self.config)
        loss_fn = get_loss_function(self.config)
        
        # ìµœê³  ì„±ëŠ¥ ì¶”ì 
        best_val_f1 = 0.0
        best_model_state = None
        fold_history = []
        
        # ì—í¬í¬ë³„ í•™ìŠµ
        for epoch in range(self.config.epochs):
            print(f"\n--- Epoch {epoch + 1}/{self.config.epochs} ---")
            
            # í•™ìŠµ
            train_results = self.trainer.train_one_epoch(
                model, train_loader, optimizer, loss_fn, self.config.device
            )
            
            # ê²€ì¦
            val_results = self.validator.validate_one_epoch(
                model, val_loader, loss_fn, self.config.device
            )
            
            # ìŠ¤ì¼€ì¤„ëŸ¬ ì—…ë°ì´íŠ¸
            if scheduler is not None:
                if isinstance(scheduler, optim.lr_scheduler.ReduceLROnPlateau):
                    scheduler.step(val_results['val_loss'])
                else:
                    scheduler.step()
            
            # ì—í¬í¬ ê²°ê³¼ ê¸°ë¡
            epoch_result = {
                "epoch": epoch + 1,
                "lr": optimizer.param_groups[0]['lr'],
                **train_results,
                **val_results
            }
            fold_history.append(epoch_result)
            
            # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥
            current_val_f1 = val_results['val_f1']
            if current_val_f1 > best_val_f1:
                best_val_f1 = current_val_f1
                best_model_state = model.state_dict().copy()
            
            # ì§„í–‰ ìƒí™© ì¶œë ¥
            print(f"Train Loss: {train_results['train_loss']:.4f} | "
                  f"Train F1: {train_results['train_f1']:.4f}")
            print(f"Val Loss: {val_results['val_loss']:.4f} | "
                  f"Val F1: {current_val_f1:.4f} (Best: {best_val_f1:.4f})")
        
        # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ë¡œ ë³µì›
        if best_model_state is not None:
            model.load_state_dict(best_model_state)
        
        # ëª¨ë¸ ì €ì¥
        if save_model:
            self.save_fold_model(model, fold_idx, best_val_f1)
        
        # Fold ê²°ê³¼ ì •ë¦¬
        fold_result = {
            "fold": fold_idx + 1,
            "best_val_f1": best_val_f1,
            "final_train_loss": fold_history[-1]['train_loss'],
            "final_val_loss": fold_history[-1]['val_loss'],
            "epochs_trained": len(fold_history),
            "history": fold_history,
            "model_state_dict": best_model_state
        }
        
        return fold_result
    
    def run_cross_validation(self, train_df: pd.DataFrame) -> Dict[str, Any]:
        """
        ì „ì²´ K-Fold Cross Validation ì‹¤í–‰
        
        Args:
            train_df: í›ˆë ¨ ë°ì´í„°í”„ë ˆì„
            
        Returns:
            Dict[str, Any]: êµì°¨ ê²€ì¦ ê²°ê³¼
        """
        
        print(f"\nğŸš€ Starting {self.config.n_folds}-Fold Cross Validation")
        print(f"Dataset size: {len(train_df)}")
        
        # ë°ì´í„° ë¶„í• 
        splits = self.prepare_data_splits(train_df)
        
        # ì „ì²´ ë°ì´í„°ì…‹ ìƒì„± (í›ˆë ¨ìš© ë³€í™˜ ì ìš©)
        train_dataset = ImageDataset(
            image_paths=[f"{self.config.train_path}{img_id}" for img_id in train_df['ID']],
            targets=train_df['target'].tolist(),
            transform=get_train_transforms(self.config)
        )
        
        # ê° Fold í•™ìŠµ
        fold_results = []
        fold_models = []
        
        for fold_idx, (train_indices, val_indices) in enumerate(splits):
            # Foldë³„ ë°ì´í„°ë¡œë” ìƒì„±
            train_loader, val_loader = self.create_fold_dataloaders(
                train_dataset, train_indices, val_indices
            )
            
            # Fold í•™ìŠµ ìˆ˜í–‰
            fold_result = self.train_single_fold(
                fold_idx, train_loader, val_loader, save_model=True
            )
            
            fold_results.append(fold_result)
            
            # ëª¨ë¸ ì €ì¥ (ë©”ëª¨ë¦¬ì—)
            model = create_model(self.config)
            model.load_state_dict(fold_result['model_state_dict'])
            fold_models.append(model)
            
            print(f"\nâœ… Fold {fold_idx + 1} completed - Best Val F1: {fold_result['best_val_f1']:.4f}")
        
        # êµì°¨ ê²€ì¦ ê²°ê³¼ ì§‘ê³„
        cv_results = self.aggregate_cv_results(fold_results)
        
        # ê²°ê³¼ ì €ì¥
        self.fold_results = fold_results
        self.fold_models = fold_models
        
        return cv_results
    
    def aggregate_cv_results(self, fold_results: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        êµì°¨ ê²€ì¦ ê²°ê³¼ ì§‘ê³„
        
        Args:
            fold_results: ê° Fold ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            Dict[str, Any]: ì§‘ê³„ëœ ê²°ê³¼
        """
        
        # F1 ìŠ¤ì½”ì–´ ì§‘ê³„
        f1_scores = [result['best_val_f1'] for result in fold_results]
        
        cv_summary = {
            "mean_f1": float(np.mean(f1_scores)),
            "std_f1": float(np.std(f1_scores)),
            "min_f1": float(np.min(f1_scores)),
            "max_f1": float(np.max(f1_scores)),
            "fold_f1_scores": f1_scores,
            "best_fold": int(np.argmax(f1_scores)) + 1,
            "worst_fold": int(np.argmin(f1_scores)) + 1,
            "cv_score": f"{np.mean(f1_scores):.4f} Â± {np.std(f1_scores):.4f}",
            "n_folds": self.config.n_folds,
            "total_epochs": sum(result['epochs_trained'] for result in fold_results)
        }
        
        print(f"\n{'='*60}")
        print(f"CROSS VALIDATION RESULTS")
        print(f"{'='*60}")
        print(f"Mean F1: {cv_summary['mean_f1']:.4f} Â± {cv_summary['std_f1']:.4f}")
        print(f"Min F1: {cv_summary['min_f1']:.4f} (Fold {cv_summary['worst_fold']})")
        print(f"Max F1: {cv_summary['max_f1']:.4f} (Fold {cv_summary['best_fold']})")
        print(f"Total epochs: {cv_summary['total_epochs']}")
        
        return cv_summary
    
    def save_fold_model(self, model: nn.Module, fold_idx: int, val_f1: float):
        """
        Fold ëª¨ë¸ ì €ì¥
        
        Args:
            model: ì €ì¥í•  ëª¨ë¸
            fold_idx: Fold ë²ˆí˜¸
            val_f1: ê²€ì¦ F1 ìŠ¤ì½”ì–´
        """
        
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
        output_dir = Path(self.config.output_path) / "models"
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # ëª¨ë¸ íŒŒì¼ ê²½ë¡œ
        model_path = output_dir / f"fold_{fold_idx + 1}_f1_{val_f1:.4f}.pth"
        
        # ëª¨ë¸ ì €ì¥
        torch.save({
            'model_state_dict': model.state_dict(),
            'fold': fold_idx + 1,
            'val_f1': val_f1,
            'config': self.config.__dict__,
            'timestamp': datetime.now().isoformat()
        }, model_path)
        
        print(f"ğŸ’¾ Fold {fold_idx + 1} model saved: {model_path}")
    
    def save_experiment_results(self, cv_results: Dict[str, Any], filename: str = None):
        """
        ì‹¤í—˜ ê²°ê³¼ ì €ì¥
        
        Args:
            cv_results: êµì°¨ ê²€ì¦ ê²°ê³¼
            filename: ì €ì¥í•  íŒŒì¼ëª… (Noneì´ë©´ ìë™ ìƒì„±)
        """
        
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
        output_dir = Path(self.config.output_path)
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # íŒŒì¼ëª… ìƒì„±
        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"cv_results_{timestamp}.json"
        
        result_path = output_dir / filename
        
        # ê²°ê³¼ ì €ì¥ (model_state_dict ì œì™¸)
        save_results = {
            "cv_summary": cv_results,
            "config": self.config.__dict__,
            "fold_results": [
                {k: v for k, v in fold_result.items() if k != 'model_state_dict'}
                for fold_result in self.fold_results
            ],
            "timestamp": datetime.now().isoformat()
        }
        
        with open(result_path, 'w', encoding='utf-8') as f:
            json.dump(save_results, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ“„ Experiment results saved: {result_path}")
    
    def load_fold_models(self, model_dir: str) -> List[nn.Module]:
        """
        ì €ì¥ëœ Fold ëª¨ë¸ë“¤ ë¡œë“œ
        
        Args:
            model_dir: ëª¨ë¸ì´ ì €ì¥ëœ ë””ë ‰í† ë¦¬
            
        Returns:
            List[nn.Module]: ë¡œë“œëœ ëª¨ë¸ ë¦¬ìŠ¤íŠ¸
        """
        
        model_dir = Path(model_dir)
        model_files = sorted(model_dir.glob("fold_*.pth"))
        
        loaded_models = []
        
        for model_file in model_files:
            # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
            checkpoint = torch.load(model_file, map_location=self.config.device)
            
            # ëª¨ë¸ ìƒì„± ë° ìƒíƒœ ë¡œë“œ
            model = create_model(self.config)
            model.load_state_dict(checkpoint['model_state_dict'])
            model.to(self.config.device)
            model.eval()
            
            loaded_models.append(model)
            
            print(f"ğŸ“‚ Loaded Fold {checkpoint['fold']} model (F1: {checkpoint['val_f1']:.4f})")
        
        print(f"âœ… Total {len(loaded_models)} fold models loaded")
        
        return loaded_models
    
    def get_experiment_summary(self) -> Dict[str, Any]:
        """ì‹¤í—˜ ìš”ì•½ ì •ë³´ ë°˜í™˜"""
        
        if not self.fold_results:
            return {"status": "No experiment results available"}
        
        f1_scores = [result['best_val_f1'] for result in self.fold_results]
        
        return {
            "n_folds": len(self.fold_results),
            "mean_cv_f1": float(np.mean(f1_scores)),
            "std_cv_f1": float(np.std(f1_scores)),
            "best_fold_f1": float(np.max(f1_scores)),
            "worst_fold_f1": float(np.min(f1_scores)),
            "total_models": len(self.fold_models),
            "config_summary": {
                "model_name": self.config.model_name,
                "img_size": self.config.img_size,
                "batch_size": self.config.batch_size,
                "epochs": self.config.epochs,
                "learning_rate": self.config.learning_rate
            }
        }


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì½”ë“œ
    import tempfile
    import os
    
    # í…ŒìŠ¤íŠ¸ìš© ì„¤ì •
    config = Config()
    config.device = "cpu"
    config.model_name = "efficientnet_b0"
    config.n_folds = 3  # ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ 3-fold
    config.epochs = 2   # ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ 2 epochs
    config.batch_size = 4
    config.num_workers = 0  # í…ŒìŠ¤íŠ¸ ì‹œ ë©€í‹°í”„ë¡œì„¸ì‹± ë¹„í™œì„±í™”
    
    print("=== K-Fold Experiment Test ===")
    
    # ì„ì‹œ ë””ë ‰í† ë¦¬ ìƒì„±
    with tempfile.TemporaryDirectory() as tmp_dir:
        config.output_path = tmp_dir + "/"
        
        # ê°€ìƒ í›ˆë ¨ ë°ì´í„° ìƒì„±
        fake_train_df = pd.DataFrame({
            'ID': [f'img_{i:03d}.jpg' for i in range(60)],
            'target': np.random.randint(0, 17, 60)  # 17ê°œ í´ë˜ìŠ¤
        })
        
        # K-Fold ì‹¤í—˜ ì´ˆê¸°í™”
        experiment = KFoldExperiment(config)
        
        print("Testing data splits...")
        splits = experiment.prepare_data_splits(fake_train_df)
        print(f"Created {len(splits)} splits")
        
        # ì‹¤í—˜ ìš”ì•½ í…ŒìŠ¤íŠ¸
        summary = experiment.get_experiment_summary()
        print(f"Experiment summary: {summary}")
        
    print("âœ… K-Fold Experiment test completed successfully")
