# GPU ìë™ ì„¤ì • ë„êµ¬ ì™„ì „ ê°€ì´ë“œ

## ğŸ“– ëª©ì°¨
1. [ê°œìš”](#ê°œìš”)
2. [ë„êµ¬ êµ¬ì„±](#ë„êµ¬-êµ¬ì„±)
3. [ìë™ ë°°ì¹˜ í¬ê¸° ìµœì í™” ë„êµ¬](#ìë™-ë°°ì¹˜-í¬ê¸°-ìµœì í™”-ë„êµ¬)
4. [GPU í˜¸í™˜ì„± ì²´í¬ ë„êµ¬](#gpu-í˜¸í™˜ì„±-ì²´í¬-ë„êµ¬)
5. [íŒ€ í˜‘ì—… ì›Œí¬í”Œë¡œìš°](#íŒ€-í˜‘ì—…-ì›Œí¬í”Œë¡œìš°)
6. [ì‹¤ì œ ì‚¬ìš© ì˜ˆì‹œ](#ì‹¤ì œ-ì‚¬ìš©-ì˜ˆì‹œ)
7. [ë¬¸ì œ í•´ê²°](#ë¬¸ì œ-í•´ê²°)
8. [ê³ ê¸‰ ì„¤ì •](#ê³ ê¸‰-ì„¤ì •)

---

## ğŸš€ ê°œìš”

ë³¸ í”„ë¡œì íŠ¸ëŠ” íŒ€ì›ë“¤ì´ ë‹¤ì–‘í•œ GPU í™˜ê²½ì—ì„œ ì¼ê´€ëœ ì„±ëŠ¥ì„ ì–»ì„ ìˆ˜ ìˆë„ë¡ **GPU ì‚¬ì–‘ì— ë§ëŠ” ìµœì ì˜ ë°°ì¹˜ í¬ê¸°ë¥¼ ìë™ìœ¼ë¡œ ì°¾ì•„ì£¼ëŠ” ë„êµ¬**ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

### ğŸ¯ í•µì‹¬ ê¸°ëŠ¥
- **GPU ìë™ ê°ì§€ ë° ë“±ê¸‰ ë¶„ë¥˜** (RTX 4090ë¶€í„° GTX 1080ê¹Œì§€)
- **ëª¨ë¸ë³„, ì´ë¯¸ì§€ í¬ê¸°ë³„ ìµœì  ë°°ì¹˜ í¬ê¸° ìë™ íƒìƒ‰**
- **ë©”ëª¨ë¦¬ ì•ˆì „ ë§ˆì§„ ì ìš©**
- **ì„¤ì • íŒŒì¼ ìë™ ì—…ë°ì´íŠ¸**
- **íŒ€ í˜‘ì—…ì„ ìœ„í•œ ê¶Œì¥ì‚¬í•­ ì œê³µ**

### ğŸ“¦ ë„êµ¬ êµ¬ì„±
```
src/utils/
â”œâ”€â”€ auto_batch_size.py      # ë©”ì¸ ìë™ ë°°ì¹˜ í¬ê¸° ìµœì í™” ë„êµ¬
â””â”€â”€ team_gpu_check.py       # GPU í˜¸í™˜ì„± ë¹ ë¥¸ ì²´í¬ ë„êµ¬
```

---

## ğŸ”§ ìë™ ë°°ì¹˜ í¬ê¸° ìµœì í™” ë„êµ¬

### íŒŒì¼ ìœ„ì¹˜
`src/utils/auto_batch_size.py`

### ì£¼ìš” ê¸°ëŠ¥

#### 1. GPU ë“±ê¸‰ë³„ ìë™ ë¶„ë¥˜
```python
def get_gpu_info_and_recommendations() -> Dict[str, Any]:
    """GPU ì •ë³´ë¥¼ í™•ì¸í•˜ê³  ê¶Œì¥ ì„¤ì •ì„ ë°˜í™˜"""
```

| GPU ë“±ê¸‰ | í•´ë‹¹ ëª¨ë¸ | íŠ¹ì§• |
|----------|-----------|------|
| **high_end** | RTX 4090, RTX 4080, RTX 3090, A100, V100 | ìµœê³  ì„±ëŠ¥, Multi-GPU í›ˆë ¨ ê°€ëŠ¥ |
| **mid_range** | RTX 3080, RTX 3070, RTX 4070 | ìš°ìˆ˜í•œ ì„±ëŠ¥, gradient_accumulation ê¶Œì¥ |
| **budget** | RTX 3060, RTX 2070, RTX 2080 | ì ì ˆí•œ ì„±ëŠ¥, ë©”ëª¨ë¦¬ íš¨ìœ¨ ì¤‘ì‹œ |
| **low_end** | GTX 1660, GTX 1080 ë“± | ì£¼ì˜ í•„ìš”, mixed precision ë¹„í™œì„±í™” ê¶Œì¥ |

#### 2. ì´ë¯¸ì§€ í¬ê¸°ë³„ ìµœì í™” í”„ë¡œí•„
```python
# RTX 4090 ì˜ˆì‹œ
profile = {
    'batch_224': {'start': 64, 'max': 128, 'safety': 0.8},  # 224px ì´ë¯¸ì§€
    'batch_384': {'start': 32, 'max': 64, 'safety': 0.8},   # 384px ì´ë¯¸ì§€
    'batch_512': {'start': 16, 'max': 32, 'safety': 0.8}    # 512px ì´ë¯¸ì§€
}
```

#### 3. ì´ì§„ íƒìƒ‰ ê¸°ë°˜ ìµœì  ë°°ì¹˜ í¬ê¸° íƒìƒ‰
```python
def find_optimal_batch_size(model_name: str, img_size: int, gpu_info: Dict[str, Any]) -> int:
    """ìµœì ì˜ ë°°ì¹˜ í¬ê¸° ì°¾ê¸° (GPU ë“±ê¸‰ë³„ ìµœì í™”)"""
```

### ì‚¬ìš©ë²•

#### ê¸°ë³¸ ì‚¬ìš©ë²•
```bash
# pyenv ê°€ìƒí™˜ê²½ í™œì„±í™” (í•„ìˆ˜)
pyenv activate cv_py3_11_9

# í…ŒìŠ¤íŠ¸ë§Œ ìˆ˜í–‰ (ì„¤ì • íŒŒì¼ ìˆ˜ì • ì•ˆí•¨)
python src/utils/auto_batch_size.py --config configs/train.yaml --test-only

# ì„¤ì • íŒŒì¼ ìë™ ì—…ë°ì´íŠ¸
python src/utils/auto_batch_size.py --config configs/train.yaml

# ê³ ì„±ëŠ¥ ì„¤ì • ìµœì í™”
python src/utils/auto_batch_size.py --config configs/train_highperf.yaml
```

#### ê³ ê¸‰ ì˜µì…˜
```bash
# íŠ¹ì • ëª¨ë¸ ì§€ì •
python src/utils/auto_batch_size.py --config configs/train.yaml --model swin_base_384

# íŠ¹ì • ì´ë¯¸ì§€ í¬ê¸° ì§€ì •
python src/utils/auto_batch_size.py --config configs/train.yaml --img-size 384

# ë„ì›€ë§ ë³´ê¸°
python src/utils/auto_batch_size.py --help
```

### ì‹¤í–‰ ê²°ê³¼ ì˜ˆì‹œ (RTX 4090)
```
ğŸš€ íŒ€ í˜‘ì—…ìš© GPU ìµœì í™” ìë™ ë°°ì¹˜ í¬ê¸° ì°¾ê¸° ë„êµ¬
=======================================================
ğŸ”§ GPU: NVIDIA GeForce RTX 4090
ğŸ’¾ GPU ë©”ëª¨ë¦¬: 24.0 GB
ğŸ† GPU ë“±ê¸‰: high_end
ğŸ’¡ ê¶Œì¥ ë°°ì¹˜ ë²”ìœ„: 32 ~ 64
ğŸ“Š ëª¨ë¸: swin_base_384
ğŸ“ ì´ë¯¸ì§€ í¬ê¸°: 384

ğŸ” high_end GPU ìµœì  ë°°ì¹˜ í¬ê¸° íƒìƒ‰ ì¤‘...
   GPU: NVIDIA GeForce RTX 4090
   ë©”ëª¨ë¦¬: 24.0 GB
   ëª¨ë¸: swin_base_384
   ì´ë¯¸ì§€ í¬ê¸°: 384
   ğŸ“Š high_end GPU ê¶Œì¥ ë²”ìœ„: 32 ~ 64
   ğŸ›¡ï¸ ì•ˆì „ ë§ˆì§„: 20%
   
   ë°°ì¹˜ í¬ê¸° 48 í…ŒìŠ¤íŠ¸ ì¤‘... âœ… (ë©”ëª¨ë¦¬: 0.14 GB)
   ë°°ì¹˜ í¬ê¸° 56 í…ŒìŠ¤íŠ¸ ì¤‘... âœ… (ë©”ëª¨ë¦¬: 0.16 GB)
   ë°°ì¹˜ í¬ê¸° 60 í…ŒìŠ¤íŠ¸ ì¤‘... âœ… (ë©”ëª¨ë¦¬: 0.16 GB)
   ë°°ì¹˜ í¬ê¸° 62 í…ŒìŠ¤íŠ¸ ì¤‘... âœ… (ë©”ëª¨ë¦¬: 0.17 GB)
   ë°°ì¹˜ í¬ê¸° 63 í…ŒìŠ¤íŠ¸ ì¤‘... âœ… (ë©”ëª¨ë¦¬: 0.17 GB)
   ë°°ì¹˜ í¬ê¸° 64 í…ŒìŠ¤íŠ¸ ì¤‘... âœ… (ë©”ëª¨ë¦¬: 0.17 GB)

ğŸ¯ high_end GPU ìµœì  ë°°ì¹˜ í¬ê¸°: 48
   ğŸ’¡ ê³ ì„±ëŠ¥ GPU: ë” í° ëª¨ë¸ì´ë‚˜ ë” ë†’ì€ í•´ìƒë„ ê³ ë ¤ ê°€ëŠ¥

=======================================================
ğŸ‰ ìµœì¢… ê²°ê³¼:
   ìµœì  ë°°ì¹˜ í¬ê¸°: 48
   GPU ë“±ê¸‰: high_end
   ì˜ˆìƒ ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ : ~38%

âœ… ì„¤ì • íŒŒì¼ ì—…ë°ì´íŠ¸ ì™„ë£Œ: batch_size = 48
```

---

## ğŸ” GPU í˜¸í™˜ì„± ì²´í¬ ë„êµ¬

### íŒŒì¼ ìœ„ì¹˜
`src/utils/team_gpu_check.py`

### ì£¼ìš” ê¸°ëŠ¥
- **CUDA í˜¸í™˜ì„± ì¦‰ì‹œ í™•ì¸**
- **GPU ì •ë³´ ìƒì„¸ ì¶œë ¥**
- **íŒ€ì›ë³„ ê¶Œì¥ ì„¤ì • ì œê³µ**
- **ë‹¤ìŒ ë‹¨ê³„ ê°€ì´ë“œ**

### ì‚¬ìš©ë²•
```bash
# pyenv ê°€ìƒí™˜ê²½ í™œì„±í™” (í•„ìˆ˜)
pyenv activate cv_py3_11_9

# GPU í˜¸í™˜ì„± ì²´í¬
python src/utils/team_gpu_check.py
```

### ì‹¤í–‰ ê²°ê³¼ ì˜ˆì‹œ
```
íŒ€ í˜‘ì—…ìš© GPU í˜¸í™˜ì„± ì²´í¬ ë„êµ¬
Team GPU Compatibility Checker

ğŸ” íŒ€ GPU í˜¸í™˜ì„± ì²´í¬
========================================
âœ… CUDA ì‚¬ìš© ê°€ëŠ¥
ğŸ”§ GPU ê°œìˆ˜: 1

ğŸ“Š GPU 0: NVIDIA GeForce RTX 4090
ğŸ’¾ ë©”ëª¨ë¦¬: 24.0 GB
ğŸ·ï¸ ë“±ê¸‰: ğŸ† HIGH-END
ğŸ“ ê¶Œì¥ ë°°ì¹˜: 64-128 (224px), 32-64 (384px)
ğŸ’¡ íŒ: ìµœê³  ì„±ëŠ¥! Multi-GPU í›ˆë ¨ ê°€ëŠ¥

ğŸš€ ë‹¤ìŒ ë‹¨ê³„:
   1. ìë™ ë°°ì¹˜ í¬ê¸° ìµœì í™”:
      python src/utils/auto_batch_size.py --config configs/train.yaml --test-only
   2. ì„¤ì • íŒŒì¼ ì—…ë°ì´íŠ¸:
      python src/utils/auto_batch_size.py --config configs/train.yaml
   3. í›ˆë ¨ ì‹œì‘:
      python src/training/train_main.py --config configs/train_highperf.yaml --mode highperf

ğŸ PyTorch ì •ë³´:
   ë²„ì „: 2.1.0+cu121
   CUDA ë²„ì „: 12.1
   cuDNN ë²„ì „: 8902

âœ… GPU ì„¤ì • ì™„ë£Œ! íŒ€ í˜‘ì—… ì¤€ë¹„ ì™„ë£Œ!
```

---

## ğŸ¤ íŒ€ í˜‘ì—… ì›Œí¬í”Œë¡œìš°

### 1ë‹¨ê³„: ê°œë³„ GPU í™˜ê²½ í™•ì¸
```bash
# ê° íŒ€ì›ì´ ìì‹ ì˜ í™˜ê²½ì—ì„œ ì‹¤í–‰
pyenv activate cv_py3_11_9
python src/utils/team_gpu_check.py
```

### 2ë‹¨ê³„: ìµœì  ë°°ì¹˜ í¬ê¸° íƒìƒ‰
```bash
# í…ŒìŠ¤íŠ¸ ëª¨ë“œë¡œ ì•ˆì „í•˜ê²Œ í™•ì¸
python src/utils/auto_batch_size.py --config configs/train.yaml --test-only
```

### 3ë‹¨ê³„: ì„¤ì • íŒŒì¼ ì—…ë°ì´íŠ¸
```bash
# ìµœì í™”ëœ ì„¤ì •ìœ¼ë¡œ ì—…ë°ì´íŠ¸
python src/utils/auto_batch_size.py --config configs/train.yaml
```

### 4ë‹¨ê³„: Git í˜‘ì—…
```bash
# ê°œë³„ ë¸Œëœì¹˜ì—ì„œ ì‘ì—…
git checkout -b optimize/gpu-[GPU_NAME]
git add configs/train.yaml
git commit -m "GPU ìµœì í™”: [GPU_NAME]ì—ì„œ batch_sizeë¥¼ [SIZE]ë¡œ ì¡°ì •"

# ë©”ì¸ ë¸Œëœì¹˜ì— ë³‘í•©
git checkout main
git merge optimize/gpu-[GPU_NAME]
```

### 5ë‹¨ê³„: í›ˆë ¨ ì‹œì‘
```bash
# ìµœì í™”ëœ ì„¤ì •ìœ¼ë¡œ í›ˆë ¨
python src/training/train_main.py --config configs/train_highperf.yaml --mode highperf
```

---

## ğŸ’» ì‹¤ì œ ì‚¬ìš© ì˜ˆì‹œ

### RTX 4090 ì‚¬ìš©ì (í˜„ì¬ í™˜ê²½)
```bash
pyenv activate cv_py3_11_9
python src/utils/auto_batch_size.py --config configs/train_highperf.yaml

# ê²°ê³¼: batch_size = 48 (384px ì´ë¯¸ì§€)
# ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ : ~38%
# ì„±ëŠ¥ í–¥ìƒ: ~50%
```

### RTX 3060 ì‚¬ìš©ì (ì˜ˆìƒ)
```bash
pyenv activate cv_py3_11_9
python src/utils/auto_batch_size.py --config configs/train.yaml

# ì˜ˆìƒ ê²°ê³¼: batch_size = 12-16 (384px ì´ë¯¸ì§€)
# ì¶”ê°€ ê¶Œì¥: gradient_accumulation_steps = 3-4
# ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ : ~85%
```

### GTX 1080 ì‚¬ìš©ì (ì˜ˆìƒ)
```bash
pyenv activate cv_py3_11_9
python src/utils/auto_batch_size.py --config configs/train.yaml

# ì˜ˆìƒ ê²°ê³¼: batch_size = 6-8 (384px ì´ë¯¸ì§€)
# ì¶”ê°€ ê¶Œì¥: mixed precision ë¹„í™œì„±í™”, gradient_accumulation_steps = 6-8
# ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ : ~90%
```

---

## ğŸš¨ ë¬¸ì œ í•´ê²°

### 1. CUDA ê´€ë ¨ ì˜¤ë¥˜
```bash
# ì˜¤ë¥˜: CUDAë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤
âŒ CUDAê°€ ì‚¬ìš© ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤
ğŸ’¡ í•´ê²°ì±…:
   - NVIDIA ë“œë¼ì´ë²„ ì„¤ì¹˜ í™•ì¸
   - CUDA ì„¤ì¹˜ í™•ì¸
   - PyTorch CUDA ë²„ì „ í™•ì¸

# í•´ê²° ë°©ë²•
nvidia-smi  # ë“œë¼ì´ë²„ í™•ì¸
python -c "import torch; print(torch.cuda.is_available())"  # PyTorch CUDA í™•ì¸
```

### 2. Out of Memory ì˜¤ë¥˜
```bash
# ë©”ëª¨ë¦¬ ë¶€ì¡± ì‹œ
ğŸ’¡ í•´ê²°ì±…:
1. ë°°ì¹˜ í¬ê¸° 50% ê°ì†Œ
2. gradient_accumulation_steps ì¦ê°€
3. mixed precision í™œì„±í™”/ë¹„í™œì„±í™” ì‹œë„
4. ì´ë¯¸ì§€ í¬ê¸° ê°ì†Œ ê³ ë ¤
```

### 3. PyYAML ëˆ„ë½ ì˜¤ë¥˜
```bash
# PyYAML ì„¤ì¹˜
pyenv activate cv_py3_11_9
pip install PyYAML
```

### 4. ê°€ìƒí™˜ê²½ ì˜¤ë¥˜
```bash
# pyenv ê°€ìƒí™˜ê²½ ì¬ì„¤ì •
pyenv deactivate
pyenv activate cv_py3_11_9

# ë˜ëŠ” ìƒˆë¡œ ìƒì„±
pyenv virtualenv 3.11.9 cv_py3_11_9_new
pyenv activate cv_py3_11_9_new
pip install -r requirements.txt
```

---

## âš™ï¸ ê³ ê¸‰ ì„¤ì •

### 1. ì»¤ìŠ¤í…€ GPU í”„ë¡œí•„ ì¶”ê°€
```python
# src/utils/auto_batch_size.py ìˆ˜ì •
# ìƒˆë¡œìš´ GPU ì¶”ê°€ ì˜ˆì‹œ
elif any(gpu in device_name for gpu in ['RTX 4060', 'NEW_GPU']):
    tier = 'custom'
    profile = {
        'batch_224': {'start': 24, 'max': 48, 'safety': 0.8},
        'batch_384': {'start': 12, 'max': 24, 'safety': 0.8},
        'batch_512': {'start': 6, 'max': 12, 'safety': 0.8}
    }
```

### 2. ì•ˆì „ ë§ˆì§„ ì¡°ì •
```python
# ë” ê³µê²©ì ì¸ ìµœì í™” (ìœ„í—˜)
'safety': 0.7  # 30% ì•ˆì „ ë§ˆì§„

# ë” ë³´ìˆ˜ì ì¸ ìµœì í™” (ì•ˆì „)
'safety': 0.9  # 10% ì•ˆì „ ë§ˆì§„
```

### 3. ëª¨ë¸ë³„ ì»¤ìŠ¤í…€ í…ŒìŠ¤íŠ¸
```python
def test_batch_size(model_name: str, img_size: int, batch_size: int):
    """íŠ¹ì • ëª¨ë¸ êµ¬ì¡°ì— ë§ëŠ” í…ŒìŠ¤íŠ¸ ë¡œì§ ì¶”ê°€"""
    # ì—¬ê¸°ì— ìƒˆë¡œìš´ ëª¨ë¸ êµ¬ì¡° ì¶”ê°€ ê°€ëŠ¥
```

### 4. íŒ€ ì„¤ì • í…œí”Œë¦¿ ìƒì„±
```yaml
# configs/team_gpu_settings.yaml
team_profiles:
  member_1:
    gpu: "RTX 4090"
    optimal_batch_224: 96
    optimal_batch_384: 48
    optimal_batch_512: 24
    
  member_2:
    gpu: "RTX 3060"
    optimal_batch_224: 32
    optimal_batch_384: 16
    optimal_batch_512: 8
    gradient_accumulation_steps: 3
```

---

## ğŸ“Š ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬

### RTX 4090 ìµœì í™” ê²°ê³¼
- **ì´ì „ ì„¤ì •**: batch_size=32, í›ˆë ¨ ì‹œê°„ ~25ì´ˆ/epoch
- **ìµœì í™” í›„**: batch_size=48, í›ˆë ¨ ì‹œê°„ ~15ì´ˆ/epoch
- **ì„±ëŠ¥ í–¥ìƒ**: 40% ë¹¨ë¼ì§
- **ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ **: 38% (ì—¬ìœ  ê³µê°„ 62%)

### ì˜ˆìƒ íŒ€ì›ë³„ ì„±ëŠ¥
| GPU | ìµœì  ë°°ì¹˜ | ì˜ˆìƒ ì†ë„ | ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  | ì¶”ê°€ ì„¤ì • |
|-----|-----------|-----------|---------------|-----------|
| RTX 4090 | 48 | 100% | 38% | - |
| RTX 3080 | 24 | 75% | 70% | grad_accum=2 |
| RTX 3060 | 12 | 50% | 85% | grad_accum=4 |
| GTX 1080 | 6 | 25% | 90% | no_amp, grad_accum=8 |

---

## ğŸ“ ì²´í¬ë¦¬ìŠ¤íŠ¸

### ì„¤ì¹˜ ì „ í™•ì¸ì‚¬í•­
- [ ] pyenv ê°€ìƒí™˜ê²½ `cv_py3_11_9` í™œì„±í™”
- [ ] NVIDIA ë“œë¼ì´ë²„ ì„¤ì¹˜ í™•ì¸
- [ ] CUDA í˜¸í™˜ì„± í™•ì¸
- [ ] PyTorch CUDA ë²„ì „ í™•ì¸
- [ ] ì¶©ë¶„í•œ ë””ìŠ¤í¬ ê³µê°„ í™•ì¸

### ì‚¬ìš© ì „ í™•ì¸ì‚¬í•­
- [ ] GPU í˜¸í™˜ì„± ì²´í¬ ì‹¤í–‰
- [ ] ì„¤ì • íŒŒì¼ ë°±ì—…
- [ ] í…ŒìŠ¤íŠ¸ ëª¨ë“œë¡œ ì•ˆì „ì„± í™•ì¸
- [ ] Git ì‘ì—… ë¸Œëœì¹˜ ìƒì„±

### ì‹¤í–‰ í›„ í™•ì¸ì‚¬í•­
- [ ] ìµœì í™”ëœ ë°°ì¹˜ í¬ê¸° í™•ì¸
- [ ] ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  ëª¨ë‹ˆí„°ë§
- [ ] í›ˆë ¨ ì•ˆì •ì„± í™•ì¸
- [ ] ì„±ëŠ¥ í–¥ìƒ ì¸¡ì •
- [ ] íŒ€ì›ê³¼ ì„¤ì • ê³µìœ 

---

## ğŸ”— ê´€ë ¨ ë¬¸ì„œ

- [Team_GPU_Optimization_Guide.md](./Team_GPU_Optimization_Guide.md) - íŒ€ í˜‘ì—… ì „ì²´ ê°€ì´ë“œ
- [High_Performance_Training_Guide.md](./High_Performance_Training_Guide.md) - ê³ ì„±ëŠ¥ í›ˆë ¨ ê°€ì´ë“œ
- [Full_Pipeline_Guide.md](./Full_Pipeline_Guide.md) - ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ê°€ì´ë“œ

---

**Created by**: AI Team  
**Date**: 2025-09-05  
**Tool Version**: auto_batch_size.py v1.0  
**Status**: âœ… Production Ready for Team Collaboration  
**Environment**: pyenv cv_py3_11_9 ê°€ìƒí™˜ê²½
