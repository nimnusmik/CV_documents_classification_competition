# íŒ€ í˜‘ì—…ìš© GPU ìµœì í™” ìë™ ë°°ì¹˜ í¬ê¸° ë„êµ¬ ì‚¬ìš© ê°€ì´ë“œ

## ğŸš€ ê°œìš”
íŒ€ì›ë“¤ì´ ë‹¤ì–‘í•œ GPU í™˜ê²½ì—ì„œ ì¼ê´€ëœ ì„±ëŠ¥ì„ ì–»ì„ ìˆ˜ ìˆë„ë¡ ê° GPUì— ìµœì í™”ëœ ë°°ì¹˜ í¬ê¸°ë¥¼ ìë™ìœ¼ë¡œ ì°¾ì•„ì£¼ëŠ” ë„êµ¬ì…ë‹ˆë‹¤.

## ğŸ¯ íŒ€ í˜‘ì—…ì„ ìœ„í•œ í•µì‹¬ ê¸°ëŠ¥

### GPU ë“±ê¸‰ë³„ ìë™ ë¶„ë¥˜
- **high_end**: RTX 4090, RTX 4080, RTX 3090, A100, V100
- **mid_range**: RTX 3080, RTX 3070, RTX 4070  
- **budget**: RTX 3060, RTX 2070, RTX 2080
- **low_end**: GTX 1660, GTX 1080 ë“± êµ¬í˜• GPU

### ì´ë¯¸ì§€ í¬ê¸°ë³„ ìµœì í™”
- **224px**: ë†’ì€ ë°°ì¹˜ í¬ê¸° ê°€ëŠ¥
- **384px**: ì¤‘ê°„ ë°°ì¹˜ í¬ê¸°
- **512px**: ë‚®ì€ ë°°ì¹˜ í¬ê¸° (ë©”ëª¨ë¦¬ ì ˆì•½)

## ğŸ“‹ ì‚¬ìš©ë²•

### ê¸°ë³¸ ì‚¬ìš©ë²•
```bash
# í…ŒìŠ¤íŠ¸ë§Œ ìˆ˜í–‰ (ì„¤ì • íŒŒì¼ ìˆ˜ì • ì•ˆí•¨)
python src/utils/auto_batch_size.py --config configs/train.yaml --test-only

# ì„¤ì • íŒŒì¼ ìë™ ì—…ë°ì´íŠ¸
python src/utils/auto_batch_size.py --config configs/train.yaml

# ê³ ì„±ëŠ¥ ì„¤ì • ìµœì í™”
python src/utils/auto_batch_size.py --config configs/train_highperf.yaml
```

### ê³ ê¸‰ ì˜µì…˜
```bash
# íŠ¹ì • ëª¨ë¸ ì§€ì •
python src/utils/auto_batch_size.py --config configs/train.yaml --model swin_base_384

# íŠ¹ì • ì´ë¯¸ì§€ í¬ê¸° ì§€ì •
python src/utils/auto_batch_size.py --config configs/train.yaml --img-size 384
```

## ğŸ¤ íŒ€ í˜‘ì—… ì‹œë‚˜ë¦¬ì˜¤

### ì‹œë‚˜ë¦¬ì˜¤ 1: RTX 4090 ì‚¬ìš©ì (í˜„ì¬ í™˜ê²½)
```bash
python src/utils/auto_batch_size.py --config configs/train_highperf.yaml
# ê²°ê³¼: batch_size = 48 (384px ì´ë¯¸ì§€)
```

### ì‹œë‚˜ë¦¬ì˜¤ 2: RTX 3060 ì‚¬ìš©ì
```bash
python src/utils/auto_batch_size.py --config configs/train.yaml
# ì˜ˆìƒ ê²°ê³¼: batch_size = 12-16 (384px ì´ë¯¸ì§€)
# ì¶”ê°€ ê¶Œì¥: gradient_accumulation_steps = 3-4
```

### ì‹œë‚˜ë¦¬ì˜¤ 3: GTX 1080 ì‚¬ìš©ì
```bash
python src/utils/auto_batch_size.py --config configs/train.yaml
# ì˜ˆìƒ ê²°ê³¼: batch_size = 6-8 (384px ì´ë¯¸ì§€)
# ì¶”ê°€ ê¶Œì¥: mixed precision ë¹„í™œì„±í™”, gradient_accumulation_steps = 6-8
```

## ğŸ“Š GPUë³„ ê¶Œì¥ ì„¤ì •

### RTX 4090/3090 (24GB)
- **384px**: batch_size 32-64
- **512px**: batch_size 16-32
- **ì¶”ê°€ ê¶Œì¥**: Multi-GPU training ê°€ëŠ¥, ensemble ëª¨ë¸ ê³ ë ¤

### RTX 3080/3070 (10-12GB)
- **384px**: batch_size 16-32
- **512px**: batch_size 8-16
- **ì¶”ê°€ ê¶Œì¥**: gradient_accumulation_steps = 2

### RTX 3060 (8GB)
- **384px**: batch_size 8-16
- **512px**: batch_size 4-8
- **ì¶”ê°€ ê¶Œì¥**: gradient_accumulation_steps = 3-4

### GTX 1080/1660 (6-8GB)
- **384px**: batch_size 4-8
- **512px**: batch_size 2-4
- **ì¶”ê°€ ê¶Œì¥**: mixed precision ë¹„í™œì„±í™”, gradient_accumulation_steps = 6-8

## ğŸ›¡ï¸ ì•ˆì „ ë§ˆì§„ ë° ìµœì í™”

### ì•ˆì „ ë§ˆì§„ ì ìš©
- **ê³ ì‚¬ì–‘ GPU**: 20% ì•ˆì „ ë§ˆì§„ (ë” ê³µê²©ì  ìµœì í™”)
- **ì¤‘ê¸‰ GPU**: 20% ì•ˆì „ ë§ˆì§„
- **ì˜ˆì‚°í˜• GPU**: 15% ì•ˆì „ ë§ˆì§„
- **êµ¬í˜• GPU**: 10% ì•ˆì „ ë§ˆì§„ (ë³´ìˆ˜ì  ì ‘ê·¼)

### ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±
- ëª¨ë“  ë°°ì¹˜ í¬ê¸°ëŠ” 4ì˜ ë°°ìˆ˜ë¡œ ì¡°ì • (GPU íš¨ìœ¨ì„±)
- ì´ì§„ íƒìƒ‰ìœ¼ë¡œ ìµœì  ë°°ì¹˜ í¬ê¸° ìë™ íƒì§€
- ì‹¤ì œ ëª¨ë¸ êµ¬ì¡° ì‹œë®¬ë ˆì´ì…˜ìœ¼ë¡œ ì •í™•í•œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¸¡ì •

## âš™ï¸ íŒ€ í˜‘ì—… ì›Œí¬í”Œë¡œìš°

### 1. ê° íŒ€ì›ë³„ ìµœì í™”
```bash
# ê°ìì˜ GPU í™˜ê²½ì—ì„œ ì‹¤í–‰
python src/utils/auto_batch_size.py --config configs/train.yaml --test-only
```

### 2. ì„¤ì • ê³µìœ 
```bash
# ìµœì í™”ëœ ì„¤ì •ìœ¼ë¡œ ì—…ë°ì´íŠ¸
python src/utils/auto_batch_size.py --config configs/train.yaml

# Gitìœ¼ë¡œ ì„¤ì • ê³µìœ 
git add configs/train.yaml
git commit -m "Optimize batch size for [GPU_NAME]"
```

### 3. ì‹¤í—˜ ì‹¤í–‰
```bash
# ìµœì í™”ëœ ì„¤ì •ìœ¼ë¡œ í›ˆë ¨
python src/training/train_main.py --mode highperf

# GPU ëª¨ë‹ˆí„°ë§
nvidia-smi -l 1
```

## ğŸ“ˆ ì˜ˆìƒ ì„±ëŠ¥ í–¥ìƒ

### RTX 4090 ê¸°ì¤€
- **ê¸°ì¡´ batch_size 32** â†’ **ìµœì í™” batch_size 48**: ~50% ì†ë„ í–¥ìƒ
- **ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ **: ~38% (ì—¬ìœ  ê³µê°„ìœ¼ë¡œ ì¶”ê°€ ì‹¤í—˜ ê°€ëŠ¥)

### RTX 3060 ê¸°ì¤€  
- **ê¸°ì¡´ batch_size 16** â†’ **ìµœì í™” batch_size 12 + gradient_accumulation_steps 4**: ë™ì¼í•œ effective batch size, ì•ˆì •ì„± í–¥ìƒ

### GTX 1080 ê¸°ì¤€
- **ê¸°ì¡´ batch_size 8** â†’ **ìµœì í™” batch_size 6 + gradient_accumulation_steps 8**: ë©”ëª¨ë¦¬ ì•ˆì •ì„± í™•ë³´

## ğŸ” ëª¨ë‹ˆí„°ë§ ë° ë””ë²„ê¹…

### GPU ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§
```bash
# ì‹¤ì‹œê°„ GPU ëª¨ë‹ˆí„°ë§
nvidia-smi -l 1

# ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸
python -c "import torch; print(f'GPU ë©”ëª¨ë¦¬: {torch.cuda.memory_allocated()/1024**3:.2f}GB')"
```

### ë¬¸ì œ í•´ê²°
- **Out of Memory ì˜¤ë¥˜**: batch_sizeë¥¼ 50% ì¤„ì´ê³  gradient_accumulation_steps ì¦ê°€
- **ëŠë¦° í›ˆë ¨ ì†ë„**: batch_size ì¦ê°€ ì‹œë„, GPU ì‚¬ìš©ë¥  í™•ì¸
- **ë¶ˆì•ˆì •í•œ í›ˆë ¨**: mixed precision ë¹„í™œì„±í™”, learning rate ì¡°ì •

## ğŸš¨ ì£¼ì˜ì‚¬í•­

### íŒ€ í˜‘ì—… ì‹œ
1. **ì„¤ì • íŒŒì¼ ì¶©ëŒ ë°©ì§€**: ê°ì ë¸Œëœì¹˜ì—ì„œ ìµœì í™” í›„ merge
2. **ì‹¤í—˜ ì¬í˜„ì„±**: ë™ì¼í•œ effective batch size ìœ ì§€ (batch_size Ã— gradient_accumulation_steps)
3. **í•˜ë“œì›¨ì–´ ì°¨ì´ ê³ ë ¤**: ê²°ê³¼ ë¹„êµ ì‹œ GPU ë“±ê¸‰ë³„ ì„±ëŠ¥ ì°¨ì´ ì¸ì •

### ì‹¤ì œ í›ˆë ¨ ì „
1. **ì‘ì€ epoch í…ŒìŠ¤íŠ¸**: 2-3 epochìœ¼ë¡œ ì•ˆì •ì„± í™•ì¸
2. **ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§**: ì „ì²´ GPU ë©”ëª¨ë¦¬ì˜ 90% ì´í•˜ ì‚¬ìš©
3. **ë°±ì—… ì„¤ì •**: ì›ë³¸ ì„¤ì • íŒŒì¼ ë°±ì—… ìœ ì§€

## ğŸ“ íŒ€ ì„¤ì • ê³µìœ  í…œí”Œë¦¿

```yaml
# íŒ€ì›ë³„ ê¶Œì¥ ì„¤ì • (configs/team_settings.yaml)
team_gpu_settings:
  rtx_4090:
    batch_size: 48
    gradient_accumulation_steps: 1
    mixed_precision: true
  
  rtx_3060:
    batch_size: 12
    gradient_accumulation_steps: 4
    mixed_precision: true
  
  gtx_1080:
    batch_size: 6
    gradient_accumulation_steps: 8
    mixed_precision: false
```

## âœ… ì„±ê³µ ì‚¬ë¡€

### í˜„ì¬ ìµœì í™” ê²°ê³¼ (RTX 4090)
- **ëª¨ë¸**: swin_base_384
- **ì´ë¯¸ì§€ í¬ê¸°**: 384px
- **ìµœì  ë°°ì¹˜ í¬ê¸°**: 48
- **ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ **: 38%
- **ì˜ˆìƒ ì„±ëŠ¥ í–¥ìƒ**: 50%

---

**Created by**: AI Team  
**Date**: 2025-01-05  
**Tool**: `/src/utils/auto_batch_size.py`  
**Status**: âœ… Production Ready for Team Collaboration
