# ğŸ“ í•™ìŠµ íŒŒì´í”„ë¼ì¸ ì™„ì „ ê°€ì´ë“œ

## ğŸ—ï¸ í•™ìŠµ íŒŒì´í”„ë¼ì¸ ì „ì²´ ì•„í‚¤í…ì²˜

```mermaid
flowchart TB
    subgraph CLI["ğŸš€ CLI ì§„ì…ì "]
        A["src/training/train_main.py<br>í†µí•© í•™ìŠµ ì¸í„°í˜ì´ìŠ¤<br>CLI ì˜µì…˜ íŒŒì‹± ë° ëª¨ë“œ ì„ íƒ"]
    end
    
    subgraph MODES["ğŸ“‹ í•™ìŠµ ëª¨ë“œ ë¶„ê¸°"]
        B["ğŸ“š basic ëª¨ë“œ<br>src/training/train.py<br>ë‹¨ì¼/K-fold + ê¸°ë³¸ ì„¤ì •"]
        C["âš¡ highperf ëª¨ë“œ<br>src/training/train_highperf.py<br>ê³ ì„±ëŠ¥ ìµœì í™” ê¸°ë²•"]
        D["ğŸ”„ full-pipeline ëª¨ë“œ<br>src/pipeline/full_pipeline.py<br>í•™ìŠµâ†’ì¶”ë¡  í†µí•© ì‹¤í–‰"]
        E["ğŸ” optimize ëª¨ë“œ<br>src/optimization/optuna_optimize.py<br>í•˜ì´í¼íŒŒë¼ë¯¸í„° ìë™ íŠœë‹"]
    end
    
    subgraph VALIDATION["ğŸ¯ ê²€ì¦ ì „ëµ"]
        F["ğŸ“ ë‹¨ì¼ í´ë“œ (Single Fold)<br>valid_fold: 0~4<br>ë¹ ë¥¸ í”„ë¡œí† íƒ€ì…"]
        G["ğŸ”€ K-fold êµì°¨ê²€ì¦<br>valid_fold: all<br>5-fold ì•ˆì •ì„± í™•ë³´"]
        H["âš–ï¸ ê³„ì¸µì  ë¶„í• <br>stratify: true<br>í´ë˜ìŠ¤ ê· í˜• ìœ ì§€"]
    end
    
    subgraph MODELS["ğŸ—ï¸ ëª¨ë¸ ì•„í‚¤í…ì²˜"]
        I["ğŸ“Š EfficientNet B3<br>efficientnet_b3<br>12M íŒŒë¼ë¯¸í„°, 224px"]
        J["ğŸ† ConvNeXt Base 384<br>convnext_base_384<br>89M íŒŒë¼ë¯¸í„°, 384px"]
        K["ğŸ¯ Swin Transformer<br>swin_base_patch4_window12_384<br>88M íŒŒë¼ë¯¸í„°, 384px"]
        L["ğŸ¨ ë‹¤ì¤‘ ëª¨ë¸ ì•™ìƒë¸”<br>train_multi_model_ensemble.yaml<br>ì—¬ëŸ¬ ì•„í‚¤í…ì²˜ ì¡°í•©"]
    end
    
    subgraph TECHS["âš¡ Team ê³ ì„±ëŠ¥ ê¸°ë²•"]
        M["ğŸ’ª Hard Augmentation<br>src/data/transforms.py<br>ë™ì  í™•ë¥  ìŠ¤ì¼€ì¤„ë§"]
        N["ğŸ² Mixup & CutMix<br>Alpha ìµœì í™”<br>ë°ì´í„° ì¦ê°• ê°•í™”"]
        O["ğŸŒ¡ï¸ Temperature Scaling<br>src/calibration/calibrate.py<br>í™•ë¥  ë³´ì •"]
        P["âš¡ Auto Batch Size<br>src/utils/gpu_optimization/<br>GPU ë©”ëª¨ë¦¬ ìµœì í™”"]
    end
    
    A --> B & C & D & E
    B --> F & G
    C --> G & H
    F & G --> I & J & K & L
    I & J & K & L --> M & N & O & P
    
    style A fill:#e1f5fe, color:#000000
    style C fill:#e8f5e8, color:#000000
    style E fill:#fff3e0, color:#000000
    style G fill:#f3e5f5, color:#000000
    style L fill:#ffcdd2, color:#000000
    style M fill:#fce4ec, color:#000000
```

## ğŸ”€ í•™ìŠµ íŒŒì´í”„ë¼ì¸ ìƒì„¸ íë¦„ë„

### ğŸ“ ë‹¨ì¼ í´ë“œ í•™ìŠµ íë¦„
```mermaid
flowchart LR
    subgraph SINGLE["ğŸ¯ ë‹¨ì¼ í´ë“œ ëª¨ë“œ"]
        A1["ğŸ“ ë°ì´í„° ì¤€ë¹„<br/>data/raw/train/<br/>data/raw/train.csv<br/>ì´ë¯¸ì§€ + ë¼ë²¨"]
        B1["ğŸ”ª ë‹¨ì¼ ë¶„í• <br/>valid_fold: 0-4<br/>íŠ¹ì • í´ë“œë§Œ ì„ íƒ<br/>ë¹ ë¥¸ í•™ìŠµ"]
        C1["ğŸš€ ëª¨ë¸ í•™ìŠµ<br/>ì„ íƒëœ í´ë“œ<br/>1ê°œ ëª¨ë¸ ì§‘ì¤‘ í•™ìŠµ<br/>GPU ìµœì í™”"]
        D1["ğŸ“Š ê²€ì¦<br/>F1-Score<br/>ë‹¨ì¼ ì„±ëŠ¥ í‰ê°€<br/>ë¹ ë¥¸ í”¼ë“œë°±"]
        E1["ğŸ’¾ ê²°ê³¼ ì €ì¥<br/>best_fold_N.pth<br/>1ê°œ íŒŒì¼<br/>ìµœì  ê°€ì¤‘ì¹˜"]
        
        A1 --> B1 --> C1 --> D1 --> E1
    end
    
    subgraph INFO1["ğŸ“‹ ë‹¨ì¼ í´ë“œ ì •ë³´"]
        F1["âš¡ ì†ë„: ë§¤ìš° ë¹ ë¦„<br/>ğŸ¯ ëª©ì : í”„ë¡œí† íƒ€ì…<br/>ğŸ“ˆ ì„±ëŠ¥: 0.92-0.95"]
        G1["âš™ï¸ ì„¤ì •: valid_fold: 0<br/>ğŸ”§ ì—í¬í¬: 5-15<br/>ğŸ’¾ ë©”ëª¨ë¦¬: 8GB"]
    end
    
    style A1 fill:#e1f5fe, color:#000000
    style C1 fill:#e8f5e8, color:#000000
    style E1 fill:#fff3e0, color:#000000
    style F1 fill:#f3e5f5, color:#000000
```

### ğŸ”€ K-Fold êµì°¨ê²€ì¦ íë¦„
```mermaid
flowchart LR
    subgraph KFOLD["ğŸ”„ K-Fold ëª¨ë“œ"]
        A2["ğŸ“ ë°ì´í„° ì¤€ë¹„<br/>ì „ì²´ í•™ìŠµ ë°ì´í„°<br/>ê³„ì¸µì  ë¶„í•  ì¤€ë¹„"]
        B2["ğŸ”€ 5-Fold ë¶„í• <br/>KFold n=5<br/>stratified=true<br/>í´ë˜ìŠ¤ ê· í˜• ìœ ì§€"]
        C2["ğŸ¯ ìˆœì°¨ í•™ìŠµ<br/>Fold 0â†’1â†’2â†’3â†’4<br/>ê°ê° ë…ë¦½ í•™ìŠµ<br/>êµì°¨ ê²€ì¦"]
        D2["ğŸ“Š í´ë“œë³„ ê²€ì¦<br/>ê° Fold ì„±ëŠ¥<br/>F1-Score ê³„ì‚°<br/>ì•ˆì •ì„± í™•ë³´"]
        E2["ğŸ’¾ ì „ì²´ ëª¨ë¸ ì €ì¥<br/>5ê°œ ëª¨ë¸ íŒŒì¼<br/>í‰ê·  ì„±ëŠ¥ ê³„ì‚°<br/>ì•™ìƒë¸” ì¤€ë¹„"]
        
        A2 --> B2 --> C2 --> D2 --> E2
        C2 --> C2
    end
    
    subgraph INFO2["ğŸ“‹ K-Fold ì •ë³´"]
        F2["â±ï¸ ì†ë„: ëŠë¦¼ (5ë°°)<br/>ğŸ¯ ëª©ì : ì•ˆì •ì„±<br/>ğŸ“ˆ ì„±ëŠ¥: 0.95-0.98"]
        G2["âš™ï¸ ì„¤ì •: valid_fold: all<br/>ğŸ”§ ì—í¬í¬: 30-50<br/>ğŸ’¾ ë©”ëª¨ë¦¬: 16GB+"]
    end
    
    style A2 fill:#e1f5fe, color:#000000
    style C2 fill:#e8f5e8, color:#000000
    style E2 fill:#fff3e0, color:#000000
    style F2 fill:#f3e5f5, color:#000000
```

### ğŸ¨ ë‹¤ì¤‘ ëª¨ë¸ ì•™ìƒë¸” í•™ìŠµ íë¦„
```mermaid
flowchart TB
    subgraph MULTI["ğŸ­ ë‹¤ì¤‘ ëª¨ë¸ ì•™ìƒë¸”"]
        A3["âš™ï¸ ë‹¤ì¤‘ ì„¤ì • ì¤€ë¹„<br/>configs/train_multi_model_ensemble.yaml<br/>ì—¬ëŸ¬ ëª¨ë¸ ì•„í‚¤í…ì²˜ ì •ì˜"]
        
        B3["ğŸ—ï¸ ëª¨ë¸ 1: ConvNeXt<br/>convnext_base_384<br/>ê³ ì„±ëŠ¥ ê¸°ë³¸ ëª¨ë¸"]
        C3["ğŸ—ï¸ ëª¨ë¸ 2: Swin<br/>swin_base_384<br/>Transformer ê¸°ë°˜"]
        D3["ğŸ—ï¸ ëª¨ë¸ 3: EfficientNet<br/>efficientnet_v2_b3<br/>íš¨ìœ¨ì„± ì¤‘ì‹¬"]
        
        E3["ğŸ”„ ìˆœì°¨/ë³‘ë ¬ í•™ìŠµ<br/>ê° ëª¨ë¸ ë…ë¦½ í•™ìŠµ<br/>ë™ì¼ ë°ì´í„° ë‹¤ë¥¸ êµ¬ì¡°"]
        F3["ğŸ“Š ê°œë³„ ì„±ëŠ¥ í‰ê°€<br/>ëª¨ë¸ë³„ F1-Score<br/>ê°•ì  ë¶„ì„"]
        G3["ğŸ’¾ ëª¨ë¸ë³„ ì €ì¥<br/>ì„œë¡œ ë‹¤ë¥¸ ê²½ë¡œ<br/>ë…ë¦½ì  ì²´í¬í¬ì¸íŠ¸"]
        
        A3 --> B3 & C3 & D3
        B3 & C3 & D3 --> E3
        E3 --> F3 --> G3
    end
    
    subgraph INFO3["ğŸ“‹ ë‹¤ì¤‘ ëª¨ë¸ ì •ë³´"]
        H3["ğŸ¯ ëª©ì : ë‹¤ì–‘ì„± í™•ë³´<br/>ğŸ“ˆ ì„±ëŠ¥: ê°œë³„ ìµœì í™”<br/>ğŸ”„ ì•™ìƒë¸” ì¤€ë¹„"]
        I3["ğŸ’¾ ì €ì¥: ê°ê° ë‹¤ë¥¸ í´ë”<br/>ğŸ“Š ë¹„êµ: ëª¨ë¸ê°„ ì„±ëŠ¥<br/>âš¡ ìµœì : GPUë³„ ëª¨ë¸ í• ë‹¹"]
    end
    
    style A3 fill:#e1f5fe, color:#000000
    style E3 fill:#e8f5e8, color:#000000
    style G3 fill:#fff3e0, color:#000000
    style H3 fill:#f3e5f5, color:#000000
```

## ğŸ“ íŒŒì¼ ê°„ ì˜ì¡´ ê´€ê³„ ë° ë°ì´í„° íë¦„ ë‹¤ì´ì–´ê·¸ë¨

### ğŸ¯ ì „ì²´ ì‹œìŠ¤í…œ ì˜ì¡´ ê´€ê³„
```mermaid
graph TB
    subgraph CONFIGS["âš™ï¸ ì„¤ì • íŒŒì¼ ê³„ì¸µ"]
        CONFIG1["configs/train.yaml<br/>ğŸ“ ë‹¨ì¼í´ë“œ + ê¸°ë³¸ì„¤ì •<br/>valid_fold: 0-4"]
        CONFIG2["configs/train_highperf.yaml<br/>ğŸ”€ K-fold + ê³ ì„±ëŠ¥<br/>valid_fold: all"]
        CONFIG3["configs/train_multi_model_ensemble.yaml<br/>ğŸ­ ë‹¤ì¤‘ëª¨ë¸ ì•™ìƒë¸”<br/>ì—¬ëŸ¬ ì•„í‚¤í…ì²˜"]
        CONFIG4["configs/optuna_config.yaml<br/>ğŸ” í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹<br/>ë² ì´ì§€ì•ˆ ìµœì í™”"]
    end
    
    subgraph CORE["ğŸ§  í•µì‹¬ ì‹¤í–‰ ì‹œìŠ¤í…œ"]
        MAIN["src/training/train_main.py<br/>ğŸš€ ë©”ì¸ CLI ì¸í„°í˜ì´ìŠ¤<br/>ëª¨ë“œ ì„ íƒ ë° ì˜µì…˜ ì²˜ë¦¬"]
        TRAIN_BASIC["src/training/train.py<br/>ğŸ“š ê¸°ë³¸ í•™ìŠµ ë¡œì§<br/>ë‹¨ì¼/K-fold ì§€ì›"]
        TRAIN_HIGH["src/training/train_highperf.py<br/>âš¡ ê³ ì„±ëŠ¥ í•™ìŠµ ë¡œì§<br/>Team ìµœì í™” ê¸°ë²•"]
        PIPELINE["src/pipeline/full_pipeline.py<br/>ğŸ”„ í†µí•© íŒŒì´í”„ë¼ì¸<br/>í•™ìŠµâ†’ì¶”ë¡  ìë™í™”"]
        OPTUNA["src/optimization/optuna_optimize.py<br/>ğŸ” í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”<br/>ìë™ íŠœë‹"]
    end
    
    subgraph SUPPORT["ğŸ”§ ì§€ì› ì‹œìŠ¤í…œ"]
        MODELS["src/models/build.py<br/>ğŸ—ï¸ ëª¨ë¸ ë¹Œë”<br/>ë™ì  ì•„í‚¤í…ì²˜ ìƒì„±"]
        DATA["src/data/dataset.py<br/>ğŸ“Š ë°ì´í„° ë¡œë”<br/>ì¦ê°• ë° ì „ì²˜ë¦¬"]
        TRANSFORMS["src/data/transforms.py<br/>ğŸ¨ ë°ì´í„° ì¦ê°•<br/>Hard Aug + TTA"]
        CALIBRATION["src/calibration/calibrate.py<br/>ğŸŒ¡ï¸ ëª¨ë¸ ë³´ì •<br/>Temperature Scaling"]
        GPU_OPT["src/utils/gpu_optimization/<br/>âš¡ GPU ìµœì í™”<br/>ë°°ì¹˜ í¬ê¸° ìë™ ì¡°ì •"]
    end
    
    subgraph INPUT["ğŸ“¥ ì…ë ¥ ë°ì´í„°"]
        RAW_IMGS["data/raw/train/<br/>ğŸ“¸ ì›ë³¸ í•™ìŠµ ì´ë¯¸ì§€<br/>17í´ë˜ìŠ¤ ë¶„ë¥˜"]
        TRAIN_CSV["data/raw/train.csv<br/>ğŸ“‹ ë¼ë²¨ ì •ë³´<br/>ì´ë¯¸ì§€-í´ë˜ìŠ¤ ë§¤í•‘"]
        SAMPLE_CSV["data/raw/sample_submission.csv<br/>ğŸ“„ ì œì¶œ í˜•ì‹<br/>ì¶”ë¡  ê²°ê³¼ í…œí”Œë¦¿"]
    end
    
    subgraph OUTPUT["ğŸ“¤ ì¶œë ¥ ê²°ê³¼"]
        EXP_SINGLE["experiments/train/YYYYMMDD/<br/>ğŸ“ ë‹¨ì¼ í´ë“œ ê²°ê³¼<br/>best_fold_N.pth"]
        EXP_KFOLD["experiments/train/YYYYMMDD/<br/>ğŸ”€ K-fold ê²°ê³¼<br/>best_fold_0-4.pth"]
        EXP_MULTI["experiments/train/YYYYMMDD/<br/>ğŸ­ ë‹¤ì¤‘ ëª¨ë¸ ê²°ê³¼<br/>ëª¨ë¸ë³„ ë¶„ë¦¬ ì €ì¥"]
        FOLD_RESULTS["fold_results.yaml<br/>ğŸ“Š í´ë“œ ì„±ëŠ¥ ìš”ì•½<br/>ì¶”ë¡ ìš© ë©”íƒ€ë°ì´í„°"]
        LOGS["logs/YYYYMMDD/train/<br/>ğŸ“ í•™ìŠµ ë¡œê·¸<br/>ì„±ëŠ¥ ì¶”ì "]
    end
    
    %% ì„¤ì • íŒŒì¼ â†’ ë©”ì¸ ì‹œìŠ¤í…œ ì—°ê²°
    CONFIG1 --> MAIN
    CONFIG2 --> MAIN  
    CONFIG3 --> MAIN
    CONFIG4 --> OPTUNA
    
    %% ë©”ì¸ ì‹œìŠ¤í…œ â†’ ì‹¤í–‰ ë¡œì§ ë¶„ê¸°
    MAIN --> TRAIN_BASIC
    MAIN --> TRAIN_HIGH
    MAIN --> PIPELINE
    MAIN --> OPTUNA
    
    %% ì‹¤í–‰ ë¡œì§ â†’ ì§€ì› ì‹œìŠ¤í…œ ì˜ì¡´
    TRAIN_BASIC --> MODELS & DATA & TRANSFORMS
    TRAIN_HIGH --> MODELS & DATA & TRANSFORMS & CALIBRATION & GPU_OPT
    PIPELINE --> TRAIN_HIGH
    OPTUNA --> TRAIN_BASIC
    
    %% ì…ë ¥ ë°ì´í„° â†’ ë°ì´í„° ì²˜ë¦¬
    RAW_IMGS --> DATA
    TRAIN_CSV --> DATA
    SAMPLE_CSV --> PIPELINE
    
    %% ì‹¤í–‰ â†’ ì¶œë ¥ ìƒì„±
    TRAIN_BASIC --> EXP_SINGLE & LOGS
    TRAIN_HIGH --> EXP_KFOLD & FOLD_RESULTS & LOGS
    PIPELINE --> EXP_MULTI & LOGS
    
    style CONFIG2 fill:#e8f5e8, color:#000000
    style CONFIG3 fill:#f3e5f5, color:#000000
    style MAIN fill:#fff3e0, color:#000000
    style TRAIN_HIGH fill:#ffcdd2, color:#000000
    style EXP_KFOLD fill:#e1f5fe, color:#000000
    style FOLD_RESULTS fill:#fce4ec, color:#000000
```

### ğŸ”„ í•™ìŠµ ëª¨ë“œë³„ ë°ì´í„° íë¦„
```mermaid
flowchart LR
    subgraph MODE1["ğŸ“ ë‹¨ì¼ í´ë“œ ëª¨ë“œ"]
        A1["train.yaml<br/>valid_fold: N"]
        B1["train.py<br/>íŠ¹ì • í´ë“œ ì„ íƒ"]
        C1["1ê°œ ëª¨ë¸ í•™ìŠµ<br/>ë¹ ë¥¸ ê²°ê³¼"]
        D1["best_fold_N.pth<br/>ë‹¨ì¼ ê²°ê³¼"]
        
        A1 --> B1 --> C1 --> D1
    end
    
    subgraph MODE2["ğŸ”€ K-fold ëª¨ë“œ"]
        A2["train_highperf.yaml<br/>valid_fold: all"]
        B2["train_highperf.py<br/>ì „ì²´ í´ë“œ ìˆœíšŒ"]
        C2["5ê°œ ëª¨ë¸ í•™ìŠµ<br/>êµì°¨ ê²€ì¦"]
        D2["5ê°œ .pth íŒŒì¼<br/>fold_results.yaml"]
        
        A2 --> B2 --> C2 --> D2
    end
    
    subgraph MODE3["ğŸ­ ë‹¤ì¤‘ ëª¨ë¸ ëª¨ë“œ"]
        A3["train_multi_model<br/>_ensemble.yaml"]
        B3["ì—¬ëŸ¬ ì•„í‚¤í…ì²˜<br/>ë™ì‹œ í•™ìŠµ"]
        C3["ConvNeXt+Swin<br/>+EfficientNet"]
        D3["ëª¨ë¸ë³„ ë¶„ë¦¬<br/>ì €ì¥ ë° ê´€ë¦¬"]
        
        A3 --> B3 --> C3 --> D3
    end
    
    style A1 fill:#e1f5fe, color:#000000
    style A2 fill:#e8f5e8, color:#000000
    style A3 fill:#f3e5f5, color:#000000
    style C1 fill:#fff3e0, color:#000000
    style C2 fill:#ffcdd2, color:#000000
    style C3 fill:#fce4ec, color:#000000
```

### ğŸ“‚ ë””ë ‰í† ë¦¬ êµ¬ì¡° ë° íŒŒì¼ ìƒì„¸ ì„¤ëª…

```text
ğŸ“ í•™ìŠµ íŒŒì´í”„ë¼ì¸ íŒŒì¼ êµ¬ì¡°
â”œâ”€â”€ src/training/
â”‚   â”œâ”€â”€ train_main.py                          # ğŸš€ ë©”ì¸ ì‹¤í–‰ ì¸í„°í˜ì´ìŠ¤
â”‚   â”œâ”€â”€ train.py                               # ğŸ§  í•µì‹¬ í•™ìŠµ ë¡œì§
â”‚   â”œâ”€â”€ train_highperf.py                      # ğŸ† ê³ ì„±ëŠ¥ í•™ìŠµ ë¡œì§
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ src/models/
â”‚   â”œâ”€â”€ build.py                               # ğŸ—ï¸ ëª¨ë¸ ì•„í‚¤í…ì²˜ ë¹Œë”
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ src/data/
â”‚   â”œâ”€â”€ dataset.py                             # ğŸ“Š ë°ì´í„°ì…‹ ë° ë¡œë”
â”‚   â”œâ”€â”€ transforms.py                          # ğŸ”„ ë°ì´í„° ì¦ê°•
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ src/metrics/
â”‚   â”œâ”€â”€ __init__.py
â”‚Â Â  â””â”€â”€ f1.cpython-311.py                     # 
â”‚
â”œâ”€â”€ src/utils/
â”‚   â”œâ”€â”€ core/                                  # ğŸ”§ í•µì‹¬ ìœ í‹¸ë¦¬í‹°
â”‚   â”‚   â””â”€â”€ common.py                          # ê³µí†µ í•¨ìˆ˜ (íŒŒì¼/YAML/ë¡œê¹…)
â”‚   â”œâ”€â”€ config/                                # âš™ï¸ ì„¤ì • ê´€ë¦¬
â”‚   â”‚   â”œâ”€â”€ seed.py                            # ì‹œë“œ ì„¤ì •
â”‚   â”‚   â””â”€â”€ update_config_dates.py             # ì„¤ì • ë‚ ì§œ ì—…ë°ì´íŠ¸
â”‚   â”œâ”€â”€ gpu_optimization/                      # ï¿½ GPU ìµœì í™”
â”‚   â”‚   â”œâ”€â”€ auto_batch_size.py                 # ë™ì  ë°°ì¹˜ í¬ê¸° ê²°ì •
â”‚   â”‚   â””â”€â”€ team_gpu_check.py                  # GPU í™˜ê²½ ë¶„ì„
â”‚   â”œâ”€â”€ code_management/                       # ğŸ“‹ ì½”ë“œ ê´€ë¦¬
â”‚   â”‚   â””â”€â”€ reorganize_experiments.py          # ì‹¤í—˜ ì •ë¦¬
â”‚   â”œâ”€â”€ visualizations/                        # ğŸ“Š ì‹œê°í™” ì‹œìŠ¤í…œ
â”‚   â”‚   â”œâ”€â”€ base_visualizer.py                 # ê¸°ë³¸ ì‹œê°í™” ì—”ì§„
â”‚   â”‚   â”œâ”€â”€ training_viz.py                    # í•™ìŠµ ì‹œê°í™”
â”‚   â”‚   â”œâ”€â”€ inference_viz.py                   # ì¶”ë¡  ì‹œê°í™”
â”‚   â”‚   â”œâ”€â”€ optimization_viz.py                # ìµœì í™” ì‹œê°í™”
â”‚   â”‚   â””â”€â”€ output_manager.py                  # ì¶œë ¥ ê´€ë¦¬
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ src/optimization/
â”‚   â”œâ”€â”€ optuna_optimize.py                     # ğŸ” í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ src/calibration/
â”‚   â”œâ”€â”€ calibrate.py                           # ğŸ“ ëª¨ë¸ ë³´ì •
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ src/logging/
â”‚   â”œâ”€â”€ logger.py                              # ï¿½ ë¡œê¹… ì‹œìŠ¤í…œ
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ configs/
â”‚   â”œâ”€â”€ train.yaml                             # âš™ï¸ ê¸°ë³¸ í•™ìŠµ ì„¤ì •
â”‚   â”œâ”€â”€ train_highperf.yaml                    # ğŸ† ê³ ì„±ëŠ¥ í•™ìŠµ ì„¤ì •
â”‚   â”œâ”€â”€ train_fast_optimized.yaml              # âš¡ ë¹ ë¥¸ í•™ìŠµ ì„¤ì •
â”‚   â”œâ”€â”€ optuna_config.yaml                     # ğŸ” í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ì„¤ì •
â”‚   â””â”€â”€ optuna_fast_config.yaml                # âš¡ ë¹ ë¥¸ íŠœë‹ ì„¤ì •
â”‚
â”œâ”€â”€ data/raw/
â”‚   â”œâ”€â”€ train/                                 # ğŸ“ í•™ìŠµ ì´ë¯¸ì§€ í´ë”
â”‚   â”œâ”€â”€ meta.csv                               # ğŸ“‹ ë¼ë²¨ ë° ë©”íƒ€ë°ì´í„°
â”‚   â””â”€â”€ sample_submission.csv                  # ğŸ“„ ì œì¶œ í˜•ì‹ ì˜ˆì‹œ
â”‚
â”œâ”€â”€ experiments/
â”‚   â”œâ”€â”€ train/YYYYMMDD/                        # ğŸ“ ë‚ ì§œë³„ í•™ìŠµ ì‹¤í—˜
â”‚   â”‚   â””â”€â”€ model_name_YYYYMMDD_HHMM/
â”‚   â”‚       â”œâ”€â”€ ckpt/                          # ğŸ’¾ ì²´í¬í¬ì¸íŠ¸ ì €ì¥ì†Œ
â”‚   â”‚       â”‚   â”œâ”€â”€ best_fold0.pth
â”‚   â”‚       â”‚   â”œâ”€â”€ best_fold1.pth
â”‚   â”‚       â”‚   â”œâ”€â”€ best_fold2.pth
â”‚   â”‚       â”‚   â”œâ”€â”€ best_fold3.pth
â”‚   â”‚       â”‚   â”œâ”€â”€ best_fold4.pth
â”‚   â”‚       â”‚   â””â”€â”€ last.pth                   # ë§ˆì§€ë§‰ ì—í¬í¬ ëª¨ë¸
â”‚   â”‚       â”œâ”€â”€ config.yaml                    # ì‹¤í—˜ ì„¤ì • ë°±ì—…
â”‚   â”‚       â””â”€â”€ metrics.json                   # ì„±ëŠ¥ ì§€í‘œ ê¸°ë¡
â”‚   â””â”€â”€ optimization/                          # ğŸ“ ìµœì í™” ì‹¤í—˜ ê²°ê³¼
â”‚
â”œâ”€â”€ logs/YYYYMMDD/
â”‚   â””â”€â”€ train/                                 # ğŸ“ í•™ìŠµ ë¡œê·¸
â”‚       â”œâ”€â”€ train_HHMM.log                     # í•™ìŠµ ì§„í–‰ ë¡œê·¸
â”‚       â””â”€â”€ metrics_HHMM.json                  # ì„±ëŠ¥ ì§€í‘œ ë¡œê·¸
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ run_fast_training.sh                   # âš¡ ë¹ ë¥¸ í•™ìŠµ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
â”‚   â”œâ”€â”€ run_highperf_training.sh               # ğŸ† ê³ ì„±ëŠ¥ í•™ìŠµ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
â”‚   â””â”€â”€ monitor_training.sh                    # ğŸ“Š í•™ìŠµ ëª¨ë‹ˆí„°ë§ ìŠ¤í¬ë¦½íŠ¸
â”‚
â””â”€â”€ wandb/                                     # ğŸ“Š ì‹¤í—˜ ì¶”ì  ë°ì´í„°
    â””â”€â”€ run-*/                                 # WandB ì‹¤í–‰ ê¸°ë¡
```

#### ğŸ” í•µì‹¬ íŒŒì¼ ìƒì„¸ ê¸°ëŠ¥

**1. src/training/train_main.py**
- **ì£¼ìš” ê¸°ëŠ¥**: ëª…ë ¹í–‰ ì¸í„°í˜ì´ìŠ¤ ì œê³µ ë° í•™ìŠµ íŒŒì´í”„ë¼ì¸ í†µí•© ê´€ë¦¬
- **í•µì‹¬ ì—­í• **: 
  - argparseë¥¼ í†µí•œ ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
  - ì„¤ì • íŒŒì¼ ë¡œë”© ë° ê²€ì¦
  - í•™ìŠµ ëª¨ë“œ ì„ íƒ (ê¸°ë³¸/ê³ ì„±ëŠ¥/ë¹ ë¥¸ ëª¨ë“œ)
  - GPU ìë™ ê°ì§€ ë° ë¶„ì‚° í•™ìŠµ ì„¤ì •
- **ì˜ì¡´ì„±**: train.py, config íŒŒì¼ë“¤ê³¼ ì§ì ‘ ì—°ê²°

**2. src/training/train.py**
- **ì£¼ìš” ê¸°ëŠ¥**: 5-Fold Cross Validation ë° í•µì‹¬ í•™ìŠµ ë¡œì§ êµ¬í˜„
- **í•µì‹¬ ì—­í• **:
  - KFold ë°ì´í„° ë¶„í•  (Stratified ë°©ì‹)
  - ê° Foldë³„ ëª¨ë¸ í•™ìŠµ ê´€ë¦¬
  - Early Stopping ë° Learning Rate Scheduling
  - ê²€ì¦ ì„±ëŠ¥ í‰ê°€ (F1-Score, Accuracy)
  - ìµœì  ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ì €ì¥
- **ì˜ì¡´ì„±**: models/build.py, data/dataset.pyì™€ ê¸´ë°€í•œ ì—°ê²°

**3. src/models/build.py**
- **ì£¼ìš” ê¸°ëŠ¥**: ëª¨ë¸ ì•„í‚¤í…ì²˜ ë™ì  ë¹Œë”© ë° ë°±ë³¸ ë„¤íŠ¸ì›Œí¬ ê´€ë¦¬
- **í•µì‹¬ ì—­í• **:
  - EfficientNet, ResNet, Swin Transformer ë“± ë°±ë³¸ ì„ íƒ
  - ì‚¬ì „ í›ˆë ¨ ê°€ì¤‘ì¹˜ ë¡œë”©
  - ë¶„ë¥˜ í—¤ë“œ ì»¤ìŠ¤í„°ë§ˆì´ì§• (17ê°œ í´ë˜ìŠ¤ ëŒ€ì‘)
  - ëª¨ë¸ íŒŒë¼ë¯¸í„° ì´ˆê¸°í™”
- **ì˜ì¡´ì„±**: timm, torchvision ë¼ì´ë¸ŒëŸ¬ë¦¬ í™œìš©

**4. src/data/dataset.py**
- **ì£¼ìš” ê¸°ëŠ¥**: ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹ í´ë˜ìŠ¤ ë° ë°ì´í„° ë¡œë” êµ¬í˜„
- **í•µì‹¬ ì—­í• **:
  - ì´ë¯¸ì§€ íŒŒì¼ ë¡œë”© ë° ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸
  - ë¼ë²¨ ì¸ì½”ë”© ë° í´ë˜ìŠ¤ ë§¤í•‘
  - ë°ì´í„° ì¦ê°• ì ìš© (Albumentations)
  - ë°°ì¹˜ ìƒì„± ë° GPU ë©”ëª¨ë¦¬ ìµœì í™”
- **ì˜ì¡´ì„±**: transforms.pyì™€ ì—°ë™í•˜ì—¬ ì¦ê°• ê¸°ë²• ì ìš©

**5. configs/train_*.yaml**
- **train.yaml**: ì¼ë°˜ì ì¸ ì‹¤í—˜ìš© ê¸°ë³¸ ì„¤ì • (EfficientNet-B3, 224px)
- **train_highperf.yaml**: ìµœê³  ì„±ëŠ¥ ì¶”êµ¬ ì„¤ì • (Swin-Base, 384px, ë‚®ì€ LR)
- **train_fast_optimized.yaml**: ë¹ ë¥¸ í”„ë¡œí† íƒ€ì… ì„¤ì • (ì‘ì€ ëª¨ë¸, ë†’ì€ LR)

## âš™ï¸ ì„¤ì • íŒŒì¼ ë° ì‹¤í–‰ ëª…ë ¹ì–´

### 1. ğŸ“ ë‹¨ì¼ í´ë“œ í•™ìŠµ ëª¨ë“œ (Single Fold Training)

**ëª©ì **: ë¹ ë¥¸ í”„ë¡œí† íƒ€ì… ë° ê¸°ë³¸ ì„±ëŠ¥ í™•ì¸
**íŠ¹ì§•**: íŠ¹ì • 1ê°œ í´ë“œë§Œ ì„ íƒí•˜ì—¬ í•™ìŠµ, ë¹ ë¥¸ ê²°ê³¼ í”¼ë“œë°±
**ê¸°ëŒ€ ì„±ëŠ¥**: F1 Score 0.92-0.95

#### ì„¤ì • íŒŒì¼: `configs/train.yaml` (ë‹¨ì¼ í´ë“œ)
```yaml
# ë‹¨ì¼ í´ë“œ í•µì‹¬ ì„¤ì •
model:
  name: efficientnet_b3        # ë‹¨ì¼ ëª¨ë¸ ì„ íƒ
  img_size: 224
  num_classes: 17

train:
  epochs: 10                   # ë¹ ë¥¸ í•™ìŠµìš©
  batch_size: 32
  learning_rate: 0.001
  
data:
  folds: 5                     # ì „ì²´ í´ë“œ ìˆ˜
  valid_fold: 0                # íŠ¹ì • í´ë“œ ì„ íƒ (0-4)
  train_csv: data/raw/train.csv
  image_dir_train: data/raw/train
```

#### ë‹¨ì¼ í´ë“œ ì‹¤í–‰ ëª…ë ¹ì–´
```bash
# Fold 0ìœ¼ë¡œ ë¹ ë¥¸ í•™ìŠµ
python src/training/train_main.py --config configs/train.yaml

# íŠ¹ì • í´ë“œ ì§€ì • (ì˜ˆ: Fold 2)
# configs/train.yamlì—ì„œ valid_fold: 2ë¡œ ìˆ˜ì • í›„ ì‹¤í–‰
python src/training/train_main.py --config configs/train.yaml --mode basic

# ë‹¨ì¼ í´ë“œ + Optuna ìµœì í™”
python src/training/train_main.py --config configs/train.yaml --optimize --n-trials 10
```

### 2. ğŸ”€ K-Fold êµì°¨ê²€ì¦ í•™ìŠµ ëª¨ë“œ (K-Fold Cross Validation)

**ëª©ì **: ì•ˆì •ì ì´ê³  ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì„±ëŠ¥ ë‹¬ì„±
**íŠ¹ì§•**: 5ê°œ í´ë“œ ëª¨ë‘ í•™ìŠµí•˜ì—¬ êµì°¨ê²€ì¦, ì•™ìƒë¸” ê¸°ë°˜ êµ¬ì¶•
**ê¸°ëŒ€ ì„±ëŠ¥**: F1 Score 0.95-0.98

### 3. ğŸ­ ë‹¤ì¤‘ ëª¨ë¸ ì•™ìƒë¸” í•™ìŠµ ëª¨ë“œ (Multi-Model Ensemble)

**ëª©ì **: ë‹¤ì–‘í•œ ì•„í‚¤í…ì²˜ë¥¼ í†µí•œ ì„±ëŠ¥ ê·¹ëŒ€í™”
**íŠ¹ì§•**: ConvNeXt, Swin, EfficientNet ë“± ì—¬ëŸ¬ ëª¨ë¸ ë™ì‹œ í•™ìŠµ
**ê¸°ëŒ€ ì„±ëŠ¥**: ê°œë³„ ëª¨ë¸ ìµœì í™” + ì•™ìƒë¸” íš¨ê³¼

#### ì„¤ì • íŒŒì¼: `configs/train_highperf.yaml` (K-fold)
```yaml
# K-fold êµì°¨ê²€ì¦ ì„¤ì •
model:
  name: "convnext_base_384_in22ft1k"  # Team ìµœê³  ì„±ëŠ¥ ëª¨ë¸
  img_size: 384
  num_classes: 17
  drop_rate: 0.05
  drop_path_rate: 0.1

train:
  epochs: 50                        # ì•ˆì •ì  ì„±ëŠ¥ ë‹¬ì„±
  batch_size: 48
  lr: 0.0001
  use_advanced_augmentation: true   # Hard Augmentation
  use_mixup: true
  mixup_alpha: 1.0
  label_smoothing: 0.05
  
data:
  folds: 5
  valid_fold: all                   # ëª¨ë“  í´ë“œ í•™ìŠµ
  stratify: true                    # ê³„ì¸µì  ë¶„í• 
```

#### K-fold ì‹¤í–‰ ëª…ë ¹ì–´
```bash
# ì „ì²´ 5-fold êµì°¨ê²€ì¦
python src/training/train_main.py --config configs/train_highperf.yaml --mode highperf

# K-fold + Temperature Scaling ë³´ì •
python src/training/train_main.py --config configs/train_highperf.yaml --mode highperf --use-calibration

# K-fold + ìµœì í™” + ìë™ ì§„í–‰ (Team ìµœê³  ì„±ëŠ¥)
python src/training/train_main.py --config configs/train_highperf.yaml --mode highperf --optimize --n-trials 30 --use-calibration --auto-continue
```

#### ì„¤ì • íŒŒì¼: `configs/train_multi_model_ensemble.yaml` (ë‹¤ì¤‘ ëª¨ë¸)
```yaml
# ë‹¤ì¤‘ ëª¨ë¸ ì•™ìƒë¸” ì„¤ì •
project:
  run_name: multi-model-ensemble
  
models:
  - name: convnext_base_384
    img_size: 384
    epochs: 30
    lr: 0.0001
  - name: swin_base_patch4_window12_384  
    img_size: 384
    epochs: 35
    lr: 0.00008
  - name: efficientnet_v2_b3
    img_size: 320
    epochs: 25
    lr: 0.0002
    
data:
  valid_fold: all                   # ëª¨ë“  ëª¨ë¸ì— K-fold ì ìš©
  use_advanced_augmentation: true
```

#### ë‹¤ì¤‘ ëª¨ë¸ ì‹¤í–‰ ëª…ë ¹ì–´
```bash
# ë‹¤ì¤‘ ëª¨ë¸ ë™ì‹œ í•™ìŠµ
python src/training/train_main.py --config configs/train_multi_model_ensemble.yaml --mode highperf

# ëª¨ë¸ë³„ ë³‘ë ¬ í•™ìŠµ (GPU ì—¬ëŸ¬ ê°œ ì‚¬ìš© ì‹œ)
CUDA_VISIBLE_DEVICES=0 python src/training/train_main.py --config configs/convnext_config.yaml &
CUDA_VISIBLE_DEVICES=1 python src/training/train_main.py --config configs/swin_config.yaml &
CUDA_VISIBLE_DEVICES=2 python src/training/train_main.py --config configs/efficientnet_config.yaml &
wait
```

## ğŸš€ ì‹¤í–‰ ì˜µì…˜ ì™„ì „ ê°€ì´ë“œ

### ê¸°ë³¸ ëª…ë ¹ì–´ êµ¬ì¡°
```bash
python src/training/train_main.py [í•„ìˆ˜ì˜µì…˜] [ì„ íƒì˜µì…˜]
```

### ğŸ“Š CLI ì˜µì…˜ ì™„ì „ ê°€ì´ë“œ

| ì˜µì…˜ | íƒ€ì… | í•„ìˆ˜/ì„ íƒ | ê¸°ë³¸ê°’ | choices | ì„¤ëª… |
|------|------|----------|--------|---------|------|
| `--config` | str | í•„ìˆ˜ | - | - | ì„¤ì • YAML íŒŒì¼ ê²½ë¡œ |
| `--mode` | str | ì„ íƒ | "full-pipeline" | ["basic", "highperf", "full-pipeline"] | ì‹¤í–‰ ëª¨ë“œ ì„ íƒ |
| `--skip-training` | flag | ì„ íƒ | False | - | í•™ìŠµ ê±´ë„ˆë›°ê³  ì¶”ë¡ ë§Œ ì‹¤í–‰ |
| `--optimize` | flag | ì„ íƒ | False | - | Optuna í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” |
| `--n-trials` | int | ì„ íƒ | 20 | - | Optuna ì‹œë„ íšŸìˆ˜ |
| `--optuna-config` | str | ì„ íƒ | None | - | Optuna ì„¤ì • íŒŒì¼ ê²½ë¡œ |
| `--use-calibration` | flag | ì„ íƒ | False | - | Temperature Scaling ì‚¬ìš© |
| `--auto-continue` | flag | ì„ íƒ | False | - | ìµœì í™” í›„ ìë™ ì§„í–‰ |

### ì„ íƒ ì˜µì…˜ ìƒì„¸ ì„¤ëª…

#### 1. `--mode <ëª¨ë“œ>` - í•™ìŠµ ì „ëµ ì„ íƒ
**ê¸°ëŠ¥**: í•™ìŠµ íŒŒì´í”„ë¼ì¸ì˜ ì‹¤í–‰ ëª¨ë“œ ì„ íƒ

**ëª¨ë“œë³„ ë¹„êµ**:
| ëª¨ë“œ | ì†ë„ | ì„±ëŠ¥ | ëª©ì  | ì¶”ì²œ ìƒí™© |
|------|------|------|------|----------|
| `basic` | âš¡ ë¹ ë¦„ (30ë¶„) | 0.92-0.94 | í”„ë¡œí† íƒ€ì… | ë¹ ë¥¸ ê²€ì¦, ë‹¨ì¼ í´ë“œ |
| `highperf` | ğŸ•°ï¸ ëŠë¦¼ (1-3ì‹œê°„) | 0.95-0.98 | ìµœê³  ì„±ëŠ¥ | K-fold, ìµœì¢… ì œì¶œ |
| `full-pipeline` | ğŸ”„ ì¤‘ê°„ (1-2ì‹œê°„) | 0.93-0.96 | ì „ì²´ ìë™í™” | í•™ìŠµ+ì¶”ë¡  í†µí•© |

```bash
# ë‹¨ì¼ í´ë“œ ë¹ ë¥¸ í•™ìŠµ (valid_fold: 0-4)
python src/training/train_main.py --config configs/train.yaml --mode basic

# K-fold êµì°¨ê²€ì¦ ê³ ì„±ëŠ¥ í•™ìŠµ (valid_fold: all)
python src/training/train_main.py --config configs/train_highperf.yaml --mode highperf

# í•™ìŠµë¶€í„° ì¶”ë¡ ê¹Œì§€ ìë™ ì™„ì„±
python src/training/train_main.py --config configs/train.yaml --mode full-pipeline
```

#### 2. `--optimize`
**ê¸°ëŠ¥**: Optuna í•˜ì´í¼íŒŒë¼ë¯¸í„° ìë™ ìµœì í™” í™œì„±í™”
**íš¨ê³¼**: learning_rate, batch_size, augmentation íŒŒë¼ë¯¸í„° ìë™ íŠœë‹

```bash
# ìµœì í™” ì—†ì´ í•™ìŠµ (ê¸°ë³¸ ì„¤ì • ì‚¬ìš©)
python src/training/train_main.py --config configs/train.yaml

# ìµœì í™”ì™€ í•¨ê»˜ í•™ìŠµ (ì„±ëŠ¥ í–¥ìƒ ê¸°ëŒ€)
python src/training/train_main.py --config configs/train.yaml --optimize
```

#### 3. `--n-trials <ìˆ«ì>`
**ê¸°ëŠ¥**: Optuna ìµœì í™” ì‹œë„ íšŸìˆ˜ ì„¤ì • (--optimizeì™€ í•¨ê»˜ ì‚¬ìš©)
**ê¸°ë³¸ê°’**: 20
**ê¶Œì¥ê°’**: 
- ë¹ ë¥¸ í…ŒìŠ¤íŠ¸: 5-10
- ì¼ë°˜ ìµœì í™”: 20
- ì™„ì „ ìµœì í™”: 50+

```bash
# ë¹ ë¥¸ ìµœì í™” (5ë²ˆ ì‹œë„)
python src/training/train_main.py --config configs/train.yaml --optimize --n-trials 5

# í‘œì¤€ ìµœì í™” (20ë²ˆ ì‹œë„)
python src/training/train_main.py --config configs/train.yaml --optimize --n-trials 20

# ì™„ì „ ìµœì í™” (50ë²ˆ ì‹œë„)
python src/training/train_main.py --config configs/train.yaml --optimize --n-trials 50
```

#### 4. `--use-calibration`
**ê¸°ëŠ¥**: Temperature Scaling ìº˜ë¦¬ë¸Œë ˆì´ì…˜ í™œì„±í™”
**íš¨ê³¼**: ëª¨ë¸ ì‹ ë¢°ë„(confidence) í–¥ìƒ, ë” ì •í™•í•œ í™•ë¥  ì˜ˆì¸¡

```bash
# ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì—†ì´
python src/training/train_main.py --config configs/train.yaml

# ìº˜ë¦¬ë¸Œë ˆì´ì…˜ í¬í•¨ (ì¶”ì²œ)
python src/training/train_main.py --config configs/train.yaml --use-calibration
```

#### 5. `--auto-continue`
**ê¸°ëŠ¥**: ìµœì í™” ì™„ë£Œ í›„ ìë™ìœ¼ë¡œ ì „ì²´ í•™ìŠµ ì§„í–‰ (--optimizeì™€ í•¨ê»˜ ì‚¬ìš©)

```bash
# ìµœì í™”ë§Œ ì‹¤í–‰ (ìˆ˜ë™ìœ¼ë¡œ ë‹¤ìŒ ë‹¨ê³„ ì§„í–‰)
python src/training/train_main.py --config configs/train.yaml --optimize

# ìµœì í™” í›„ ìë™ìœ¼ë¡œ ì „ì²´ í•™ìŠµ ì§„í–‰
python src/training/train_main.py --config configs/train.yaml --optimize --auto-continue
```

#### 6. `--resume`
**ê¸°ëŠ¥**: ì¤‘ë‹¨ëœ í•™ìŠµì„ ì²´í¬í¬ì¸íŠ¸ë¶€í„° ì¬ê°œ

```bash
# ì²˜ìŒë¶€í„° í•™ìŠµ
python src/training/train_main.py --config configs/train.yaml

# ì¤‘ë‹¨ëœ ì§€ì ë¶€í„° ì¬ê°œ
python src/training/train_main.py --config configs/train.yaml --resume
```

## ğŸ¯ ì‹¤ì „ ì‚¬ìš© ì˜ˆì‹œ

### 1. ë¹ ë¥¸ ê²°ê³¼ í™•ì¸ (30ë¶„)
```bash
python src/training/train_main.py --config configs/train.yaml --mode basic
```

### 2. ìµœê³  ì„±ëŠ¥ ì¶”êµ¬ (2-3ì‹œê°„)
```bash
python src/training/train_main.py \
    --config configs/train_highperf.yaml \
    --mode highperf \
    --optimize \
    --n-trials 20 \
    --use-calibration \
    --auto-continue
```

### 3. ë¹ ë¥¸ ìµœì í™” í…ŒìŠ¤íŠ¸ (1ì‹œê°„)
```bash
python src/training/train_main.py \
    --config configs/train.yaml \
    --optimize \
    --n-trials 5 \
    --use-calibration
```

### 4. ì „ì²´ íŒŒì´í”„ë¼ì¸ (í•™ìŠµ+ì¶”ë¡ )
```bash
python src/training/train_main.py \
    --config configs/train_highperf.yaml \
    --mode full-pipeline \
    --use-calibration
```

### 5. ğŸš€ ë‹¨ì¼ í´ë“œ ìµœì í™” (ì‹ ê·œ - 2025.09.10 ì¶”ê°€)
**ë°°ê²½**: ê²½ì§„ëŒ€íšŒ ë§ˆê° ì‹œê°„ ë‹¨ì¶•ì„ ìœ„í•´ K-fold ëŒ€ì‹  ë‹¨ì¼ í´ë“œ + ì•™ìƒë¸” ì „ëµ ì ìš©

```bash
# ë‹¨ì¼ í´ë“œ í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” (ë§¤ìš° ë¹ ë¦„ - 2ë¶„/trial)
python src/training/train_main.py \
    --config configs/train_highperf.yaml \
    --mode full-pipeline \
    --use-calibration \
    --optimize \
    --optuna-config configs/optuna_single_fold_config.yaml \
    --auto-continue
```

**í•µì‹¬ ê°œì„ ì‚¬í•­:**
- âš¡ **ì†ë„ í–¥ìƒ**: ë§¤ trial 2ì´ˆ ì™„ë£Œ (ë°ì´í„°ì…‹ ìºì‹± ì ìš©)
- ğŸ¯ **ì‹¤ì œ F1 ì ìˆ˜**: ì‹œë®¬ë ˆì´ì…˜ ì•„ë‹Œ ì‹¤ì œ í•™ìŠµ ê¸°ë°˜ í‰ê°€
- ğŸ“Š **ë†’ì€ ì„±ëŠ¥**: F1 0.947+ ë‹¬ì„± ê°€ëŠ¥
- ğŸ”§ **ë©”ëª¨ë¦¬ ìµœì í™”**: ìºì‹œëœ ë°ì´í„°ë¡œ ë°˜ë³µ í•™ìŠµ ì†ë„ ê·¹ëŒ€í™”

**ì„¤ì • íŒŒì¼**: `configs/optuna_single_fold_config.yaml`
```yaml
optuna:
  n_trials: 20              # ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ìš© (ì‹¤ì œ 100+ ê¶Œì¥)
  n_jobs: 1                 # GPU ë©”ëª¨ë¦¬ì— ë”°ë¼ ì¡°ì •
  single_fold_validation:
    epochs: 5               # ë¹ ë¥¸ ê²€ì¦ìš©
    validation_split: 0.2   # 80:20 ë¶„í• 
```

## ğŸ“Š ì„±ëŠ¥ ë¹„êµ ë° Team ê¸°ë²• ë¶„ì„

### ğŸ† ìµœì‹  vs ê¸°ì¡´ ì„±ëŠ¥ ë¹„êµ

| êµ¬ë¶„ | ëª¨ë¸ | F1 Score | ì„±ëŠ¥ í–¥ìƒ | ì‹¤í—˜ ì¼ì‹œ | í•µì‹¬ ê¸°ë²• |
|------|------|----------|----------|---------|---------|
| **ê¸°ì¡´ ë² ì´ìŠ¤ë¼ì¸** | EfficientNet B3 | 0.9238 | - | - | ê¸°ë³¸ ì¦ê°• |
| **ê³ ì„±ëŠ¥ ìµœì‹ ** | ConvNeXt Base 384 | **0.98362** | **+6.5%** | 2025-09-10 12:13 | **ìµœì í™”ëœ ì „ì²´ ê¸°ë²•** |
| **ê³ ì„±ëŠ¥ ì´ì „** | ConvNeXt Base 384 | **0.97918** | **+5.9%** | 2025-09-10 09:29 | Hard Aug + TTA + ìº˜ë¦¬ë¸Œë ˆì´ì…˜ |

### âš¡ ì‹¤í–‰ ëª¨ë“œë³„ ì„±ëŠ¥ ë¶„ì„

| ì‹¤í–‰ ì˜µì…˜ | ì˜ˆìƒ ì‹œê°„ | ì˜ˆìƒ F1 | GPU ë©”ëª¨ë¦¬ | Team ê¸°ë²• ì ìš© | ì¶”ì²œ ìƒí™© |
|-----------|-----------|---------|------------|-------------|-----------|
| `--mode basic` | 30ë¶„ | 0.920-0.930 | 8GB | âŒ | ë¹ ë¥¸ í”„ë¡œí† íƒ€ì… |
| `--mode basic --optimize` | 1ì‹œê°„ | 0.935-0.945 | 8GB | ë¶€ë¶„ì  | ê°œì„ ëœ ë² ì´ìŠ¤ë¼ì¸ |
| `--mode highperf` | 2ì‹œê°„ | **0.950-0.965** | 16GB | âœ… **ì „ì²´** | **ìµœì¢… ì œì¶œìš©** |
| `--mode highperf --optimize` | 3ì‹œê°„ | **0.965+** | 16GB | âœ… **ì „ì²´+íŠœë‹** | **ëŒ€íšŒ ìš°ìŠ¹ìš©** |
| **ğŸš€ ë‹¨ì¼ í´ë“œ ìµœì í™”** | **23ë¶„** | **0.969-0.984** | **12GB** | âœ… **ìºì‹±+ìµœì í™”** | **âš¡ ë¹ ë¥¸ ê²½ì§„ëŒ€íšŒìš©** |

### ğŸ¯ Team ê³ ì„±ëŠ¥ ê¸°ë²•ë³„ ê¸°ì—¬ë„

| ê¸°ë²• | ì„±ëŠ¥ ê¸°ì—¬ | êµ¬í˜„ ìœ„ì¹˜ | ì„¤ëª… |
|------|----------|---------|------|
| **ConvNeXt ImageNet-22k** | +2.0% | `configs/train_highperf.yaml` | ì‚¬ì „í•™ìŠµ ëª¨ë¸ ì—…ê·¸ë ˆì´ë“œ |
| **Hard Augmentation** | +1.5% | `src/data/transforms.py:180-216` | ë™ì  í™•ë¥  ìŠ¤ì¼€ì¤„ë§ |
| **Essential TTA** | +0.8% | `src/data/transforms.py:221-250` | 5ê°€ì§€ í•µì‹¬ ë³€í™˜ |
| **Temperature Scaling** | +0.3% | `src/calibration/` | í™•ë¥  ë³´ì • |
| **ì „ì²´ ì¡°í•©** | **+4.14%** | í†µí•© ì ìš© | ì‹œë„ˆì§€ íš¨ê³¼ |

## âš ï¸ ì£¼ì˜ì‚¬í•­ ë° íŒ

### GPU ë©”ëª¨ë¦¬ ìµœì í™”
```bash
# GPU ë©”ëª¨ë¦¬ ë¶€ì¡± ì‹œ
python src/utils/gpu_optimization/auto_batch_size.py --config configs/train.yaml
python src/training/train_main.py --config configs/train.yaml --mode basic
```

### í•™ìŠµ ëª¨ë‹ˆí„°ë§
```bash
# ì‹¤ì‹œê°„ ë¡œê·¸ í™•ì¸
tail -f logs/$(date +%Y%m%d)/train/*.log

# GPU ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§
watch -n 1 nvidia-smi
```

### ì²´í¬í¬ì¸íŠ¸ ê´€ë¦¬
```bash
# ìµœì‹  ëª¨ë¸ í™•ì¸
ls -la experiments/train/$(date +%Y%m%d)/*/results/ckpt/

# ì‹œê°í™” ì´ë¯¸ì§€ í™•ì¸  
ls -la experiments/train/$(date +%Y%m%d)/*/images/

# íŠ¹ì • fold ëª¨ë¸ ì‚¬ìš©
python src/training/train_main.py --config configs/train.yaml --resume --fold 0
```

## ğŸš€ ëª¨ë“  ì‹¤í–‰ ëª…ë ¹ì–´ ëª¨ìŒ

### ê¸°ë³¸ í•™ìŠµ ëª…ë ¹ì–´
```bash
# 1. ê¸°ë³¸ í•™ìŠµ (EfficientNet-B3, 224px)
python src/training/train_main.py --config configs/train.yaml

# 2. ê³ ì„±ëŠ¥ í•™ìŠµ (Swin-Base, 384px)
python src/training/train_main.py --config configs/train_highperf.yaml

# 3. ë¹ ë¥¸ í•™ìŠµ (í”„ë¡œí† íƒ€ì…ìš©)
python src/training/train_main.py --config configs/train_fast_optimized.yaml
```

### ê³ ê¸‰ í•™ìŠµ ì˜µì…˜
```bash
# 4. íŠ¹ì • ëª¨ë“œë¡œ í•™ìŠµ
python src/training/train_main.py --config configs/train.yaml --mode basic
python src/training/train_main.py --config configs/train.yaml --mode highperf
python src/training/train_main.py --config configs/train.yaml --mode fast

# 5. í•™ìŠµ ì¬ê°œ (ì²´í¬í¬ì¸íŠ¸ì—ì„œ)
python src/training/train_main.py --config configs/train.yaml --resume
python src/training/train_main.py --config configs/train.yaml --resume --fold 2

# 6. ìë™ ê³„ì† (ì¤‘ë‹¨ëœ í•™ìŠµ ìë™ ì¬ê°œ)
python src/training/train_main.py --config configs/train.yaml --auto-continue

# 7. íŠ¹ì • foldë§Œ í•™ìŠµ
python src/training/train_main.py --config configs/train.yaml --fold 0
python src/training/train_main.py --config configs/train.yaml --fold 1,2,3
```

### ìµœì í™” ê´€ë ¨ ëª…ë ¹ì–´
```bash
# 8. Optuna í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹
python src/training/train_main.py --config configs/train.yaml --optimize --n-trials 50

# 9. ë¹ ë¥¸ ìµœì í™” (ì ì€ trial)
python src/training/train_main.py --config configs/train_fast_optimized.yaml --optimize --n-trials 10

# 10. ë³´ì • í¬í•¨ í•™ìŠµ
python src/training/train_main.py --config configs/train.yaml --use-calibration

# 11. ìµœì í™” + ë³´ì • ì¡°í•©
python src/training/train_main.py --config configs/train_highperf.yaml --optimize --n-trials 30 --use-calibration
```

### GPU ë° ë°°ì¹˜ ì„¤ì •
```bash
# 12. íŠ¹ì • GPU ì§€ì •
CUDA_VISIBLE_DEVICES=0 python src/training/train_main.py --config configs/train.yaml
CUDA_VISIBLE_DEVICES=1 python src/training/train_main.py --config configs/train_highperf.yaml

# 13. ìë™ ë°°ì¹˜ í¬ê¸° ê²°ì •
python src/utils/gpu_optimization/auto_batch_size.py --config configs/train.yaml
python src/utils/gpu_optimization/auto_batch_size.py --config configs/train_highperf.yaml

# 14. GPU ìƒíƒœ í™•ì¸
python src/utils/gpu_optimization/team_gpu_check.py
```

### ë°ì´í„° ë° ì „ì²˜ë¦¬
```bash
# 15. ë°ì´í„° ì¤€ë¹„ í™•ì¸
ls -la data/raw/train/
head -5 data/raw/meta.csv

# 16. í´ë˜ìŠ¤ ë¶„í¬ í™•ì¸
python -c "
import pandas as pd
df = pd.read_csv('data/raw/meta.csv')
print('í´ë˜ìŠ¤ ë¶„í¬:')
print(df['label'].value_counts().sort_index())
print(f'\nì´ ì´ë¯¸ì§€ ìˆ˜: {len(df)}')
print(f'í´ë˜ìŠ¤ ìˆ˜: {df["label"].nunique()}')
"
```

### ëª¨ë‹ˆí„°ë§ ë° ë¡œê·¸
```bash
# 17. ì‹¤ì‹œê°„ í•™ìŠµ ë¡œê·¸ í™•ì¸
tail -f logs/$(date +%Y%m%d)/train/*.log

# 18. GPU ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§
watch -n 1 nvidia-smi

# 19. í•™ìŠµ ì§„í–‰ë¥  í™•ì¸
grep -i "epoch\|loss\|f1" logs/$(date +%Y%m%d)/train/*.log | tail -20

# 20. WandB ë™ê¸°í™”
wandb sync wandb/
```

### ê²°ê³¼ ë¶„ì„
```bash
# 21. ìµœì‹  ì‹¤í—˜ ê²°ê³¼ í™•ì¸ (ì „ì²´ êµ¬ì¡°)
ls -la experiments/train/$(date +%Y%m%d)/

# 22. ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ í™•ì¸
find experiments/train -path "*/results/ckpt/*.pth" | head -10

# 22-1. ì‹œê°í™” ì´ë¯¸ì§€ í™•ì¸
find experiments/train/$(date +%Y%m%d) -name "*.png" | head -10

# 23. í•™ìŠµ ì„±ëŠ¥ ìš”ì•½
python -c "
import json, glob
metric_files = glob.glob('experiments/train/$(date +%Y%m%d)/*/results/metrics.json')
for file in metric_files:
    with open(file) as f:
        metrics = json.load(f)
        print(f'{file}: F1={metrics.get(\"best_f1\", \"N/A\"):.4f}')
"

# 24. ëª¨ë¸ í¬ê¸° í™•ì¸
ls -lh experiments/train/$(date +%Y%m%d)/*/results/ckpt/*.pth

# 25. ì‹œê°í™” ê²°ê³¼ í™•ì¸
echo "=== ìƒì„±ëœ ì‹œê°í™” ì°¨íŠ¸ ==="
find experiments/train/$(date +%Y%m%d) -name "*.png" -exec basename {} \; | sort
```

### ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
```bash
# 25. ë¹ ë¥¸ í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸
bash scripts/run_fast_training.sh

# 26. ê³ ì„±ëŠ¥ í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸  
bash scripts/run_highperf_training.sh

# 27. í•™ìŠµ ëª¨ë‹ˆí„°ë§ ìŠ¤í¬ë¦½íŠ¸
bash scripts/monitor_training.sh
```

### í™˜ê²½ ì„¤ì •
```bash
# 28. Python í™˜ê²½ í™œì„±í™”
eval "$(pyenv init --path)" && pyenv activate cv_py3_11_9

# 29. í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install -r requirements.txt

# 30. í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
source path.env
```
