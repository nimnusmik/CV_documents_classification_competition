# ğŸ› ï¸ ë¬¸ì œ í•´ê²° ê°€ì´ë“œ (Team ConvNeXt ê¸°ë²• í¬í•¨)

## ğŸ“ˆ Team ê¸°ë²• ê´€ë ¨ ë¬¸ì œ í•´ê²°

### ğŸ¯ Team ConvNeXt ìµœì í™” ë¬¸ì œ ì§„ë‹¨

| ë¬¸ì œ ìœ í˜• | ì¦ìƒ | ì˜ˆìƒ ì„±ëŠ¥ | í•´ê²° ë°©ë²• | ëŒ€ì•ˆ | ì‚¬ìš© ëª…ë ¹ì–´ |
|----------|------|-----------|---------|------|-----------|
| **TTA ë©”ëª¨ë¦¬ ë¶€ì¡±** | CUDA OOM | F1: 0.9652 â†’ ì‚¬ìš© ë¶ˆê°€ | Essential TTA ì‚¬ìš© | tta_type: "essential" | `--config infer_highperf.yaml` |
| **ë°°ì¹˜ í¬ê¸° ì´ˆê³¼** | í•™ìŠµ ì‹¤íŒ¨ | F1: 0.9489 ê¸°ëŒ€ | ë°°ì¹˜ í¬ê¸° ê°ì†Œ | batch_size: 32 â†’ 16 | `auto_batch_size.py` |
| **fold_results.yaml ì—†ìŒ** | ì¶”ë¡  ì˜¤ë¥˜ | ì•±ìƒë¸” ë¶ˆê°€ | í•™ìŠµ ë¨¼ì € ì‹¤í–‰ | highperf ëª¨ë“œ ì™„ë£Œ | `train_main.py --mode highperf` |
| **GPU ë©”ëª¨ë¦¬ ë¶€ì¡±** | ConvNeXt ì‹¤í–‰ ë¶ˆê°€ | RTX 3060 ì—ì„œ ì‹¤íŒ¨ | ë°°ì¹˜ í¬ê¸° 16 | EfficientNet ëŒ€ì•ˆ | `--batch-size 16` |

### ğŸš€ Team TTA ì‹œìŠ¤í…œ ë¬¸ì œí•´ê²°

#### 1. Comprehensive TTA CUDA OOM ì˜¤ë¥˜
```bash
# ì˜¤ë¥˜: RuntimeError: CUDA out of memory (Comprehensive TTA)
RuntimeError: CUDA out of memory. Tried to allocate 2.50 GiB (GPU 0; 9.78 GiB total capacity)

# í•´ê²°ë°©ë²• 1: Essential TTAë¡œ ì „í™˜ (F1: 0.9565)
python src/inference/infer_main.py \
    --config configs/infer_highperf.yaml \
    --mode highperf \
    --fold-results experiments/train/lastest-train/fold_results.yaml
# configs/infer_highperf.yamlì—ì„œ: tta_type: "essential"

# í•´ê²°ë°©ë²• 2: ë°°ì¹˜ í¬ê¸° ê°ì†Œ
# train.batch_size: 48 â†’ 32 â†’ 16
```

#### 2. ConvNeXt Base 384 ë©”ëª¨ë¦¬ ë¶€ì¡±
```bash
# RTX 3060/3070ì—ì„œ ConvNeXt ì‹¤í–‰ ì‹œ ë©”ëª¨ë¦¬ ë¶€ì¡±

# ìë™ ìµœì í™”
python src/utils/gpu_optimization/auto_batch_size.py \
    --config configs/train_highperf.yaml \
    --model-type convnext \
    --safety-factor 0.8

# ìˆ˜ë™ ì„¤ì • ì˜ˆì‹œ (RTX 3060)
# configs/train_highperf.yaml:
# train:
#   batch_size: 16  # 48ì—ì„œ 16ìœ¼ë¡œ ê°ì†Œ
#   accumulate_grad_batches: 3  # ì‹¤ì§ˆ ë°°ì¹˜ 48 ìœ ì§€
```

#### 3. fold_results.yaml íŒŒì¼ ì—†ìŒ
```bash
# ì˜¤ë¥˜: FileNotFoundError: fold_results.yaml not found

# í•´ê²°ë°©ë²•: í•™ìŠµ ë¨¼ì € ì™„ë£Œ
python src/training/train_main.py \
    --config configs/train_highperf.yaml \
    --mode highperf

# í•™ìŠµ ì™„ë£Œ í›„ ìë™ ìƒì„±ëœ ê²½ë¡œ í™•ì¸
ls experiments/train/lastest-train/fold_results.yaml

# ìˆ˜ë™ ê²½ë¡œ ì§€ì •
python src/inference/infer_main.py \
    --fold-results experiments/train/20250910/convnext_base_384_team/fold_results.yaml
```

## ğŸš¨ ì¼ë°˜ì ì¸ ë¬¸ì œë“¤

## ğŸ¯ Team ConvNeXt ì„±ëŠ¥ ì§„ë‹¨ ë„êµ¬

### Team ëª¨ë¸ ì„±ëŠ¥ ì²´í¬ë¦¬ìŠ¤íŠ¸

| í™•ì¸ í•­ëª© | ê¸°ëŒ€ê°’ | í™•ì¸ ëª…ë ¹ì–´ | ë¬¸ì œ ì‹œ í•´ê²°ë°©ë²• |
|----------|-------|------------|----------------|
| **ê¸°ë³¸ ConvNeXt** | F1: 0.9489 | í•™ìŠµ ë¡œê·¸ í™•ì¸ | í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¡°ì • |
| **Essential TTA** | F1: 0.9565 | ì¶”ë¡  ì‹¤í–‰ í™•ì¸ | tta_type ì„¤ì • ê²€ì¦ |
| **Comprehensive TTA** | F1: 0.9652 | GPU ë©”ëª¨ë¦¬ ì¶©ë¶„ì„± | RTX 3080+ í•„ìš” |
| **Temperature Scaling** | ì‹ ë¢°ë„ ê°œì„  | í•™ìŠµ ì„¤ì • í™•ì¸ | ì„¤ì • íŒŒì¼ ê²€ì¦ |
| **Hard Augmentation** | í•™ìŠµ ì•ˆì •ì„± | ë°°ì¹˜ í¬ê¸° ê²€ì¦ | ë©”ëª¨ë¦¬ ìµœì í™” |

### Team ëª¨ë¸ íŒŒì¼ ìë™ ì°¾ê¸°
```bash
# Team ConvNeXt ì „ìš© ëª¨ë¸ ì°¾ê¸°
find experiments/train -name "*convnext*" -o -name "*team*" | head -10
find experiments/train -path "*/lastest-train/best_fold*.pth"

# Team ìµœì‹  ê²°ê³¼ í™•ì¸
ls -la experiments/train/lastest-train/
echo "Team fold_results.yaml ì¡´ì¬ í™•ì¸"
test -f experiments/train/lastest-train/fold_results.yaml && echo "âœ… ë°œê²¬ë¨" || echo "âŒ ì—†ìŒ - í•™ìŠµ í•„ìš”"

# Team ëª¨ë¸ ì„±ëŠ¥ ì˜ˆìƒì¹˜ í™•ì¸
echo "=== Team ConvNeXt ì˜ˆìƒ ì„±ëŠ¥ ==="
echo "ê¸°ë³¸ ëª¨ë¸: F1 0.9489 (10-15ë¶„ ì¶”ë¡ )"
echo "Essential TTA: F1 0.9565 (17ë¶„ ì¶”ë¡ )"  
echo "Comprehensive TTA: F1 0.9652 (50ë¶„+ ì¶”ë¡ )"
```

### 1. GPU ë©”ëª¨ë¦¬ ë¶€ì¡± (CUDA Out of Memory)

#### Team ConvNeXt ìµœì í™” í•´ê²°ë²•
```bash
# 1) í˜„ì¬ GPU ìƒíƒœ ë˜ëŠ” Team ëª¨ë¸ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸
nvidia-smi
echo "ConvNeXt Base 384 ë©”ëª¨ë¦¬ ìš”êµ¬ì‚¬í•­: RTX 3080 10GB ì´ìƒ ê¶Œì¥"

# 2) Team ëª¨ë¸ ë©”ëª¨ë¦¬ ì •ë¦¬ ë° ìµœì í™”
python -c "import torch; torch.cuda.empty_cache(); print('Team ConvNeXt ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ')"

# 3) Team ìµœì í™” ìë™ ë°°ì¹˜ í¬ê¸° ê²°ì •
python src/utils/gpu_optimization/auto_batch_size.py \
    --config configs/train_highperf.yaml \
    --model-type convnext \
    --safety-factor 0.85 \
    --target-f1 0.9550

# 4) GPUë³„ Team ConvNeXt ìµœì  ë°°ì¹˜ í¬ê¸°
echo "RTX 4090 (24GB): batch_size 64, F1 0.9652 ê¸°ëŒ€"
echo "RTX 3080 (10GB): batch_size 32, F1 0.9550 ê¸°ëŒ€"
echo "RTX 3060 (8GB):  batch_size 16, F1 0.9520 ê¸°ëŒ€"
```

### 2. Team ConvNeXt ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ

#### Team ìµœì í™” í•´ê²°ë²•
```bash
# 1) Team ConvNeXt ëª¨ë¸ ì°¾ê¸°
find experiments/train -name "*convnext*" -path "*/results/ckpt/*.pth" | head -5
find experiments/train -path "*/lastest-train/best_fold*.pth" | head -5

# 2) Team ìµœì‹  ëª¨ë¸ ìë™ ì„ íƒ
TEAM_MODEL=$(find experiments/train -path "*/lastest-train/best_fold0.pth" | head -1)
echo "Team ConvNeXt ìµœì‹  ëª¨ë¸: $TEAM_MODEL"

# 3) Team ëª¨ë¸ ì§ì ‘ ì§€ì • ì¶”ë¡  (F1: 0.9652 ëª©í‘œ)
python src/inference/infer_main.py \
    --config configs/infer_highperf.yaml \
    --mode highperf \
    --fold-results experiments/train/lastest-train/fold_results.yaml

# 4) Team ëª¨ë¸ ìƒíƒœ í™•ì¸
ls -la experiments/train/lastest-train/
echo "fold_results.yaml ì¡´ì¬ ì—¬ë¶€ í™•ì¸ ì¤‘..."
```

### 3. í•™ìŠµì´ ì§„í–‰ë˜ì§€ ì•ŠìŒ

#### í•´ê²° ë°©ë²•
```bash
# 1) ë¡œê·¸ í™•ì¸
tail -20 logs/$(date +%Y%m%d)/train/*.log

# 2) ë°ì´í„° ê²½ë¡œ í™•ì¸
ls -la data/raw/train/ | head -5
ls -la data/raw/test/ | head -5

# 3) í™˜ê²½ ì¬ì„¤ì •
eval "$(pyenv init --path)" && pyenv activate cv_py3_11_9
pip install -r requirements.txt
```

### 4. ì„¤ì • íŒŒì¼ ì˜¤ë¥˜

#### í•´ê²° ë°©ë²•
```bash
# 1) YAML ë¬¸ë²• í™•ì¸
python -c "import yaml; yaml.safe_load(open('configs/train.yaml'))"

# 2) ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ ì´ˆê¸°í™”
cp configs/train.yaml.backup configs/train.yaml  # ë°±ì—…ì´ ìˆëŠ” ê²½ìš°

# 3) ì„¤ì • ë‚ ì§œ ì—…ë°ì´íŠ¸
python src/utils/config/update_config_dates.py
```

## ï¿½ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸ ë¬¸ì œ

### Python ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ì˜¤ë¥˜

#### ë¬¸ì œ: ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì§ì ‘ ì‹¤í–‰í•˜ë ¤ í•  ë•Œ ì˜¤ë¥˜ ë°œìƒ
```bash
# âŒ ì˜ëª»ëœ ì‹¤í–‰ ë°©ë²•
src/utils/gpu_optimization/auto_batch_size.py --config configs/train.yaml

# âœ… ì˜¬ë°”ë¥¸ ì‹¤í–‰ ë°©ë²•
python src/utils/gpu_optimization/auto_batch_size.py --config configs/train.yaml
```

#### í•´ê²° ë°©ë²•
```bash
# 1) Python ì¸í„°í”„ë¦¬í„°ë¡œ ì‹¤í–‰
python src/utils/gpu_optimization/auto_batch_size.py --config configs/train_highperf.yaml
python src/utils/gpu_optimization/team_gpu_check.py

# 2) ì‹¤í–‰ ê¶Œí•œ í™•ì¸ ë° ì„¤ì • (ì„ íƒì‚¬í•­)
chmod +x src/utils/**/*.py

# 3) shebang ì¶”ê°€ (ìŠ¤í¬ë¦½íŠ¸ ë§¨ ìœ„ì—)
#!/usr/bin/env python3
```

### ë¡œê·¸ íŒŒì¼ ì €ì¥ ìœ„ì¹˜ ë¬¸ì œ

#### ë¬¸ì œ: ì¶”ë¡  ë¡œê·¸ê°€ ì˜ˆìƒê³¼ ë‹¤ë¥¸ ìœ„ì¹˜ì— ì €ì¥ë¨
```bash
# ì‹¤ì œ ì €ì¥ ìœ„ì¹˜: logs/infer/
# ì˜ˆìƒ ìœ„ì¹˜: logs/YYYYMMDD/infer/
```

#### í˜„ì¬ ìƒí™©
```bash
# ì¶”ë¡  ë¡œê·¸ ì‹¤ì œ ì €ì¥ ìœ„ì¹˜
ls -la logs/infer/
# ì¶œë ¥: infer_YYYYMMDD-HHMM_modelname-inference.log

# í•™ìŠµ ë¡œê·¸ëŠ” ë‚ ì§œë³„ í´ë”ì— ì €ì¥
ls -la logs/YYYYMMDD/train/
```

#### ì„ì‹œ í•´ê²° ë°©ë²•
```bash
# 1) í˜„ì¬ ì¶”ë¡  ë¡œê·¸ í™•ì¸
tail -20 logs/infer/*.log

# 2) ìµœì‹  ì¶”ë¡  ë¡œê·¸ ì°¾ê¸°
ls -t logs/infer/*.log | head -1

# 3) ìˆ˜ë™ìœ¼ë¡œ ë‚ ì§œë³„ í´ë”ë¡œ ì´ë™ (ì„ íƒì‚¬í•­)
mkdir -p logs/$(date +%Y%m%d)/infer/
mv logs/infer/*.log logs/$(date +%Y%m%d)/infer/
```

## ï¿½ğŸ“Š ì„±ëŠ¥ ë¬¸ì œ

### ì„±ëŠ¥ì´ ì˜ˆìƒë³´ë‹¤ ë‚®ì„ ë•Œ

#### í•´ê²° ë°©ë²•
```bash
# 1) ë°ì´í„° ê²€ì¦
python -c "
import pandas as pd
df = pd.read_csv('data/raw/train.csv')
print(f'ë°ì´í„° í¬ê¸°: {len(df)}')
print(f'í´ë˜ìŠ¤ ë¶„í¬:\n{df.iloc[:, 1].value_counts()}')
"

# 2) í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”
python src/training/train_main.py \
    --config configs/train.yaml \
    --optimize \
    --n-trials 10

# 3) ê²€ì¦ëœ ì„¤ì • ì‚¬ìš©
python src/training/train_main.py --config configs/train.yaml --mode basic
```

### í•™ìŠµì´ ë„ˆë¬´ ëŠë¦´ ë•Œ

#### í•´ê²° ë°©ë²•
```bash
# 1) GPU ì„±ëŠ¥ í™•ì¸
python src/utils/gpu_optimization/team_gpu_check.py

# 2) ë°°ì¹˜ í¬ê¸° ìµœì í™”
python src/utils/gpu_optimization/auto_batch_size.py --config configs/train.yaml

# 3) ë¹ ë¥¸ ì„¤ì • ì‚¬ìš©
python src/training/train_main.py --config configs/train_fast.yaml --mode basic
```

## ğŸ”§ í™˜ê²½ ë¬¸ì œ

### Python í™˜ê²½ ë¬¸ì œ

#### í•´ê²° ë°©ë²•
```bash
# 1) Python ë²„ì „ í™•ì¸
python3 --version  # 3.11.9 í•„ìš”

# 2) ê°€ìƒí™˜ê²½ ì¬ì„¤ì •
pyenv deactivate
pyenv activate cv_py3_11_9

# 3) ì˜ì¡´ì„± ì¬ì„¤ì¹˜
pip install -r requirements.txt --force-reinstall
```

### CUDA í™˜ê²½ ë¬¸ì œ

#### í•´ê²° ë°©ë²•
```bash
# 1) CUDA ë²„ì „ í™•ì¸
nvidia-smi
nvcc --version

# 2) PyTorch CUDA í˜¸í™˜ì„± í™•ì¸
python -c "
import torch
print(f'PyTorch: {torch.__version__}')
print(f'CUDA available: {torch.cuda.is_available()}')
print(f'CUDA version: {torch.version.cuda}')
"

# 3) PyTorch ì¬ì„¤ì¹˜ (í•„ìš”ì‹œ)
pip uninstall torch torchvision
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121
```

## ğŸ“‹ ë¡œê·¸ ë¶„ì„

### ë¡œê·¸ íŒŒì¼ ìœ„ì¹˜
```bash
# ìµœì‹  ë¡œê·¸ í™•ì¸
ls -la logs/$(date +%Y%m%d)/

# í•™ìŠµ ë¡œê·¸
tail -f logs/$(date +%Y%m%d)/train/*.log

# ì¶”ë¡  ë¡œê·¸
tail -f logs/$(date +%Y%m%d)/infer/*.log
```

### ì˜¤ë¥˜ íŒ¨í„´ ì°¾ê¸°
```bash
# GPU ë©”ëª¨ë¦¬ ì˜¤ë¥˜
grep -i "out of memory\|cuda\|memory" logs/$(date +%Y%m%d)/*/*.log

# íŒŒì¼ ê²½ë¡œ ì˜¤ë¥˜
grep -i "not found\|no such file" logs/$(date +%Y%m%d)/*/*.log

# ì„±ëŠ¥ ì§€í‘œ
grep -i "f1\|accuracy\|loss" logs/$(date +%Y%m%d)/*/*.log
```

## ğŸ†˜ ê¸´ê¸‰ ë³µêµ¬

### ëª¨ë“  ê²ƒì´ ì‘ë™í•˜ì§€ ì•Šì„ ë•Œ
```bash
# 1) ê¸°ë³¸ í…ŒìŠ¤íŠ¸
python -c "
import torch, pandas, numpy
print('âœ… ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì •ìƒ')
print(f'GPU: {torch.cuda.is_available()}')
"

# 2) ìµœì†Œ ì„¤ì •ìœ¼ë¡œ í…ŒìŠ¤íŠ¸
python src/training/train_main.py --config configs/train.yaml --mode basic --epochs 1

# 3) ì „ì²´ í™˜ê²½ ì¬êµ¬ì„±
# (í•„ìš”ì‹œ README.mdì˜ í™˜ê²½ ì„¤ì • ì„¹ì…˜ ì°¸ì¡°)
```
