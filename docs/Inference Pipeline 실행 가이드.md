# ğŸ“˜ Inference Pipeline ì‹¤í–‰ ê°€ì´ë“œ

## 1) ì‹¤í–‰ ëª…ë ¹ì–´

```bash
python -m src.inference.infer_main --config configs/infer.yaml
```

**ë¬´ìŠ¨ ëœ»?**

- `m src.inference.infer_main` â†’ `src/inference/infer_main.py`ë¥¼ **ì—”íŠ¸ë¦¬í¬ì¸íŠ¸**ë¡œ ì‹¤í–‰
- `-config configs/infer.yaml` â†’ ì¶”ë¡ ìš© **ì„¤ì • íŒŒì¼** ì§€ì •

> âš™ï¸ í™˜ê²½ ë³€ìˆ˜(í•„ìš” ì‹œ)
> 
> 
> ```bash
> export PYTHONPATH="$(pwd):$PYTHONPATH"
> ```
> 

---

## 2) í™˜ê²½ ìš”êµ¬ì‚¬í•­ & ì„¤ì¹˜(ğŸ§°)

- Python â‰¥ 3.9 ê¶Œì¥
- í•µì‹¬ íŒ¨í‚¤ì§€: `torch`, `timm`, `albumentations`, `opencv-python`, `pandas`, `numpy`, `tqdm`, `Pillow`, `torchvision`
- ì„¤ì¹˜ ì˜ˆì‹œ
    
    ```bash
    pip install -r requirements.txt
    ```
    
- NVIDIA GPU ì‚¬ìš© ì‹œ: CUDA ëŸ°íƒ€ì„/ë“œë¼ì´ë²„ ë²„ì „ê³¼ ì„¤ì¹˜ëœ PyTorch CUDA ë¹Œë“œê°€ **í˜¸í™˜**ë˜ì–´ì•¼ í•¨

---

## 3) ì‹¤í–‰ ì „ ì²´í¬ë¦¬ìŠ¤íŠ¸(ğŸ§±)

- ğŸ—‚ï¸ **ë°ì´í„°**
    - `data/raw/sample_submission.csv` (í•„ìˆ˜ ì»¬ëŸ¼: `ID`)
    - `data/raw/test/` (í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€)
- ğŸ”¤ **í™•ì¥ì ì²˜ë¦¬**
    - CSV `ID`ì— í™•ì¥ìê°€ **ìˆì–´ë„/ì—†ì–´ë„** OK
    - ì—†ìœ¼ë©´ `data.image_ext`(ì˜ˆ: `.jpg`) â†’ ê·¸ë˜ë„ ì—†ìœ¼ë©´ `[".jpg",".jpeg",".png", ëŒ€/ì†Œë¬¸ì]` **Fallback**
- ğŸ“ **ë””ë ‰í† ë¦¬**
    - `logs/`, `submissions/` ë“± **ë¶€ëª¨ í´ë” ìë™ ìƒì„±**
- ğŸ§ª **ì²´í¬í¬ì¸íŠ¸**
    - `-ckpt` ë¯¸ì§€ì • ì‹œ: `experiments/<YYYYMMDD>/<run_name>/ckpt/best_fold0.pth` **ìë™ íƒìƒ‰**
- ğŸ§¬ **ì¼ê´€ì„±**
    - ê²€ì¦/ì¶”ë¡  ë³€í™˜ì€ `build_valid_tfms(img_size)` â†’ **í•™ìŠµì˜ img_sizeì™€ ë™ì¼**í•´ì•¼ í•¨

---

## 4) ì‹¤í–‰ ì»¤ë§¨ë“œ & ì˜µì…˜ (CLI)

```bash
# ê¸°ë³¸
python -m src.inference.infer_main --config configs/infer.yaml

# ckpt/out ëª…ì‹œ
python -m src.inference.infer_main \
  --config configs/infer.yaml \
  --ckpt experiments/20250904/v087-8c206e/ckpt/best_fold0.pth \
  --out  submissions/20250904/infer.csv
```

**ì˜µì…˜ ìš°ì„ ìˆœìœ„(ğŸ”½ ë†’ì€ â†’ ë‚®ì€)**

1. CLI `-ckpt` / `-out`
2. YAML `ckpt.path` / `inference.out_csv`
3. ìë™ ê·œì¹™ ê²½ë¡œ(ckpt): `experiments/<ë‚ ì§œ>/<run_name>/ckpt/best_fold0.pth`

**ì¢…ë£Œ ì½”ë“œ**: ì •ìƒ `0` / ì‚¬ìš©ì ì¤‘ë‹¨ `130` / ì˜ˆì™¸ `1`

---

## 5) ì„¤ì • íŒŒì¼ ë§µí•‘ (ì˜ˆ: `configs/infer.yaml`)

```yaml
project: { run_name, device, num_workers, date_format, time_format }
data:    { sample_csv, image_dir_test, image_ext, id_col, target_col, num_classes }
model:   { name, pretrained, drop_rate, drop_path_rate, pooling }
inference: { tta, tta_rot_degrees, out_csv }
ckpt:    { path }
output:  { logs_dir, exp_dir, snapshots }
```

**í•µì‹¬ í¬ì¸íŠ¸**

- `data.sample_csv`ì—ì„œ **IDë¥¼ ì½ì–´** ì¶”ë¡  ëŒ€ìƒ ê²°ì •
- `dataset`ì´ **í™•ì¥ì Fallback** ì§€ì›
- `model.pooling`ì€ ìœ íš¨ ê°’ë§Œ í—ˆìš©(ì˜ëª»ë˜ë©´ `avg` ê°•ì œ), `num_classes>0` + `pooling=None` **ê¸ˆì§€**
- `inference.tta=true`ì´ë©´ `tta_rot_degrees` ê°ë„ë³„ **softmax í™•ë¥  í‰ê· **

> ğŸ“Œ ê²½ë¡œëŠ” config íŒŒì¼ ê¸°ì¤€ ìƒëŒ€ê²½ë¡œ ì‚¬ìš© ê¶Œì¥
> 
> 
> (ì˜ˆ: `configs/infer.yaml` ê¸°ì¤€ `../data/raw/test` â†’ ë ˆí¬ ë£¨íŠ¸ `data/raw/test`)
> 

---

## 6) ë‚´ë¶€ íë¦„(ëª¨ë“ˆ & í˜¸ì¶œ ìˆœì„œ)

### (1) ì—”íŠ¸ë¦¬í¬ì¸íŠ¸: `src/inference/infer_main.py`

1. `argparse`: `-config/--ckpt/--out`
2. `run_inference(config, out, ckpt)` í˜¸ì¶œ
3. ì¢…ë£Œ ì½”ë“œ ì¶œë ¥

### (2) íŒŒì´í”„ë¼ì¸: `src/inference/infer.py â†’ run_inference(...)`

1. **Config ë¡œë“œ** & **Logger ì‹œì‘**(í‘œì¤€ ì¶œë ¥ ë¦¬ë””ë ‰íŠ¸, íŒŒì¼ ë¡œê·¸ ê¸°ë¡)
2. **ê²½ë¡œ ê²€ì¦**: `require_file(sample_csv)`, `require_dir(image_dir_test)`
3. **CSV ë¡œë“œ**: `ID` ëª©ë¡ í™•ë³´
4. **Dataset/DataLoader**: `DocClsDataset` + `build_valid_tfms(img_size)`
5. **ëª¨ë¸ ë¹Œë“œ**: `build_model(name, num_classes, pretrained, drop_rate, drop_path_rate, pooling)` â†’ `.eval()`
6. **ckpt ë¡œë“œ**: CLI > YAML > ìë™ ê·œì¹™ ê²½ë¡œ
7. **TTA ì¶”ë¡ **: ê° `deg` â†’ `_rotate_tensor` â†’ `softmax` â†’ **í™•ë¥  í‰ê· **
8. **CSV ì €ì¥**: `ID,target` (ë¶€ëª¨ í´ë” ìë™ ìƒì„±)
9. **ì¢…ë£Œ ë¡œê·¸**: ì„±ê³µ/ì‹¤íŒ¨/ì¤‘ë‹¨ ì½”ë“œ ë° ë§ˆì»¤

---

## 7) íŒŒì¼ ê°„ ê´€ê³„(ì˜ì¡´ ë‹¤ì´ì–´ê·¸ë¨)

```mermaid
flowchart TD
A[infer_main.py] -->|run_inference| B[infer.py]
B -->|config/log/path utils| C[utils/common.py]
B -->|Logger| J[utils/logger.py]
B -->|Dataset| D[data/dataset.py]
B -->|Transforms| E[data/transforms.py]
B -->|Model| F[models/build.py]
D -->|read images| K[data/raw/test/*]
B -->|read IDs| L[data/raw/sample_submission.csv]
B -->|write| M[submissions/<YYYYMMDD>/infer.csv]
B -->|load| N[experiments/<YYYYMMDD>/<run_name>/ckpt/*.pth]

```

---

## 8) ê²°ê³¼ë¬¼ & ë””ë ‰í† ë¦¬ êµ¬ì¡°(ğŸ§ª)

```
submissions/
â””â”€â”€ 20250904/
    â””â”€â”€ infer.csv
logs/
â””â”€â”€ infer/
    â””â”€â”€ infer_<run_name>.log
```

**CSV ìŠ¤í‚¤ë§ˆ**

```
ID,target
0001,3
0002,7
...
```

- `ID`: sample CSV ê·¸ëŒ€ë¡œ
- `target`: ì˜ˆì¸¡ í´ë˜ìŠ¤(0 ~ num_classes-1)

---

## 9) TTA ì„¤ê³„(ğŸ§­)

- `inference.tta: true` â†’ `tta_rot_degrees`(ì˜ˆ: `[0, -3, 3]`) ìˆœíšŒ
- ê°ë„ë³„ **ëª¨ë¸ ì¶”ë¡ ** â†’ `softmax` í™•ë¥  **ëˆ„ì /í‰ê· ** â†’ `argmax`
- ğŸ“Œ ë¬¸ì„œ ì´ë¯¸ì§€ íŠ¹ì„±ìƒ **ì†Œê°(Â±3~6ë„)**ë¶€í„° ì ì¦ ê¶Œì¥
    
    90Â° ë‹¨ìœ„ ê°•íšŒì „ì€ í…ìŠ¤íŠ¸ ë°©í–¥ì„±ì— ë¯¼ê°(ì„±ëŠ¥ ì €í•˜ ê°€ëŠ¥)
    

---

## 10) ì„±ëŠ¥/ë¦¬ì†ŒìŠ¤ íŠœë‹(âš¡)

- **DataLoader**
    - `project.num_workers`: ë””ìŠ¤í¬Â·CPU ìƒí™©ì— ë§ê²Œ ì¡°ì •(ë³‘ëª© ì‹œ ê³¼ë„ ì¦ê°€ëŠ” ì—­íš¨ê³¼)
    - `pin_memory=True` ìœ ì§€, í° ë°°ì¹˜ê°€ ê°€ëŠ¥í•˜ë©´ **ì¶”ë¡  ì „ìš© ë°°ì¹˜ í¬ê¸° í‚¤**ë¥¼ ë„ì…í•´ ì†ë„ â†‘
- **ì…ë ¥ í¬ê¸°**
    - í•™ìŠµ/ê²€ì¦/ì¶”ë¡  `img_size` ì¼ì¹˜ê°€ **ì •ë‹µ**
    - ì œì¶œ ì§ì „ì—ëŠ” `img_size` ë‹¤ìš´ìŠ¤ì¼€ì¼ë¡œ ì†ë„-ì •í™•ë„ íŠ¸ë ˆì´ë“œì˜¤í”„ í‰ê°€
- **I/O ìµœì í™”**
    - ì´ë¯¸ì§€ê°€ ëŒ€ìš©ëŸ‰ì´ë©´ **ì´ë¯¸ì§€ ìºì‹œ**(e.g., LMDB) ê²€í† 
    - ë„¤íŠ¸ì›Œí¬ ìŠ¤í† ë¦¬ì§€ ì‚¬ìš© ì‹œ Prefetch/ë¡œì»¬ ìºì‹œ
- **ë½/ë©”ëª¨ë¦¬**
    - OOM ë°œìƒ ì‹œ: ë°°ì¹˜ ì¶•ì†Œ, `num_workers` ì¶•ì†Œ, ë¶ˆí•„ìš”í•œ í…ì„œ ì¦‰ì‹œ `del` ë° `torch.cuda.empty_cache()` ì£¼ê¸°ì  í˜¸ì¶œ(í•„ìš” ì‹œ)

---

## 11) ë¡œê·¸ ë¶„ì„ íŒ(ğŸ”)

- â­ ì‹œì‘/ê²½ë¡œ/ì„¤ì •:
    - `[PATH] OK ...` : CSV/ì´ë¯¸ì§€ ê²½ë¡œ ê²€ì¦ í†µê³¼
    - `[DATA] test size=...` : ìƒ˜í”Œ ìˆ˜ í™•ì¸
    - `[CKPT] loaded: ...` : ê°€ì¤‘ì¹˜ ì •ìƒ ë¡œë“œ
- âœ… ì²´í¬í¬ì¸íŠ¸:
    - `[CKPT] loaded: .../best_fold0.pth` : ìµœê³  ì„±ëŠ¥ ì²´í¬í¬ì¸íŠ¸
- ğŸ” ì§„í–‰ë¥ :
    - `[INFER] step i/total processed` : ëŒ€ëµì ì¸ ë‚¨ì€ ì‹œê°„ ê°
- ğŸ ê²°ê³¼/ì¢…ë£Œ:
    - `[OUT] submission saved: ... | shape=(N, 2)`
    - `[EXIT] INFERENCE SUCCESS code=0`

**ë¹ ë¥¸ ì¶”ì¶œ ì˜ˆì‹œ**

```bash
# ê°€ì¥ ì¤‘ìš”í•œ ë¼ì¸ë§Œ ì¶”ì¶œ
grep -E "^\[PATH\]|\[CKPT\]|\[OUT\]|\[EXIT\]" logs/infer/infer_*.log
```

---

## 12) ì—ëŸ¬ í”Œë¡œìš°(ğŸ§¯)

```mermaid
flowchart TD
start([Start]) --> c1{sample_csv exists}
c1 -- yes --> c2{image_dir_test exists}
c1 -- no  --> x1[FileNotFoundError sample_csv] --> end1(((End)))

c2 -- no  --> x2[FileNotFoundError image_dir_test] --> end2(((End)))
c2 -- yes --> m1[build_model pooling]

m1 --> d1{pooling valid}
d1 -- no  --> x3[ValueError invalid pooling set to avg] --> ck[load ckpt --ckpt > yaml > auto]
d1 -- yes --> ck[load ckpt --ckpt > yaml > auto]

ck --> d2{shape mismatch}
d2 -- yes --> x4[RuntimeError state_dict] --> end3(((End)))
d2 -- no  --> tta[TTA infer + softmax mean] --> save[save CSV] --> end4(((End)))

```

---

## 14) TTA ê°ë„ ì‹¤í—˜

```yaml
# configs/infer.yaml
inference:
  tta: true
  tta_rot_degrees: [0, -3, 3, 6]
```

> ê³¼ë„í•œ ê°ë„ëŠ” ì†ë„/ì„±ëŠ¥ ëª¨ë‘ ì•…ì˜í–¥ ê°€ëŠ¥ â†’ ì†Œê°ë¶€í„° ì ì¦
> 

---

## 15) FAQ(â“)

- **Q. `-ckpt` ì—†ì´ë„ ë˜ë‚˜ìš”?**
    
    A. ë„¤. YAMLì˜ `ckpt.path` ë˜ëŠ” ìë™ ê·œì¹™ ê²½ë¡œë¥¼ ìˆœì°¨ì ìœ¼ë¡œ íƒìƒ‰í•©ë‹ˆë‹¤. ì—†ìœ¼ë©´ ì—ëŸ¬.
    
- **Q. `ID`ì— í™•ì¥ìê°€ ì„ì—¬ ìˆì–´ë„?**
    
    A. ë„¤. ì´ë¯¸ í™•ì¥ìê°€ ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©, ì—†ìœ¼ë©´ ê¸°ë³¸ í™•ì¥ì â†’ Fallback ìˆœìœ¼ë¡œ íƒìƒ‰í•©ë‹ˆë‹¤.
    
- **Q. í´ë˜ìŠ¤ ê°œìˆ˜ê°€ ë‹¤ë¥¸ ckpt ë¡œë”© ì—ëŸ¬?**
    
    A. `model.num_classes/pooling/ë°±ë³¸`ì´ í•™ìŠµ ë‹¹ì‹œ ì„¤ì •ê³¼ ì¼ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤.
    
- **Q. ì¶”ë¡  ë°°ì¹˜ í¬ê¸° ì–´ë””ì„œ ë°”ê¾¸ë‚˜ìš”?**
    
    A. í˜„ì¬ í•™ìŠµ ì„¤ì •(`train.batch_size`)ì„ ì¬ì‚¬ìš©í•©ë‹ˆë‹¤. ì¶”ë¡  ì „ìš© í‚¤ë¥¼ YAMLì— ì¶”ê°€í•´ ì˜¤ë²„ë¼ì´ë“œí•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤.
    

---

## 16) í…ŒìŠ¤íŠ¸ ì „/ì œì¶œ ì „ ìµœì¢… ì²´í¬(âœ…)

- [ ]  `sample_csv` **ì¡´ì¬** & `ID` ì»¬ëŸ¼ í™•ì¸
- [ ]  `image_dir_test` **ì¡´ì¬** & ì‹¤ì œ ì´ë¯¸ì§€ íŒŒì¼ í™•ì¸
- [ ]  í™•ì¥ì/ëŒ€ì†Œë¬¸ì(Fallback) ë™ì‘ ì´í•´
- [ ]  `model.name/num_classes/pooling`ì´ ckptì™€ **ì¼ì¹˜**
- [ ]  `img_size`(í•™ìŠµ/ê²€ì¦/ì¶”ë¡ ) **ì¼ì¹˜**
- [ ]  `-out` ë˜ëŠ” `inference.out_csv` ê²½ë¡œ **ì“°ê¸° ê¶Œí•œ**
- [ ]  ì œì¶œ ìŠ¤í‚¤ë§ˆ `ID,target` + í—¤ë” + `index=False`

---

## 17) íŠ¸ëŸ¬ë¸”ìŠˆíŒ…(ì¦ìƒ â†’ ì¡°ì¹˜)

- âŒ `FileNotFoundError: ...sample_submission.csv`
    
    â†’ `configs/infer.yaml`ì—ì„œ **config ê¸°ì¤€ ìƒëŒ€ê²½ë¡œ** í™•ì¸, ì² ì/ëŒ€ì†Œë¬¸ì ì ê²€
    
- âŒ `FileNotFoundError: .../test`
    
    â†’ í…ŒìŠ¤íŠ¸ í´ë”/ì´ë¯¸ì§€ ì‹¤ì¡´ ì—¬ë¶€ í™•ì¸
    
- âŒ ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨
    
    â†’ í™•ì¥ì/ëŒ€ì†Œë¬¸ì ë¶ˆì¼ì¹˜. í´ë”ì— íŒŒì¼ ìì²´ê°€ ì—†ìœ¼ë©´ Fallbackë„ ì‹¤íŒ¨
    
- âŒ `RuntimeError: state_dict`
    
    â†’ ckptì™€ ëª¨ë¸ êµ¬ì¡° ë¶ˆì¼ì¹˜. `name/num_classes/pooling` ì¬í™•ì¸
    
- âŒ `ValueError: pooling(None) + num_classes>0`
    
    â†’ `pooling: "avg"`ë¡œ ìˆ˜ì •
    

---

### ë¶€ë¡) ë¡œê·¸ ì˜ˆì‹œ(ìš”ì•½)

```
[BOOT] inference pipeline started
[PATH] OK | sample_csv=... | image_dir_test=...
[CFG] data=..., model=..., inference=...
[CKPT] loaded: .../best_fold0.pth
[TTA] enabled=True degs=[0, -3, 3]
[INFER] >>> start
[INFER] step 20/XXX processed
[OUT] submission saved: submissions/20250904/infer.csv | shape=(N, 2)
[INFER] <<< finished successfully
[EXIT] INFERENCE SUCCESS code=0
```