# ğŸ“˜ Training Pipeline ì‹¤í–‰ ê°€ì´ë“œ (ğŸš€ í†µí•© CLI ë²„ì „)

## ğŸ“‹ ì‚¬ì „ ì¤€ë¹„ (í•„ìˆ˜)

### ğŸ”§ í™˜ê²½ ì„¤ì • ë° GPU ìµœì í™”
```bash
# 1. pyenv ê°€ìƒí™˜ê²½ í™œì„±í™”
pyenv activate cv_py3_11_9

# 2. í†µí•© ëª¨ë“ˆ import í…ŒìŠ¤íŠ¸
python -c "
from src.optimization.optuna_tuner import OptunaTuner
from src.calibration.temperature_scaling import TemperatureScaling
print('âœ… ëª¨ë“  ëª¨ë“ˆ ì •ìƒ')
"
```

### ğŸ“ ìƒˆë¡œìš´ ë‚ ì§œë³„ ë¡œê·¸ êµ¬ì¡°
ì´ì œ ëª¨ë“  ë¡œê·¸ê°€ ë‚ ì§œë³„ë¡œ ì²´ê³„ì ìœ¼ë¡œ ê´€ë¦¬ë©ë‹ˆë‹¤:
```
logs/
â””â”€â”€ YYYYMMDD/  (ì˜ˆ: 20250907)
    â”œâ”€â”€ train/         # í•™ìŠµ ë¡œê·¸
    â”œâ”€â”€ infer/         # ì¶”ë¡  ë¡œê·¸  
    â”œâ”€â”€ optimization/  # ìµœì í™” ë¡œê·¸
    â””â”€â”€ pipeline/      # íŒŒì´í”„ë¼ì¸ ë¡œê·¸
```

## 1) ğŸš€ í†µí•© CLI ì‹¤í–‰ ëª…ë ¹ì–´

### ğŸ† ìµœê³  ì„±ëŠ¥ ëª¨ë“œ (ê¶Œì¥ - F1 ~0.940+ ëª©í‘œ)
```bash
# í™˜ê²½ í™œì„±í™”
pyenv activate cv_py3_11_9

# ì™„ì „ ìµœì í™” íŒŒì´í”„ë¼ì¸ (Optuna + Calibration)
python src/training/train_main.py \
    --config configs/train_highperf.yaml \
    --optimize \
    --n-trials 20 \
    --use-calibration \
    --mode full-pipeline \
    --auto-continue
```

### âš¡ ë¹ ë¥¸ ì‹¤í—˜ ëª¨ë“œ (20-30ë¶„, ê²½ì§„ëŒ€íšŒìš©)
```bash
# ë¹ ë¥¸ í”„ë¡œí† íƒ€ì´í•‘ ë° ì•„ì´ë””ì–´ ê²€ì¦ìš©
python src/training/train_main.py \
    --config configs/train_fast_optimized.yaml \
    --optimize \
    --optuna-config configs/optuna_fast_config.yaml \
    --n-trials 8 \
    --mode full-pipeline \
    --auto-continue
```

**ë¹ ë¥¸ ì‹¤í—˜ ëª¨ë“œ íŠ¹ì§•:**
- ğŸ•’ **ì‹¤í–‰ ì‹œê°„**: 20-30ë¶„
- ğŸ¯ **ëª©í‘œ ì„±ëŠ¥**: F1 ìŠ¤ì½”ì–´ 0.92+
- ğŸ”„ **ë°˜ë³µ ì‹¤í—˜**: ë¹ ë¥¸ ì•„ì´ë””ì–´ ê²€ì¦
- âš™ï¸ **ìµœì í™”**: 8íšŒ ì‹œë„ë¡œ íš¨ìœ¨ì  íƒìƒ‰

### ğŸ… ê³ ì„±ëŠ¥ ëª¨ë“œ (ì‚¬ì „ ìµœì í™” ì‚¬ìš©)
```bash
# ì‚¬ì „ ìµœì í™”ëœ ì„¤ì •ìœ¼ë¡œ ë¹ ë¥¸ ì‹¤í–‰
python src/training/train_main.py \
    --config configs/train_optimized_20250907_1825.yaml \
    --use-calibration \
    --mode full-pipeline
```

### ğŸ“š ê¸°ë³¸ ëª¨ë“œ (ê¸°ì¡´ ì„±ëŠ¥)
```bash
# ê¸°ë³¸ ì¦ê°• + ê¸°ë³¸ ëª¨ë¸
python src/training/train_main.py \
    --config configs/train.yaml \
    --mode basic
```

### ğŸ§ª ìµœì í™”ë§Œ ì‹¤í–‰ (ì‹¤í—˜ìš©)
```bash
# í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”ë§Œ ì‹¤í–‰
python src/training/train_main.py \
    --config configs/train_highperf.yaml \
    --optimize \
    --n-trials 30 \
    --mode highperf
```

**ğŸ¯ ìƒˆë¡œìš´ í†µí•© CLI ì˜µì…˜ ì„¤ëª…:**

- `--config`: ì„¤ì • íŒŒì¼ ê²½ë¡œ (í•„ìˆ˜)
- `--mode`: ì‹¤í–‰ ëª¨ë“œ (basic, highperf, full-pipeline)
- `--optimize`: Optuna í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ì‚¬ìš©
- `--n-trials`: ìµœì í™” ì‹œë„ íšŸìˆ˜ (ê¸°ë³¸: 20)
- `--use-calibration`: Temperature Scaling ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì ìš©
- `--auto-continue`: ìµœì í™” í›„ ìë™ìœ¼ë¡œ ì „ì²´ í•™ìŠµ ì§„í–‰
- `--skip-training`: í•™ìŠµ ê±´ë„ˆë›°ê³  ì¶”ë¡ ë§Œ ì‹¤í–‰

> ğŸ¯ **ì„±ëŠ¥ ë¹„êµ**
> - **ê¸°ë³¸ ëª¨ë“œ**: F1 ~0.89 (EfficientNet-B3 + ê¸°ë³¸ ì¦ê°•)
> - **ê³ ì„±ëŠ¥ ëª¨ë“œ**: F1 ~0.934 (Swin Transformer + ê³ ê¸‰ ì¦ê°•)
> - **ìµœì í™” ëª¨ë“œ**: F1 ~0.940+ (Optuna + Temperature Scaling)

## 2) ê³ ê¸‰ ê¸°ëŠ¥

### ğŸ” Optuna í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”
```bash
# Optuna ìµœì í™” ì „ìš© ì‹¤í–‰ (ìµœì í™”ë§Œ)
python src/training/train_main.py \
    --config configs/train_highperf.yaml \
    --optimize \
    --n-trials 50 \
    --skip-training

# ìµœì í™” + ìë™ í•™ìŠµ ì§„í–‰
python src/training/train_main.py \
    --config configs/train_highperf.yaml \
    --optimize \
    --n-trials 30 \
    --auto-continue
```

### ğŸŒ¡ï¸ Temperature Scaling ìº˜ë¦¬ë¸Œë ˆì´ì…˜
```bash
# ìº˜ë¦¬ë¸Œë ˆì´ì…˜ë§Œ ì ìš©
python src/training/train_main.py \
    --config configs/train_optimized_20250907_1825.yaml \
    --use-calibration \
    --mode full-pipeline

# ìµœì í™” + ìº˜ë¦¬ë¸Œë ˆì´ì…˜ í†µí•©
python src/training/train_main.py \
    --config configs/train_highperf.yaml \
    --optimize \
    --n-trials 20 \
    --use-calibration \
    --auto-continue
```

### ğŸ“Š ì‹¤ì‹œê°„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
```bash
# WandB ëŒ€ì‹œë³´ë“œ í™•ì¸
wandb dashboard

# ë¡œê·¸ ì‹¤ì‹œê°„ í™•ì¸
tail -f logs/$(date +%Y%m%d)/train/train_*.log
```

---

## 3) ì‹¤í–‰ ì „ ì²´í¬ë¦¬ìŠ¤íŠ¸

- ğŸ—‚ï¸ **ë°ì´í„° ë°°ì¹˜**
    - `data/raw/train.csv` : í•™ìŠµ ë©”íƒ€ (í•„ìˆ˜ ì»¬ëŸ¼: `ID`, `target`)
    - `data/raw/sample_submission.csv` : ì œì¶œ í¬ë§· ì°¸ê³ ìš©
    - `data/raw/train/` : **í•™ìŠµ ì´ë¯¸ì§€ í´ë”**
    - `data/raw/test/` : (ì¶”ë¡ ìš© ì´ë¯¸ì§€ í´ë” â€” *í•™ìŠµ ê°€ì´ë“œì—ì„œëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠìŒ*)
- ğŸ”¤ **íŒŒì¼ëª…/í™•ì¥ì**
    - CSVì˜ `ID`ê°€ `abc123.jpg`ì²˜ëŸ¼ **í™•ì¥ìë¥¼ í¬í•¨**í•˜ë“ , `abc123`ì²˜ëŸ¼ **ì—†ë“ ** ëª¨ë‘ ì•ˆì „ ì²˜ë¦¬ë©ë‹ˆë‹¤. (`.jpg.jpg` ë°©ì§€)
- ğŸ§± **ë””ë ‰í† ë¦¬**
    - `logs/`, `experiments/` í´ë”ëŠ” ì‹¤í–‰ ì¤‘ **ìë™ ìƒì„±**ë©ë‹ˆë‹¤.
- ğŸ§¬ **ì¬í˜„ì„±**
    - ì‹œë“œ(`project.seed`) ê³ ì •, ì„¤ì • ìŠ¤ëƒ…ìƒ·(`experiments/.../config.yaml`) ì €ì¥ìœ¼ë¡œ **ì™„ì „ ì¬í˜„**ì„ ì§€ì›í•©ë‹ˆë‹¤.

---

## 3) ì‹¤í–‰ ì‹œ ë‚´ë¶€ íë¦„ (ëª¨ë“ˆ & í•¨ìˆ˜ í˜¸ì¶œ ìˆœì„œ)

### (1) ì—”íŠ¸ë¦¬í¬ì¸íŠ¸: `src/training/train_main.py`

1. ğŸ§­ `argparse`ë¡œ CLI ì¸ì íŒŒì‹± (`-config`)
2. ğŸš€ `run_training(config_path)` í˜¸ì¶œ
3. ğŸ ì¢…ë£Œ ìƒíƒœë¥¼ **ì½˜ì†”**ì— ì¶œë ¥
    - ì •ìƒ: `[EXIT] training finished successfully (see logs/* for details)`
    - ì—ëŸ¬: `[EXIT][ERROR] training failed: ...`

### (2) í•µì‹¬ íŒŒì´í”„ë¼ì¸: `src/training/train.py` â†’ `run_training(cfg_path)`

1. ğŸ“„ **Config ë¡œë“œ & í‘œì‹œ**
    - `load_yaml`ë¡œ YAML ë¡œë“œ â†’ `[CFG] ...` ì„¹ì…˜ ë¡œê·¸ ì¶œë ¥
    - ì˜ˆ: ëª¨ë¸/í•™ìŠµ/ë°ì´í„°/ì¶œë ¥ ê²½ë¡œ ë“± ì„¤ì •ê°’ì„ ì „ë¶€ ë¡œê·¸ì— ë‚¨ê¹€
2. ğŸ² **Seed ê³ ì •**
    - `set_seed` í˜¸ì¶œ â†’ PyTorch/NumPy/ëœë¤ ì‹œë“œ ê³ ì •
3. ğŸ“ **Logger ì‹œì‘ + í‘œì¤€ ì…Â·ì¶œë ¥ ë¦¬ë””ë ‰ì…˜**
    - `logs/YYYYMMDD/train/train_YYYYMMDD-HHMM_<run_id>_<augmentation_type>.log` ìƒì„±
    - ëª¨ë“  `print`/ì˜¤ë¥˜ê°€ **ë¡œê·¸ íŒŒì¼ì—ë„** ê¸°ë¡
    - ì‹œì‘: `>> Logger started: ...` / ì¢…ë£Œ: `>> Stopping logger and restoring stdio`
4. ğŸ“‚ **ê²½ë¡œ ê²€ì¦ & ë°ì´í„° ë¡œë“œ**
    - `require_file/require_dir`ë¡œ `train.csv`, `image_dir_train` ë“± **í•„ìˆ˜ ê²½ë¡œ í™•ì¸**
    - `[PATH] OK | train_csv=... | sample_csv=... | image_dir_train=...`
    - `pd.read_csv(train_csv)` â†’ í•„ìˆ˜ ì»¬ëŸ¼(`ID`, `target`) ì ê²€
5. ğŸ”€ **K-Fold ë¶„í• **
    - `StratifiedKFold(n_splits=folds)` ë˜ëŠ” ê¸°ì¡´ `fold` ì—´ ê²€ì¦
    - `[FOLD] distribution={0:..., 1:..., ...}` ë¡œ ë¶„ë°° ë¡œê·¸
6. ğŸ“¦ **ì•„í‹°íŒ©íŠ¸ ë””ë ‰í† ë¦¬ ìƒì„±**
    - `experiments/YYYYMMDD/<run_id>/` ìƒì„±
    - í¬í•¨:
        - `ckpt/` (ì²´í¬í¬ì¸íŠ¸)
        - `metrics.jsonl` (ì—í­ë³„ ì§€í‘œ: loss/F1/lr/ì‹œê°„/ë©”ëª¨ë¦¬)
        - `config.yaml` (ì‹¤í–‰ ìŠ¤ëƒ…ìƒ·)
    - `[ARTIFACTS] ...`ë¡œ ê²½ë¡œë¥¼ ëª…í™•íˆ ë¡œê¹…
7. ğŸ§° **ë°ì´í„°ë¡œë” & ëª¨ë¸ ë¹Œë“œ**
    - `DocClsDataset` + `DataLoader` êµ¬ì„± (`_build_loaders`)
    - `build_model`ë¡œ timm ê¸°ë°˜ ë°±ë³¸ ìƒì„± (`global_pool` ì •ì„ ë§¤í•‘)
    - `Adam/AdamW`, `CosineAnnealingLR` ë“± ì˜µí‹°ë§ˆ/ìŠ¤ì¼€ì¤„ëŸ¬ ì´ˆê¸°í™” ë¡œê·¸
8. ğŸ” **í•™ìŠµ/ê²€ì¦ ë£¨í”„**
    - `train_one_epoch` : ìŠ¤í…ë³„ loss, lr, ë©”ëª¨ë¦¬ ë“± ì´˜ì´˜ ë¡œê·¸
    - `validate` : `macro_f1`/loss ê³„ì‚°, ìš”ì•½ ë¡œê·¸
    - Best ê°±ì‹  ì‹œ `ckpt/best_fold{n}.pth` ì €ì¥ + `NEW_BEST` ë¡œê·¸
    - ê° ì—í­ ê²°ê³¼ëŠ” `metrics.jsonl`ì— **JSON Lines**ë¡œ ëˆ„ì 
9. ğŸ“š **ëª¨ë“œ ë¶„ê¸°**
    - `data.valid_fold: int` â†’ **ë‹¨ì¼ í´ë“œ í•™ìŠµ**
    - `data.valid_fold: "all"` â†’ **ì „ í´ë“œ ìˆœíšŒ(K-Fold í•™ìŠµ)**
        - OOF ê²°ê³¼(`oof_logits.npy`, `oof_targets.npy`) ì €ì¥
10. âœ… **ì¢…ë£Œ ë§ˆì»¤**
    - íŒŒì´í”„ë¼ì¸ ì •ìƒ ì¢…ë£Œ: `[BOOT] training pipeline finished successfully`
    - **í•­ìƒ ê¸°ë¡ë˜ëŠ” ìµœì¢… ë§ˆì»¤**:
        - ì •ìƒ: `[EXIT] TRAINING SUCCESS code=0`
        - ì—ëŸ¬: `[EXIT] TRAINING ERROR code=1` (Traceback í¬í•¨)

---

## 4) ê²°ê³¼ë¬¼ & ë””ë ‰í† ë¦¬ êµ¬ì¡°

### ğŸ§¾ ë¡œê·¸

- ìœ„ì¹˜: `logs/YYYYMMDD/train/train_YYYYMMDD-HHMM_<run_id>_<augmentation_type>.log`
- ì£¼ìš” íƒœê·¸:
    
    `[BOOT]`, `[CFG]`, `[PATH]`, `[DATA]`, `[MODEL]`, `[EPOCH]`, `NEW_BEST`, `[DONE]`, `[EXIT]`
    

### ğŸ§ª ì‹¤í—˜ ì•„í‹°íŒ©íŠ¸

- ìœ„ì¹˜: `experiments/YYYYMMDD/<run_id>/`
- ğŸ†• **Latest-train ìë™ ë³µì‚¬**: ëª¨ë“  í•™ìŠµ ê²°ê³¼ê°€ `experiments/train/latest-train/`ì—ë„ ìë™ ë³µì‚¬ë©ë‹ˆë‹¤!

```
experiments/
â”œâ”€â”€ train/                    # ë‚ ì§œë³„ í•™ìŠµ ê²°ê³¼
â”‚   â”œâ”€â”€ 20250907/
â”‚   â”‚   â””â”€â”€ swin-highperf_20250907_1825/
â”‚   â”œâ”€â”€ 20250908/
â”‚   â”‚   â””â”€â”€ efficientnet-basic_20250908_1030/
â”‚   â””â”€â”€ latest-train/         # ğŸ†• ìµœì‹  í•™ìŠµ ê²°ê³¼ ìë™ ë³µì‚¬
â”‚       â””â”€â”€ efficientnet-basic_20250908_1030/  # ë®ì–´ì“°ê¸° ë°©ì‹
â””â”€â”€ 20250904/                 # ê¸°ì¡´ í˜¸í™˜ì„± ìœ ì§€
    â””â”€â”€ v087-8c206e/
        â”œâ”€â”€ ckpt/
        â”‚   â”œâ”€â”€ best_fold0.pth
        â”‚   â”œâ”€â”€ best_fold1.pth
        â”‚   â”œâ”€â”€ best_fold2.pth
        â”‚   â”œâ”€â”€ best_fold3.pth
        â”‚   â””â”€â”€ best_fold4.pth
        â”œâ”€â”€ oof/
        â”‚   â”œâ”€â”€ oof_logits.npy
        â”‚   â””â”€â”€ oof_targets.npy
        â”œâ”€â”€ config.yaml
        â””â”€â”€ metrics.jsonl
```

**íŒŒì¼ ì„¤ëª…**

- `ckpt/best_fold*.pth` : í´ë“œë³„ **ìµœê³  ì„±ëŠ¥** ì‹œì ì˜ ê°€ì¤‘ì¹˜
- `metrics.jsonl` : ê° ì—í­ì˜ `train_loss`, `valid_loss`, `macro_f1`, `lr`, `time_s`, `mem_MiB` ê¸°ë¡
- `config.yaml` : ì‹¤í–‰ ë‹¹ì‹œ ì„¤ì • ìŠ¤ëƒ…ìƒ· (ì¬í˜„ì„±)
- `oof/*.npy` : ì „ í´ë“œ OOF ê²€ì¦ ê²°ê³¼(ì„ íƒ ì €ì¥)

---

## 5) íŒŒì¼ ê°„ ê´€ê³„(ì˜ì¡´ ë‹¤ì´ì–´ê·¸ë¨)

```mermaid
flowchart TD

subgraph "ğŸ› ï¸ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸"
    S1[scripts/run_fast_training.sh]
    S2[scripts/run_highperf_training.sh]
    S3[scripts/monitor_training.sh]
end

subgraph "âš™ï¸ ì„¤ì • íŒŒì¼"
    C1[configs/train_fast_optimized.yaml]
    C2[configs/train_highperf.yaml]
    C3[configs/optuna_fast_config.yaml]
    C4[configs/optuna_config.yaml]
end

subgraph "ğŸš€ í•™ìŠµ ì—”ì§„"
    A[train_main.py] -->|run_training| B[train.py]
    B -->|optuna ìµœì í™”| O1[optimization/optuna_tuner.py]
    B -->|calibration| O2[calibration/temperature_scaling.py]
end

subgraph "ğŸ”§ ìœ í‹¸ë¦¬í‹°"
    B -->|config load| C[utils/common.py]
    B -->|set_seed| D[utils/seed.py]
    B -->|Logger| E[utils/logger.py]
    C -->|create_log_path| L1[logs/YYYYMMDD/train/]
end

subgraph "ğŸ“Š ë°ì´í„° ì²˜ë¦¬"
    B -->|Dataset| F[data/dataset.py]
    B -->|Transforms| G[data/transforms.py]
    F -->|load images| F1[data/raw/train/]
    F -->|load labels| F2[data/raw/train.csv]
end

subgraph "ğŸ§  ëª¨ë¸ ê´€ë¦¬"
    B -->|Model build| H[models/build.py]
    B -->|Metrics| I[metrics/f1.py]
    H -->|save checkpoints| H1[experiments/YYYYMMDD/]
end

S1 -.->|uses| C1
S1 -.->|uses| C3
S2 -.->|uses| C2
S2 -.->|uses| C4
S1 -->|executes| A
S2 -->|executes| A
S3 -.->|monitors| L1

C1 -->|config input| A
C2 -->|config input| A
```

---

## 6) ì„¤ì •(`train_v087.yaml`) í•µì‹¬ í‚¤ ì„¤ëª…

- ğŸŒ³ `data.*`
    - `train_csv` : í•™ìŠµ CSV ê²½ë¡œ (ì˜ˆ: `../data/raw/train.csv`)
    - `sample_csv` : ìƒ˜í”Œ ì œì¶œ CSV (ê²½ë¡œ ê²€ì¦ìš©)
    - `image_dir_train` : **í•™ìŠµ ì´ë¯¸ì§€ í´ë”** (ì˜ˆ: `../data/raw/train`)
    - `image_ext` : í™•ì¥ì ê¸°ë³¸ê°’ (`.jpg` ë“±).
        
        â†’ CSV `ID`ì— ì´ë¯¸ í™•ì¥ìê°€ ìˆìœ¼ë©´ **ì¶”ê°€í•˜ì§€ ì•ŠìŒ**. ì—†ìœ¼ë©´ ë¶™ì„. ê·¸ë˜ë„ ëª» ì°¾ìœ¼ë©´ `.jpg/.png/...` **í›„ë³´ í™•ì¥ì ìë™ íƒìƒ‰**
        
    - `id_col`, `target_col` : ì»¬ëŸ¼ëª… ì§€ì • (ê¸°ë³¸ `ID`, `target`)
    - `folds` / `valid_fold` : í´ë“œ ìˆ˜ / **`int`(ë‹¨ì¼ í´ë“œ) ë˜ëŠ” `"all"`(ì „ í´ë“œ)**
    - `stratify` : ì¸µí™” ì—¬ë¶€
- ğŸ§  `model.*`
    - `name` : timm ëª¨ë¸ëª… (ì˜ˆ: `efficientnet_b3`)
    - `pretrained` : ì‚¬ì „í•™ìŠµ ê°€ì¤‘ì¹˜ ì‚¬ìš©
    - `pooling` : `avg`/`gem`/`max`/â€¦ â†’ timm `global_pool`ë¡œ ë§¤í•‘
- ğŸ‹ï¸ `train.*`
    - `img_size`, `batch_size`, `epochs`, `lr`, `weight_decay`, `optimizer`, `scheduler`, `amp`, `grad_clip_norm`, `label_smoothing`
    - `log_interval` : ë¯¸ë‹ˆë°°ì¹˜ ë¡œê·¸ ê°„ê²©
- ğŸ—ƒï¸ `output.*`
    - `logs_dir` : ë¡œê·¸ ë””ë ‰í† ë¦¬
    - `exp_dir` : ì‹¤í—˜(ì•„í‹°íŒ©íŠ¸) ë””ë ‰í† ë¦¬
    - `snapshots` : ì„¤ì • ìŠ¤ëƒ…ìƒ· ì €ì¥ ì—¬ë¶€

> ğŸ“Œ ê²½ë¡œ í•´ì„ ê·œì¹™
> 
> 
> í˜„ì¬ ì˜ˆì‹œëŠ” **config íŒŒì¼ ê¸°ì¤€ ìƒëŒ€ê²½ë¡œ**(`../data/...`)ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
> 
> â†’ `configs/train_v087.yaml`ì—ì„œ `../data/...`ëŠ” ë ˆí¬ ë£¨íŠ¸ì˜ `data/...`ë¥¼ ê°€ë¦¬í‚µë‹ˆë‹¤.
> 

---

## 7) ë¡œê·¸ íŒë… ìš”ë ¹ (í˜„ì—…ìš© í¬ì¸íŠ¸)

- âœ… **ì •ìƒ ì‹œì‘ ì§€í‘œ**
    - `[PATH] OK ...` : CSV/ì´ë¯¸ì§€ ê²½ë¡œ ê²€ì¦ í†µê³¼
    - `[DATA] dataset sizes | train=... valid=...` : ìƒ˜í”Œ ìˆ˜ í™•ì¸
    - `[MODEL] name=... pooling=... params(total/trainable)=...` : ëª¨ë¸/íŒŒë¼ë¯¸í„° í™•ì¸
- ğŸ“ˆ **ì—í­ë³„ í•µì‹¬**
    - `[EPOCH n] ... loss=... lr=...`
    - `validate` í›„ `macro_f1=...`
    - `NEW_BEST F1=... -> ckpt/best_foldX.pth` : ìµœê³  ì„±ëŠ¥ ì €ì¥ í¬ì¸íŠ¸
- ğŸ **ë§ˆì§€ë§‰ ì¤„(ê°€ì¥ ì¤‘ìš”)**
    - ì •ìƒ ì¢…ë£Œ: `[EXIT] TRAINING SUCCESS code=0`
    - ì—ëŸ¬ ì¢…ë£Œ: `[EXIT] TRAINING ERROR code=1` (+ Traceback)

---

## 8) íŠ¸ëŸ¬ë¸”ìŠˆíŒ… (ì¦ìƒ â†’ ì¡°ì¹˜)

- âŒ `FileNotFoundError: .../data/raw/train.csv`
    - `train_v087.yaml`ì˜ ê²½ë¡œê°€ **config ê¸°ì¤€ ìƒëŒ€ê²½ë¡œ**ë¡œ ë§ëŠ”ì§€ í™•ì¸
    - `../data/raw/train.csv` í˜•íƒœì¸ì§€ ê²€ì¦
- âŒ ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨(`.../train/xxx.jpg.jpg`)
    - CSV `ID`ì— í™•ì¥ìê°€ ì´ë¯¸ ë“¤ì–´ìˆìŒ
    - **í˜„ì¬ ë°ì´í„°ì…‹ ë¡œì§ì´ ì¤‘ë³µ í™•ì¥ ë°©ì§€**í•˜ë¯€ë¡œ, í˜¹ì‹œ ìµœì‹  ì½”ë“œê°€ ì•„ë‹ˆë¼ë©´ `src/data/dataset.py` ì—…ë°ì´íŠ¸
- âŒ `AssertionError: Pooling can only be disabled ...`
    - `model.pooling`ì´ timm `global_pool`ë¡œ ì˜¬ë°”ë¥´ê²Œ ë§¤í•‘ë˜ì–´ì•¼ í•¨
    - `pooling: "avg"` ê¶Œì¥ (ì»¤ìŠ¤í…€ í’€ë§ì„ ì“°ë ¤ë©´ ì™¸ë¶€ head êµ¬ì„± í•„ìš”)
- âŒ `No module named src.training.train_main`
    - `PYTHONPATH` í™•ì¸: `export PYTHONPATH="$(pwd):$PYTHONPATH"`

---

## 9) ë¡œê·¸ & ë©”íŠ¸ë¦­ í™œìš© íŒ

- ğŸ” `metrics.jsonl`ì€ **JSON Lines** í˜•ì‹ â†’ ì†ì‰½ê²Œ ì§‘ê³„/ì‹œê°í™” ê°€ëŠ¥
- ì˜ˆ) ë§ˆì§€ë§‰ ì—í­ë§Œ ì¶”ë ¤ë³´ê¸°(Python)
    
    ```python
    import json
    with open("experiments/20250904/v087-xxxxxx/metrics.jsonl") as f:
        rows = [json.loads(l) for l in f]
    last = [r for r in rows if isinstance(r.get("epoch"), int)]
    print(sorted(last, key=lambda x:(x["fold"], x["epoch"]))[-1])
    ```

---

## ğŸ†• 10) Latest-train ìë™ ë³µì‚¬ ì‹œìŠ¤í…œ

### ğŸ¯ **ìƒˆë¡œìš´ ê¸°ëŠ¥**: í•™ìŠµ ê²°ê³¼ ìë™ ë³µì‚¬
ì´ì œ ëª¨ë“  í•™ìŠµì´ ì™„ë£Œë˜ë©´ **ìë™ìœ¼ë¡œ** `experiments/train/latest-train/` í´ë”ì— ê²°ê³¼ê°€ ë³µì‚¬ë©ë‹ˆë‹¤!

### ğŸ“ **í´ë” êµ¬ì¡°**
```
experiments/train/
â”œâ”€â”€ 20250907/                    # ì›ë³¸: ë‚ ì§œë³„ ì €ì¥ (ê¸°ì¡´ ë°©ì‹ ìœ ì§€)
â”‚   â””â”€â”€ swin-highperf_20250907_1825/
â”œâ”€â”€ 20250908/
â”‚   â””â”€â”€ efficientnet-basic_20250908_1030/
â””â”€â”€ latest-train/                # ğŸ†• ìµœì‹  ê²°ê³¼ ìë™ ë³µì‚¬
    â””â”€â”€ efficientnet-basic_20250908_1030/  # ê°€ì¥ ìµœê·¼ í•™ìŠµ ê²°ê³¼
```

### ğŸ”„ **ë™ì‘ ë°©ì‹**
1. **ê¸°ë³¸ ì €ì¥**: `experiments/train/YYYYMMDD/ëª¨ë¸ëª…_ë‚ ì§œì‹œê°„/` (ê¸°ì¡´ ë°©ì‹ ìœ ì§€)
2. **ì¶”ê°€ ë³µì‚¬**: `experiments/train/latest-train/ëª¨ë¸ëª…_ë‚ ì§œì‹œê°„/` (ë®ì–´ì“°ê¸° ë°©ì‹)
3. **ë¡œê·¸ í™•ì¸**: í•™ìŠµ ì™„ë£Œ ì‹œ ë‹¤ìŒ ë©”ì‹œì§€ ì¶œë ¥
   ```
   [COPY] Results copied to latest-train/swin-highperf_20250908_1030
   ğŸ“ Latest results: experiments/train/latest-train/swin-highperf_20250908_1030
   ```

### ğŸš€ **ì´ì **
- âœ… **ë‚ ì§œ ê±±ì • ì—†ìŒ**: í›ˆë ¨ì´ ìì •ì„ ë„˜ê²¨ë„ latest-trainì—ì„œ ìµœì‹  ê²°ê³¼ ì ‘ê·¼
- âœ… **ì„¤ì • íŒŒì¼ ìë™í™”**: `update_inference_date.sh --latest-train` ëª…ë ¹ì–´ ì§€ì›
- âœ… **ì›Œí¬í”Œë¡œìš° ê°„ì†Œí™”**: í•­ìƒ ì¼ê´€ëœ ê²½ë¡œë¡œ ìµœì‹  ê²°ê³¼ ì°¸ì¡° ê°€ëŠ¥
- âœ… **ê¸°ì¡´ í˜¸í™˜ì„±**: ë‚ ì§œë³„ í´ë”ëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€

### ğŸ“ **ì¶”ë¡  ì„¤ì • ì—…ë°ì´íŠ¸ ë°©ë²•**
```bash
# ìµœì‹  í•™ìŠµ ê²°ê³¼ ê¸°ì¤€ìœ¼ë¡œ ì¶”ë¡  ì„¤ì • ì—…ë°ì´íŠ¸
./scripts/update_inference_date.sh --latest-train

# ë˜ëŠ” íŠ¹ì • ë‚ ì§œ ê¸°ì¤€
./scripts/update_inference_date.sh 20250908
./scripts/update_inference_date.sh --latest
```

ì´ì œ í•™ìŠµ í›„ ë°”ë¡œ `--latest-train` ì˜µì…˜ìœ¼ë¡œ ì¶”ë¡  ì„¤ì •ì„ ì—…ë°ì´íŠ¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤! ğŸ‰