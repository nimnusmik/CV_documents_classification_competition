# ğŸ“˜ Inference Pipeline ì‹¤í–‰ ê°€ì´ë“œ (ğŸš€ í†µí•© CLI ë²„ì „)

## ğŸ“‹ ì‚¬ì „ ì¤€ë¹„

### ğŸ”§ ì¶”ë¡ ìš© í™˜ê²½ ìµœì í™”
```bash
# 1. pyenv ê°€ìƒí™˜ê²½ í™œì„±í™”
pyenv activate cv_py3_11_9

# 2. ì˜ì¡´ì„± í™•ì¸ (Optuna, calibration í¬í•¨)
pip list | grep -E "optuna|sklearn|torch"

# 3. í™˜ê²½ í…ŒìŠ¤íŠ¸
python -c "
from src.calibration.temperature_scaling import TemperatureScaling
from src.inference.infer_calibrated import InferenceCalibrated
print('âœ… ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ëª¨ë“ˆ ì •ìƒ')
"
```

## 1) í†µí•© CLI ì‹¤í–‰ ëª…ë ¹ì–´

### ğŸ† ê³ ì„±ëŠ¥ ì¶”ë¡  (ê¶Œì¥ - ì•™ìƒë¸” + TTA + ìº˜ë¦¬ë¸Œë ˆì´ì…˜)
```bash
# ì™„ì „í•œ ì‹¤í–‰ ì‹œí€€ìŠ¤
pyenv activate cv_py3_11_9

# ì¶”ë¡ ë§Œ ì‹¤í–‰ (í•™ìŠµëœ ëª¨ë¸ ì‚¬ìš©)
python src/training/train_main.py \
    --config configs/train_highperf.yaml \
    --mode full-pipeline \
    --skip-training \
    --use-calibration
```

### ğŸ“š ê¸°ë³¸ ì¶”ë¡  (ë‹¨ì¼ ëª¨ë¸)
```bash
# ê¸°ë³¸ ì¶”ë¡  ì‹¤í–‰
python src/training/train_main.py \
    --config configs/train.yaml \
    --mode full-pipeline \
    --skip-training
```

### ğŸ¯ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì ìš© ì¶”ë¡ 
```bash
# Temperature Scaling ìº˜ë¦¬ë¸Œë ˆì´ì…˜ í¬í•¨ ì¶”ë¡ 
python src/training/train_main.py \
    --config configs/train_highperf.yaml \
    --mode full-pipeline \
    --skip-training \
    --use-calibration
```

**ìƒˆë¡œìš´ í†µí•© CLI ì„¤ëª…:**

- `--mode full-pipeline` â†’ í•™ìŠµ + ì¶”ë¡  í†µí•© íŒŒì´í”„ë¼ì¸
- `--skip-training` â†’ í•™ìŠµ ê±´ë„ˆë›°ê³  ì¶”ë¡ ë§Œ ì‹¤í–‰
- `--use-calibration` â†’ Temperature Scaling ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì ìš©
- `--config configs/train_highperf.yaml` â†’ ê³ ì„±ëŠ¥ ì„¤ì • ì‚¬ìš©

## ğŸ¯ ì„±ëŠ¥ ë¹„êµ

| ì¶”ë¡  ëª¨ë“œ | ì„±ëŠ¥ ì˜ˆìƒ | ì‹¤í–‰ ì‹œê°„ | ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ | íŠ¹ì§• |
|---------|---------|----------|-----------|-----|
| **ê¸°ë³¸ ëª¨ë“œ** | F1: ~0.89 | ~5ë¶„ | 4GB | ë‹¨ì¼ ëª¨ë¸, ê¸°ë³¸ ì¦ê°• |
| **ê³ ì„±ëŠ¥ ëª¨ë“œ** | F1: ~0.934 | ~15ë¶„ | 8GB | 5-Fold ì•™ìƒë¸” + TTA + ê³ ê¸‰ ì¦ê°• |
| **ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ëª¨ë“œ** | F1: ~0.940+ | ~18ë¶„ | 8GB | ì•™ìƒë¸” + TTA + Temperature Scaling |

---

## 2) ê³ ê¸‰ ì¶”ë¡  ì˜µì…˜

### ğŸ”¥ ì™„ì „ ìµœì í™” ì¶”ë¡  (ìµœê³  ì„±ëŠ¥)
```bash
# ì „ì²´ íŒŒì´í”„ë¼ì¸ (í•™ìŠµ + ìµœì í™” + ìº˜ë¦¬ë¸Œë ˆì´ì…˜ + ì¶”ë¡ )
python src/training/train_main.py \
    --config configs/train_highperf.yaml \
    --optimize \
    --n-trials 10 \
    --use-calibration \
    --mode full-pipeline \
    --auto-continue
```

### ğŸ¯ ì‚¬ì „ ìµœì í™”ëœ ì„¤ì •ìœ¼ë¡œ ì¶”ë¡ 
```bash
# ìµœì í™”ëœ ì„¤ì • íŒŒì¼ ì‚¬ìš©
python src/training/train_main.py \
    --config configs/train_optimized_20250907_1825.yaml \
    --mode full-pipeline \
    --skip-training \
    --use-calibration
```

### ğŸ“Š ê°œë³„ ëª¨ë“ˆ ì‹¤í–‰ (ê¸°ì¡´ ë°©ì‹ í˜¸í™˜)
```bash
# ê¸°ë³¸ ì¶”ë¡  (ê¸°ì¡´ ë°©ì‹)
python src/inference/infer.py configs/train_highperf.yaml

# ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì¶”ë¡  (ê¸°ì¡´ ë°©ì‹)
python src/inference/infer_calibrated.py configs/train_highperf.yaml
```

- Python â‰¥ 3.9 ê¶Œì¥
- í•µì‹¬ íŒ¨í‚¤ì§€: `torch`, `timm`, `albumentations`, `opencv-python`, `pandas`, `numpy`, `tqdm`, `Pillow`, `torchvision`
- ì„¤ì¹˜ ì˜ˆì‹œ
    
    ```bash
    pip install -r requirements.txt
    ```
    
- NVIDIA GPU ì‚¬ìš© ì‹œ: CUDA ëŸ°íƒ€ì„/ë“œë¼ì´ë²„ ë²„ì „ê³¼ ì„¤ì¹˜ëœ PyTorch CUDA ë¹Œë“œê°€ **í˜¸í™˜**ë˜ì–´ì•¼ í•¨

---

## 3) ì‹¤í–‰ ì „ ì²´í¬ë¦¬ìŠ¤íŠ¸(ğŸ§±)

- ğŸ—‚ï¸ **ë°ì´í„°**
    - `data/raw/sample_submission.csv` (í•„ìˆ˜ ì»¬ëŸ¼: `ID`)
    - `data/raw/test/` (í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€)
- ğŸ”¤ **í™•ì¥ì ì²˜ë¦¬**
    - CSV `ID`ì— í™•ì¥ìê°€ **ìˆì–´ë„/ì—†ì–´ë„** OK
    - ì—†ìœ¼ë©´ `data.image_ext`(ì˜ˆ: `.jpg`) â†’ ê·¸ë˜ë„ ì—†ìœ¼ë©´ `[".jpg",".jpeg",".png", ëŒ€/ì†Œë¬¸ì]` **Fallback**
- ğŸ“ **ë””ë ‰í† ë¦¬**
    - `logs/`, `submissions/` ë“± **ë¶€ëª¨ í´ë” ìë™ ìƒì„±**
- ğŸ§ª **ì²´í¬í¬ì¸íŠ¸**
    - `-ckpt` ë¯¸ì§€ì • ì‹œ: `experiments/<YYYYMMDD>/<run_name>/ckpt/best_fold0.pth` **ìë™ íƒìƒ‰**
- ğŸ§¬ **ì¼ê´€ì„±**
    - ê²€ì¦/ì¶”ë¡  ë³€í™˜ì€ `build_valid_tfms(img_size)` â†’ **í•™ìŠµì˜ img_sizeì™€ ë™ì¼**í•´ì•¼ í•¨

---

## 4) ì‹¤í–‰ ì»¤ë§¨ë“œ & ì˜µì…˜ (CLI)

```bash
# ê¸°ë³¸
python -m src.inference.infer_main --config configs/infer.yaml

# ckpt/out ëª…ì‹œ
python -m src.inference.infer_main \
  --config configs/infer.yaml \
  --ckpt experiments/20250904/v087-8c206e/ckpt/best_fold0.pth \
  --out  submissions/20250904/infer.csv
```

**ì˜µì…˜ ìš°ì„ ìˆœìœ„(ğŸ”½ ë†’ì€ â†’ ë‚®ì€)**

1. CLI `-ckpt` / `-out`
2. YAML `ckpt.path` / `inference.out_csv`
3. ìë™ ê·œì¹™ ê²½ë¡œ(ckpt): `experiments/<ë‚ ì§œ>/<run_name>/ckpt/best_fold0.pth`

**ì¢…ë£Œ ì½”ë“œ**: ì •ìƒ `0` / ì‚¬ìš©ì ì¤‘ë‹¨ `130` / ì˜ˆì™¸ `1`

---

## 5) ì„¤ì • íŒŒì¼ ë§µí•‘ (ì˜ˆ: `configs/infer.yaml`)

```yaml
project: { run_name, device, num_workers, date_format, time_format }
data:    { sample_csv, image_dir_test, image_ext, id_col, target_col, num_classes }
model:   { name, pretrained, drop_rate, drop_path_rate, pooling }
inference: { tta, tta_rot_degrees, out_csv }
ckpt:    { path }
output:  { logs_dir, exp_dir, snapshots }
```

**í•µì‹¬ í¬ì¸íŠ¸**

- `data.sample_csv`ì—ì„œ **IDë¥¼ ì½ì–´** ì¶”ë¡  ëŒ€ìƒ ê²°ì •
- `dataset`ì´ **í™•ì¥ì Fallback** ì§€ì›
- `model.pooling`ì€ ìœ íš¨ ê°’ë§Œ í—ˆìš©(ì˜ëª»ë˜ë©´ `avg` ê°•ì œ), `num_classes>0` + `pooling=None` **ê¸ˆì§€**
- `inference.tta=true`ì´ë©´ `tta_rot_degrees` ê°ë„ë³„ **softmax í™•ë¥  í‰ê· **

> ğŸ“Œ ê²½ë¡œëŠ” config íŒŒì¼ ê¸°ì¤€ ìƒëŒ€ê²½ë¡œ ì‚¬ìš© ê¶Œì¥
> 
> 
> (ì˜ˆ: `configs/infer.yaml` ê¸°ì¤€ `../data/raw/test` â†’ ë ˆí¬ ë£¨íŠ¸ `data/raw/test`)
> 

---

## 6) ë‚´ë¶€ íë¦„(ëª¨ë“ˆ & í˜¸ì¶œ ìˆœì„œ)

### (1) ì—”íŠ¸ë¦¬í¬ì¸íŠ¸: `src/inference/infer_main.py`

1. `argparse`: `-config/--ckpt/--out`
2. `run_inference(config, out, ckpt)` í˜¸ì¶œ
3. ì¢…ë£Œ ì½”ë“œ ì¶œë ¥

### (2) íŒŒì´í”„ë¼ì¸: `src/inference/infer.py â†’ run_inference(...)`

1. **Config ë¡œë“œ** & **Logger ì‹œì‘**(í‘œì¤€ ì¶œë ¥ ë¦¬ë””ë ‰íŠ¸, íŒŒì¼ ë¡œê·¸ ê¸°ë¡)
2. **ê²½ë¡œ ê²€ì¦**: `require_file(sample_csv)`, `require_dir(image_dir_test)`
3. **CSV ë¡œë“œ**: `ID` ëª©ë¡ í™•ë³´
4. **Dataset/DataLoader**: `DocClsDataset` + `build_valid_tfms(img_size)`
5. **ëª¨ë¸ ë¹Œë“œ**: `build_model(name, num_classes, pretrained, drop_rate, drop_path_rate, pooling)` â†’ `.eval()`
6. **ckpt ë¡œë“œ**: CLI > YAML > ìë™ ê·œì¹™ ê²½ë¡œ
7. **TTA ì¶”ë¡ **: ê° `deg` â†’ `_rotate_tensor` â†’ `softmax` â†’ **í™•ë¥  í‰ê· **
8. **CSV ì €ì¥**: `ID,target` (ë¶€ëª¨ í´ë” ìë™ ìƒì„±)
9. **ì¢…ë£Œ ë¡œê·¸**: ì„±ê³µ/ì‹¤íŒ¨/ì¤‘ë‹¨ ì½”ë“œ ë° ë§ˆì»¤

---

## 7) íŒŒì¼ ê°„ ê´€ê³„(ì˜ì¡´ ë‹¤ì´ì–´ê·¸ë¨)

```mermaid
flowchart TD

subgraph "ğŸ› ï¸ ìŠ¤í¬ë¦½íŠ¸ ê´€ë¦¬"
    S1[scripts/update_inference_date.sh]
    S2[scripts/monitor_training.sh]
end

subgraph "âš™ï¸ ì¶”ë¡  ì„¤ì •"
    C1[configs/infer.yaml]
    C2[configs/infer_highperf.yaml]
end

subgraph "ğŸ” ì¶”ë¡  ì—”ì§„"
    A[infer_main.py] -->|run_inference| B[infer.py]
end

subgraph "ğŸ”§ ìœ í‹¸ë¦¬í‹°"
    B -->|config/log/path utils| C[utils/common.py]
    B -->|Logger| J[utils/logger.py]
    C -->|create_log_path| L1[logs/YYYYMMDD/infer/]
end

subgraph "ğŸ“Š ë°ì´í„° ì²˜ë¦¬"
    B -->|Dataset| D[data/dataset.py]
    B -->|Transforms| E[data/transforms.py]
    D -->|read images| K[data/raw/test/*]
    B -->|read IDs| L[data/raw/sample_submission.csv]
end

subgraph "ğŸ§  ëª¨ë¸ ë¡œë“œ"
    B -->|Model| F[models/build.py]
    B -->|load checkpoints| N[experiments/YYYYMMDD/<run_name>/ckpt/*.pth]
end

subgraph "ğŸ“¤ ê²°ê³¼ ì¶œë ¥"
    B -->|write results| M[submissions/YYYYMMDD/infer_*.csv]
    B -->|augmentation type| M2[*_basic_augmentation.csv<br/>*_advanced_augmentation.csv]
end

S1 -.->|updates dates| C1
S1 -.->|updates dates| C2
S2 -.->|monitors| L1
C1 -->|config input| A
C2 -->|config input| A
M --> M2
```

---

## 8) ê²°ê³¼ë¬¼ & ë””ë ‰í† ë¦¬ êµ¬ì¡°(ğŸ§ª)

```
submissions/
â””â”€â”€ 20250908/                          # ë‚ ì§œë³„ ê²°ê³¼ ê´€ë¦¬
    â”œâ”€â”€ infer_basic_augmentation.csv    # ê¸°ë³¸ ì¦ê°• ê²°ê³¼
    â””â”€â”€ infer_advanced_augmentation.csv # ê³ ê¸‰ ì¦ê°• ê²°ê³¼

logs/
â””â”€â”€ 20250908/                          # ë‚ ì§œë³„ ë¡œê·¸ ê´€ë¦¬
    â””â”€â”€ infer/
        â”œâ”€â”€ infer_basic_20250908_1400.log
        â””â”€â”€ infer_highperf_20250908_1500.log

experiments/
â””â”€â”€ 20250908/                          # ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸
    â””â”€â”€ <run_name>/
        â””â”€â”€ ckpt/
            â”œâ”€â”€ best_fold_0.pth
            â”œâ”€â”€ best_fold_1.pth
            â””â”€â”€ ...
```

**CSV ìŠ¤í‚¤ë§ˆ**

```
ID,target
0001,3
0002,7
...
```

- `ID`: sample CSV ê·¸ëŒ€ë¡œ
- `target`: ì˜ˆì¸¡ í´ë˜ìŠ¤(0 ~ num_classes-1)
- **íŒŒì¼ëª…**: ì¦ê°• íƒ€ì…ë³„ ìë™ ë¶„ë¥˜ (`_basic_augmentation` / `_advanced_augmentation`)

---

## 9) TTA ì„¤ê³„(ğŸ§­)

- `inference.tta: true` â†’ `tta_rot_degrees`(ì˜ˆ: `[0, -3, 3]`) ìˆœíšŒ
- ê°ë„ë³„ **ëª¨ë¸ ì¶”ë¡ ** â†’ `softmax` í™•ë¥  **ëˆ„ì /í‰ê· ** â†’ `argmax`
- ğŸ“Œ ë¬¸ì„œ ì´ë¯¸ì§€ íŠ¹ì„±ìƒ **ì†Œê°(Â±3~6ë„)**ë¶€í„° ì ì¦ ê¶Œì¥
    
    90Â° ë‹¨ìœ„ ê°•íšŒì „ì€ í…ìŠ¤íŠ¸ ë°©í–¥ì„±ì— ë¯¼ê°(ì„±ëŠ¥ ì €í•˜ ê°€ëŠ¥)
    

---

## 10) ì„±ëŠ¥/ë¦¬ì†ŒìŠ¤ íŠœë‹(âš¡)

- **DataLoader**
    - `project.num_workers`: ë””ìŠ¤í¬Â·CPU ìƒí™©ì— ë§ê²Œ ì¡°ì •(ë³‘ëª© ì‹œ ê³¼ë„ ì¦ê°€ëŠ” ì—­íš¨ê³¼)
    - `pin_memory=True` ìœ ì§€, í° ë°°ì¹˜ê°€ ê°€ëŠ¥í•˜ë©´ **ì¶”ë¡  ì „ìš© ë°°ì¹˜ í¬ê¸° í‚¤**ë¥¼ ë„ì…í•´ ì†ë„ â†‘
- **ì…ë ¥ í¬ê¸°**
    - í•™ìŠµ/ê²€ì¦/ì¶”ë¡  `img_size` ì¼ì¹˜ê°€ **ì •ë‹µ**
    - ì œì¶œ ì§ì „ì—ëŠ” `img_size` ë‹¤ìš´ìŠ¤ì¼€ì¼ë¡œ ì†ë„-ì •í™•ë„ íŠ¸ë ˆì´ë“œì˜¤í”„ í‰ê°€
- **I/O ìµœì í™”**
    - ì´ë¯¸ì§€ê°€ ëŒ€ìš©ëŸ‰ì´ë©´ **ì´ë¯¸ì§€ ìºì‹œ**(e.g., LMDB) ê²€í† 
    - ë„¤íŠ¸ì›Œí¬ ìŠ¤í† ë¦¬ì§€ ì‚¬ìš© ì‹œ Prefetch/ë¡œì»¬ ìºì‹œ
- **ë½/ë©”ëª¨ë¦¬**
    - OOM ë°œìƒ ì‹œ: ë°°ì¹˜ ì¶•ì†Œ, `num_workers` ì¶•ì†Œ, ë¶ˆí•„ìš”í•œ í…ì„œ ì¦‰ì‹œ `del` ë° `torch.cuda.empty_cache()` ì£¼ê¸°ì  í˜¸ì¶œ(í•„ìš” ì‹œ)

---

## 11) ë¡œê·¸ ë¶„ì„ íŒ(ğŸ”)

- â­ ì‹œì‘/ê²½ë¡œ/ì„¤ì •:
    - `[PATH] OK ...` : CSV/ì´ë¯¸ì§€ ê²½ë¡œ ê²€ì¦ í†µê³¼
    - `[DATA] test size=...` : ìƒ˜í”Œ ìˆ˜ í™•ì¸
    - `[CKPT] loaded: ...` : ê°€ì¤‘ì¹˜ ì •ìƒ ë¡œë“œ
- âœ… ì²´í¬í¬ì¸íŠ¸:
    - `[CKPT] loaded: .../best_fold0.pth` : ìµœê³  ì„±ëŠ¥ ì²´í¬í¬ì¸íŠ¸
- ğŸ” ì§„í–‰ë¥ :
    - `[INFER] step i/total processed` : ëŒ€ëµì ì¸ ë‚¨ì€ ì‹œê°„ ê°
- ğŸ ê²°ê³¼/ì¢…ë£Œ:
    - `[OUT] submission saved: ... | shape=(N, 2)`
    - `[EXIT] INFERENCE SUCCESS code=0`

**ë¹ ë¥¸ ì¶”ì¶œ ì˜ˆì‹œ**

```bash
# ê°€ì¥ ì¤‘ìš”í•œ ë¼ì¸ë§Œ ì¶”ì¶œ (ìƒˆë¡œìš´ ë¡œê·¸ êµ¬ì¡°)
grep -E "^\[PATH\]|\[CKPT\]|\[OUT\]|\[EXIT\]" logs/$(date +%Y%m%d)/infer/infer_*.log

# scriptsë¥¼ ì‚¬ìš©í•œ ëª¨ë‹ˆí„°ë§
bash scripts/monitor_training.sh

# íŠ¹ì • ë‚ ì§œ ë¡œê·¸ í™•ì¸
grep -E "^\[PATH\]|\[CKPT\]|\[OUT\]|\[EXIT\]" logs/20250908/infer/infer_*.log
```

---

## 12) ì—ëŸ¬ í”Œë¡œìš°(ğŸ§¯)

```mermaid
flowchart TD
start([ì¶”ë¡  ì‹œì‘]) --> script_check{scripts í´ë” ì‚¬ìš©?}

script_check -- yes --> script_run[scripts/update_inference_date.sh<br/>ìë™ config ì—…ë°ì´íŠ¸]
script_check -- no --> config_check[ìˆ˜ë™ config ì²´í¬]

script_run --> config_updated[configs/infer*.yaml ì—…ë°ì´íŠ¸ë¨]
config_updated --> c1{sample_csv exists}
config_check --> c1

c1 -- yes --> c2{image_dir_test exists}
c1 -- no  --> x1[FileNotFoundError sample_csv<br/>data/raw/sample_submission.csv í™•ì¸] --> end1(((End)))

c2 -- no  --> x2[FileNotFoundError image_dir_test<br/>data/raw/test/ í´ë” í™•ì¸] --> end2(((End)))
c2 -- yes --> config_validate{config validation}

config_validate -- fail --> x5[Config Error<br/>infer.yaml vs infer_highperf.yaml í™•ì¸] --> end5(((End)))
config_validate -- pass --> m1[build_model pooling]

m1 --> d1{pooling valid}
d1 -- no  --> x3[ValueError invalid pooling<br/>ìë™ìœ¼ë¡œ avgë¡œ ì„¤ì •] --> ck
d1 -- yes --> ck[ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ<br/>experiments/YYYYMMDD/]

ck --> d2{ë‚ ì§œ ë§¤ì¹­}
d2 -- no --> x6[ì²´í¬í¬ì¸íŠ¸ ë‚ ì§œ ë¶ˆì¼ì¹˜<br/>update_inference_date.sh ì‹¤í–‰ í•„ìš”] --> end6(((End)))
d2 -- yes --> d3{shape mismatch}

d3 -- yes --> x4[RuntimeError state_dict<br/>ëª¨ë¸ ì•„í‚¤í…ì²˜ ë¶ˆì¼ì¹˜] --> end3(((End)))
d3 -- no  --> augment_check{ì¦ê°• íƒ€ì… ì„¤ì •}

augment_check --> tta[TTA ì¶”ë¡  + softmax í‰ê· ]
tta --> log_create[logs/YYYYMMDD/infer/ ë¡œê·¸ ìƒì„±]
log_create --> save[ê²°ê³¼ ì €ì¥<br/>submissions/YYYYMMDD/*_augmentation.csv]
save --> monitor[scripts/monitor_training.shë¡œ í™•ì¸ ê°€ëŠ¥]
monitor --> end4(((ì„±ê³µ ì™„ë£Œ)))
```

---

## 14) TTA ê°ë„ ì‹¤í—˜

```yaml
# configs/infer.yaml (ê¸°ë³¸ ì¶”ë¡ )
inference:
  tta: true
  tta_rot_degrees: [0, -3, 3]

# configs/infer_highperf.yaml (ê³ ì„±ëŠ¥ ì¶”ë¡ )  
inference:
  tta: true
  tta_rot_degrees: [0, -3, 3, 6, -6]  # ë” ë§ì€ ê°ë„ë¡œ ì •í™•ë„ í–¥ìƒ
```

### ë¹ ë¥¸ vs ê³ ì„±ëŠ¥ TTA ì„¤ì •

| ì„¤ì • | ê¸°ë³¸ ì¶”ë¡  | ê³ ì„±ëŠ¥ ì¶”ë¡  |
|------|-----------|-------------|
| **Config íŒŒì¼** | `infer.yaml` | `infer_highperf.yaml` |
| **TTA ê°ë„** | `[0, -3, 3]` | `[0, -3, 3, 6, -6]` |
| **ì²˜ë¦¬ ì‹œê°„** | ë¹ ë¦„ | ëŠë¦¼ (ë†’ì€ ì •í™•ë„) |
| **ì‚¬ìš© ëª©ì ** | ë¹ ë¥¸ ê²€ì¦ | ìµœì¢… ì œì¶œ |

### scripts í´ë”ë¥¼ í™œìš©í•œ TTA ì„¤ì • ìë™í™”

```bash
# ğŸ†• ìµœì‹  í•™ìŠµ ê²°ê³¼ ê¸°ì¤€ìœ¼ë¡œ ìë™ ì—…ë°ì´íŠ¸ (ê¶Œì¥!)
bash scripts/update_inference_date.sh --latest-train

# ê³ ì„±ëŠ¥ ì¶”ë¡  ì„¤ì •ìœ¼ë¡œ ìë™ ì—…ë°ì´íŠ¸ (íŠ¹ì • ë‚ ì§œ)
bash scripts/update_inference_date.sh --latest --config highperf

# ê¸°ë³¸ ì¶”ë¡  ì„¤ì •ìœ¼ë¡œ ìë™ ì—…ë°ì´íŠ¸ (íŠ¹ì • ë‚ ì§œ)
bash scripts/update_inference_date.sh --latest --config basic

# íŠ¹ì • ë‚ ì§œ ì§€ì •
bash scripts/update_inference_date.sh 20250908
```

**ğŸ†• Latest-train ê¸°ëŠ¥ì˜ ì¥ì :**
- âœ… **ë‚ ì§œ ê±±ì • ì—†ìŒ**: í•™ìŠµì´ ìì •ì„ ë„˜ì–´ë„ ìë™ìœ¼ë¡œ ìµœì‹  ê²°ê³¼ ì°¸ì¡°
- âœ… **ì›Œí¬í”Œë¡œìš° ê°„ì†Œí™”**: í•­ìƒ `--latest-train` ì˜µì…˜ í•˜ë‚˜ë¡œ í•´ê²°
- âœ… **ì‹¤ìˆ˜ ë°©ì§€**: ì˜ëª»ëœ ë‚ ì§œ ì§€ì •ìœ¼ë¡œ ì¸í•œ ì˜¤ë¥˜ ë°©ì§€

> ê³¼ë„í•œ ê°ë„ëŠ” ì†ë„/ì„±ëŠ¥ ëª¨ë‘ ì•…ì˜í–¥ ê°€ëŠ¥ â†’ ì†Œê°ë¶€í„° ì ì¦
> 

---

## 15) FAQ(â“)

- **Q. scripts í´ë”ì˜ update_inference_date.shëŠ” ì–¸ì œ ì‚¬ìš©í•˜ë‚˜ìš”?**
    
    A. í•™ìŠµ ì™„ë£Œ í›„ ì¶”ë¡  ì „ì— ì‹¤í–‰í•˜ì—¬ config íŒŒì¼ì˜ ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œë¥¼ ìµœì‹  ë‚ ì§œë¡œ ìë™ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤. ğŸ†• `--latest-train` ì˜µì…˜ì„ ì‚¬ìš©í•˜ë©´ ë‚ ì§œì™€ ê´€ê³„ì—†ì´ í•­ìƒ ìµœì‹  í•™ìŠµ ê²°ê³¼ë¥¼ ì°¸ì¡°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    
- **Q. latest-train í´ë”ëŠ” ë¬´ì—‡ì¸ê°€ìš”?**
    
    A. ğŸ†• í•™ìŠµ ì™„ë£Œ ì‹œ ìë™ìœ¼ë¡œ ìƒì„±ë˜ëŠ” í´ë”ë¡œ, ê°€ì¥ ìµœê·¼ í•™ìŠµ ê²°ê³¼ê°€ ë³µì‚¬ë©ë‹ˆë‹¤. `--latest-train` ì˜µì…˜ì„ ì‚¬ìš©í•˜ë©´ ë‚ ì§œì— ê´€ê³„ì—†ì´ í•­ìƒ ìµœì‹  ê²°ê³¼ì— ì ‘ê·¼í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    
- **Q. `-ckpt` ì—†ì´ë„ ë˜ë‚˜ìš”?**
    
    A. ë„¤. YAMLì˜ `ckpt.path` ë˜ëŠ” ìë™ ê·œì¹™ ê²½ë¡œë¥¼ ìˆœì°¨ì ìœ¼ë¡œ íƒìƒ‰í•©ë‹ˆë‹¤. scripts/update_inference_date.shë¥¼ ì‚¬ìš©í•˜ë©´ ìë™ìœ¼ë¡œ ì„¤ì •ë©ë‹ˆë‹¤.
    
- **Q. ë¹ ë¥¸ ì¶”ë¡ ê³¼ ê³ ì„±ëŠ¥ ì¶”ë¡ ì˜ ì°¨ì´ëŠ”?**
    
    A. `configs/infer.yaml`(ë¹ ë¥¸)ì€ ê¸°ë³¸ TTA, `configs/infer_highperf.yaml`(ê³ ì„±ëŠ¥)ì€ ë” ë§ì€ TTA ê°ë„ë¡œ ì •í™•ë„ë¥¼ ë†’ì…ë‹ˆë‹¤.
    
- **Q. `ID`ì— í™•ì¥ìê°€ ì„ì—¬ ìˆì–´ë„?**
    
    A. ë„¤. ì´ë¯¸ í™•ì¥ìê°€ ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©, ì—†ìœ¼ë©´ ê¸°ë³¸ í™•ì¥ì â†’ Fallback ìˆœìœ¼ë¡œ íƒìƒ‰í•©ë‹ˆë‹¤.
    
- **Q. í´ë˜ìŠ¤ ê°œìˆ˜ê°€ ë‹¤ë¥¸ ckpt ë¡œë”© ì—ëŸ¬?**
    
    A. `model.num_classes/pooling/ë°±ë³¸`ì´ í•™ìŠµ ë‹¹ì‹œ ì„¤ì •ê³¼ ì¼ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤.
    
- **Q. ë¡œê·¸ íŒŒì¼ì´ ì–´ë””ì— ì €ì¥ë˜ë‚˜ìš”?**
    
    A. `logs/YYYYMMDD/infer/` í´ë”ì— ë‚ ì§œë³„ë¡œ ê´€ë¦¬ë˜ë©°, ì¦ê°• íƒ€ì…ë³„ë¡œ íŒŒì¼ëª…ì— í‘œì‹œë©ë‹ˆë‹¤.
    
- **Q. ì¶”ë¡  ë°°ì¹˜ í¬ê¸° ì–´ë””ì„œ ë°”ê¾¸ë‚˜ìš”?**
    
    A. í˜„ì¬ í•™ìŠµ ì„¤ì •(`train.batch_size`)ì„ ì¬ì‚¬ìš©í•©ë‹ˆë‹¤. ì¶”ë¡  ì „ìš© í‚¤ë¥¼ YAMLì— ì¶”ê°€í•´ ì˜¤ë²„ë¼ì´ë“œí•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤.

---

## 16) í…ŒìŠ¤íŠ¸ ì „/ì œì¶œ ì „ ìµœì¢… ì²´í¬(âœ…)

- [ ]  `sample_csv` **ì¡´ì¬** & `ID` ì»¬ëŸ¼ í™•ì¸
- [ ]  `image_dir_test` **ì¡´ì¬** & ì‹¤ì œ ì´ë¯¸ì§€ íŒŒì¼ í™•ì¸  
- [ ]  **scripts ì‹¤í–‰**: `bash scripts/update_inference_date.sh --latest`
- [ ]  í™•ì¥ì/ëŒ€ì†Œë¬¸ì(Fallback) ë™ì‘ ì´í•´
- [ ]  `model.name/num_classes/pooling`ì´ ckptì™€ **ì¼ì¹˜**
- [ ]  `img_size`(í•™ìŠµ/ê²€ì¦/ì¶”ë¡ ) **ì¼ì¹˜**
- [ ]  **config ì„ íƒ**: `infer.yaml`(ë¹ ë¥¸) vs `infer_highperf.yaml`(ê³ ì„±ëŠ¥)
- [ ]  **ë¡œê·¸ í™•ì¸**: `logs/YYYYMMDD/infer/` í´ë” ì²´í¬
- [ ]  **ê²°ê³¼ í™•ì¸**: `submissions/YYYYMMDD/*_augmentation.csv` ìƒì„± í™•ì¸
- [ ]  `-out` ë˜ëŠ” `inference.out_csv` ê²½ë¡œ **ì“°ê¸° ê¶Œí•œ**
- [ ]  ì œì¶œ ìŠ¤í‚¤ë§ˆ `ID,target` + í—¤ë” + `index=False`

---

## 17) íŠ¸ëŸ¬ë¸”ìŠˆíŒ…(ì¦ìƒ â†’ ì¡°ì¹˜)

- âŒ `FileNotFoundError: ...sample_submission.csv`
    
    â†’ `configs/infer.yaml`ì—ì„œ **config ê¸°ì¤€ ìƒëŒ€ê²½ë¡œ** í™•ì¸, ì² ì/ëŒ€ì†Œë¬¸ì ì ê²€
    
- âŒ `FileNotFoundError: .../test`
    
    â†’ í…ŒìŠ¤íŠ¸ í´ë”/ì´ë¯¸ì§€ ì‹¤ì¡´ ì—¬ë¶€ í™•ì¸
    
- âŒ ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨
    
    â†’ í™•ì¥ì/ëŒ€ì†Œë¬¸ì ë¶ˆì¼ì¹˜. í´ë”ì— íŒŒì¼ ìì²´ê°€ ì—†ìœ¼ë©´ Fallbackë„ ì‹¤íŒ¨
    
- âŒ `RuntimeError: state_dict`
    
    â†’ ckptì™€ ëª¨ë¸ êµ¬ì¡° ë¶ˆì¼ì¹˜. `name/num_classes/pooling` ì¬í™•ì¸
    
- âŒ `ValueError: pooling(None) + num_classes>0`
    
    â†’ `pooling: "avg"`ë¡œ ìˆ˜ì •
    

---

### ë¶€ë¡) ë¡œê·¸ ì˜ˆì‹œ(ìš”ì•½)

```
[BOOT] inference pipeline started
[PATH] OK | sample_csv=... | image_dir_test=...
[CFG] data=..., model=..., inference=...
[CKPT] loaded: .../best_fold0.pth
[TTA] enabled=True degs=[0, -3, 3]
[INFER] >>> start
[INFER] step 20/XXX processed
[OUT] submission saved: submissions/20250904/infer.csv | shape=(N, 2)
[INFER] <<< finished successfully
[EXIT] INFERENCE SUCCESS code=0
```