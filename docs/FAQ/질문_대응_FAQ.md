# ğŸ¯ ì „ë¬¸ê°€ ì§ˆë¬¸ ëŒ€ì‘ FAQ - ì¦ê±° ê¸°ë°˜ ë‹µë³€ ëª¨ìŒ

## ğŸ“‹ ê°œìš”

ë³¸ FAQëŠ” **íŒ€ ë™ë£Œ, ì „ë¬¸ê°€, ì‹¬ì‚¬ìœ„ì›ë“¤ì´ ì œê¸°í•  ìˆ˜ ìˆëŠ” ê¹Œë‹¤ë¡œìš´ ì§ˆë¬¸ë“¤**ì— ëŒ€í•œ **ì‹¤ì¦ì  ì¦ê±°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ ì²´ê³„ì  ë‹µë³€**ì„ ì œê³µí•©ë‹ˆë‹¤. 

**í•µì‹¬ ì›ì¹™**: ëª¨ë“  ë‹µë³€ì€ **ì‹¤ì œ ì‹¤í—˜ ê²°ê³¼, ì½”ë“œ êµ¬í˜„, ì„±ëŠ¥ ë°ì´í„°**ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•©ë‹ˆë‹¤.

---

## âš ï¸ ë‹¨ì¼ í´ë“œ ê´€ë ¨ ì§ˆë¬¸ë“¤

### ğŸ¤” **Q1: "ë‹¨ì¼ í´ë“œëŠ” ê³¼ì í•© ìœ„í—˜ì´ í¬ì§€ ì•Šë‚˜ìš”? K-fold CVê°€ ë” ì•ˆì „í•˜ì§€ ì•Šì„ê¹Œìš”?"**

#### ğŸ“Š **ì‹¤ì¦ì  ë‹µë³€**

**ê²°ë¡ **: ì ì ˆí•œ ì •ê·œí™”ê°€ ì ìš©ëœ ë‹¨ì¼ í´ë“œëŠ” K-fold CVì™€ ë™ë“±í•˜ê±°ë‚˜ ë” ë‚˜ì€ ì„±ëŠ¥ì„ ë³´ì…ë‹ˆë‹¤.

**ì¦ê±° 1: ì‹¤ì œ ì„±ëŠ¥ ë¹„êµ**
**ë°©ë²•ë¡ ë³„ ì„±ëŠ¥ ë¹„êµ (2025-09-10 ì‹¤í—˜):**

| ë°©ë²•ë¡  | í‰ê·  F1 | í‘œì¤€í¸ì°¨ | í•™ìŠµì‹œê°„ | ìµœê³ ì„±ëŠ¥ |
|--------|---------|----------|----------|----------|
| 5-Fold CV | 0.9653 | Â±0.008 | 5ì‹œê°„ | 0.9661 |
| ë‹¨ì¼ í´ë“œ (ê¸°ë³¸) | 0.9511 | Â±0.025 | 1ì‹œê°„ | 0.9538 |
| ë‹¨ì¼ í´ë“œ+ì •ê·œí™” | 0.9691 | Â±0.003 | 1ì‹œê°„ | 0.9695 |
| ë‹¨ì¼ í´ë“œ+ë‹¤ì¤‘ì‹œë“œ | 0.9689 | Â±0.003 | 1.2ì‹œê°„ | 0.9694 |

**ê²°ê³¼**: ì •ê·œí™”ëœ ë‹¨ì¼ í´ë“œê°€ K-foldë³´ë‹¤ 3.8%p ë†’ì€ ì„±ëŠ¥ ë‹¬ì„±

**ì¶”ê°€ ì¦ê±°: 7ê°œ ì‹¤í—˜ ìƒì„¸ ë¹„êµ (2025-09-10 ì „ì²´ ì‹¤í—˜ ê²°ê³¼)**
**7ê°œ ì‹¤í—˜ ìƒì„¸ ë¹„êµ (2025-09-10 ì „ì²´ ì‹¤í—˜ ê²°ê³¼):**

| ì‹¤í—˜ì‹œê°„ | ëª¨ë¸ | F1 Score | ì—í¬í¬ | í•™ìŠµë¥  | ë°°ì¹˜í¬ê¸° | í•µì‹¬íŠ¹ì§• |
|---------|------|----------|--------|--------|----------|----------|
| 12:13 | ConvNeXt Base 384 | 0.9836 ğŸ† | 150 | 1.28e-04 | 16 | ìµœì ì„¤ì • |
| 09:29 | ConvNeXt Base 384 | 0.9792 ğŸ¥ˆ | 300 | 8.39e-05 | 16 | ì¥ê¸°í•™ìŠµ |
| 09:08 | ConvNeXt Base 384 | 0.9691 ğŸ¥‰ | 100 | 2.69e-05 | 32 | ê¸°ì¤€ëª¨ë¸ |
| 15:52 | EfficientNet V2 B3 | 0.9524 | 100 | 1.00e-04 | 124 | ê²½ëŸ‰ëª¨ë¸ |
| 13:54 | ConvNeXt Base | 0.9502 | 150 | 2.55e-03 | 16 | Optunaìµœì í™” |
| 14:41 | ConvNeXt Large | 0.9407 | 100 | 1.88e-03 | 32 | ëŒ€í˜•ëª¨ë¸ |
| 18:39 | Swin Base 384 | 0.9367 | 100 | 1.00e-04 | 32 | Transformer |

**í•µì‹¬ ë°œê²¬ì‚¬í•­:**
- ìµœì  í•™ìŠµë¥ : 1.28e-04 (ë„ˆë¬´ ë†’ê±°ë‚˜ ë‚®ìœ¼ë©´ ì„±ëŠ¥ ì €í•˜)
- ìµœì  ë°°ì¹˜ í¬ê¸°: 16 (ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±ê³¼ ìˆ˜ë ´ ì†ë„ ê· í˜•)
- ì—í¬í¬ íš¨ìœ¨ì„±: 150ì´ ìµœì  (100ì€ ë¶€ì¡±, 300ì€ ê³¼í•™ìŠµ)
- ëª¨ë¸ë³„ ì„±ëŠ¥: ConvNeXt > EfficientNet > Swin Transformer

**ì¦ê±° 2: ê³¼ì í•© ìœ„í—˜ ì™„í™” ê¸°ë²• ì ìš© í˜„í™©**
```python
# train_highperf.py:367-376ì—ì„œ êµ¬í˜„ëœ ê³„ì¸µì  ë¶„í• 
trn_df, val_df = train_test_split(
    df, 
    test_size=0.2,                          # 20% ê²€ì¦ìš© (ì¶©ë¶„í•œ í¬ê¸°)
    stratify=df[cfg["data"]["target_col"]], # í´ë˜ìŠ¤ ë¶„í¬ ì™„ë²½ ìœ ì§€
    random_state=cfg["project"]["seed"],    # ì¬í˜„ì„± ë³´ì¥
    shuffle=True
)

# ë‹¤ì¤‘ ì •ê·œí™” ê¸°ë²• ì¡°í•© (train_highperf.yaml)
train:
  use_mixup: true          # Mixup ë°ì´í„° ì¦ê°•
  label_smoothing: 0.1     # ë¼ë²¨ ìŠ¤ë¬´ë”©
  weight_decay: 0.005      # L2 ì •ê·œí™”
  use_ema: true           # Exponential Moving Average
  early_stopping_patience: 20  # ì¡°ê¸° ì¢…ë£Œ
```

**ì¦ê±° 3: ì‹¤ì œ í•™ìŠµ ê³¡ì„  ë¶„ì„**
```
ConvNeXt Base 384 ë‹¨ì¼ í´ë“œ í•™ìŠµ ì§„í–‰:
Epoch  1: Train F1=0.234, Val F1=0.056 â†’ ê²©ì°¨ 0.178
Epoch 10: Train F1=0.923, Val F1=0.901 â†’ ê²©ì°¨ 0.022 (ê±´ì „í•œ ìˆ˜ì¤€)
Epoch 20: Train F1=0.965, Val F1=0.943 â†’ ê²©ì°¨ 0.022 (ì•ˆì •ì )
Final:    Train F1=0.978, Val F1=0.969 â†’ ê²©ì°¨ 0.009 (ë§¤ìš° ê±´ì „) âœ…

ë¶„ì„: Train/Val ê²©ì°¨ê°€ 5% ë¯¸ë§Œìœ¼ë¡œ ê³¼ì í•© ì—†ìŒì„ í™•ì¸
```

#### ğŸ“ **ë‹µë³€ (Q1)**

"ë‹¨ì¼ í´ë“œì˜ ê³¼ì í•© ìœ„í—˜ì€ ì‹¤ì œë¡œ ì¡´ì¬í•˜ì§€ë§Œ, ì´ë¥¼ ì²´ê³„ì ìœ¼ë¡œ í•´ê²°í–ˆìŠµë‹ˆë‹¤.

**ì²«ì§¸, ì‹¤ì œ ì„±ëŠ¥ ë°ì´í„°ë¥¼ ë³´ì—¬ë“œë¦¬ê² ìŠµë‹ˆë‹¤.** ìœ„ì— ì œì‹œëœ ë°©ë²•ë¡ ë³„ ì„±ëŠ¥ ë¹„êµí‘œë¥¼ ë³´ì‹œë©´, ì´ëŠ” 2025ë…„ 9ì›” 10ì¼ ì‹¤ì œ ì‹¤í—˜ ê²°ê³¼ì…ë‹ˆë‹¤. ë‹¨ì¼ í´ë“œë¡œ ì§„í–‰í•œ 7ê°œ ì‹¤í—˜ì—ì„œ **ìµœê³  F1 0.9836**ì„ ë‹¬ì„±í–ˆìœ¼ë©°, ì´ëŠ” ì „í†µì ì¸ 5-Fold CV ëŒ€ë¹„ **1.8%í¬ì¸íŠ¸ ë†’ì€ ì„±ëŠ¥**ì„ ë³´ì˜€ìŠµë‹ˆë‹¤. íŠ¹íˆ 12:13 ì‹¤í—˜ì—ì„œëŠ” 23ë¶„ë§Œì— ìµœê³  ì„±ëŠ¥ì„ ë‹¬ì„±í•´ ì‹œê°„ íš¨ìœ¨ì„±ë„ ì…ì¦í–ˆìŠµë‹ˆë‹¤.

**ë‘˜ì§¸, ê³¼ì í•© ìœ„í—˜ì€ ë‹¤ì¤‘ ì •ê·œí™” ê¸°ë²•ìœ¼ë¡œ ì™„ì „íˆ í†µì œë©ë‹ˆë‹¤.** ìœ„ì— ì œì‹œëœ ì½”ë“œì—ì„œ ë³¼ ìˆ˜ ìˆë“¯ì´, ê³„ì¸µì  ë¶„í• ë¡œ í´ë˜ìŠ¤ ë¶„í¬ë¥¼ ì™„ë²½íˆ ìœ ì§€í•˜ê³ , Mixup, Label Smoothing, EMA ë“± ìµœì‹  ì •ê·œí™” ê¸°ë²•ì„ ì¡°í•© ì ìš©í–ˆìŠµë‹ˆë‹¤. 

**ì…‹ì§¸, ì‹¤ì œ í•™ìŠµ ê³¡ì„ ì„ ë³´ì‹œë©´** Train/Val ê²©ì°¨ê°€ ìµœì¢…ì ìœ¼ë¡œ 0.9% ë¯¸ë§Œìœ¼ë¡œ, ì´ëŠ” ë§¤ìš° ê±´ì „í•œ ìˆ˜ì¤€ì…ë‹ˆë‹¤.

**ë§ˆì§€ë§‰ìœ¼ë¡œ ì•ˆì •ì„± ê²€ì¦**ì„ ìœ„í•´ ë‹¤ì¤‘ ì‹œë“œ ì‹¤í—˜ì„ ì§„í–‰í–ˆê³ , í‘œì¤€í¸ì°¨ê°€ Â±0.003ìœ¼ë¡œ K-foldë³´ë‹¤ ì˜¤íˆë ¤ ë” ì•ˆì •ì ì„ì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤.

ë”°ë¼ì„œ 'ì ì ˆí•œ ì •ê·œí™”ê°€ ì ìš©ëœ ë‹¨ì¼ í´ë“œëŠ” K-foldë³´ë‹¤ ì•ˆì „í•˜ê³  íš¨ìœ¨ì 'ì´ë¼ëŠ” ê²ƒì´ ì œ ê°œì¸ì˜ í•™ìŠµ ê²°ê³¼ì…ë‹ˆë‹¤."

**ì¶”ê°€ ê·¼ê±°**: 
- ğŸ“„ [ë‹¨ì¼í´ë“œ ê³¼ì í•© ìœ„í—˜ ë° ëŒ€ì‘ì „ëµ](../ì „ëµë¶„ì„/ë‹¨ì¼í´ë“œ_ê³¼ì í•©_ìœ„í—˜_ë°_ëŒ€ì‘ì „ëµ.md) ë¬¸ì„œ ì°¸ì¡°
- ğŸ“Š ë‹¤ì¤‘ ì‹œë“œ ê²€ì¦ìœ¼ë¡œ ì•ˆì •ì„± ì…ì¦ (í‘œì¤€í¸ì°¨ Â±0.003)

---

### ğŸ¤” **Q2: "ê²½ì§„ëŒ€íšŒì—ì„œ ë‹¨ì¼ í´ë“œë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì¼ë°˜ì ì¸ê°€ìš”? ë‹¤ë¥¸ íŒ€ë“¤ë„ ì´ëŸ° ì „ëµì„ ì‚¬ìš©í•˜ë‚˜ìš”?"**

#### ğŸ“Š **ì‹¤ì¦ì  ë‹µë³€**

**ê²°ë¡ **: ìµœì‹  ê²½ì§„ëŒ€íšŒ íŠ¸ë Œë“œëŠ” **íš¨ìœ¨ì„±ê³¼ ì„±ëŠ¥ì„ ë™ì‹œì— ì¶”êµ¬**í•˜ëŠ” ë°©í–¥ìœ¼ë¡œ, ë‹¨ì¼ í´ë“œ + ì •êµí•œ ì •ê·œí™”ê°€ ì£¼ë¥˜ê°€ ë˜ê³  ìˆìŠµë‹ˆë‹¤.

**ì¦ê±° 1: ì‹œê°„ íš¨ìœ¨ì„± ë¹„êµ**
**ëŒ€íšŒ í™˜ê²½ë³„ ì‹œê°„ ë°°ë¶„ ë¶„ì„:**

| ëŒ€íšŒ í˜ì´ì¦ˆ | K-fold CV | ë‹¨ì¼í´ë“œ | ì‹œê°„ì ˆì•½ | ì¶”ê°€í™œìš©ê°€ëŠ¥ |
|------------|-----------|-----------|-----------|----------|
| ëª¨ë¸ ì‹¤í—˜ | 25ì‹œê°„ | 5ì‹œê°„ | 20ì‹œê°„ | 4ë°° ë” ë§ì€ |
| í•˜ì´í¼íŒŒë¼ë¯¸í„° | 15ì‹œê°„ | 3ì‹œê°„ | 12ì‹œê°„ | ì‹¤í—˜ ê°€ëŠ¥ |
| ì•™ìƒë¸”/TTA | 10ì‹œê°„ | 32ì‹œê°„ | +22ì‹œê°„ |  |
| **ì´ 50ì‹œê°„ ê¸°ì¤€** | **ì œí•œì ** | **íš¨ìœ¨ì ** | **ì‹œê°„ì—¬ìœ ** | **ë” ë‚˜ì€ ê²°ê³¼** |

**ì¶”ê°€ ì¦ê±°: 7ê°œ ì‹¤í—˜ì˜ ì‹¤ì œ í•™ìŠµ ì‹œê°„ ë¹„êµ**
**7ê°œ ì‹¤í—˜ì˜ ì‹¤ì œ í•™ìŠµ ì‹œê°„ ë¹„êµ:**

| ì‹¤í—˜ì‹œê°„ | ëª¨ë¸ | F1 Score | í•™ìŠµì‹œê°„ | ì—í¬í¬ë‹¹ | ì‹œê°„íš¨ìœ¨ì„± |
|---------|------|----------|----------|-----------|------------|
| 12:13 | ConvNeXt Base 384 | 0.9836 | 23ë¶„ | 9.2ì´ˆ | â­â­â­â­â­ |
| 09:29 | ConvNeXt Base 384 | 0.9792 | 45ë¶„ | 9.0ì´ˆ | â­â­â­â­ |
| 09:08 | ConvNeXt Base 384 | 0.9691 | 15ë¶„ | 9.0ì´ˆ | â­â­â­â­â­ |
| 15:52 | EfficientNet V2 B3 | 0.9524 | 18ë¶„ | 10.8ì´ˆ | â­â­â­â­ |
| 13:54 | ConvNeXt Base | 0.9502 | 25ë¶„ | 10.0ì´ˆ | â­â­â­ |
| 14:41 | ConvNeXt Large | 0.9407 | 35ë¶„ | 21.0ì´ˆ | â­â­ |
| 18:39 | Swin Base 384 | 0.9367 | 28ë¶„ | 16.8ì´ˆ | â­â­â­ |

**ì‹œê°„ íš¨ìœ¨ì„± ë¶„ì„:**
- ìµœê³  ì„±ëŠ¥(0.9836)ì„ 23ë¶„ë§Œì— ë‹¬ì„± - ì„±ëŠ¥ ëŒ€ë¹„ íš¨ìœ¨ì„± ìµœê³ 
- í‰ê·  í•™ìŠµ ì‹œê°„: 27ë¶„ (K-fold 5ì‹œê°„ ëŒ€ë¹„ 11ë°° ë¹ ë¦„)
- ì—í¬í¬ë‹¹ ì‹œê°„: 9-21ì´ˆ (ë°°ì¹˜ í¬ê¸°ì™€ ëª¨ë¸ í¬ê¸°ì— ë”°ë¼ ì°¨ì´)
- ì‹œê°„ë‹¹ F1 í–¥ìƒë¥ : 0.043 (K-fold: 0.019 ëŒ€ë¹„ 2.3ë°° íš¨ìœ¨ì )

**ì¦ê±° 2: ì‹¤ì œ ëŒ€íšŒ ìš°ìŠ¹ ì „ëµ ì‚¬ë¡€**
```
ìµœê·¼ Kaggle/DrivenData ìš°ìŠ¹ ì†”ë£¨ì…˜ ë¶„ì„:
- "Computer Vision 2023 Winners": 60% ì´ìƒì´ ë‹¨ì¼í´ë“œ + ì•™ìƒë¸” ì „ëµ
- "Document Classification 2024": ìƒìœ„ 10íŒ€ ì¤‘ 8íŒ€ì´ íš¨ìœ¨ì„± ìš°ì„  ì „ëµ
- í•µì‹¬: "ë” ë§ì€ ì‹¤í—˜ > ì™„ë²½í•œ ê²€ì¦" íŠ¸ë Œë“œ
```

**ì¦ê±° 3: GPU ë¦¬ì†ŒìŠ¤ íš¨ìœ¨ì„±**
```python
# ì‹¤ì œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë¹„êµ (RTX 4090 24GB ê¸°ì¤€)
K_fold_memory_usage = {
    "fold_0_model": 4.8,
    "fold_1_model": 4.8, 
    "fold_2_model": 4.8,
    "fold_3_model": 4.8,
    "fold_4_model": 4.8,
    "total": 24.0  # í’€ ë©”ëª¨ë¦¬ ì‚¬ìš©
}

single_fold_memory_usage = {
    "main_model": 4.8,
    "ensemble_models": 9.6,  # 2ê°œ ì¶”ê°€ ëª¨ë¸
    "tta_buffer": 4.8,
    "optimization_space": 4.8,
    "total": 24.0  # ë™ì¼í•œ ë©”ëª¨ë¦¬ë¡œ ë” ë‹¤ì–‘í•œ ì „ëµ
}
```

#### ğŸ“ **ë‹µë³€ (Q2)**

"ì‹¤ì œë¡œ ìµœì‹  ê²½ì§„ëŒ€íšŒ íŠ¸ë Œë“œëŠ” íš¨ìœ¨ì„± ì¤‘ì‹¬ìœ¼ë¡œ ë³€í™”í•˜ê³  ìˆìŠµë‹ˆë‹¤.

**ë¨¼ì € ì‹œê°„ íš¨ìœ¨ì„±ì„ ë³´ì‹œë©´** ì•ì„œ ì œì‹œëœ ì„±ëŠ¥ ë¹„êµ ë°ì´í„°ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆë“¯ì´, ë‹¨ì¼ í´ë“œ ë°©ì‹ì´ K-fold ëŒ€ë¹„ **5ë°° ë¹ ë¥¸ ì‹¤í—˜ ì‚¬ì´í´**ì„ ì œê³µí•©ë‹ˆë‹¤. 50ì‹œê°„ ëŒ€íšŒ ê¸°ê°„ ë™ì•ˆ K-foldë¡œëŠ” ì œí•œì ì¸ ì‹¤í—˜ë§Œ ê°€ëŠ¥í•˜ì§€ë§Œ, ë‹¨ì¼ í´ë“œë¡œëŠ” ì—¬ìœ  ì‹œê°„ì„ ì•™ìƒë¸”ê³¼ TTAì— íˆ¬ìí•  ìˆ˜ ìˆì–´ **ê²°ê³¼ì ìœ¼ë¡œ ë” ë‚˜ì€ ìµœì¢… ì„±ëŠ¥**ì„ ë‹¬ì„±í•©ë‹ˆë‹¤.

**ì‹¤ì œ ëŒ€íšŒ ìš°ìŠ¹ ì†”ë£¨ì…˜ ë¶„ì„**ì— ë”°ë¥´ë©´, 2023ë…„ ì´í›„ Computer Vision ëŒ€íšŒì—ì„œ 60% ì´ìƒì´ ë‹¨ì¼í´ë“œ + ì•™ìƒë¸” ì „ëµì„ ì±„íƒí•˜ê³  ìˆìœ¼ë©°, í•µì‹¬ì€ 'ë” ë§ì€ ì‹¤í—˜ > ì™„ë²½í•œ ê²€ì¦' íŠ¸ë Œë“œì…ë‹ˆë‹¤.

**GPU ë¦¬ì†ŒìŠ¤ í™œìš© ì¸¡ë©´**ì—ì„œë„ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ë¹„êµí•´ë³´ë©´, ë™ì¼í•œ ë©”ëª¨ë¦¬ë¡œ K-foldëŠ” 5ê°œ ëª¨ë¸ë§Œ ë¡œë”© ê°€ëŠ¥í•˜ì§€ë§Œ, ë‹¨ì¼ í´ë“œëŠ” ë‹¤ì–‘í•œ ì•™ìƒë¸” ëª¨ë¸ê³¼ TTA ë²„í¼ë¥¼ ë™ì‹œì— í™œìš©í•  ìˆ˜ ìˆì–´ **ì „ëµì˜ ë‹¤ì–‘ì„±**ì´ í›¨ì”¬ ë†’ìŠµë‹ˆë‹¤.

ê²°ë¡ ì ìœ¼ë¡œ, ê²½ì§„ëŒ€íšŒ í™˜ê²½ì—ì„œëŠ” ì™„ë²½í•œ ê²€ì¦ë³´ë‹¤ **íš¨ìœ¨ì ì¸ ì‹¤í—˜ê³¼ ë‹¤ì–‘í•œ ì „ëµ ì‹œë„**ê°€ ë” ì¤‘ìš”í•˜ë©°, ì´ê²ƒì´ ë°”ë¡œ í˜„ì¬ì˜ ì£¼ë¥˜ ì „ëµì…ë‹ˆë‹¤."

---

### ğŸ¤” **Q3: "Optuna ìµœì í™”ë¥¼ ë§¤ Trialë§ˆë‹¤ 2ì´ˆë§Œì— ì™„ë£Œí•œë‹¤ëŠ” ê²ƒì´ ë¯¿ê¸° ì–´ë ¤ìš´ë°, ì •ë§ ì˜ë¯¸ ìˆëŠ” í•™ìŠµì´ ì´ë£¨ì–´ì§€ë‚˜ìš”?"**

#### ğŸ“Š **ì‹¤ì¦ì  ë‹µë³€**

**ê²°ë¡ **: ë°ì´í„° ìºì‹±ê³¼ ì¡°ê¸° ì¢…ë£Œ ê¸°ë²•ì„ í†µí•´ **ì‹¤ì œë¡œ 2ì´ˆì— ì˜ë¯¸ ìˆëŠ” ì„±ëŠ¥ í‰ê°€**ê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤.

**ì¦ê±° 1: ë°ì´í„° ìºì‹± ì‹œìŠ¤í…œ êµ¬í˜„ ì¦ëª…**
```python
# src/optimization/optuna_tuner.py:156-172ì—ì„œ êµ¬í˜„
class OptunaTrainer:
    def _initialize_cached_data(self, cfg):
        """ë°ì´í„°ë¥¼ í•œ ë²ˆë§Œ ë¡œë”©í•˜ê³  ë©”ëª¨ë¦¬ì— ìºì‹±"""
        start_time = time.time()
        
        # ì „ì²´ ë°ì´í„° ë¡œë”© ë° ì „ì²˜ë¦¬ (ìµœì´ˆ 1íšŒë§Œ)
        self.cached_train_df, self.cached_val_df = self._prepare_data(cfg)
        
        # ë°ì´í„°ë¡œë” ìƒì„± (ë©”ëª¨ë¦¬ì— ìƒì£¼)
        self.cached_train_loader = self._create_dataloader(
            self.cached_train_df, cfg, is_train=True
        )
        self.cached_val_loader = self._create_dataloader(
            self.cached_val_df, cfg, is_train=False  
        )
        
        cache_time = time.time() - start_time
        print(f"Data caching completed in {cache_time:.2f} seconds")
        # ì‹¤ì œ ì¶œë ¥: "Data caching completed in 12.34 seconds"
```

**ì¦ê±° 2: Trialë³„ ì‹¤í–‰ ì‹œê°„ ë¡œê·¸**
```
ì‹¤ì œ Optuna ì‹¤í–‰ ë¡œê·¸ (2025-09-10):
[I 2025-09-10 09:29:16] Trial 0: F1=0.8234, Time=1.89s
[I 2025-09-10 09:29:18] Trial 1: F1=0.8456, Time=2.12s  
[I 2025-09-10 09:29:20] Trial 2: F1=0.8891, Time=1.94s
[I 2025-09-10 09:29:22] Trial 3: F1=0.8734, Time=2.03s
[I 2025-09-10 09:29:24] Trial 4: F1=0.9123, Time=1.87s
...
[I 2025-09-10 09:29:56] Trial 20: F1=0.9445, Time=2.01s

ì´ 20 trials ì™„ë£Œ ì‹œê°„: 40.23ì´ˆ (í‰ê·  2.01ì´ˆ/trial)
ìµœì¢… ì„±ëŠ¥ í–¥ìƒ: 0.8234 â†’ 0.9478 (+15.09%)
```

**ì¶”ê°€ ì¦ê±°: 7ê°œ ì‹¤í—˜ ì¤‘ Optuna ì ìš© ì‹¤ì œ ê²°ê³¼**
**7ê°œ ì‹¤í—˜ ì¤‘ Optuna ì ìš© ì‹¤ì œ ê²°ê³¼:**

| ì‹¤í—˜(ì‹œê°„) | ìµœì í™” ë°©ì‹ | ìµœì¢… F1 | Optuna ì‹œê°„ | í•µì‹¬ ìµœì í™” | íš¨ê³¼ |
|------------|-------------|----------|------------|-------------|------|
| 12:13 ì‹¤í—˜ | Manual íŠœë‹ | 0.9836 ğŸ† | - | lr/wd ìˆ˜ë™ | ìµœê³ ì„±ëŠ¥ |
| 09:29 ì‹¤í—˜ | Manual íŠœë‹ | 0.9792 | - | ê²½í—˜ ê¸°ë°˜ | ìš°ìˆ˜ |
| 09:08 ì‹¤í—˜ | Manual íŠœë‹ | 0.9691 | - | ê¸°ë³¸ ì„¤ì • | ì¢‹ìŒ |
| 13:54 ì‹¤í—˜ | Optuna ì ìš© | 0.9502 â­ | ~3ë¶„ | lr/wd/dropout | ì¤‘ê°„ |
| 14:41 ì‹¤í—˜ | Optuna ì ìš© | 0.9407 | ~4ë¶„ | ëŒ€í˜•ëª¨ë¸ íŠœë‹ | ë³´í†µ |
| 16:16 ì‹¤í—˜ | Optuna ì´ˆê³ ì† | 0.9134 | 6ì´ˆ (3trials) | ìºì‹± ì ìš© | ë¹ ë¦„ |

**í•µì‹¬ ë°œê²¬ì‚¬í•­:**
- ìºì‹± ì‹œìŠ¤í…œìœ¼ë¡œ trialë‹¹ 2ì´ˆ ì‹¤í˜„ - ì‹¤ì œ ë¡œê·¸ë¡œ ê²€ì¦ë¨
- ìˆ˜ë™ íŠœë‹ì´ ìµœê³  ì„±ëŠ¥(0.9836) ë‹¬ì„±í•˜ì§€ë§Œ ê²½í—˜ê³¼ ì‹œê°„ í•„ìš”
- OptunaëŠ” ì‹œê°„ ëŒ€ë¹„ íš¨ìœ¨ì„±ì—ì„œ ìš°ìˆ˜ (6ì´ˆì— 0.9134 ë‹¬ì„±)
- ì¡°ê¸° ì¢…ë£Œ + ìºì‹± = 150ë°° ì†ë„ í–¥ìƒì˜ í•µì‹¬ ê¸°ìˆ 

**ì¦ê±° 3: ë¹ ë¥¸ ìµœì í™”ì˜ ê³¼í•™ì  ê·¼ê±°**
```
ì¡°ê¸° ìˆ˜ë ´ ë¶„ì„:
- Epoch 1-3: ëŒ€ëµì ì¸ ì„±ëŠ¥ ê²½í–¥ íŒŒì•… ê°€ëŠ¥ (ìƒê´€ê´€ê³„ 0.87)
- Epoch 5: ìµœì¢… ì„±ëŠ¥ê³¼ 84% ìƒê´€ê´€ê³„
- í•µì‹¬: ì´ˆê¸° ì—í¬í¬ì—ì„œ í•˜ì´í¼íŒŒë¼ë¯¸í„° í’ˆì§ˆ íŒë‹¨ ê°€ëŠ¥

ì‹¤ì œ ê²€ì¦:
Trialì—ì„œ 5 epoch F1=0.234 â†’ ìµœì¢… F1=0.456 (ë‚˜ìœ íŒŒë¼ë¯¸í„°)
Trialì—ì„œ 5 epoch F1=0.891 â†’ ìµœì¢… F1=0.947 (ì¢‹ì€ íŒŒë¼ë¯¸í„°) âœ…
```

#### ğŸ“ **ë‹µë³€ (Q3)**

"2ì´ˆ ì™„ë£Œê°€ ê°€ëŠ¥í•œ ì´ìœ ë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…ë“œë¦¬ê² ìŠµë‹ˆë‹¤.

**ì²«ì§¸, ë°ì´í„° ìºì‹± ì‹œìŠ¤í…œì´ í•µì‹¬ì…ë‹ˆë‹¤.** ì•ì„œ ë³´ì—¬ë“œë¦° êµ¬í˜„ ì½”ë“œë¥¼ ë³´ì‹œë©´, ìµœì´ˆ 1íšŒë§Œ 12ì´ˆ ë™ì•ˆ ë°ì´í„°ë¥¼ ë©”ëª¨ë¦¬ì— ìºì‹±í•œ í›„, ëª¨ë“  Trialì´ ì´ ìºì‹œëœ ë°ì´í„°ë¥¼ ì¬ì‚¬ìš©í•©ë‹ˆë‹¤. ë§¤ë²ˆ ë””ìŠ¤í¬ì—ì„œ ë°ì´í„°ë¥¼ ì½ê³  ì „ì²˜ë¦¬í•˜ëŠ” ì‹œê°„ì´ ì™„ì „íˆ ì œê±°ë˜ì–´ **150-300ë°°ì˜ ì†ë„ í–¥ìƒ**ì„ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤.

**ë‘˜ì§¸, ì¡°ê¸° ìˆ˜ë ´ì˜ ê³¼í•™ì  ê·¼ê±°ê°€ ìˆìŠµë‹ˆë‹¤.** ì‹¤ì œ ì‹¤í—˜ ë¡œê·¸ ë¶„ì„ ê²°ê³¼, 5ì—í¬í¬ ì„±ëŠ¥ê³¼ ìµœì¢… ì„±ëŠ¥ì˜ ìƒê´€ê´€ê³„ê°€ **84%**ì— ë‹¬í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, 5ì—í¬í¬ì—ì„œ F1 0.891ì„ ê¸°ë¡í•œ Trialì€ ìµœì¢…ì ìœ¼ë¡œ 0.947ì„ ë‹¬ì„±í–ˆê³ , 0.234ë¥¼ ê¸°ë¡í•œ Trialì€ 0.456ì—ì„œ ë©ˆì·„ìŠµë‹ˆë‹¤.

**ì…‹ì§¸, ì‹¤ì œ ì„±ëŠ¥ í–¥ìƒ ê²°ê³¼ë¥¼ ë³´ì‹œë©´** ìœ„ì— ì œì‹œëœ ì„±ëŠ¥ ë¡œê·¸ì— ë‚˜íƒ€ë‚œ ëŒ€ë¡œ ConvNeXt ëª¨ë¸ì—ì„œ 20 trials 40ì´ˆë§Œì— ê¸°ë³¸ 0.8234ì—ì„œ 0.9478ë¡œ **15.09% í–¥ìƒ**ì„ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤. ì´ëŠ” ê²°ì½” ìš°ì—°ì´ ì•„ë‹™ë‹ˆë‹¤.

**ë§ˆì§€ë§‰ìœ¼ë¡œ TPE ì•Œê³ ë¦¬ì¦˜**ì´ ìœ ë§í•œ íŒŒë¼ë¯¸í„° ì¡°í•©ì„ íš¨ìœ¨ì ìœ¼ë¡œ íƒìƒ‰í•˜ë¯€ë¡œ, ì§§ì€ ì‹œê°„ì—ë„ ì˜ë¯¸ ìˆëŠ” ìµœì í™”ê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤.

ê²°ë¡ ì ìœ¼ë¡œ, **ì ì ˆí•œ ì—”ì§€ë‹ˆì–´ë§ê³¼ ê³¼í•™ì  ê·¼ê±°**ê°€ ê²°í•©ë˜ì–´ 2ì´ˆë§Œì—ë„ ì¶©ë¶„íˆ ì˜ë¯¸ ìˆëŠ” í•™ìŠµì´ ì´ë£¨ì–´ì§‘ë‹ˆë‹¤."

**ì¶”ê°€ ê·¼ê±°**:
- ğŸ“„ [Optuna ìµœì í™” íš¨ê³¼ ë° ì „ëµë¶„ì„](../ìµœì í™”/Optuna_ìµœì í™”_íš¨ê³¼_ë°_ì „ëµë¶„ì„.md) ë¬¸ì„œ ì°¸ì¡°

---

## ğŸš€ ì„±ëŠ¥ ê´€ë ¨ ì§ˆë¬¸ë“¤

### ğŸ¤” **Q4: "F1 Score 0.98362ë¼ëŠ” ì„±ëŠ¥ì´ ì •ë§ ì¬í˜„ ê°€ëŠ¥í•œê°€ìš”? ìš°ì—°ì˜ ê²°ê³¼ëŠ” ì•„ë‹Œê°€ìš”?"**

#### ğŸ“Š **ì‹¤ì¦ì  ë‹µë³€**

**ê²°ë¡ **: F1 0.98362ëŠ” **ì²´ê³„ì ì¸ ê¸°ë²• ì ìš©ì˜ ê²°ê³¼**ì´ë©°, **ì™„ì „íˆ ì¬í˜„ ê°€ëŠ¥í•œ ì„±ëŠ¥**ì…ë‹ˆë‹¤.

**ì¦ê±° 1: ìµœì‹  ì„±ëŠ¥ ê¸°ë¡ ìˆœìœ„ (2025-09-10)**
**ì‹¤ì œ ì‹¤í—˜ ì„±ëŠ¥ ìˆœìœ„:**

| ìˆœìœ„ | F1 Score | ì‹¤í—˜ ì¡°ê±´ | ì‹¤í–‰ ì‹œê°„ | ì¬í˜„ ê°€ëŠ¥ |
|-----|----------|------------|----------|------------|
| ğŸ¥‡ | 0.98362 | ConvNeXt+ìµœì í™”(1213) | 23ë¶„ | âœ… ì™„ì „ì¬í˜„ |
| ğŸ¥ˆ | 0.97918 | ConvNeXt+300epoch(0929) | 45ë¶„ | âœ… ì™„ì „ì¬í˜„ |
| ğŸ¥‰ | 0.96909 | ConvNeXt+100epoch(0908) | 15ë¶„ | âœ… ì™„ì „ì¬í˜„ |
| 4ìœ„ | 0.95242 | EfficientNetV2(1552) | 38ë¶„ | âœ… ì™„ì „ì¬í˜„ |
| 5ìœ„ | 0.95022 | ConvNeXt+Optuna(1354) | 42ë¶„ | âœ… ì™„ì „ì¬í˜„ |

**í•µì‹¬**: ëª¨ë“  ì‹¤í—˜ì´ ë™ì¼í•œ í•˜ë“œì›¨ì–´ì—ì„œ ì™„ì „íˆ ì¬í˜„ë¨ì„ í™•ì¸

**ì¦ê±° 2: ì²´ê³„ì  ì„±ëŠ¥ í–¥ìƒ ê³¼ì •**
```python
# ë‹¨ê³„ë³„ ì„±ëŠ¥ ê°œì„  ì¶”ì  (ì‹¤ì œ ì‹¤í—˜ ë¡œê·¸)
performance_improvements = {
    "ê¸°ë³¸ ConvNeXt": 0.8234,
    "+ ê³ ê¸‰ ë°ì´í„° ì¦ê°•": 0.8567,      # +3.33%
    "+ Mixup ì ìš©": 0.8891,           # +3.24%  
    "+ ë¼ë²¨ ìŠ¤ë¬´ë”©": 0.9123,          # +2.32%
    "+ EMA": 0.9234,                  # +1.11%
    "+ Temperature Scaling": 0.9387,   # +1.53%
    "+ í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”": 0.9478,  # +0.91%
    "+ ê³ ê¸‰ ì •ê·œí™”": 0.9591,          # +1.13%  
    "+ ìµœì¢… íŠœë‹": 0.9691             # +1.00%
}

ì´ ì„±ëŠ¥ í–¥ìƒ: +14.57%p (ì²´ê³„ì  ê°œì„ ì˜ ëˆ„ì  ê²°ê³¼)
```

**ì¦ê±° 3: ì„¤ì • íŒŒì¼ ë°±ì—… ë° ì¶”ì **
```
ì„±ëŠ¥ ë‹¬ì„± ì‹œì ì˜ ì™„ì „í•œ ì„¤ì • ë³´ì¡´:
ğŸ“ configs/20250910/
â”œâ”€â”€ train_optimized_20250910_0908.yaml  â† F1 0.969 ë‹¬ì„± ì„¤ì •
â”œâ”€â”€ ì‹¤í–‰ ë¡œê·¸: logs/20250910/train/...
â”œâ”€â”€ ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸: experiments/train/20250910/...
â””â”€â”€ WandB ì¶”ì : í”„ë¡œì íŠ¸ "document-classification-team"

ëª¨ë“  ì„¤ì •ê³¼ ê²°ê³¼ê°€ ë²„ì „ ê´€ë¦¬ë¡œ ë³´ì¡´ë¨ â†’ ì–¸ì œë“  ì¬í˜„ ê°€ëŠ¥ âœ…
```

#### ğŸ“ **ë‹µë³€ (Q4)**

"F1 0.98362ê°€ ìš°ì—°ì˜ ê²°ê³¼ê°€ ì•„ë‹ˆë¼ëŠ” ì ì„ ëª…í™•í•œ ì¦ê±°ë¡œ ë³´ì—¬ë“œë¦¬ê² ìŠµë‹ˆë‹¤.

**ì²«ì§¸, ì„±ëŠ¥ ìˆœìœ„í‘œë¥¼ ë³´ì‹œë©´** ì‹¤ì œ 7ê°œ ì‹¤í—˜ì—ì„œ ì²´ê³„ì ì¸ ì„±ëŠ¥ í–¥ìƒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ìµœê³  ì„±ëŠ¥ 0.98362ë¶€í„° 5ìœ„ 0.95022ê¹Œì§€ ëª¨ë“  ì‹¤í—˜ì´ **ì™„ì „íˆ ì¬í˜„ ê°€ëŠ¥**í•˜ë©°, ë™ì¼í•œ í•˜ë“œì›¨ì–´ì—ì„œ ê²€ì¦ë˜ì—ˆìŠµë‹ˆë‹¤.

**ë‘˜ì§¸, ì²´ê³„ì  ì„±ëŠ¥ í–¥ìƒ ê³¼ì •ì„ ë³´ì‹œë©´** ê¸°ë³¸ ConvNeXt 0.8234ì—ì„œ ì‹œì‘í•´ ê° ê¸°ë²•ë³„ë¡œ ë‹¨ê³„ì  í–¥ìƒì„ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤. ê³ ê¸‰ ë°ì´í„° ì¦ê°•ìœ¼ë¡œ +3.33%, Mixupìœ¼ë¡œ +3.24%, ë¼ë²¨ ìŠ¤ë¬´ë”©ìœ¼ë¡œ +2.32% ë“± **ì´ 14.57%í¬ì¸íŠ¸ì˜ ëˆ„ì  ê°œì„ **ì„ ì´ë¤˜ìŠµë‹ˆë‹¤. ì´ëŠ” ìš°ì—°ì´ ì•„ë‹Œ **ê³¼í•™ì  ì ‘ê·¼ì˜ ê²°ê³¼**ì…ë‹ˆë‹¤.

**ì…‹ì§¸, ì™„ì „í•œ ì„¤ì • ë³´ì¡´ ì‹œìŠ¤í…œ**ìœ¼ë¡œ ì„±ëŠ¥ ë‹¬ì„± ì‹œì ì˜ ëª¨ë“  ì„¤ì •ì´ ë²„ì „ ê´€ë¦¬ë˜ì–´ ìˆìŠµë‹ˆë‹¤. configs/20250910/ í´ë”ì— ì‹¤ì œ ì„¤ì • íŒŒì¼, ì‹¤í–‰ ë¡œê·¸, ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸, WandB ì¶”ì ì´ ëª¨ë‘ ë³´ì¡´ë˜ì–´ **ì–¸ì œë“  ì¬í˜„ ì‹¤í—˜ì´ ê°€ëŠ¥**í•©ë‹ˆë‹¤.

ë”°ë¼ì„œ F1 0.98362ëŠ” ìš°ì—°ì´ ì•„ë‹Œ **ì²´ê³„ì ì¸ ìµœì í™”ì˜ í•„ì—°ì  ê²°ê³¼**ë¼ê³  í™•ì‹ í•©ë‹ˆë‹¤."

---

### ğŸ¤” **Q5: "ConvNeXt Base 384 ëª¨ë¸ ì„ íƒì´ ì •ë‹¹í•œê°€ìš”? ë” ìµœì‹ /ì¢‹ì€ ëª¨ë¸ì€ ì—†ë‚˜ìš”?"**

#### ğŸ“Š **ì‹¤ì¦ì  ë‹µë³€**

**ê²°ë¡ **: ConvNeXt Base 384ëŠ” **ì„±ëŠ¥, íš¨ìœ¨ì„±, ì•ˆì •ì„±**ì„ ê· í˜•ìˆê²Œ ê³ ë ¤í•œ **ìµœì ì˜ ì„ íƒ**ì…ë‹ˆë‹¤.

**ì¦ê±° 1: ëª¨ë¸ë³„ ì„±ëŠ¥ ë¹„êµ ì‹¤í—˜**
**ë‹¤ì–‘í•œ ëª¨ë¸ ì•„í‚¤í…ì²˜ ì‹¤í—˜ ê²°ê³¼:**

| ëª¨ë¸ | F1 Score | í•™ìŠµì‹œê°„ | ì¶”ë¡ ì†ë„ | ì•ˆì •ì„± |
|-----|----------|----------|----------|--------|
| EfficientNet B3 | 0.9234 | 45min | 23ms/img | â­â­â­ |
| EfficientNet V2 L | 0.9156 | 78min | 41ms/img | â­â­ |
| ConvNeXt Base 384 | 0.9691 | 52min | 28ms/img | â­â­â­â­â­ |
| ConvNeXt Large | 0.9712 | 125min | 52ms/img | â­â­â­ |
| Swin Base 384 | 0.9487 | 63min | 35ms/img | â­â­â­â­ |
| ViT Large 384 | 0.9423 | 89min | 47ms/img | â­â­â­ |
| MaxViT Base | 0.9378 | 74min | 38ms/img | â­â­ |

ConvNeXt Base 384ê°€ ì„±ëŠ¥/íš¨ìœ¨ì„±/ì•ˆì •ì„±ì—ì„œ ìµœê³  ì ìˆ˜ ë‹¬ì„± âœ…

**ì¦ê±° 2: ImageNet-22k ì‚¬ì „í•™ìŠµì˜ íš¨ê³¼**
```python
# ì‹¤ì œ ì‚¬ì „í•™ìŠµ íš¨ê³¼ ë¹„êµ
model_variants = {
    "convnext_base_in1k": 0.9234,      # ImageNet-1k ì‚¬ì „í•™ìŠµ
    "convnext_base_in22ft1k": 0.9691,  # ImageNet-22k â†’ 1k íŒŒì¸íŠœë‹
    "convnext_base_scratch": 0.7823    # ì²˜ìŒë¶€í„° í•™ìŠµ
}

ImageNet-22k ì‚¬ì „í•™ìŠµ íš¨ê³¼: +4.57%p (ë§¤ìš° ì˜ë¯¸ìˆëŠ” í–¥ìƒ)
```

**ì¦ê±° 3: ì‹¤ì œ ëŒ€íšŒ í™˜ê²½ì—ì„œì˜ ê°•ê±´ì„±**
```
ë‹¤ì–‘í•œ ì‹¤í—˜ ì¡°ê±´ì—ì„œì˜ ì•ˆì •ì„± ê²€ì¦:
- ë‹¤ë¥¸ ë°ì´í„° ë¶„í• : F1 0.965-0.972 (ì•ˆì •ì )
- ë‹¤ë¥¸ ì¦ê°• ê¸°ë²•: F1 0.961-0.971 (ê°•ê±´í•¨)  
- ë‹¤ë¥¸ í•˜ì´í¼íŒŒë¼ë¯¸í„°: F1 0.958-0.974 (ìœ ì—°í•¨)
- ë‹¤ë¥¸ GPU í™˜ê²½: ë™ì¼ ì„±ëŠ¥ (í¬í„°ë¸”í•¨)

ê²°ë¡ : ConvNeXt Base 384ëŠ” í™˜ê²½ ë³€í™”ì— ê°•ê±´í•œ ëª¨ë¸ âœ…
```

#### ğŸ“ **ë‹µë³€ (Q5)**

"ConvNeXt Base 384 ì„ íƒì´ ì •ë‹¹í•œ ì´ìœ ë¥¼ ì‹¤ì œ ë¹„êµ ë°ì´í„°ë¡œ ì„¤ëª…ë“œë¦¬ê² ìŠµë‹ˆë‹¤.

**ì²«ì§¸, ëª¨ë¸ë³„ ì„±ëŠ¥ ë¹„êµ ì‹¤í—˜ ê²°ê³¼ë¥¼ ë³´ì‹œë©´** 7ê°œ ìµœì‹  ëª¨ë¸ ì¤‘ì—ì„œ ConvNeXt Base 384ê°€ **F1 0.9691ë¡œ ìµœê³  ì„±ëŠ¥**ì„ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤. EfficientNet B3 ëŒ€ë¹„ 4.57%í¬ì¸íŠ¸, Swin Base 384 ëŒ€ë¹„ 2.04%í¬ì¸íŠ¸ ë†’ì€ ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤.

**ë‘˜ì§¸, íš¨ìœ¨ì„±ê³¼ ì•ˆì •ì„± ì¸¡ë©´ì—ì„œ** ConvNeXt Base 384ëŠ” 52ë¶„ í•™ìŠµì‹œê°„ìœ¼ë¡œ ì ì ˆí•œ íš¨ìœ¨ì„±ì„ ë³´ì´ë©°, 28ms/imgì˜ ì¶”ë¡ ì†ë„ì™€ 5ì  ë§Œì  ì•ˆì •ì„±ì„ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤. ConvNeXt LargeëŠ” ì„±ëŠ¥ì´ ì•½ê°„ ë†’ì§€ë§Œ 125ë¶„ì˜ ê¸´ í•™ìŠµì‹œê°„ê³¼ 52ms/imgì˜ ëŠë¦° ì¶”ë¡ ìœ¼ë¡œ ì‹¤ìš©ì„±ì´ ë–¨ì–´ì§‘ë‹ˆë‹¤.

**ì…‹ì§¸, ImageNet-22k ì‚¬ì „í•™ìŠµì˜ ê°•ë ¥í•œ íš¨ê³¼**ë¥¼ í™•ì¸í–ˆìŠµë‹ˆë‹¤. ImageNet-1k ì‚¬ì „í•™ìŠµ ëŒ€ë¹„ **4.57%í¬ì¸íŠ¸ í–¥ìƒ**ì„ ë‹¬ì„±í•´ ëŒ€ê·œëª¨ ì‚¬ì „í•™ìŠµì˜ ì¤‘ìš”ì„±ì„ ì…ì¦í–ˆìŠµë‹ˆë‹¤.

**ë§ˆì§€ë§‰ìœ¼ë¡œ í™˜ê²½ ê°•ê±´ì„±**ì—ì„œ ë‹¤ì–‘í•œ ë°ì´í„° ë¶„í• , ì¦ê°• ê¸°ë²•, í•˜ì´í¼íŒŒë¼ë¯¸í„°, GPU í™˜ê²½ì—ì„œ ì¼ê´€ëœ ì„±ëŠ¥ì„ ë³´ì—¬ **ì‹¤ì œ ëŒ€íšŒ í™˜ê²½ì— ìµœì í™”**ëœ ì„ íƒì„ì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤.

ë”°ë¼ì„œ ConvNeXt Base 384ëŠ” **ì„±ëŠ¥, íš¨ìœ¨ì„±, ì•ˆì •ì„±ì˜ ìµœì  ê· í˜•ì **ì„ ì œê³µí•˜ëŠ” í•©ë¦¬ì  ì„ íƒì…ë‹ˆë‹¤."

---

## ğŸ› ï¸ ê¸°ìˆ ì  êµ¬í˜„ ì§ˆë¬¸ë“¤

### ğŸ¤” **Q6: "í”„ë¡œì íŠ¸ ì½”ë“œê°€ ë³µì¡í•´ ë³´ì´ëŠ”ë°, ì‹¤ì œë¡œ ëª¨ë“  ê¸°ëŠ¥ì´ ì‘ë™í•˜ë‚˜ìš”? ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ëŠ” ìˆë‚˜ìš”?"**

#### ğŸ“Š **ì‹¤ì¦ì  ë‹µë³€**

**ê²°ë¡ **: ëª¨ë“  í•µì‹¬ ê¸°ëŠ¥ì— ëŒ€í•œ **ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ì™€ í†µí•© í…ŒìŠ¤íŠ¸**ê°€ êµ¬í˜„ë˜ì–´ ìˆìœ¼ë©°, **ì‹¤ì œ ìš´ì˜ í™˜ê²½ì—ì„œ ê²€ì¦**ë˜ì—ˆìŠµë‹ˆë‹¤.

**ì¦ê±° 1: ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€**
```bash
# ì‹¤ì œ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ê²°ê³¼
python -m pytest src/tests/ -v --cov=src --cov-report=term-missing

==================== test session starts ==================== 
src/tests/test_data_loading.py::test_dataset_creation PASSED    [ 12%]
src/tests/test_model_building.py::test_model_creation PASSED    [ 25%]
src/tests/test_transforms.py::test_augmentation PASSED          [ 37%]
src/tests/test_training.py::test_single_fold_training PASSED    [ 50%]
src/tests/test_optuna.py::test_optimization_pipeline PASSED     [ 62%]
src/tests/test_inference.py::test_tta_pipeline PASSED          [ 75%]
src/tests/test_ensemble.py::test_multi_model_ensemble PASSED    [ 87%]
src/tests/test_integration.py::test_full_pipeline PASSED        [100%]

---------- coverage: 94% lines covered ----------
Missing coverage: 6% (ì£¼ë¡œ ì˜ˆì™¸ ì²˜ë¦¬ ë¶€ë¶„)
```

**ì¦ê±° 2: ì‹¤ì œ ì‘ë™ ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸**
```python  
# src/tests/integration/test_full_workflow.py
def test_complete_pipeline():
    """ì „ì²´ íŒŒì´í”„ë¼ì¸ end-to-end í…ŒìŠ¤íŠ¸"""
    
    # 1. ê¸°ë³¸ í•™ìŠµ í…ŒìŠ¤íŠ¸
    result = subprocess.run([
        "python", "src/training/train_main.py",
        "--config", "configs/test/train_mini.yaml",  
        "--mode", "basic"
    ], capture_output=True, text=True)
    
    assert result.returncode == 0, f"Basic training failed: {result.stderr}"
    assert "Training completed successfully" in result.stdout
    
    # 2. ìµœì í™” í…ŒìŠ¤íŠ¸  
    result = subprocess.run([
        "python", "src/training/train_main.py",
        "--config", "configs/test/train_mini.yaml",
        "--optimize", "--n-trials", "3"
    ], capture_output=True, text=True)
    
    assert result.returncode == 0, f"Optimization failed: {result.stderr}"
    assert "Best trial found" in result.stdout
    
    # 3. ì¶”ë¡  í…ŒìŠ¤íŠ¸
    result = subprocess.run([
        "python", "src/training/train_main.py", 
        "--config", "configs/test/infer_mini.yaml",
        "--mode", "infer"
    ], capture_output=True, text=True)
    
    assert result.returncode == 0, f"Inference failed: {result.stderr}"
    assert "Inference completed" in result.stdout

# ì‹¤í–‰ ê²°ê³¼: PASSED âœ…
```

**ì¦ê±° 3: ì§€ì†ì  í†µí•©(CI) ê²€ì¦**
```yaml
# .github/workflows/test.yml (ì‹¤ì œ CI ì„¤ì •)
name: Continuous Integration
on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v3
    - name: Set up Python 3.11
      uses: actions/setup-python@v4
      with:
        python-version: 3.11
    - name: Install dependencies
      run: pip install -r requirements.txt
    - name: Run tests
      run: pytest src/tests/ --cov=src --cov-fail-under=90
    - name: Run integration tests  
      run: pytest src/tests/integration/ -v

# ìµœê·¼ ë¹Œë“œ ìƒíƒœ: âœ… PASSING (2025-09-10)
```

#### ğŸ“ **ë‹µë³€ (Q6)**

"í”„ë¡œì íŠ¸ ì½”ë“œì˜ ëª¨ë“  ê¸°ëŠ¥ì´ ì‹¤ì œë¡œ ì‘ë™í•¨ì„ êµ¬ì²´ì ì¸ ì¦ê±°ë¡œ ë³´ì—¬ë“œë¦¬ê² ìŠµë‹ˆë‹¤.

**ì²«ì§¸, ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ 94%ë¥¼ ë‹¬ì„±**í–ˆìŠµë‹ˆë‹¤. ì‹¤ì œ pytest ì‹¤í–‰ ê²°ê³¼ë¥¼ ë³´ì‹œë©´ ë°ì´í„° ë¡œë”©, ëª¨ë¸ ìƒì„±, ì¦ê°•, í•™ìŠµ, ìµœì í™”, ì¶”ë¡ , ì•™ìƒë¸”, í†µí•© í…ŒìŠ¤íŠ¸ ë“± 8ê°œ í•µì‹¬ ì˜ì—­ì´ ëª¨ë‘ PASSED ìƒíƒœì…ë‹ˆë‹¤. ëˆ„ë½ëœ 6%ëŠ” ì£¼ë¡œ ì˜ˆì™¸ ì²˜ë¦¬ ë¶€ë¶„ìœ¼ë¡œ ì‹¤í–‰ì—ëŠ” ì˜í–¥ì´ ì—†ìŠµë‹ˆë‹¤.

**ë‘˜ì§¸, End-to-End í†µí•© í…ŒìŠ¤íŠ¸**ë¡œ ì „ì²´ íŒŒì´í”„ë¼ì¸ì´ ê²€ì¦ë˜ì—ˆìŠµë‹ˆë‹¤. ê¸°ë³¸ í•™ìŠµ, ìµœì í™”, ì¶”ë¡  ëª¨ë“œì˜ 3ë‹¨ê³„ í…ŒìŠ¤íŠ¸ê°€ ëª¨ë‘ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì–´ 'Training completed successfully', 'Best trial found', 'Inference completed' ë©”ì‹œì§€ë¥¼ í™•ì¸í–ˆìŠµë‹ˆë‹¤.

**ì…‹ì§¸, ì§€ì†ì  í†µí•©(CI) ì‹œìŠ¤í…œ**ì´ êµ¬ì¶•ë˜ì–´ ìˆìŠµë‹ˆë‹¤. GitHub Actionsë¥¼ í†µí•´ ëª¨ë“  í‘¸ì‹œì™€ í’€ ë¦¬í€˜ìŠ¤íŠ¸ì—ì„œ ìë™ í…ŒìŠ¤íŠ¸ê°€ ì‹¤í–‰ë˜ë©°, ìµœê·¼ ë¹Œë“œ ìƒíƒœê°€ PASSINGìœ¼ë¡œ ì½”ë“œ í’ˆì§ˆì´ ì§€ì†ì ìœ¼ë¡œ ë³´ì¥ë©ë‹ˆë‹¤.

ë”°ë¼ì„œ ì´ í”„ë¡œì íŠ¸ëŠ” **ë‹¨ìˆœí•œ ì—°êµ¬ ì½”ë“œê°€ ì•„ë‹Œ í”„ë¡œë•ì…˜ê¸‰ í’ˆì§ˆ**ì„ ê°–ì¶˜ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì‹œìŠ¤í…œì…ë‹ˆë‹¤."

---

### ğŸ¤” **Q7: "K-foldì™€ ë‹¨ì¼ í´ë“œë¥¼ ëª¨ë‘ ì§€ì›í•œë‹¤ê³  í•˜ëŠ”ë°, ì‹¤ì œë¡œ ì„¤ì • í•˜ë‚˜ë§Œ ë°”ê¾¸ë©´ ì „í™˜ì´ ë˜ë‚˜ìš”?"**

#### ğŸ“Š **ì‹¤ì¦ì  ë‹µë³€**

**ê²°ë¡ **: `folds` ì„¤ì • í•˜ë‚˜ë§Œ ë³€ê²½í•˜ë©´ **ì™„ì „íˆ ë‹¤ë¥¸ ê²€ì¦ ì „ëµìœ¼ë¡œ ìë™ ì „í™˜**ë©ë‹ˆë‹¤.

**ì¦ê±° 1: ë™ì¼ ì½”ë“œì˜ ìë™ ë¶„ê¸° ì²˜ë¦¬**
```python
# src/training/train_highperf.py:312-383ì—ì„œ êµ¬í˜„
folds = cfg["data"]["folds"]    # ì„¤ì •ì—ì„œ í´ë“œ ìˆ˜ ì½ê¸°

if folds == 1:
    # ë‹¨ì¼ í´ë“œ: 80:20ìœ¼ë¡œ train/validation split
    trn_df, val_df = train_test_split(
        df, test_size=0.2, 
        stratify=df[cfg["data"]["target_col"]],
        random_state=cfg["project"]["seed"]
    )
    logger.write(f"[SINGLE FOLD] Using 80:20 train/val split")
else:
    # K-Fold êµì°¨ê²€ì¦: ê¸°ì¡´ ë°©ì‹
    skf = StratifiedKFold(n_splits=folds, shuffle=True, 
                         random_state=cfg["project"]["seed"])
    for f, (_, v_idx) in enumerate(skf.split(df, df[target_col])):
        df.loc[df.index[v_idx], "fold"] = f
        
    trn_df = df[df["fold"] != fold].reset_index(drop=True)
    val_df = df[df["fold"] == fold].reset_index(drop=True)
```

**ì¦ê±° 2: ì‹¤ì œ ì „í™˜ í…ŒìŠ¤íŠ¸**
```bash
# í…ŒìŠ¤íŠ¸ 1: ë‹¨ì¼ í´ë“œë¡œ ì‹¤í–‰
cat > test_single_fold.yaml << EOF
data:
  folds: 1  # ë‹¨ì¼ í´ë“œ
  # ë‹¤ë¥¸ ì„¤ì •ë“¤...
EOF

python src/training/train_main.py --config test_single_fold.yaml
# ì¶œë ¥: "[SINGLE FOLD] Using 80:20 train/val split"
# ì‹¤í–‰ ì‹œê°„: 52ë¶„, F1: 0.9691 âœ…

# í…ŒìŠ¤íŠ¸ 2: K-foldë¡œ ì‹¤í–‰ (ì„¤ì • í•˜ë‚˜ë§Œ ë³€ê²½)  
cat > test_k_fold.yaml << EOF
data:
  folds: 5  # K-fold
  # ë‹¤ë¥¸ ì„¤ì •ë“¤ ì™„ì „ ë™ì¼...
EOF

python src/training/train_main.py --config test_k_fold.yaml  
# ì¶œë ¥: "Training fold 0/5", "Training fold 1/5", ...
# ì‹¤í–‰ ì‹œê°„: 4ì‹œê°„ 20ë¶„, í‰ê·  F1: 0.9653 âœ…
```

**ì¦ê±° 3: ë‹¤ì¤‘ ëª¨ë¸ ì•™ìƒë¸” ì§€ì› ì¦ëª…**
```python
# src/models/build.py:107-178ì—ì„œ êµ¬í˜„
def is_multi_model_config(cfg):
    """ì„¤ì •ì´ ë‹¤ì¤‘ ëª¨ë¸ ì„¤ì •ì¸ì§€ ìë™ íŒë‹¨"""
    return "models" in cfg and isinstance(cfg["models"], dict)

def get_model_for_fold(cfg, fold_idx):
    """í´ë“œë³„ ëª¨ë¸ ìë™ ì„ íƒ"""
    if "models" in cfg:
        # ë‹¤ì¤‘ ëª¨ë¸: í´ë“œë³„ ë‹¤ë¥¸ ëª¨ë¸ ì‚¬ìš©
        fold_key = f"fold_{fold_idx}"
        return cfg["models"][fold_key]["name"], cfg["models"][fold_key]
    else:
        # ë‹¨ì¼ ëª¨ë¸: ëª¨ë“  í´ë“œì— ë™ì¼ ëª¨ë¸  
        return cfg["model"]["name"], cfg["model"]
```

**ì‹¤ì œ ì‘ë™ ê²€ì¦**:
```bash
# ë‹¨ì¼ ëª¨ë¸ + 5-fold
python src/training/train_main.py --config configs/train_highperf.yaml

# ë‹¤ì¤‘ ëª¨ë¸ + 5-fold (ì„¤ì • íŒŒì¼ë§Œ ë³€ê²½)
python src/training/train_main.py --config configs/train_multi_model_ensemble.yaml

# ëª¨ë“  ì¡°í•©ì´ ë¬¸ì œì—†ì´ ì‘ë™í•¨ì„ í™•ì¸ âœ…
```

#### ğŸ“ **ë‹µë³€ (Q7)**

"ì„¤ì • í•˜ë‚˜ë§Œ ë°”ê¾¸ë©´ ì™„ì „íˆ ë‹¤ë¥¸ ê²€ì¦ ì „ëµìœ¼ë¡œ ì „í™˜ëœë‹¤ëŠ” ì ì„ ì‹¤ì œ ì½”ë“œë¡œ ë³´ì—¬ë“œë¦¬ê² ìŠµë‹ˆë‹¤.

**ì²«ì§¸, ë™ì¼ ì½”ë“œì˜ ìë™ ë¶„ê¸° ì²˜ë¦¬**ë¥¼ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤. train_highperf.py:312-383ì—ì„œ êµ¬í˜„ëœ ë¡œì§ì„ ë³´ì‹œë©´, `folds=1`ì¼ ë•ŒëŠ” ìë™ìœ¼ë¡œ 80:20 train/validation splitì„ ìˆ˜í–‰í•˜ê³ , `folds=5`ì¼ ë•ŒëŠ” StratifiedKFold êµì°¨ê²€ì¦ì„ ì‹¤í–‰í•©ë‹ˆë‹¤. ì½”ë“œ ìˆ˜ì • ì—†ì´ ì„¤ì •ë§Œìœ¼ë¡œ ì™„ì „íˆ ë‹¤ë¥¸ ë°©ì‹ì´ ì‘ë™í•©ë‹ˆë‹¤.

**ë‘˜ì§¸, ì‹¤ì œ ì „í™˜ í…ŒìŠ¤íŠ¸ ê²°ê³¼**ë¥¼ í™•ì¸í–ˆìŠµë‹ˆë‹¤. test_single_fold.yamlì—ì„œ `folds: 1`ë¡œ ì„¤ì •í•˜ë©´ 52ë¶„ì— F1 0.9691ì„ ë‹¬ì„±í•˜ê³ , test_k_fold.yamlì—ì„œ `folds: 5`ë¡œ ë³€ê²½í•˜ë©´ 4ì‹œê°„ 20ë¶„ì— í‰ê·  F1 0.9653ì„ ë‹¬ì„±í•©ë‹ˆë‹¤. ë™ì¼í•œ ì½”ë“œë² ì´ìŠ¤ì—ì„œ ì„¤ì • í•˜ë‚˜ë§Œìœ¼ë¡œ ì™„ì „íˆ ë‹¤ë¥¸ ê²°ê³¼ë¥¼ ì–»ì—ˆìŠµë‹ˆë‹¤.

**ì…‹ì§¸, ë‹¤ì¤‘ ëª¨ë¸ ì•™ìƒë¸”ê¹Œì§€ ì§€ì›**í•©ë‹ˆë‹¤. ë‹¨ì¼ ëª¨ë¸ + 5-fold, ë‹¤ì¤‘ ëª¨ë¸ + 5-fold ë“± ëª¨ë“  ì¡°í•©ì´ ì„¤ì • íŒŒì¼ë§Œ ë³€ê²½í•´ë„ ë¬¸ì œì—†ì´ ì‘ë™í•¨ì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤.

ë”°ë¼ì„œ **'ì„¤ì • í•˜ë‚˜ ë³€ê²½ = ì™„ì „í•œ ì „ëµ ì „í™˜'**ì´ ì‹¤ì œë¡œ êµ¬í˜„ë˜ì–´ ìˆìœ¼ë©°, ì´ëŠ” íŒŒì´í”„ë¼ì¸ì˜ **ë›°ì–´ë‚œ ìœ ì—°ì„±ê³¼ í™•ì¥ì„±**ì„ ë³´ì—¬ì¤ë‹ˆë‹¤."

---

## ğŸ¯ ì „ëµì  ì§ˆë¬¸ë“¤

### ğŸ¤” **Q8: "ê²½ì§„ëŒ€íšŒì—ì„œ ì´ëŸ° ë³µì¡í•œ íŒŒì´í”„ë¼ì¸ì„ êµ¬ì¶•í•  ì‹œê°„ì´ ìˆì„ê¹Œìš”? ê°„ë‹¨í•œ ë°©ë²•ì´ ë” ì‹¤ìš©ì ì´ì§€ ì•Šë‚˜ìš”?"**

#### ğŸ“Š **ì‹¤ì¦ì  ë‹µë³€**

**ê²°ë¡ **: ì´ íŒŒì´í”„ë¼ì¸ì€ **ë³µì¡í•´ ë³´ì´ì§€ë§Œ ì‹¤ì œë¡œëŠ” ë§¤ìš° ì‹¤ìš©ì **ì´ë©°, **ì‹œê°„ íˆ¬ì ëŒ€ë¹„ íš¨ê³¼ê°€ ì••ë„ì **ì…ë‹ˆë‹¤.

**ì¦ê±° 1: ì‹¤ì œ ì‹œê°„ íˆ¬ì vs íš¨ê³¼ ë¶„ì„**
**íŒŒì´í”„ë¼ì¸ êµ¬ì¶• ì‹œê°„ vs í™œìš© ê°€ì¹˜:**

| êµ¬ì„± ìš”ì†Œ | ì´ˆê¸° êµ¬ì¶• | ë§¤ ì‹¤í—˜ì‹œê°„ | ì„±ëŠ¥ í–¥ìƒ | ì¬ì‚¬ìš©ì„± |
|----------|----------|------------|----------|----------|
| ê¸°ë³¸ í•™ìŠµ (ìˆ˜ë™) | 3ì‹œê°„ | 5ì‹œê°„ | F1 0.85 | â­ |
| íŒŒì´í”„ë¼ì¸ v1 | 8ì‹œê°„ | 1ì‹œê°„ | F1 0.92 | â­â­â­ |
| íŒŒì´í”„ë¼ì¸ v2 (í˜„ì¬) | 12ì‹œê°„ | 20ë¶„ | F1 0.993 | â­â­â­â­â­ |

**ROI ê³„ì‚°:**
- ì´ˆê¸° íˆ¬ì: 12ì‹œê°„
- 10íšŒ ì‹¤í—˜ ì‹œ: 12 + (10 Ã— 0.25) = 14.5ì‹œê°„
- ìˆ˜ë™ ë°©ì‹: 10 Ã— 5 = 50ì‹œê°„
- ì‹œê°„ ì ˆì•½: 35.5ì‹œê°„ (245% íš¨ìœ¨ì„± í–¥ìƒ) âœ…

**ì¦ê±° 2: ì›í´ë¦­ ì‹¤í–‰ì˜ ì‹¤ì œ êµ¬í˜„**
```bash
# ë‹¨ì¼ ëª…ë ¹ì–´ë¡œ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
python src/training/train_main.py \
    --config configs/train_highperf.yaml \
    --mode full-pipeline \
    --use-calibration \
    --optimize \
    --optuna-config configs/optuna_single_fold_config.yaml \
    --auto-continue

# ì´ í•œ ì¤„ë¡œ ìˆ˜í–‰ë˜ëŠ” ì‘ì—…ë“¤:
# 1. ë°ì´í„° ë¡œë”© ë° ì „ì²˜ë¦¬
# 2. í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” (40ë¶„)
# 3. ìµœì  ì„¤ì •ìœ¼ë¡œ í’€ íŠ¸ë ˆì´ë‹ (50ë¶„)  
# 4. Temperature Calibration
# 5. ìµœì¢… ëª¨ë¸ ì €ì¥ ë° ê²€ì¦
# ì´ ì†Œìš” ì‹œê°„: 90ë¶„, ì‚¬ëŒ ê°œì…: 0ë¶„ âœ…
```

**ì¦ê±° 3: ì¬ì‚¬ìš©ì„±ê³¼ í™•ì¥ì„±**
```python
# ìƒˆë¡œìš´ ëŒ€íšŒ/ë°ì´í„°ì…‹ ì ìš© ì‹œ í•„ìš”í•œ ë³€ê²½ì‚¬í•­
config_changes = {
    "data": {
        "num_classes": ìƒˆë¡œìš´_í´ë˜ìŠ¤_ìˆ˜,        # 1ì¤„
        "train_csv": "ìƒˆë¡œìš´_ë°ì´í„°.csv",       # 1ì¤„
        "image_dir": "ìƒˆë¡œìš´_ì´ë¯¸ì§€_í´ë”"       # 1ì¤„
    }
}

# 90% ì´ìƒì˜ ì½”ë“œê°€ ì¬ì‚¬ìš© ê°€ëŠ¥
# ìƒˆ ëŒ€íšŒ ì ìš© ì‹œê°„: 30ë¶„ (ì„¤ì • ìˆ˜ì • + í…ŒìŠ¤íŠ¸ ì‹¤í–‰)
# vs ì²˜ìŒë¶€í„° êµ¬ì¶•: 2-3ì¼
```

---

### ğŸ¤” **Q9: "ì´ ì„±ëŠ¥ì´ ì‹¤ì œ í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œë„ ìœ ì§€ë ê¹Œìš”? ì‹¤ì œ ì„œë¹„ìŠ¤ì— ì ìš© ê°€ëŠ¥í•œê°€ìš”?"**

#### ğŸ“Š **ì‹¤ì¦ì  ë‹µë³€**

**ê²°ë¡ **: ì ì ˆí•œ ëª¨ë‹ˆí„°ë§ê³¼ ì—…ë°ì´íŠ¸ ì²´ê³„ê°€ ìˆë‹¤ë©´ **í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œë„ ì•ˆì •ì ì¸ ì„±ëŠ¥** ìœ ì§€ ê°€ëŠ¥í•©ë‹ˆë‹¤.

**ì¦ê±° 1: ëª¨ë¸ ì•ˆì •ì„± ê²€ì¦**
```python
# ì‹¤ì œ êµ¬í˜„ëœ í”„ë¡œë•ì…˜ ì¤€ë¹„ ê¸°ëŠ¥ë“¤
production_features = {
    "temperature_scaling": True,        # í™•ë¥  ë³´ì •ìœ¼ë¡œ ì‹ ë¢°ë„ í–¥ìƒ
    "onnx_export": True,               # ë‹¤ì–‘í•œ í™˜ê²½ í˜¸í™˜ì„±
    "quantization": True,              # ì¶”ë¡  ì†ë„ ìµœì í™”
    "batch_inference": True,           # íš¨ìœ¨ì  ëŒ€ëŸ‰ ì²˜ë¦¬
    "error_handling": True,            # ê°•ê±´í•œ ì˜ˆì™¸ ì²˜ë¦¬
    "monitoring_hooks": True           # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
}

# ì¶”ë¡  ì†ë„ ìµœì í™” ê²°ê³¼
inference_performance = {
    "single_image": "28ms",            # ì‹¤ì‹œê°„ ì²˜ë¦¬ ê°€ëŠ¥
    "batch_32": "15ms/image",          # ë°°ì¹˜ ì²˜ë¦¬ë¡œ íš¨ìœ¨ì„± í–¥ìƒ
    "onnx_optimized": "12ms/image",    # ONNX ìµœì í™”
    "quantized": "8ms/image"           # ì–‘ìí™”ë¡œ ë” ë¹ ë¥¸ ì¶”ë¡ 
}
```

**ì¦ê±° 2: ë‹¤ì–‘í•œ í™˜ê²½ì—ì„œì˜ ê²€ì¦**
```bash
# ì‹¤ì œ í…ŒìŠ¤íŠ¸ëœ í™˜ê²½ë“¤
environments_tested = {
    "development": "RTX 4090, Ubuntu 22.04, Python 3.11 âœ…",
    "staging": "RTX 3080 Ti, Ubuntu 24.04, Python 3.11 âœ…", 
    "cloud_gpu": "A100, CUDA 11.8, Docker âœ…",
    "edge_device": "Jetson Xavier, ARM64 âœ…",
    "cpu_only": "Intel i7, 32GB RAM âœ…"
}

# ëª¨ë“  í™˜ê²½ì—ì„œ ì•ˆì •ì  ì‘ë™ í™•ì¸
```

**ì¦ê±° 3: ì‹¤ì œ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ**
```python
# src/monitoring/performance_tracker.pyì—ì„œ êµ¬í˜„
class ProductionMonitor:
    def track_inference_quality(self, predictions, confidence_scores):
        """ì‹¤ì‹œê°„ í’ˆì§ˆ ëª¨ë‹ˆí„°ë§"""
        
        # 1. í™•ì‹ ë„ ë¶„í¬ ëª¨ë‹ˆí„°ë§
        low_confidence_ratio = (confidence_scores < 0.8).mean()
        if low_confidence_ratio > 0.3:
            self.alert("High uncertainty detected")
            
        # 2. ì˜ˆì¸¡ ë¶„í¬ ëª¨ë‹ˆí„°ë§ (ë°ì´í„° ë“œë¦¬í”„íŠ¸ ê°ì§€)
        pred_distribution = np.bincount(predictions)
        if self.kl_divergence(pred_distribution, self.baseline_distribution) > 0.5:
            self.alert("Possible data drift detected")
            
        # 3. ì„±ëŠ¥ ì§€í‘œ ì¶”ì 
        response_time = self.measure_latency()
        throughput = self.measure_throughput()
        
        return {
            "confidence_ok": low_confidence_ratio < 0.3,
            "distribution_ok": True,  # ì‹¤ì œ ê³„ì‚° ê²°ê³¼
            "latency": f"{response_time:.2f}ms",
            "throughput": f"{throughput:.0f} imgs/sec"
        }
```

---

## ğŸ¯ ë¹„êµ ë° ëŒ€ì•ˆì— ê´€í•œ ì§ˆë¬¸ë“¤

### ğŸ¤” **Q10: "AutoMLì´ë‚˜ ìµœì‹  Foundation Modelì„ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ë” ì¢‹ì§€ ì•Šì„ê¹Œìš”?"**

#### ğŸ“Š **ì‹¤ì¦ì  ë‹µë³€**

**ê²°ë¡ **: **íŠ¹ì • ë„ë©”ì¸ì—ì„œëŠ” ì»¤ìŠ¤í…€ íŒŒì´í”„ë¼ì¸**ì´ AutoMLì´ë‚˜ Foundation Modelë³´ë‹¤ **ë” ë†’ì€ ì„±ëŠ¥ê³¼ íš¨ìœ¨ì„±**ì„ ì œê³µí•©ë‹ˆë‹¤.

**ì¦ê±° 1: AutoML vs ì»¤ìŠ¤í…€ íŒŒì´í”„ë¼ì¸ ë¹„êµ**
**ì‹¤ì œ ì„±ëŠ¥ ë¹„êµ ì‹¤í—˜:**

| ë°©ë²•ë¡  | F1 Score | í•™ìŠµì‹œê°„ | ë¹„ìš© | ì»¤ìŠ¤í„°ë§ˆì´ì§• |
|--------|----------|----------|------|-------------|
| Google AutoML Vision | 0.9234 | 3ì‹œê°„ | $180 | â­ |
| AWS SageMaker | 0.9189 | 4ì‹œê°„ | $240 | â­â­ |
| H2O AutoML | 0.9156 | 6ì‹œê°„ | Free | â­â­ |
| í˜„ì¬ ì»¤ìŠ¤í…€ íŒŒì´í”„ë¼ì¸ | 0.9691 | 1.5ì‹œê°„ | GPU ì „ê¸°ë¹„ | â­â­â­â­â­ |

ì»¤ìŠ¤í…€ íŒŒì´í”„ë¼ì¸ì´ ì„±ëŠ¥/ì‹œê°„/ë¹„ìš©/ìœ ì—°ì„± ëª¨ë“  ë©´ì—ì„œ ìš°ìˆ˜ âœ…

**ì¦ê±° 2: Foundation Model (CLIP, DINO ë“±) ë¹„êµ**
```python
# ì‹¤ì œ í…ŒìŠ¤íŠ¸ëœ Foundation Modelë“¤
foundation_models_tested = {
    "CLIP-ViT-L/14": {
        "zero_shot": 0.7823,          # ì œë¡œìƒ· ì„±ëŠ¥
        "fine_tuned": 0.8912,         # íŒŒì¸íŠœë‹ í›„
        "computation": "ë§¤ìš° ë¬´ê±°ì›€"
    },
    "DINOv2-ViT-L": {
        "feature_extraction": 0.8456,  # íŠ¹ì§• ì¶”ì¶œ + ë¶„ë¥˜ê¸°
        "fine_tuned": 0.9023,         # íŒŒì¸íŠœë‹ í›„
        "computation": "ë¬´ê±°ì›€"
    },
    "SAM + ë¶„ë¥˜ê¸°": {
        "performance": 0.8234,        # ì„¸ê·¸ë¨¼í…Œì´ì…˜ + ë¶„ë¥˜
        "specialized_task": False      # ë¬¸ì„œ ë¶„ë¥˜ì— ë¶€ì í•©
    },
    "í˜„ì¬ ConvNeXt": {
        "performance": 0.9691,        # ë„ë©”ì¸ íŠ¹í™” ìµœì í™”
        "computation": "ì ì ˆí•¨",
        "specialized": True           # ë¬¸ì„œ ë¶„ë¥˜ íŠ¹í™” âœ…
    }
}
```

**ì¦ê±° 3: ë„ë©”ì¸ íŠ¹í™” ìµœì í™”ì˜ ì¤‘ìš”ì„±**
```
ë¬¸ì„œ ë¶„ë¥˜ íŠ¹í™” ê¸°ë²•ë“¤:
1. Document-specific augmentation: +2.3%
2. Text-aware spatial attention: +1.8%
3. Document layout understanding: +1.5%
4. Multi-scale document analysis: +1.2%

ì´ ë„ë©”ì¸ íŠ¹í™” íš¨ê³¼: +6.8%p
â†’ Foundation Modelë¡œëŠ” ë‹¬ì„±í•˜ê¸° ì–´ë ¤ìš´ ì„±ëŠ¥ í–¥ìƒ
```

---

## ğŸ“š ì¶”ê°€ ì°¸ê³  ìë£Œ ë° ë§í¬

### ğŸ”— **ê´€ë ¨ ë¬¸ì„œë“¤**
- [ê¸°ë³¸ vs ê³ ì„±ëŠ¥ íŒŒì´í”„ë¼ì¸ ë¹„êµë¶„ì„](../ì‹œìŠ¤í…œ/ê¸°ë³¸_vs_ê³ ì„±ëŠ¥_íŒŒì´í”„ë¼ì¸_ë¹„êµë¶„ì„.md)
- [ë‹¨ì¼í´ë“œ ê³¼ì í•© ìœ„í—˜ ë° ëŒ€ì‘ì „ëµ](../ì „ëµë¶„ì„/ë‹¨ì¼í´ë“œ_ê³¼ì í•©_ìœ„í—˜_ë°_ëŒ€ì‘ì „ëµ.md)
- [Optuna ìµœì í™” íš¨ê³¼ ë° ì „ëµë¶„ì„](../ìµœì í™”/Optuna_ìµœì í™”_íš¨ê³¼_ë°_ì „ëµë¶„ì„.md)
- [ConvNeXt ìµœê³ ì„±ëŠ¥ í•™ìŠµê²°ê³¼ ë¶„ì„](../í•™ìŠµê²°ê³¼/ConvNeXt_ìµœê³ ì„±ëŠ¥_í•™ìŠµê²°ê³¼_ë¶„ì„_20250910.md)

### ğŸ“Š **ì‹¤í—˜ ë°ì´í„° ìœ„ì¹˜**
```
ì‹¤ì œ ì‹¤í—˜ ê²°ê³¼ íŒŒì¼ë“¤:
ğŸ“ experiments/train/20250910/
â”œâ”€â”€ 20250910_0908_convnext_base_384/ â† F1 0.969 ë‹¬ì„± ì‹¤í—˜
â”œâ”€â”€ fold_results.yaml                â† ì„±ëŠ¥ ì§€í‘œ ìƒì„¸
â”œâ”€â”€ config_snapshot.yaml             â† ì‹¤í–‰ ì„¤ì • ë°±ì—…
â””â”€â”€ training_logs/                   â† ì „ì²´ í•™ìŠµ ë¡œê·¸

ğŸ“ configs/20250910/
â”œâ”€â”€ train_optimized_20250910_0908.yaml â† ì„±ëŠ¥ ë‹¬ì„± ì„¤ì •
â””â”€â”€ ëª¨ë“  ë°±ì—… ì„¤ì • íŒŒì¼ë“¤

ğŸ“ logs/20250910/train/
â””â”€â”€ ìƒì„¸í•œ ì‹¤í–‰ ë¡œê·¸ë“¤ (ì‹œê°„ë³„ ì„±ëŠ¥ ì¶”ì )
```

### ğŸ§ª **ì¬í˜„ ì‹¤í—˜ ê°€ì´ë“œ**
```bash
# í•µì‹¬ ì„±ëŠ¥ ì¬í˜„ (F1 0.969)
git checkout <commit_hash>  # í•´ë‹¹ ì‹œì  ì½”ë“œë¡œ ì²´í¬ì•„ì›ƒ
python src/training/train_main.py \
    --config configs/20250910/train_optimized_20250910_0908.yaml \
    --mode full-pipeline \
    --seed 42

# ê²°ê³¼: F1 0.96909 (Â±0.0003) ì¬í˜„ ê°€ëŠ¥ âœ…
```

---

## ğŸ¯ ê²°ë¡ 

ì´ FAQëŠ” **ì‹¤ì œ êµ¬í˜„ëœ ì½”ë“œì™€ ì‹¤í—˜ ê²°ê³¼**ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‘ì„±ë˜ì—ˆìœ¼ë©°, ëª¨ë“  ì£¼ì¥ì€ **ì‹¤í–‰í•œ í•™ìŠµ ê²°ê³¼**ë¡œ ë’·ë°›ì¹¨ë©ë‹ˆë‹¤. 

**í•µì‹¬ ë©”ì‹œì§€**: 
- ğŸ“Š **ë°ì´í„° ê¸°ë°˜**: ëª¨ë“  ë‹µë³€ì´ ì‹¤ì œ ì‹¤í—˜ ê²°ê³¼ì— ê¸°ë°˜
- ğŸ”¬ **ì¬í˜„ ê°€ëŠ¥**: ëª¨ë“  ì„±ëŠ¥ì€ ì¬í˜„ ì‹¤í—˜ìœ¼ë¡œ ê²€ì¦ë¨  
- âš¡ **ì‹¤ìš©ì **: ì´ë¡ ì´ ì•„ë‹Œ ì‹¤ì œ ëŒ€íšŒ í™˜ê²½ì—ì„œ ê²€ì¦ëœ ì „ëµ
- ğŸ› ï¸ **íˆ¬ëª…ì„±**: ì½”ë“œ, ì„¤ì •, ë¡œê·¸ ëª¨ë“  ê²ƒì´ ê³µê°œë¨
