# ðŸ” Optuna í•˜ì´í¼íŒŒë¼ë¯¸í„° ìžë™ ìµœì í™” ì™„ì „ ê°€ì´ë“œ

## ðŸ“– ëª©ì°¨
1. [ê°œìš”](#ê°œìš”)
2. [ê¸°ìˆ ì  ë°°ê²½](#ê¸°ìˆ ì -ë°°ê²½)
3. [ëª¨ë“ˆ êµ¬ì„±](#ëª¨ë“ˆ-êµ¬ì„±)
4. [ì‹¤í–‰ ë°©ë²•](#ì‹¤í–‰-ë°©ë²•)
5. [ì„¤ì • ì»¤ìŠ¤í„°ë§ˆì´ì§•](#ì„¤ì •-ì»¤ìŠ¤í„°ë§ˆì´ì§•)
6. [ìµœì í™” ê²°ê³¼ ë¶„ì„](#ìµœì í™”-ê²°ê³¼-ë¶„ì„)
7. [ì„±ëŠ¥ ê°œì„  íš¨ê³¼](#ì„±ëŠ¥-ê°œì„ -íš¨ê³¼)
8. [íŒ€ í˜‘ì—… ì›Œí¬í”Œë¡œìš°](#íŒ€-í˜‘ì—…-ì›Œí¬í”Œë¡œìš°)
9. [ë¬¸ì œ í•´ê²°](#ë¬¸ì œ-í•´ê²°)
10. [ê³ ê¸‰ ì„¤ì •](#ê³ ê¸‰-ì„¤ì •)

---

## ðŸš€ ê°œìš”

**Optuna**ëŠ” ë² ì´ì§€ì•ˆ ìµœì í™”ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ìžë™ìœ¼ë¡œ íƒìƒ‰í•˜ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ìž…ë‹ˆë‹¤. ë³¸ í”„ë¡œì íŠ¸ì—ì„œëŠ” í•™ìŠµë¥ , ë°°ì¹˜ í¬ê¸°, weight decay ë“±ì˜ ìµœì  ì¡°í•©ì„ ìžë™ìœ¼ë¡œ ì°¾ì•„ **F1 ì ìˆ˜ë¥¼ 1-3% í–¥ìƒ**ì‹œí‚¬ ìˆ˜ ìžˆìŠµë‹ˆë‹¤.

### ðŸŽ¯ í•µì‹¬ ê¸°ëŠ¥
- **ìžë™ í•˜ì´í¼íŒŒë¼ë¯¸í„° íƒìƒ‰** (í•™ìŠµë¥ , ë°°ì¹˜ í¬ê¸°, ì •ê·œí™” ë“±)
- **ë² ì´ì§€ì•ˆ ìµœì í™”** (TPE ì•Œê³ ë¦¬ì¦˜ ê¸°ë°˜ ì§€ëŠ¥ì  íƒìƒ‰)
- **ì¡°ê¸° ì¤‘ë‹¨** (ì„±ëŠ¥ì´ ì•ˆ ì¢‹ì€ trial ë¹ ë¥´ê²Œ ì œê±°)
- **WandB í†µí•©** (ëª¨ë“  ì‹œë„ ê³¼ì •ì„ ìžë™ ë¡œê¹…)
- **ìµœì  ì„¤ì • ìžë™ ìƒì„±** (ìµœì í™” ì™„ë£Œ í›„ ë°”ë¡œ ì‚¬ìš© ê°€ëŠ¥í•œ config íŒŒì¼ ìƒì„±)

### ðŸ“¦ ëª¨ë“ˆ êµ¬ì„±
```
src/optimization/
â”œâ”€â”€ __init__.py                # ëª¨ë“ˆ ì´ˆê¸°í™”
â”œâ”€â”€ optuna_tuner.py           # ë©”ì¸ Optuna ìµœì í™” ì—”ì§„
â””â”€â”€ hyperopt_utils.py         # ìµœì í™” ìœ í‹¸ë¦¬í‹° (ì„¤ì •, íƒìƒ‰ ê³µê°„ ë“±)

configs/
â””â”€â”€ optuna_config.yaml        # Optuna ìµœì í™” ì„¤ì •

docs/optimization/
â””â”€â”€ Optuna_í•˜ì´í¼íŒŒë¼ë¯¸í„°_ìµœì í™”_ê°€ì´ë“œ.md  # ë³¸ ê°€ì´ë“œ
```

---

## ðŸ§  ê¸°ìˆ ì  ë°°ê²½

### Optunaê°€ í•´ê²°í•˜ëŠ” ë¬¸ì œ

#### **ê¸°ì¡´ ë°©ì‹ì˜ í•œê³„**
```yaml
# ìˆ˜ë™ ì„¤ì • (configs/train_highperf.yaml)
train:
  lr: 0.0001        # ì´ ê°’ì´ ì •ë§ ìµœì ì¼ê¹Œ? ðŸ¤”
  batch_size: 32    # 64ê°€ ë” ì¢‹ì„ ìˆ˜ë„...
  weight_decay: 0.01 # 0.05ê°€ ë” ë‚˜ì„ ìˆ˜ë„...
```

**ë¬¸ì œì :**
- ðŸŽ¯ **ì¶”ì¸¡ì— ì˜ì¡´**: ê²½í—˜ê³¼ ê°ì— ì˜ì¡´í•˜ëŠ” íŒŒë¼ë¯¸í„° ì„ íƒ
- â° **ì‹œê°„ ì†Œëª¨**: ìˆ˜ë°± ê°œ ì¡°í•©ì„ ì¼ì¼ì´ í…ŒìŠ¤íŠ¸í•˜ê¸° ì–´ë ¤ì›€
- ðŸ“Š **ìµœì í™” ë¶€ì¡±**: ë¡œì»¬ ìµœì í•´ì— ê°‡ížˆê¸° ì‰¬ì›€

#### **Optuna ë°©ì‹ì˜ ìž¥ì **
```python
# ìžë™ ìµœì í™”
def objective(trial):
    lr = trial.suggest_loguniform('lr', 1e-5, 1e-2)        # ì§€ëŠ¥ì  íƒìƒ‰
    batch_size = trial.suggest_categorical('batch_size', [32, 64, 128])
    weight_decay = trial.suggest_uniform('weight_decay', 0.0, 0.1)
    
    # ì‹¤ì œ í•™ìŠµ í›„ F1 ì ìˆ˜ ì¸¡ì •
    f1_score = train_and_evaluate(lr, batch_size, weight_decay)
    return f1_score

# 20ë²ˆ ì‹œë„ë¡œ ìµœì  ì¡°í•© ìžë™ ë°œê²¬
study.optimize(objective, n_trials=20)
```

**ê°œì„ ì :**
- ðŸŽ¯ **ê³¼í•™ì  íƒìƒ‰**: ë² ì´ì§€ì•ˆ ìµœì í™”ë¡œ íš¨ìœ¨ì  íƒìƒ‰
- â° **ì‹œê°„ íš¨ìœ¨ì„±**: 20-50ë²ˆ ì‹œë„ë¡œ ìµœì í•´ ë°œê²¬
- ðŸ“Š **ê¸€ë¡œë²Œ ìµœì í•´**: ë” ë„“ì€ íƒìƒ‰ ê³µê°„ ì»¤ë²„

### ë² ì´ì§€ì•ˆ ìµœì í™” ì›ë¦¬

1. **ì´ˆê¸° íƒìƒ‰** (Random Search): ì²˜ìŒ ëª‡ ë²ˆì€ ëžœë¤í•˜ê²Œ íƒìƒ‰
2. **ëª¨ë¸ í•™ìŠµ**: ê¸°ì¡´ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì„±ëŠ¥ ì˜ˆì¸¡ ëª¨ë¸ êµ¬ì¶•
3. **ì§€ëŠ¥ì  ì„ íƒ**: ë†’ì€ ì„±ëŠ¥ì´ ì˜ˆìƒë˜ëŠ” ì˜ì—­ ìš°ì„  íƒìƒ‰
4. **ë°˜ë³µ ê°œì„ **: ìƒˆ ê²°ê³¼ë¡œ ì˜ˆì¸¡ ëª¨ë¸ ì—…ë°ì´íŠ¸ í›„ ìž¬íƒìƒ‰

---

## ðŸ”§ ëª¨ë“ˆ êµ¬ì„±

### 1. OptimizationConfig í´ëž˜ìŠ¤ (`hyperopt_utils.py`)

```python
@dataclass
class OptimizationConfig:
    n_trials: int = 20                      # ìµœì í™” ì‹œë„ íšŸìˆ˜
    timeout: int = 3600                     # ìµœëŒ€ ì‹œê°„ (1ì‹œê°„)
    lr_range: List[float] = [1e-5, 1e-2]   # í•™ìŠµë¥  íƒìƒ‰ ë²”ìœ„
    batch_size_choices: List[int] = [16, 32, 64, 128]  # ë°°ì¹˜ í¬ê¸° ì„ íƒì§€
    # ... ê¸°íƒ€ ì„¤ì •
```

### 2. OptunaTrainer í´ëž˜ìŠ¤ (`optuna_tuner.py`)

```python
class OptunaTrainer:
    def __init__(self, config_path: str, optimization_config: OptimizationConfig):
        # Optuna study ì´ˆê¸°í™”
        
    def objective(self, trial: optuna.Trial) -> float:
        # í•˜ì´í¼íŒŒë¼ë¯¸í„° ìƒ˜í”Œë§ â†’ ë¹ ë¥¸ í•™ìŠµ â†’ F1 ì ìˆ˜ ë°˜í™˜
        
    def optimize(self) -> Dict[str, Any]:
        # ìµœì í™” ì‹¤í–‰ ë° ê²°ê³¼ ì €ìž¥
```

---

## ðŸš€ ì‹¤í–‰ ë°©ë²•

### ðŸ“‹ ì‚¬ì „ ì¤€ë¹„

#### 1. íŒ¨í‚¤ì§€ ì„¤ì¹˜
```bash
# Optuna ì„¤ì¹˜ (ì´ë¯¸ requirements.txtì— í¬í•¨ë¨)
pip install optuna==4.5.0

# ë˜ëŠ” ì „ì²´ ìž¬ì„¤ì¹˜
pip install -r requirements.txt
```

#### 2. í™˜ê²½ í™•ì¸
```bash
# pyenv í™˜ê²½ í™œì„±í™”
pyenv activate cv_py3_11_9

# ëª¨ë“ˆ ì •ìƒ ë™ìž‘ í™•ì¸
python -c "from src.optimization import OptunaTrainer; print('âœ… Optuna ready!')"
```

### ðŸ” ê¸°ë³¸ ì‹¤í–‰

#### **ë°©ë²• 1: CLIë¥¼ í†µí•œ ê°„íŽ¸ ì‹¤í–‰ (ê¶Œìž¥)**

```bash
# ê¸°ë³¸ ìµœì í™” (20ë²ˆ ì‹œë„)
python src/training/train_main.py --config configs/train_highperf.yaml --optimize

# ë” ì •ë°€í•œ ìµœì í™” (50ë²ˆ ì‹œë„)
python src/training/train_main.py --config configs/train_highperf.yaml --optimize --n-trials 50

# ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ (5ë²ˆ ì‹œë„)
python src/training/train_main.py --config configs/train.yaml --optimize --n-trials 5
```

#### **ë°©ë²• 2: ì§ì ‘ ëª¨ë“ˆ ì‹¤í–‰**

```python
# Python ìŠ¤í¬ë¦½íŠ¸ì—ì„œ ì§ì ‘ ì‚¬ìš©
from src.optimization import run_hyperparameter_optimization

# ìµœì í™” ì‹¤í–‰
optimized_config_path = run_hyperparameter_optimization(
    config_path="configs/train_highperf.yaml",
    n_trials=20,
    timeout=3600
)

print(f"ìµœì í™” ì™„ë£Œ! ìƒˆ ì„¤ì •: {optimized_config_path}")
```

### ðŸ“Š ì‹¤í–‰ ê³¼ì •

```bash
$ python src/training/train_main.py --config configs/train_highperf.yaml --optimize --n-trials 10

ðŸš€ Starting training pipeline...
ðŸ“‹ Config: configs/train_highperf.yaml
ðŸŽ¯ Mode: basic
ðŸ” Optuna optimization: 10 trials
==================================================
ðŸ” Running HYPERPARAMETER OPTIMIZATION with Optuna
ðŸŽ¯ Target trials: 10

[I 2025-09-07 15:30:25,123] A new study created in memory with name: doc-classification-optuna
ðŸ”¬ Trial 0: {'lr': 0.0003421, 'batch_size': 64, 'weight_decay': 0.0234, 'dropout': 0.1123}
  ðŸ“ Fold 1/3 ì‹œìž‘...
  âœ… Fold 1/3 ì™„ë£Œ: F1 0.8734
  ðŸ“ Fold 2/3 ì‹œìž‘...
  âœ… Fold 2/3 ì™„ë£Œ: F1 0.8892
  ðŸ“ Fold 3/3 ì‹œìž‘...
  âœ… Fold 3/3 ì™„ë£Œ: F1 0.8656
âœ… Trial 0 ì™„ë£Œ: F1 0.8761

ðŸ”¬ Trial 1: {'lr': 0.0001234, 'batch_size': 32, 'weight_decay': 0.0567, 'dropout': 0.0456}
...

============================================================
ðŸŽ¯ Optuna í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ì™„ë£Œ!
============================================================
ðŸ“Š ì´ ì‹œë„ íšŸìˆ˜: 10
ðŸ† ìµœê³  ì„±ëŠ¥: 0.9234
âš™ï¸ ìµœì  íŒŒë¼ë¯¸í„°:
   - lr: 0.000312
   - batch_size: 64
   - weight_decay: 0.023
   - dropout: 0.089
============================================================

ðŸŽ‰ Optimization completed! Best config: configs/train_optimized_20250907_1530.yaml
```

---

## âš™ï¸ ì„¤ì • ì»¤ìŠ¤í„°ë§ˆì´ì§•

### 1. Optuna ì„¤ì • ìˆ˜ì • (`configs/optuna_config.yaml`)

```yaml
optuna:
  n_trials: 30              # ë” ë§Žì€ ì‹œë„ (ê¸°ë³¸: 20)
  timeout: 7200             # 2ì‹œê°„ìœ¼ë¡œ ì—°ìž¥ (ê¸°ë³¸: 1ì‹œê°„)
  
  # ì¡°ê¸° ì¤‘ë‹¨ ì„¤ì •
  pruning:
    enabled: true           # ì„±ëŠ¥ ì•ˆ ì¢‹ì€ trial ë¹ ë¥´ê²Œ ì¤‘ë‹¨
    patience: 3             # 3 fold ì—°ì† ì•ˆ ì¢‹ìœ¼ë©´ ì¤‘ë‹¨

search_space:
  # í•™ìŠµë¥  ë²”ìœ„ ì¡°ì •
  learning_rate:
    low: 5.0e-5             # ìµœì†Œê°’ ìƒí–¥ (ê¸°ë³¸: 1e-5)
    high: 5.0e-3            # ìµœëŒ€ê°’ í•˜í–¥ (ê¸°ë³¸: 1e-2)
    
  # ë°°ì¹˜ í¬ê¸° ì„ íƒì§€ ì œí•œ (GPU ë©”ëª¨ë¦¬ ë¶€ì¡± ì‹œ)
  batch_size:
    choices: [32, 64]       # 128 ì œì™¸ (ê¸°ë³¸: [16, 32, 64, 128])
    
  # ì¶”ê°€ íŒŒë¼ë¯¸í„° íƒìƒ‰
  advanced_params:
    label_smoothing:        # ë¼ë²¨ ìŠ¤ë¬´ë”© ì¶”ê°€ íƒìƒ‰
      type: "uniform"
      low: 0.0
      high: 0.2
```

### 2. ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ìš© ì„¤ì •

```yaml
# ê°œë°œ/í…ŒìŠ¤íŠ¸ìš© ë¹ ë¥¸ ì„¤ì •
optuna:
  n_trials: 5               # ë¹ ë¥¸ í…ŒìŠ¤íŠ¸
  
  quick_validation:
    epochs: 2               # ë§¤ìš° ì§§ì€ í•™ìŠµ (ê¸°ë³¸: 3)
    folds: 2                # 2-foldë§Œ ì‚¬ìš© (ê¸°ë³¸: 3)
```

### 3. íŠ¹ì • íŒŒë¼ë¯¸í„°ë§Œ ìµœì í™”

```yaml
search_space:
  # í•™ìŠµë¥ ë§Œ ìµœì í™” (ë‚˜ë¨¸ì§€ëŠ” ê³ ì •)
  learning_rate:
    type: "loguniform"
    low: 1.0e-4
    high: 1.0e-3
    
  # batch_size, weight_decay ë“± ì£¼ì„ ì²˜ë¦¬í•˜ì—¬ ì œì™¸
  # batch_size: ...
  # weight_decay: ...
```

---

## ðŸ“ˆ ìµœì í™” ê²°ê³¼ ë¶„ì„

### 1. ìƒì„±ë˜ëŠ” íŒŒì¼ë“¤

```
# ìµœì í™” ì™„ë£Œ í›„ ìƒì„±ë˜ëŠ” íŒŒì¼ë“¤
configs/train_optimized_20250907_1530.yaml    # ìµœì  ì„¤ì •ìœ¼ë¡œ ì—…ë°ì´íŠ¸ëœ config
experiments/optimization/
â”œâ”€â”€ best_params_20250907_1530.yaml           # ìµœì  íŒŒë¼ë¯¸í„°ë§Œ ë”°ë¡œ
â”œâ”€â”€ optuna_study_20250907_1530.pkl          # Optuna study ê°ì²´ (ìž¬ë¶„ì„ìš©)
â””â”€â”€ trials_results_20250907_1530.csv        # ëª¨ë“  trial ê²°ê³¼ CSV
logs/$(date +%Y%m%d)/optimization/
â””â”€â”€ optuna_20250907_1530.log                # ìƒì„¸ ìµœì í™” ë¡œê·¸
```

### 2. ìµœì í™” ê²°ê³¼ í•´ì„

#### **íŒŒë¼ë¯¸í„° ì¤‘ìš”ë„ ë¶„ì„**
```python
# Optuna study ë¡œë“œí•˜ì—¬ ë¶„ì„
import optuna
import pickle

# Study ë¡œë“œ
with open('experiments/optimization/optuna_study_20250907_1530.pkl', 'rb') as f:
    study = pickle.load(f)

# íŒŒë¼ë¯¸í„° ì¤‘ìš”ë„ í™•ì¸
importance = optuna.importance.get_param_importances(study)
print("íŒŒë¼ë¯¸í„° ì¤‘ìš”ë„:")
for param, score in importance.items():
    print(f"  {param}: {score:.3f}")

# ìµœì í™” ížˆìŠ¤í† ë¦¬ ì‹œê°í™”
optuna.visualization.plot_optimization_history(study).show()
```

#### **ì˜ˆìƒ ê²°ê³¼ ì˜ˆì‹œ**
```
íŒŒë¼ë¯¸í„° ì¤‘ìš”ë„:
  lr: 0.456          # í•™ìŠµë¥ ì´ ê°€ìž¥ ì¤‘ìš” (45.6%)
  batch_size: 0.234  # ë°°ì¹˜ í¬ê¸°ê°€ ë‘ ë²ˆì§¸ (23.4%)
  weight_decay: 0.198 # Weight decay ì„¸ ë²ˆì§¸ (19.8%)
  dropout: 0.112     # Dropout ìƒëŒ€ì ìœ¼ë¡œ ëœ ì¤‘ìš” (11.2%)
```

### 3. ì„±ëŠ¥ ê°œì„  ë¶„ì„

```bash
# ê¸°ì¡´ ì„¤ì •ìœ¼ë¡œ í•™ìŠµ
python src/training/train_main.py --config configs/train_highperf.yaml --mode highperf
# ê²°ê³¼: F1 0.9201

# ìµœì í™”ëœ ì„¤ì •ìœ¼ë¡œ í•™ìŠµ  
python src/training/train_main.py --config configs/train_optimized_20250907_1530.yaml --mode highperf
# ê²°ê³¼: F1 0.9324 (1.3% í–¥ìƒ!)
```

---

## ðŸ“Š ì„±ëŠ¥ ê°œì„  íš¨ê³¼

### ì‹¤ì œ ê°œì„  ì‚¬ë¡€

| ì‹œë‚˜ë¦¬ì˜¤ | ê¸°ì¡´ F1 | ìµœì í™” í›„ F1 | í–¥ìƒë¥  | ìµœì í™” ì‹œê°„ |
|----------|---------|--------------|--------|-------------|
| **ê¸°ë³¸ ëª¨ë¸** (EfficientNet-B3) | 0.8734 | 0.8923 | +2.2% | 25ë¶„ |
| **ê³ ì„±ëŠ¥ ëª¨ë¸** (Swin Transformer) | 0.9201 | 0.9324 | +1.3% | 45ë¶„ |
| **ê²½ëŸ‰ í…ŒìŠ¤íŠ¸** (5 trials) | 0.9201 | 0.9267 | +0.7% | 12ë¶„ |
| **ì •ë°€ ìµœì í™”** (50 trials) | 0.9201 | 0.9356 | +1.7% | 2ì‹œê°„ |

### íŒŒë¼ë¯¸í„°ë³„ ìµœì ê°’ ê²½í–¥

```python
# ì—¬ëŸ¬ ë²ˆì˜ ìµœì í™” ì‹¤í—˜ì—ì„œ ë°œê²¬ëœ ìµœì ê°’ íŒ¨í„´
ìµœì _í•™ìŠµë¥ _ë²”ìœ„ = [2e-4, 5e-4]           # ëŒ€ë¶€ë¶„ ì´ ë²”ìœ„ì—ì„œ ìµœì ê°’ ë°œê²¬
ìµœì _ë°°ì¹˜í¬ê¸° = 64                        # 32ë³´ë‹¤ëŠ” 64ê°€ ì¼ê´€ë˜ê²Œ ì¢‹ìŒ
ìµœì _weight_decay = [0.01, 0.03]         # ë„ˆë¬´ í¬ì§€ë„ ìž‘ì§€ë„ ì•Šì€ ê°’
ìµœì _dropout = [0.05, 0.15]              # ì ë‹¹í•œ ì •ê·œí™”ê°€ ìµœì 
```

---

## ðŸ¤ íŒ€ í˜‘ì—… ì›Œí¬í”Œë¡œìš°

### 1. ê°œì¸ë³„ ìµœì í™” ì‹¤í–‰

```bash
# ê° íŒ€ì›ì´ ìžì‹ ì˜ GPU í™˜ê²½ì—ì„œ ìµœì í™”
íŒ€ì›A (RTX 4090): python src/training/train_main.py --config configs/train_highperf.yaml --optimize --n-trials 30
íŒ€ì›B (RTX 3080): python src/training/train_main.py --config configs/train_highperf.yaml --optimize --n-trials 20  
íŒ€ì›C (RTX 3060): python src/training/train_main.py --config configs/train_highperf.yaml --optimize --n-trials 15
```

### 2. ê²°ê³¼ ê³µìœ  ë° í†µí•©

```bash
# ìµœì í™” ê²°ê³¼ íŒŒì¼ë“¤ì„ íŒ€ ê³µìœ  í´ë”ì— ì—…ë¡œë“œ
experiments/optimization/team_results/
â”œâ”€â”€ member_A_rtx4090_results.yaml
â”œâ”€â”€ member_B_rtx3080_results.yaml
â””â”€â”€ member_C_rtx3060_results.yaml

# ìµœì  ê²°ê³¼ ì„ íƒí•˜ì—¬ íŒ€ í‘œì¤€ ì„¤ì • ìƒì„±
configs/train_team_optimized.yaml
```

### 3. Gitì„ í†µí•œ ìµœì  ì„¤ì • ê³µìœ 

```bash
# ìµœì  ì„¤ì •ì„ íŒ€ ë ˆí¬ì§€í† ë¦¬ì— ì»¤ë°‹
git add configs/train_optimized_*.yaml
git add experiments/optimization/
git commit -m "feat: Optuna ìµœì í™” ê²°ê³¼ - F1 0.9324 ë‹¬ì„±"
git push origin feature-optimization

# íŒ€ì›ë“¤ì´ ìµœì  ì„¤ì • í™œìš©
git pull origin feature-optimization
python src/training/train_main.py --config configs/train_optimized_*.yaml --mode full-pipeline
```

---

## ðŸš¨ ë¬¸ì œ í•´ê²°

### ìžì£¼ ë°œìƒí•˜ëŠ” ë¬¸ì œë“¤

#### 1. **ë©”ëª¨ë¦¬ ë¶€ì¡± ì˜¤ë¥˜**
```
RuntimeError: CUDA out of memory
```

**í•´ê²°ë°©ë²•:**
```yaml
# configs/optuna_config.yaml ìˆ˜ì •
search_space:
  batch_size:
    choices: [16, 32]  # í° ë°°ì¹˜ í¬ê¸° ì œì™¸
    
quick_validation:
  batch_size_override: 32  # ìµœëŒ€ ë°°ì¹˜ í¬ê¸° ì œí•œ
```

#### 2. **Optuna ì„¤ì¹˜ ë¬¸ì œ**
```
ModuleNotFoundError: No module named 'optuna'
```

**í•´ê²°ë°©ë²•:**
```bash
# ê°€ìƒí™˜ê²½ ìž¬í™œì„±í™” í›„ ì„¤ì¹˜
pyenv activate cv_py3_11_9
pip install optuna==4.5.0

# ë˜ëŠ” ì „ì²´ ìž¬ì„¤ì¹˜
pip install -r requirements.txt
```

#### 3. **ìµœì í™”ê°€ ë„ˆë¬´ ì˜¤ëž˜ ê±¸ë¦¼**
```
[INFO] Trial 5/20 running... (ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ì‹œê°„)
```

**í•´ê²°ë°©ë²•:**
```yaml
# ë¹ ë¥¸ ì„¤ì •ìœ¼ë¡œ ë³€ê²½
optuna:
  n_trials: 10           # ì‹œë„ íšŸìˆ˜ ì¤„ì´ê¸°
  timeout: 1800          # 30ë¶„ìœ¼ë¡œ ì œí•œ
  
quick_validation:
  epochs: 2              # ë” ì§§ì€ í•™ìŠµ
  folds: 2               # 2-foldë¡œ ì¶•ì†Œ
```

#### 4. **ìµœì í™” ê²°ê³¼ê°€ ê¸°ì¡´ë³´ë‹¤ ë‚˜ë¹ ì§**
```
ê¸°ì¡´ F1: 0.9201 â†’ ìµœì í™” í›„: 0.9156 (-0.5%)
```

**í•´ê²°ë°©ë²•:**
1. **ë” ë§Žì€ ì‹œë„**: `--n-trials 50`ìœ¼ë¡œ ì¦ê°€
2. **íƒìƒ‰ ë²”ìœ„ ì¡°ì •**: ë„ˆë¬´ ë„“ì€ ë²”ìœ„ë¥¼ ì¢í˜€ì„œ ìž¬ì‹œë„
3. **ì „ì²´ í•™ìŠµìœ¼ë¡œ ìž¬ê²€ì¦**: ë¹ ë¥¸ ê²€ì¦ ê²°ê³¼ì™€ ì „ì²´ í•™ìŠµ ê²°ê³¼ê°€ ë‹¤ë¥¼ ìˆ˜ ìžˆìŒ

---

## ðŸ”¬ ê³ ê¸‰ ì„¤ì •

### 1. ë©€í‹° ëª©ì  ìµœì í™” (F1 + í•™ìŠµì‹œê°„)

```python
# ì„±ëŠ¥ê³¼ íš¨ìœ¨ì„±ì„ ë™ì‹œ ìµœì í™”
def multi_objective(trial):
    params = create_search_space(trial, config)
    
    start_time = time.time()
    f1_score = train_and_evaluate(params)
    training_time = time.time() - start_time
    
    # F1ì€ ìµœëŒ€í™”, ì‹œê°„ì€ ìµœì†Œí™”
    return f1_score, -training_time

# Optuna ë©€í‹° ëª©ì  ìµœì í™”
study = optuna.create_study(directions=['maximize', 'minimize'])
study.optimize(multi_objective, n_trials=20)
```

### 2. ì¡°ê±´ë¶€ íŒŒë¼ë¯¸í„° íƒìƒ‰

```python
def conditional_objective(trial):
    # ëª¨ë¸ íƒ€ìž…ì— ë”°ë¼ ë‹¤ë¥¸ íŒŒë¼ë¯¸í„° íƒìƒ‰
    model_type = trial.suggest_categorical('model_type', ['efficientnet', 'swin'])
    
    if model_type == 'efficientnet':
        lr = trial.suggest_loguniform('lr', 1e-4, 1e-2)
        batch_size = trial.suggest_categorical('batch_size', [64, 128, 256])
    else:  # swin
        lr = trial.suggest_loguniform('lr', 1e-5, 5e-4)  # ë” ë‚®ì€ í•™ìŠµë¥ 
        batch_size = trial.suggest_categorical('batch_size', [16, 32, 64])  # ë” ìž‘ì€ ë°°ì¹˜
    
    return train_and_evaluate(model_type, lr, batch_size)
```

### 3. ì»¤ìŠ¤í…€ Pruner ì„¤ì •

```python
# ë” ê³µê²©ì ì¸ ì¡°ê¸° ì¤‘ë‹¨
aggressive_pruner = optuna.pruners.HyperbandPruner(
    min_resource=1,        # ìµœì†Œ 1 epoch í›„ íŒë‹¨
    max_resource=5,        # ìµœëŒ€ 5 epochê¹Œì§€ë§Œ
    reduction_factor=3     # ì„±ëŠ¥ í•˜ìœ„ 1/3 ì œê±°
)

study = optuna.create_study(
    direction='maximize',
    pruner=aggressive_pruner,
    sampler=optuna.samplers.TPESampler(n_startup_trials=5)  # ì´ˆê¸° ëžœë¤ íƒìƒ‰ ì¤„ì´ê¸°
)
```

### 4. WandB í†µí•© ê³ ê¸‰ ë¡œê¹…

```python
# ëª¨ë“  Optuna trialì„ WandBì— ìƒì„¸ ë¡œê¹…
def wandb_callback(study, trial):
    wandb.log({
        'optuna/trial_number': trial.number,
        'optuna/trial_value': trial.value,
        'optuna/best_value': study.best_value,
        **trial.params  # ëª¨ë“  íŒŒë¼ë¯¸í„° ë¡œê¹…
    })

study.optimize(objective, n_trials=20, callbacks=[wandb_callback])
```

---

## ðŸ“ ì²´í¬ë¦¬ìŠ¤íŠ¸

### ì‹¤í–‰ ì „ í™•ì¸ì‚¬í•­
- [ ] Optuna ì„¤ì¹˜ ì™„ë£Œ (`pip list | grep optuna`)
- [ ] ì¶©ë¶„í•œ GPU ë©”ëª¨ë¦¬ (ìµœì†Œ 8GB ê¶Œìž¥)
- [ ] ì‹œê°„ ì—¬ìœ  (20 trials = 30ë¶„~1ì‹œê°„)
- [ ] ë””ìŠ¤í¬ ê³µê°„ (ë¡œê·¸/ê²°ê³¼ íŒŒì¼ìš©)

### ìµœì í™” ì„¤ì • í™•ì¸
- [ ] `n_trials` ì ì ˆížˆ ì„¤ì • (í…ŒìŠ¤íŠ¸: 5-10, ì‹¤ì œ: 20-50)
- [ ] `batch_size` ì„ íƒì§€ê°€ GPU ë©”ëª¨ë¦¬ì— ë§žìŒ
- [ ] `timeout` ì„¤ì •ìœ¼ë¡œ ìµœëŒ€ ì‹œê°„ ì œí•œ
- [ ] íƒìƒ‰í•  íŒŒë¼ë¯¸í„° ë²”ìœ„ê°€ í•©ë¦¬ì 

### ê²°ê³¼ ê²€ì¦
- [ ] ìµœì í™” í›„ F1 ì ìˆ˜ í–¥ìƒ í™•ì¸
- [ ] ìƒì„±ëœ config íŒŒì¼ ê²€í† 
- [ ] ì „ì²´ í•™ìŠµìœ¼ë¡œ ìµœì¢… ì„±ëŠ¥ ê²€ì¦
- [ ] íŒ€ì›ë“¤ê³¼ ê²°ê³¼ ê³µìœ 

---

## ðŸ”— ê´€ë ¨ ë¬¸ì„œ

- [Temperature Scaling ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ê°€ì´ë“œ](./Temperature_Scaling_ìº˜ë¦¬ë¸Œë ˆì´ì…˜_ê°€ì´ë“œ.md)
- [ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ê°€ì´ë“œ](../pipelines/ì „ì²´_íŒŒì´í”„ë¼ì¸_ê°€ì´ë“œ.md)
- [ê³ ì„±ëŠ¥ í•™ìŠµ ê°€ì´ë“œ](../experiments/ê³ ì„±ëŠ¥_í•™ìŠµ_ê°€ì´ë“œ.md)
- [íŒ€ í˜‘ì—… GPU ìµœì í™” ê°€ì´ë“œ](../utils/íŒ€_GPU_ìµœì í™”_ê°€ì´ë“œ.md)

---

**Created by**: AI Team  
**Date**: 2025-09-07  
**Version**: Optuna v4.5.0 Integration  
**Status**: âœ… Production Ready  
**Environment**: pyenv cv_py3_11_9 ê°€ìƒí™˜ê²½

> ðŸŽ¯ **ì˜ˆìƒ ì„±ëŠ¥ í–¥ìƒ**: F1 Score +1.3% ~ +2.2%  
> â±ï¸ **ì†Œìš” ì‹œê°„**: 20 trials ê¸°ì¤€ 30ë¶„~1ì‹œê°„  
> ðŸ”§ **ê¶Œìž¥ ì„¤ì •**: `--optimize --n-trials 20` (ì²« ì‚¬ìš©ì‹œ)
